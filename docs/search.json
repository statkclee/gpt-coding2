[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "챗GPT 코딩",
    "section": "",
    "text": "서문\n지난 몇 년간, 인공지능(AI)의 발전은 우리가 코드를 이해하고 데이터를 바라보는 방식을 근본적으로 바꾸어 놓았습니다. AI가 코드 초안을 작성해주고, 막혔던 질문에 길을 터주는 시대에, 어떤 역량을 갖춰야 할까요? 넘쳐나는 정보와 도구 속에서 길을 잃지 않고, 데이터로부터 진정한 가치를 만들어내는 전문가로 성장하려면 무엇을 배워야 할까요?\n많은 이들이 데이터 과학 프로젝트를 ’일회성 실험’으로 생각합니다. 데이터를 가져와 모델을 만들고, 결과를 보고하는 작업은 분명 중요합니다. 하지만 거기서 멈춘다면, 그 노력은 파편적인 코드와 지식으로만 남게 됩니다. AI에게 복잡한 작업을 맡기더라도, 그 결과가 얼마나 믿을 수 있는지, 내일 또 다른 데이터가 들어왔을 때 전체 과정을 손쉽게 반복할 수 있는지 확신하기 어렵습니다.\n이 책은 그 한계를 넘어서기 위한 여정으로의 초대입니다.\n단순히 코딩 문법이나 AI 도구 사용법을 나열하는 데 그치지 않고, 이 책은 ‘스스로 살아 움직이며 가치를 창출하는 지능형 데이터 시스템’ 을 구축하는 전체 과정을 안내합니다. 이 책에서 펼쳐질 여정은 다음과 같습니다.\n첫 단계는 전문가의 작업실처럼 체계적인 프로젝트 관리, git을 활용한 버전 관리, 테스트를 통해 실수를 줄이는 법을 배우며 견고한 토대를 다지는 것입니다.\n그 위에서, AI라는 강력한 도구를 단순한 장난감이 아닌, 그 결과물을 검증하고 신뢰할 수 있는 지적인 동료로 만드는 방법을 탐구합니다.\n나아가 이 모든 과정을 자동화하여, 버튼 클릭 한 번, 혹은 정해진 시간마다 스스로 전체 데이터 작업을 수행하고 결과를 도출하는 효율성의 극치를 경험하게 될 것입니다.\n이 책의 최종 목표는, 이 모든 것을 통합하여 매일 새로운 데이터를 바탕으로 AI의 지능을 빌려 새로운 지식을 창출하고, 그 결과를 정해진 형태로 만들어내는 하나의 완전한 ’자동화된 지능형 시스템’을 완성하는 것입니다.\n이 책을 덮을 때쯤, 독자 여러분은 단순히 코드를 작성하는 사람을 넘어, 신뢰할 수 있고 자동화된 데이터 시스템을 설계하고 구축하는 전문가로 성장해 있을 것입니다. AI의 시대, 데이터로 진짜 문제를 해결하는 전문가가 되기 위한 여정을 이제 시작하겠습니다.",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "index.html#감사의-글",
    "href": "index.html#감사의-글",
    "title": "챗GPT 코딩",
    "section": "감사의 글",
    "text": "감사의 글\n\n이 책이 탄생할 수 있도록 도움을 주신 여러분께 깊은 감사의 마음을 표합니다.\n공익법인 한국 R 사용자회가 없었다면 데이터 과학분야 챗GPT 시리즈가 세상에 나오지 못했을 것입니다. 한국 R 사용자회의 유충현 회장님, 신종화 사무처장님, 홍성학 감사님, 올해부터 새롭게 공익법인 한국 R 사용자를 이끌어주실 형환희 회장님께 감사드립니다.\n또한 이 책은 2014년 처음 몸담게 된 소프트웨어 카펜트리 그렉 윌슨 박사님과 Python for Informatics 저자인 미시건 대학 찰스 세브란스 교수님을 비롯한 전세계 수많은 익명의 기여자들의 노력과 지원이 있었고, 서울 R 미트업에서 발표해주시고 참여해주신 수많은 분들이 격려와 영감을 주셨기에 가능했습니다.\n이 책이 출간되는데 있어 이들 모든 분들의 도움 없이는 어려웠을 것입니다. 그동안의 관심과 지원에 깊은 감사를 드리며, 이 책이 데이터 과학의 발전과 독자들에게 도움이 될 수 있기를 바라는 마음으로 마무리하겠습니다.\n\n2024년 3월 속초 청초호\n이광춘",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "ide.html",
    "href": "ide.html",
    "title": "1  IDE 선택과 발전",
    "section": "",
    "text": "1.1 IDE 탄생과 발전\n소프트웨어 개발 세계는 끊임없이 진화하는 도구 생태계다. 중심에는 개발자 생산성을 극대화하는 통합 개발 환경(IDE, Integrated Development Environment)이 있다. IDE는 단순한 코드 편집기를 넘어, 컴파일, 디버깅, 버전 관리 등 개발 전 과정을 하나의 창에서 처리하는 강력한 작업 공간이다.\n모든 개발자에게 완벽한 단 하나의 IDE는 없다. 프로젝트 종류, 주 사용 언어, 개발 스타일에 따라 최적 도구는 달라진다. 본문에서는 IDE 역사부터 최신 AI 트렌드까지 살펴보고, 자신에게 맞는 IDE 선택과 구성에 필요한 지식을 다룬다.\n그림 1.1 는 오픈소스 소프트웨어(OSS) VS Code 기반 현대 데이터 과학 IDE(Positron, Cursor 등) 아키텍처다. 클라이언트 레이어(UI), Extension Host(확장 프로그램 실행), 커널 레이어(코드 실행), 외부 서비스 연동이 명확히 분리되어 있다.\nIDE 역사는 ’어떻게 하면 개발을 더 편하고 효율적으로 할 수 있을까?’라는 고민의 역사와 같다. 60년이 넘는 시간 동안 IDE는 기술 패러다임의 변화와 함께 진화해왔다.\n그림 1.2 은 1964년부터 2025년까지 IDE 진화를 5개 기술 시대로 구분해 보여준다. 각 시대는 당시 컴퓨팅 환경 특성을 반영한다. 메인프레임 시대에는 시분할 시스템으로 원격 터미널을 통해 대화형 프로그래밍이 가능해졌다. 1964년 다트머스 베이직(Dartmouth BASIC)은 학생들이 터미널에서 직접 코드를 입력하고 결과를 즉시 확인할 수 있는 최초의 대화형 환경을 제공했다.\nPC 시대가 열리면서 IDE는 개인 컴퓨터 위에서 작동하는 독립적인 소프트웨어가 되었다. 1983년 터보 파스칼(Turbo Pascal)은 앤더스 헤일스버그(Anders Hejlsberg)가 개발한 혁명적 제품으로, 초고속 컴파일과 통합 에디터를 $49.99라는 파격적 가격에 제공하며 상업용 IDE를 대중화했고 볼란드(Borland) 전성기였다. 1991년 Visual Basic은 드래그 & 드롭 GUI로 비주얼 프로그래밍 패러다임을 열었고, RAD(Rapid Application Development) 혁명을 일으켰다. 개발자가 폼 디자이너에서 버튼을 배치하고 속성을 설정하면 코드가 자동 생성되는 방식은 당시로서는 놀라운 생산성 향상이었다.\n인터넷 시대에는 오픈소스 IDE가 부상했다. 2001년 이클립스(Eclipse)가 플러그인 아키텍처로 자바(Java) 표준 IDE가 되었고, IBM의 대규모 지원으로 확장 생태계를 구축했다. 같은 해 등장한 인텔리제이(IntelliJ) IDEA는 심층 코드 분석과 리팩토링 혁신으로 “스마트 IDE” 기준을 세웠다. 젯브레인즈(JetBrains)가 내건 “즐거운 개발(Develop with Pleasure)” 슬로건은 단순히 개발자 경험을 개선하겠다는 선언이었고, 이후 Kotlin 언어까지 탄생시키는 혁신의 기반이 되었다.\n클라우드 시대는 개발 환경에 대한 물리적 제약을 허물었다. 2015년 등장한 VS Code는 일렉트론(Electron) 기반 크로스 플랫폼 편집기로 시작해, 모나코 편집기(Monaco Editor) 웹 기술과 30,000개 이상의 확장 프로그램으로 시장을 지배하게 되었다. 2020년 GitHub Codespaces는 브라우저 IDE로 설치 없이 즉시 개발할 수 있는 환경을 제공했으며, 컨테이너 기반으로 개발 환경을 정의하면 클라우드에서 즉시 실행되는 클라우드 네이티브 개발 방식이 확산되었다.\nAI IDE 시대는 2021년 GitHub Copilot 등장으로 본격화되었다. 생성형 코드로 개발자 생산성을 혁신했고, OpenAI Codex 기반 AI 페어 프로그래머는 주석이나 함수명만으로도 전체 함수를 자동 생성했다. 2024-25년에는 포지트론(Positron)이 R/Python 데이터 과학 특화 IDE로, Claude Code가 CLI 기반 자율 에이전트로 등장하며 AI 코딩의 새 지평을 열고 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-history",
    "href": "ide.html#sec-ide-history",
    "title": "1  IDE 선택과 발전",
    "section": "",
    "text": "그림 1.2: IDE 발전사: 60년의 진화",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-features",
    "href": "ide.html#sec-ide-features",
    "title": "1  IDE 선택과 발전",
    "section": "1.3 IDE 핵심 기능",
    "text": "1.3 IDE 핵심 기능\nIDE 구조를 이해했으니 이제 실전에서 사용하는 핵심 기능을 살펴보자. 현대 IDE는 단순한 텍스트 편집기를 넘어 개발 전 과정을 통합한 작업 환경으로, 마우스 클릭보다는 키보드 단축키로 모든 기능을 빠르게 호출하는 것이 효율적인 워크플로우의 핵심이다.\n\n\n\n\n\n\n그림 1.4: IDE 핵심 기능: 키보드 중심 워크플로우\n\n\n\n그림 1.4 는 현대 오픈소스 IDE의 화면 구성과 키보드 중심 워크플로우를 보여준다. 화면은 크게 4개 영역으로 나뉜다. 왼쪽 탐색기는 프로젝트 파일 트리를 표시하며, 중앙 편집기는 코드를 작성하는 메인 작업 공간이다. 하단 터미널은 명령어를 실행하고, 최하단 상태 바는 Git 브랜치, 오류 개수, 언어 버전을 한눈에 보여준다.\n편집기 영역을 자세히 보면 AI가 개발에 깊이 통합된 모습이 드러난다. 9번 라인에서 df.dropna() 다음에 .reset_index(drop=True) 메서드가 회색으로 표시되는데, 이것은 GitHub Copilot의 AI 자동완성 제안이다. 개발자가 코드 문맥을 읽고 다음에 필요할 로직을 미리 제안하는 것이다. Tab 키를 누르면 제안을 수락하고, 무시하려면 계속 타이핑하면 된다. 더 나아가 Cmd+I 단축키로 AI 편집 모드를 열어 “파일 없음 에러 처리 추가”처럼 자연어로 의도를 설명하면, AI가 직접 코드를 생성하거나 수정한다. 이것은 코딩 패러다임의 근본적 변화다.\nCmd+Shift+P 명령 팔레트는 IDE 숨겨진 보물이다. 마우스로 메뉴를 탐색하지 않고도 2,000개 이상의 명령에 즉시 접근한다. “Python: Select Interpreter”를 입력하면 파이썬 버전을 바꾸고, “Terminal: Create New Terminal”로 터미널을 추가하며, “Git: Commit”으로 커밋한다. 모든 작업이 키보드에서 손을 떼지 않고 진행된다.\n기존 개발 워크플로우는 에러가 발생하면 브라우저로 전환해 StackOverflow를 검색하고, 코드를 복사해 붙여넣은 뒤 디버깅하는 방식이었다. 현대 AI 네이티브 워크플로우는 다르다. Cmd+I로 “에러 설명해줘”라고 물으면 AI가 즉시 답하고, Tab으로 상용구 코드(boilerplate)를 자동 완성하며, IDE를 벗어나지 않고 플로우를 유지한다. 컨텍스트 전환이 사라지면서 생산성이 2-3배 향상되는 이유다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-evolution",
    "href": "ide.html#sec-ide-evolution",
    "title": "1  IDE 선택과 발전",
    "section": "1.4 IDE 진화",
    "text": "1.4 IDE 진화\n최근 IDE는 두 가지 방향으로 진화하고 있다. 하나는 특정 개발 영역에 깊이 파고들어 전문화되는 것이고, 다른 하나는 AI로 개발 방식 자체를 근본적으로 바꾸는 것이다. 데이터 과학 분야는 두 트렌드가 모두 적용되는 대표적인 영역으로, 전문화된 기능과 AI 통합이 동시에 진행되고 있다.\n\n1.4.1 데이터 과학 IDE\n데이터 과학 IDE는 일반 프로그래밍 IDE와 다른 특화된 기능을 갖춘다. 코드 실행 결과로 생성된 플롯이나 그래프를 IDE 내에서 직접 확인하고 상호작용하는 데이터 시각화 도구가 핵심이다. 변수 탐색기는 현재 실행 환경의 데이터프레임, 변수, 객체 등을 실시간으로 보여주며, 데이터 구조와 값을 쉽게 파악하게 한다. 주피터(Jupyter) 노트북 통합은 코드, 텍스트, 시각화를 하나의 문서로 엮어 재현가능한 분석 보고서를 만든다. 패키지 및 환경 관리 기능은 uv나 conda로 프로젝트별로 격리된 환경을 구성하고, pandas나 scikit-learn 같은 데이터 과학 라이브러리를 손쉽게 설치하고 업데이트한다.\n\n\n1.4.2 AI 에이전트 개발 환경\n최근 LLM 활용 AI 에이전트 개발이 급부상하며 특화된 개발 환경이 등장했다. 에이전트 동작 흐름을 시각적으로 설계하고, 여러 에이전트 간 상호작용을 테스트하며, 복잡한 프롬프트 체인을 관리하는 도구들이다.\nLangSmith는 LangChain 기반 에이전트 동작을 추적하고 디버깅하는 플랫폼이다. 에이전트가 어떤 도구를 호출했고, 어떤 프롬프트를 사용했으며, 왜 특정 결정을 내렸는지 시각화한다. AutoGen Studio는 여러 에이전트 팀을 손쉽게 만들고 테스트하는 시각 인터페이스를 제공한다. 코드 작성 에이전트, 리뷰 에이전트, 테스트 에이전트가 협업하는 과정을 그래프로 보여준다. Flowise와 Langflow는 코드 없이 드래그 & 드롭으로 LLM 애플리케이션을 만드는 시각 IDE 역할을 한다. 프롬프트 노드, LLM 노드, 데이터 처리 노드를 연결해 복잡한 AI 워크플로우를 구축한다.\n\n\n1.4.3 AI 통합\nAI 코딩 도구는 지난 3년간 급격히 진화했다. 처음에는 개발자가 별도 웹사이트를 방문해야 했던 챗 인터페이스에서 시작해, IDE 내부로 통합된 확장 프로그램으로 발전했고, 이제는 프로젝트 전체를 자율적으로 편집하는 에이전트 단계에 이르렀다. 진화 과정의 핵심은 AI가 개발자 작업 흐름 속으로 점점 더 깊숙이 들어와 컨텍스트 전환을 최소화하는 것이다.\n\n\n\n\n\n\n그림 1.5: AI 코딩 진화 - 챗 인터페이스에서 IDE 통합까지\n\n\n\n그림 1.5 는 AI 코딩 도구의 4단계 진화 과정을 보여준다. 1단계(2022-2023)는 챗GPT(ChatGPT) 웹사이트를 별도로 방문하는 방식이었다. IDE에서 코드를 작성하다가 질문이 생기면 브라우저로 전환하고, 챗GPT에 질문하고, 답변을 복사해서 IDE로 돌아와 붙여넣었다. 컨텍스트 전환이 빈번하고 코드 컨텍스트를 수동으로 복사해야 했으며, 플로우 상태가 깨지면서 생산성이 저하되었다.\n2단계(2023)는 GitHub Copilot 같은 IDE 확장이 등장하면서 시작되었다. AI가 IDE 내부로 들어와 자동완성을 제공했다. 코드 문맥을 자동으로 인식하고, Tab으로 제안을 수락하며, IDE를 벗어나지 않게 되었다. 하지만 자동완성만 지원할 뿐 대화형 설명이나 복잡한 요청은 어려웠다.\n3단계(2024)는 커서(Cursor)와 윈드서프(Windsurf) 같은 AI 네이티브 IDE가 깊은 통합을 실현했다. Cmd+K로 인라인 편집 모드를 열고, 자연어로 의도를 설명하면 AI가 코드를 직접 수정한다. 대화하며 결과를 개선할 수 있다. 하지만 여전히 IDE 내부로 제한되고, 파일 단위 작업이며, 자율성은 제한적이었다.\n4단계(2024-2025)는 클로드 코드(Claude Code)와 구글 앤티그래비티(Google Antigravity) 같은 자율 에이전트다. 2025년 11월 구글이 제미나이(Gemini) 3와 함께 발표한 앤티그래비티는 “에이전트 우선” 개발 플랫폼이다. Editor View(AI 기반 IDE)와 에이전트 관리자(Agent Manager)라는 두 가지 모드를 제공한다. Agent Manager에서는 에이전트를 생성하고, 오케스트레이션하며, 비동기로 작업하는 과정을 관찰한다. 에이전트는 작업 목록, 구현 계획, 스크린샷, 브라우저 녹화 같은 아티팩트(Artifacts)를 생성해 로직을 검증 가능하게 한다. 제미나이 3 Pro뿐 아니라 클로드 소넷(Claude Sonnet) 4.5, OpenAI 모델도 지원하며 무료 공개 프리뷰로 제공된다.\nCLI 명령으로 작업을 요청하면 프로젝트 전체를 이해하고, 다중 파일을 자율적으로 편집하며, Git 커밋까지 자동화한다. 프로젝트 전체 컨텍스트를 유지하고, 스스로 의사결정하며, 개발자의 플로우를 완전히 유지한다. 생산성이 10-100배 향상되는 혁명적 단계다.\n진화의 핵심은 컨텍스트 전환 최소화다. AI가 개발자의 작업 공간 밖에 있을 때는 지속적으로 전환해야 했지만, IDE 안으로 들어오고, 더 깊이 통합되고, 마침내 자율 에이전트가 되면서 개발자는 플로우 상태를 유지한 채로 AI의 도움을 받게 되었다.\n💡 생각해볼 점\n60년 IDE 역사가 보여준 패턴은 명확하다. 컴퓨팅 패러다임이 바뀔 때마다 새로운 IDE가 등장했고, 이전 도구는 레거시가 되었다. 메인프레임 시대 시분할 시스템, PC 시대 터보 파스칼, 인터넷 시대 이클립스, 클라우드 시대의 VS Code, 지금 AI 시대 커서와 구글 앤티그래비티. 중요한 것은 “현재 패러다임에 최적화된 도구를 빠르게 습득”하는 능력이다. 2025년 12월 현재 AI 통합 수준이 IDE 선택의 가장 중요한 기준이 되었다.\n키보드 중심 워크플로우는 생산성의 핵심이다. Cmd+P, Cmd+Shift+P, Cmd+I, F5, F9, Ctrl+\\ - 6개 단축키만 암기해도 마우스 의존도가 80% 줄어든다. 명령 팔레트(Cmd+Shift+P)로 2,000개 이상의 기능에 즉시 접근하고, AI 편집(Cmd+I)으로 자연어를 코드로 바꾸며, 디버거(F5, F9)로 버그를 추적한다. 근육 기억이 형성되면 플로우 상태가 유지되고, 생산성이 2-3배 향상된다.\nAI 도구 선택은 통합 수준으로 판단한다. 아직 별도 챗GPT 웹사이트에서 복사-붙여넣기 사용한다면 1단계다. GitHub Copilot으로 자동완성을 받는다면 2단계, 커서로 대화하며 코드를 수정한다면 3단계다. 구글 앤티그래비티나 클로드 코드처럼 에이전트 관리자에서 에이전트가 프로젝트 전체를 자율적으로 편집하고 아티팩트(Artifacts)를 생성하며 검증하는 4단계가 현재 최전선이다. 단계가 높을수록 컨텍스트 전환은 줄고 작업플로우는 유지된다.\n다음 장에서는 데이터 과학에 특화된 포지트론(Positron) IDE를 설치하고, R과 파이썬 환경을 구성하며, 키보드 단축키를 실전에서 활용하는 방법을 다룬다. 이론을 넘어 실제로 “작업플로우에서 AI와 함께 코딩하는” 환경을 직접 구축한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-conclusion",
    "href": "ide.html#sec-ide-conclusion",
    "title": "1  IDE 선택과 발전",
    "section": "1.4 결론: 자신에게 맞는 IDE 선택",
    "text": "1.4 결론: 자신에게 맞는 IDE 선택\n완벽한 IDE는 없다. 오직 ‘자신에게 맞는’ IDE만 있을 뿐이다. 주력 언어와 플랫폼이 선택의 첫 기준이다. Java 개발자라면 IntelliJ IDEA가, iOS 개발자라면 Xcode가, R 사용자라면 RStudio나 포지트론이 좋은 출발점이다. 프로젝트 종류도 중요하다. 웹 프론트엔드 개발에는 VS Code가, 데이터 분석에는 JupyterLab이나 Spyder가, AI 에이전트 개발에는 LangSmith 같은 전문 도구가 효율적이다.\n개발 스타일도 고려해야 한다. 시각 인터페이스와 마우스 클릭을 선호한다면 GUI 중심 IDE를, 키보드와 명령어로 모든 것을 제어하려면 터미널과 CLI 확장이 강력한 IDE를 선택한다. AI 기능 활용도도 결정 요인이다. 최신 AI 기능을 적극 활용하려면 GitHub Copilot 통합이 잘 된 VS Code나, AI 네이티브로 설계된 Cursor를, 자율 에이전트 수준을 원한다면 Claude Code를 고려한다.\nIDE는 개발자 장인의 작업대다. 다양한 도구 특징을 이해하고, 자신의 작업 스타일에 맞게 작업대를 구성할 때 최고의 생산성과 만족감을 얻는다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide_positron.html",
    "href": "ide_positron.html",
    "title": "2  포지트론",
    "section": "",
    "text": "2.1 포지트론 철학\n데이터 과학 세계는 빠르게 변화하고 있으며, 이제 R과 파이썬(Python) 강력한 언어를 함께 사용하는 것이 표준이 되었다. R은 통계 분석과 시각화에 독보적 강점을 가지며, 파이썬은 머신러닝, 범용 프로그래밍, 시스템 통합에 널리 쓰인다. 하지만 오랫동안 데이터 과학자들은 두 언어를 동시에 편안하게 사용할 완벽한 통합 개발 환경(IDE)을 찾기 어려웠다. R 사용자에게는 RStudio가, 파이썬 사용자에게는 다양한 선택지가 있었지만, 두 세계를 자연스럽게 넘나들기에는 항상 아쉬움이 남았다.\n이런 문제의식에서 출발한 것이 포짓(Posit, 과거 RStudio)사가 개발한 차세대 데이터 과학 IDE 포지트론(포지트론)이다. 포지트론은 “하나의 팀, 두 개의 언어” 현실을 받아들이고, R과 파이썬을 모두 일급 시민1으로 대우하는 현대 ‘다언어(polyglot)’ 개발 환경을 지향한다.\n포지트론 핵심 철학은 RStudio 데이터 과학 전문성과 Visual Studio Code(VS Code) 현대적 개발 경험 결합이다. 포지트론은 VS Code 오픈소스 버전인 ‘Code OSS’ 기반으로 구축되었다. VS Code의 빠르고 유연한 인터페이스, 방대한 확장 기능 생태계, 강력한 코드 편집 기능을 가져오면서, RStudio가 수십 년간 쌓은 데이터 과학 워크플로우 이해를 녹여냈다.\n그림 2.1 는 포지트론 전체 화면 구성을 보여준다. 왼쪽 탐색기는 프로젝트 파일 트리를, 중앙 편집기는 R 코드를, 오른쪽 패널은 변수 탐색기와 플롯 창을, 하단은 R 콘솔을 표시한다. 콘솔 상단 드롭다운으로 R과 파이썬을 즉시 전환할 수 있다. 편집기에서는 AI가 회색으로 다음 코드를 제안하며, 변수 탐색기는 메모리에는 데이터프레임을 포함한 모든 객체를 실시간으로 보여준다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-philosophy",
    "href": "ide_positron.html#sec-positron-philosophy",
    "title": "2  포지트론",
    "section": "",
    "text": "그림 2.1: 포지트론 화면 구성 - R/Python 동시 지원 UI\n\n\n\n\n\n\n\n\n\n노트왜 RStudio를 두고 포지트론을 만들었나?\n\n\n\n포짓 답변은 명확하다: “RStudio는 계속된다.”\n포지트론 개발은 RStudio 대체가 아니다. RStudio와 포지트론은 서로 다른 목표와 사용자를 가진다. RStudio는 R 언어에 깊이 집중하는 데이터 분석가와 통계학자를 위한 최고의 R 개발 환경으로 계속 발전하고 유지된다. 반면 포지트론은 R과 파이썬을 함께 사용하는 다언어 데이터 과학 팀과 개발자를 위한 새로운 선택지다.\n포지트론은 ‘R 전용’ RStudio의 성공적 틀을 넘어, ’R과 파이썬 모두’를 필요로 하는 현대 데이터 과학의 새로운 요구에 부응하기 위한 포짓의 전략적 확장이자 AI 시대 경쟁에서 밀릴 수 없다는 전략적 노림수다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-ai",
    "href": "ide_positron.html#sec-positron-ai",
    "title": "2  포지트론",
    "section": "\n2.2 AI 시대 포지트론",
    "text": "2.2 AI 시대 포지트론\n포지트론 가장 큰 혁신은 단순 다언어 지원을 넘어, AI 기능을 데이터 과학 워크플로우에 깊이 통합한 점이다. 포지트론 AI 어시스턴트는 일반 코딩 도우미와 근본적으로 다르다. 현재 실행 중인 R/파이썬 세션 내부 상태(메모리 데이터, 변수, 플롯 등)를 직접 파악하고 상호작용하기 때문이다.\n탐색적 데이터 분석(EDA) 단계를 예로 들어보자. “penguins 데이터셋에서 종(species)별로 몸무게(body_mass_g) 분포를 박스플롯으로 그려줘”라고 자연어로 요청하면, AI는 현재 메모리에 있는 penguins 데이터프레임 구조를 이해하고 즉시 ggplot2나 matplotlib 코드를 생성해 실행 결과를 플롯 창에 보여준다. 탐색적 데이터 탐색 단계가 몇 분에서 몇 초로 단축된다.\n데이터 전처리(data wrangling)도 마찬가지다. “결측치가 있는 행을 제거하고, ‘bill_length_mm’와 ’bill_depth_mm’ 열만 선택해줘”라는 요청을 dplyr이나 pandas 코드로 즉시 변환한다. 개발자는 파이프 연산자 문법이나 메서드 체이닝(method chaining)을 기억하는 데 에너지를 쏟지 않고, 데이터 분석에 대한 큰 그림과 로직에 집중할 수 있다.\n더 나아가 AI는 코드뿐 아니라 통계 모델 결과까지 해석한다. “방금 실행한 선형 회귀 모델의 \\(R^2\\) 값은 무엇을 의미하지?” 또는 “복잡한 purrr 코드를 단계별로 설명해줘” 같은 질문에, AI는 통계학적 배경 지식과 함께 깊이 있는 답변을 제공한다. 데이터 과학자가 더 나은 통찰(insight)을 얻도록 돕는 지능형 파트너 역할도 한다.\n\n\n\n\n\n\n힌트IDE 선택 가이드\n\n\n\n표 2.1 비교 정보를 바탕으로 선택은 명확하다. R만 사용하는 통계학자라면 R 패키지 개발, Shiny 앱 배포, R Markdown 프로파일링 같은 고급 기능이 완벽히 통합된 RStudio가 가장 안정적이고 편리하다. 웹 개발, 시스템 프로그래밍 등 범용 목적이라면 수많은 확장 기능을 갖춘 VS Code가 최고 유연성을 제공한다. 하지만 R과 파이썬을 함께 사용하며 최신 AI 기능을 적극 활용하고 싶다면, 포지트론은 두 언어를 매끄럽게 오가며 AI 지원을 받을 수 있는 현재 가장 진보적 환경이다.\n\n\n\n\n\n\n\n\n특성\nRStudio\nVS Code\n포지트론\n\n\n\n주력 언어\nR\n범용 (모든 언어)\nR & Python\n\n\n주요 사용자\nR 데이터 분석가, 통계학자\n모든 종류의 개발자\n다언어 데이터 과학자\n\n\n설정\n거의 불필요 (R 최적화)\n높은 유연성 (직접 구성)\n낮은 설정 (R/Python 최적화)\n\n\n장점\nR 생태계 완벽 통합\n최고의 유연성과 확장성\nR/Python 동시 작업 및 AI 통합\n\n\n단점\nPython 지원 제한적\n데이터 과학 초기 설정 복잡\n일부 고급 기능 아직 개발 중\n\n\n\n\n\n\n\n표 2.1: IDE 비교: RStudio vs VS Code vs 포지트론",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-comparison",
    "href": "ide_positron.html#sec-positron-comparison",
    "title": "2  포지트론",
    "section": "\n2.3 IDE 비교와 선택",
    "text": "2.3 IDE 비교와 선택\n\n\n\n\n\n\n\n\n특성\nRStudio\nVS Code\n포지트론\n\n\n\n주력 언어\nR\n범용 (모든 언어)\nR & Python\n\n\n주요 사용자\nR 데이터 분석가, 통계학자\n모든 종류의 개발자\n다언어 데이터 과학자\n\n\n설정\n거의 불필요 (R 최적화)\n높은 유연성 (직접 구성)\n낮은 설정 (R/Python 최적화)\n\n\n장점\nR 생태계 완벽 통합\n최고의 유연성과 확장성\nR/Python 동시 작업 및 AI 통합\n\n\n단점\nPython 지원 제한적\n데이터 과학 초기 설정 복잡\n일부 고급 기능 아직 개발 중\n\n\n\n\n\n\n\n표 2.1: IDE 비교: RStudio vs VS Code vs 포지트론\n\n\n\n\n\n\n\n\n\n힌트IDE 선택 가이드\n\n\n\n선택은 명확하다. R만 사용하는 통계학자라면 여전히 RStudio가 가장 안정적이고 편리하다. R 패키지 개발, Shiny 앱 배포, R Markdown 프로파일링 같은 고급 기능이 완벽히 통합되어 있기 때문이다.\n웹 개발, 시스템 프로그래밍 등 범용 목적이라면 수많은 확장 기능을 갖춘 VS Code가 최고 유연성을 제공한다.\n하지만 R과 파이썬을 함께 사용하며 최신 AI 기능을 적극 활용하고 싶다면, 포지트론은 두 언어를 매끄럽게 오가며 AI 지원을 받을 수 있는 현재 가장 진보적 환경이다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-conclusion",
    "href": "ide_positron.html#sec-positron-conclusion",
    "title": "2  포지트론",
    "section": "\n2.6 결론",
    "text": "2.6 결론\n포지트론은 아직 베타 버전이며 RStudio 일부 기능(예: R Markdown 프로파일링, 간편한 앱 배포)이 아직 구현되지 않았다는 한계가 있다. 하지만 R과 파이썬이 공존하는 현대 데이터 과학 흐름을 가장 잘 반영하고, AI를 개발 워크플로우 핵심으로 가져왔다는 점에서 미래가 기대된다.\n포지트론은 단순히 새로운 도구가 아니다. 포짓 팀이 생각하는 미래 데이터 과학 작업 환경의 구체적 실험이다. AI와 함께 더 빠르고 깊이 있게 데이터 문제를 해결하고 싶은 데이터 과학자라면, 포지트론은 여정을 함께할 흥미로운 파트너다.\n💡 생각해볼 점\n포지트론을 도입할 준비가 되었다면 다음 질문에 답해보자. 현재 프로젝트에서 R과 파이썬을 모두 사용하는가? RStudio에서 파이썬을 쓰려다 불편함을 느낀 적이 있는가? 데이터 전처리부터 머신러닝까지 하나의 IDE에서 처리하고 싶은가? 이 질문에 “그렇다”고 답한다면 포지트론은 충분히 시도해볼 가치가 있다.\n단축키를 익히는 것이 첫걸음이다. Cmd+Shift+P 명령 팔레트로 모든 기능에 접근하고, Cmd+Shift+A로 AI 어시스턴트를 호출하며, Cmd+Enter로 코드를 실행한다. 3개 단축키만 암기해도 마우스 의존도가 70% 줄어든다.\n다음 장에서는 포지트론에서 실제 데이터 분석 프로젝트를 만들고, AI 어시스턴트로 탐색적 데이터 분석을 수행하며, R과 파이썬을 오가는 전 과정을 다룬다. 이론을 넘어 실제로 “AI와 함께 데이터 과학하는” 환경을 직접 경험한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_extension.html",
    "href": "ide_extension.html",
    "title": "3  IDE 확장 프로그램",
    "section": "",
    "text": "3.1 IDE 확장 프로그램 아키텍처\n현대 통합 개발 환경(IDE)의 가장 큰 힘은 ’확장성’에 있다. 어떤 IDE도 세상의 모든 프로그래밍 언어, 프레임워크, 도구를 기본 지원할 수는 없다. 그렇게 시도한다면 IDE는 극도로 무거워지고 복잡해져 사용할 수 없게 된다.\n문제 해결의 핵심 아이디어가 바로 확장 프로그램(Extensions)이다. IDE는 핵심 기능(텍스트 편집, UI)만 제공하고, 추가 기능들은 사용자가 필요에 따라 ’레고 블록’처럼 조립해 사용한다. 이번 장에서 IDE 확장 프로그램이 왜 필요하며, 어떤 아키텍처로 안정적으로 구현되는지 살펴본다.\n확장 프로그램이 IDE를 무너뜨리지 않으면서도 강력한 기능을 제공하려면 어떻게 해야 할까? 현대 IDE는 이러한 문제를 해결하기 위해 공통된 아키텍처 패턴을 따른다. 핵심은 ‘격리’다. 확장 프로그램을 메인 프로세스에서 분리하고, 언어 기능을 표준 프로토콜로 분리하며, 기여 지점을 명확히 정의한다. 비주얼 스튜디오 Code(VS Code)는 세 가지 원칙을 가장 성공적으로 구현한 대표 사례로, 30,000개 이상의 확장 프로그램을 지원하면서도 가볍고 안정적인 성능을 유지한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-extension-need",
    "href": "ide_extension.html#sec-extension-need",
    "title": "3  IDE 확장 프로그램",
    "section": "",
    "text": "새로운 기술에 대한 유연한 대응: 프로그래밍 언어, 프레임워크, 도구는 끊임없이 등장하고 변화한다. 확장 프로그램 모델은 IDE 개발팀이 모든 기술을 직접 지원하지 않고도, 각 기술 커뮤니티나 서드파티 개발자가 직접 확장 프로그램을 만들어 생태계에 기여하게 한다.\n사용자 맞춤형 환경 구축: 모든 개발자는 자신만의 작업 방식과 선호 도구가 있다. 확장 프로그램으로 개발자는 테마, 키보드 단축키, 코드 린터(linter) 등 자신에게 맞는 개발 환경을 구축한다.\n성능과 안정성: 필요한 기능만 선택적으로 설치하고 활성화해 IDE를 가볍고 빠르게 유지한다. 잘 설계된 아키텍처는 하나의 확장 프로그램 오류가 전체 IDE를 마비시키는 것을 방지한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-extension-architecture",
    "href": "ide_extension.html#sec-extension-architecture",
    "title": "3  IDE 확장 프로그램",
    "section": "",
    "text": "3.1.1 확장 프로그램 격리\nVS Code는 확장 프로그램을 IDE 메인 프로세스가 아닌, ‘확장 호스트(Extension Host)’ 라고 불리는 별도 독립 프로세스에서 실행한다. 이러한 격기 구조의 가장 큰 목적은 안정성이다. 특정 확장 프로그램이 과도한 메모리를 사용하거나 오류를 일으켜 멈추더라도, IDE 메인 프로세스(UI, 텍스트 편집 등)는 전혀 영향을 받지 않는다. 사용자는 문제가 된 확장 프로그램을 비활성화하거나 재시작할 수 있으며, 작업 내용은 안전하게 보존된다.\n\n\n\n\n\n\n그림 3.1: VS Code 안정성 비결 - 확장 프로그램 격리 아키텍처\n\n\n\n그림 3.1 는 VS Code가 메인 프로세스와 확장 호스트를 분리해 안정성을 확보하는 방식을 보여준다. 확장 프로그램이 오류를 일으켜도 메인 프로세스는 안전하게 작동한다.\n\n\n3.1.2 LSP: 언어 기능 분리\n과거에는 C++ 언어 ‘코드 자동 완성’ 기능을 만들려면, VS Code용, Sublime Text용, 아톰용 코드를 각각 따로 만들어야 했다. 언어 개발자(m)와 IDE 개발자(n) 모두에게 m x n의 비효율적 개발 부담을 주었다.\n마이크로소프트가 개발해 표준으로 제안한 언어 서버 프로토콜(Language Server Protocol, LSP)은 이 문제를 해결했다. LSP는 언어 관련 기능(코드 분석, 자동 완성, 오류 검출 등)을 ‘언어 서버’ 라는 독립 프로세스로 분리한다. IDE(클라이언트)는 표준화된 JSON-RPC 메시지로 언어 서버와 통신하며 정보를 주고받는다.\n효과는 획기적이었다. C++ 언어 개발자는 ‘C++ 언어 서버’ 하나만 만들면 된다. LSP를 지원하는 모든 IDE(VS Code, 이클립스, 주피터 등)는 별도 노력 없이 C++ 언어의 모든 지능형 기능을 사용할 수 있다. 개발 부담을 m + n으로 획기적으로 줄였고, 새로운 언어가 빠르게 다양한 IDE에 채택될 수 있는 길을 열었다.\n\n\n\n\n\n\n그림 3.2: 언어 서버 프로토콜 (LSP): m × n 문제의 해결\n\n\n\n그림 3.2 는 LSP가 m × n 문제를 m + n으로 해결한 과정을 보여준다. 과거에는 각 언어와 IDE마다 별도 통합 작업이 필요했지만, LSP로 언어 서버 하나만 만들면 모든 LSP 지원 IDE에서 사용할 수 있게 되었다.\n\n\n3.1.3 기능 기여 모델\n확장 프로그램은 package.json이라는 Manifest(설명서) 파일로 IDE 메뉴, 아이콘, 명령어 목록에 자신의 기능을 추가한다. 매니페스트 파일에는 확장 프로그램 이름, 버전, 설명 등 기본 정보와 함께, ‘어떤 조건에서 활성화될지’(Activation Events), ‘IDE 어느 부분에 어떤 기능을 추가할지’(Contribution Points)가 명시되어 있다.\nVS Code는 확장 프로그램이 기여할 수 있는 ’슬롯’을 미리 정의해 두었다. 예를 들어, contributes.commands는 새로운 명령어를, contributes.menus는 메뉴 항목을, contributes.views는 사이드바에 새로운 UI 창을 추가한다. IDE는 시작될 때 package.json 파일들을 읽어들여 전체 UI와 기능을 구성한다.\n\n\n\n\n\n\n경고아톰 편집기 교훈: 자유도 vs 안정성\n\n\n\n아톰(Atom) 편집기는 VS Code의 성공적 아키텍처를 이해하는 데 좋은 대조 사례다. 아톰 역시 일렉트론(Electron) 기반으로 만들어졌고 ‘핵킹 가능한(hackable)’ 편집기를 표방하며 엄청난 유연성을 제공했지만, VS Code와 결정적 아키텍처 차이가 있었다.\n아톰은 확장 프로그램을 격리된 ’확장 호스트’에서 실행하지 않았다. 모든 확장 프로그램은 편집기 UI와 동일한 렌더러 프로세스에서 실행되었다. 이러한 구조는 편집기 거의 모든 부분을 수정할 수 있는 극강의 자유도를 제공했지만, 치명적 단점을 낳았다. 확장 하나가 오작동하거나 느려지면 편집기 전체가 버벅거리거나 멈추는 현상이 잦았다. 결국 아톰은 성능 저하 문제로 사용자를 잃었다.\n아톰 사례는 확장 프로그램 아키텍처에서 ‘격리’ 가 왜 중요한지 명확히 보여준다. VS Code가 확장 호스트로 안정성과 성능을 모두 잡을 수 있었던 것은 아톰 편집기 단점을 반면교사로 삼았기 때문이다. 소프트웨어 설계에서 한 가지를 얻으면 다른 것을 포기해야 하는 절충은 피할 수 없다. 중요한 것은 사용자가 진정으로 원하는 것이 무엇인지 정확히 파악하는 것이다. 개발자들은 “자유롭지만 느린” 편집기보다 “약간 제한적이지만 빠르고 안정적인” 편집기를 선택했다.\n(참고: 아톰 프로젝트는 2022년 12월 공식 개발 중단)\n\n\n\n\n3.1.4 VS Code 아키텍처 영향\n최근 포지트론(Positron), 커서(Cursor) 등 많은 IDE가 VS Code 오픈소스 코어인 ‘Code - OSS’ 기반으로 만들어지고 있다. VS Code 확장 프로그램 아키텍처가 그만큼 뛰어나고, 현대 IDE 개발의 ’성공 공식’이 되었다는 의미다.\n새로운 IDE가 VS Code 기반으로 만들어진다는 것은, 수만 개의 기존 VS Code 확장 프로그램을 거의 그대로 사용할 수 있다는 뜻이다. 새로운 IDE는 처음부터 모든 언어 지원, 테마, 도구를 만들 필요 없이, 이미 검증된 거대한 생태계를 즉시 활용해 개발을 시작한다. VS Code ‘확장 호스트’ 같은 멀티 프로세스 아키텍처는 안정성과 성능이 이미 검증되었다. 새로운 IDE는 복잡한 기반을 직접 설계하는 대신, 자신만의 핵심적 특화 기능 개발에만 집중한다.\n전 세계 수많은 개발자가 이미 VS 코드 UI와 사용 방식에 익숙하다는 점도 중요하다. VS 코드 기반으로 만들어진 IDE는 사용자가 별도 학습 없이도 쉽고 빠르게 적응할 수 있다. VS 코드 확장 프로그램 아키텍처는 단순 기술적 성공을 넘어, 다른 IDE가 활용할 수 있는 강력한 플랫폼이자 생태계를 창조했다. 많은 현대 IDE가 ’바퀴를 재발명’하는 대신 VS Code라는 거인의 어깨 위에 올라타는 이유다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-extension-conclusion",
    "href": "ide_extension.html#sec-extension-conclusion",
    "title": "3  IDE 확장 프로그램",
    "section": "3.3 결론",
    "text": "3.3 결론\n현대 IDE 확장 프로그램 아키텍처는 ‘분리와 표준화’ 두 가지 핵심 원칙에 기반한다. Extension Host로 각 확장 프로그램을 분리해 안정성을 확보하고, LSP라는 표준화된 프로토콜로 언어 기능을 재사용 가능하게 만든다.\n영리한 아키텍처 덕분에 VS Code 같은 현대 IDE는 수많은 언어와 도구를 지원하는 거대한 생태계를 구축하면서도, 가볍고 안정적인 성능을 유지한다. IDE가 더 이상 하나의 회사가 만드는 단일 제품이 아니라, 전 세계 개발자 커뮤니티가 함께 만들어가는 ’플랫폼’이 되었다.\n💡 생각해볼 점\n확장 프로그램 생태계가 IDE의 핵심 경쟁력이 된 시대다. Positron을 선택했다면 R과 Python이 이미 내장되어 있으므로, Shiny Publisher, Quarto, SandDance부터 설치해 즉시 인터랙티브 앱과 문서를 만들어보자. VS Code를 사용한다면 R, Python, Jupyter를 먼저 설치하고 언어 기반을 구축한 뒤 나머지 확장을 추가한다.\n15개 확장을 한 번에 설치하기보다는, 프로젝트 성격에 따라 선택적으로 설치한다. Shiny 대시보드 개발 프로젝트라면 Shiny Publisher와 Thunder Client를, 공간 데이터 분석이라면 Geo Data Viewer와 SQLTools를, 원격 GPU 서버에서 딥러닝을 훈련한다면 Remote-SSH와 Docker를 먼저 설치한다. 필요할 때마다 하나씩 추가하며 자신만의 최적 환경을 구축하는 것이 가장 효율적이다.\n협업 프로젝트에서는 Live Share로 실시간 페어 프로그래밍을 시도해보자. 주니어 개발자가 막힌 부분을 시니어가 원격으로 함께 디버깅하거나, 코드 리뷰를 화면 공유 없이 IDE 내에서 직접 수행하는 경험은 협업 방식을 근본적으로 바꾼다.\n확장 생태계는 계속 진화한다. 2025년 현재 15개 필수 확장이 데이터 과학 워크플로우를 완성하지만, 1년 후에는 새로운 AI 도구, 시각화 확장, 협업 플랫폼이 등장할 것이다. 중요한 것은 “어떤 확장이 있는지” 지속적으로 탐색하고, “내 워크플로우에 필요한지” 빠르게 판단하는 능력이다. 확장 마켓플레이스에서 “data science”, “visualization”, “collaboration” 키워드로 정기적으로 검색하며 새로운 도구를 발견하자.\n다음 장에서는 이론을 넘어 실제로 포지트론 개발 환경을 구축한다. 운영체제별 설치, R/Python 인터프리터 설정, 필수 확장 15종 설치, 키보드 단축키 암기까지 완전한 작업 환경을 처음부터 끝까지 구성한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_setup.html",
    "href": "ide_setup.html",
    "title": "5  개발 환경 구축",
    "section": "",
    "text": "5.1 Git 설치\nAI로 데이터 과학 문제를 해결하기 위한 첫걸음은 강력한 프로그래밍 언어와 안정적인 개발 환경 구축이다. 본 장에서는 필수적인 버전 관리 도구 Git과 재현 가능한 환경을 위한 도커(Docker), 워크플로우 자동화를 위한 Make를 시작으로, 데이터 과학의 양대 산맥인 R과 파이썬(Python)을 설치하고, 마지막으로 이들을 통합해 사용할 포지트론 IDE 설정 전 과정을 안내한다.\n그림 5.1 는 데이터 과학 개발 환경 구축의 전체 단계를 보여준다. Git, 도커, Make 같은 필수 도구를 먼저 설치하고, R과 파이썬을 설치한 후, 마지막으로 포지트론 IDE를 설치한다.\n본격적인 개발 환경 구축에 앞서, 가장 중요한 버전 관리 시스템 Git을 먼저 설치한다. Git은 코드 변경 이력을 추적하고, 여러 개발자가 협업하게 하며, AI 모델 개발 시 다양한 실험을 관리하는 필수 도구다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-git",
    "href": "ide_setup.html#sec-setup-git",
    "title": "5  개발 환경 구축",
    "section": "",
    "text": "5.1.1 Git 설치\n맥OS(macOS)에서는 터미널을 열고 xcode-select --install 명령어를 실행하면 뜨는 팝업창에서 ’설치’를 클릭한다. Xcode Command Line Tools에 Git이 포함되어 있다. 이미 설치되어 있다면 git --version 명령어로 확인한다.\n윈도우(Windows)에서는 git-scm.com 공식 다운로드 페이지에 접속해 최신 버전 설치 파일을 다운로드한다. 설치 프로그램을 실행하고 대부분 옵션을 기본값으로 두고 설치를 진행한다. ’Git Bash’가 함께 설치되어 강력한 명령어 환경을 제공한다.\n리눅스(Linux, 우분투/데비안)에서는 터미널을 열고 다음 명령어를 실행한다:\nsudo apt-get update\nsudo apt-get install git\n\n5.1.2 설치 확인\n터미널에서 다음 명령어를 실행해 Git이 정상 설치되었는지 확인한다:\n$ git --version\ngit version 2.39.2 (Apple Git-143)\n\n5.1.3 최초 설정\nGit 설치 후, 터미널에서 다음 두 명령어를 실행해 사용자 이름과 이메일 주소를 반드시 설정한다. 정보는 코드를 변경하고 저장(커밋)할 때마다 기록된다.\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\"Your Name\"과 \"youremail@example.com\" 부분을 본인의 정보로 바꿔서 입력하세요.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#컨테이너-환경-도커-설치",
    "href": "ide_setup.html#컨테이너-환경-도커-설치",
    "title": "5  개발 환경 구축",
    "section": "\n5.2 컨테이너 환경: 도커 설치",
    "text": "5.2 컨테이너 환경: 도커 설치\nAI/머신러닝 프로젝트는 복잡한 라이브러리, 시스템 의존성, 드라이버 버전 등으로 내 컴퓨터에서는 잘 동작하던 코드가 다른 사람의 컴퓨터나 서버에서는 동작하지 않는 ’환경 문제’를 자주 겪는다. 도커는 프로젝트에 필요한 모든 것을 ’컨테이너’라는 격리된 공간에 담아 어디서든 동일한 환경을 완벽하게 복제한다. 재현 가능한 연구와 안정적 배포를 위한 현대 AI 개발 필수 도구다.\n\n\n도커 Desktop 설치:\n\n\n도커 공식 웹사이트에 접속해 자신의 운영체제(맥OS, 윈도우, 리눅스)에 맞는 도커 Desktop을 다운로드하고 설치한다.\n\n\n\n설치 확인: 설치 후 도커 Desktop을 실행한다. 터미널에서 다음 명령어를 실행해 정상 설치를 확인한다:\n$ docker --version\nDocker version 24.0.6, build ed223bc\n\n$ docker run hello-world\nHello from Docker!\nThis message shows that your installation appears to be working correctly.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-make",
    "href": "ide_setup.html#sec-setup-make",
    "title": "5  개발 환경 구축",
    "section": "\n5.3 워크플로우 자동화",
    "text": "5.3 워크플로우 자동화\n데이터 과학 프로젝트는 ‘데이터 가져오기 → 전처리 → 모델 학습 → 결과 분석 → 보고서 생성’ 같은 여러 단계 작업 흐름을 가진다. 각 단계를 수동으로 반복 실행하는 것은 비효율적일 뿐 아니라 실수를 유발한다. 1970년대 유닉스 시스템에서 탄생한 make는 이런 반복 작업을 자동화하는 검증된 도구다.\nmake 핵심은 의존성 기반 실행이다. Makefile에 “분석 보고서는 전처리된 데이터에 의존하고, 전처리된 데이터는 원본 데이터에 의존한다”는 관계를 정의하면, make는 변경된 파일만 감지해 필요한 작업만 지능적으로 재실행한다. 예를 들어 원본 데이터가 바뀌면 전처리부터 보고서까지 전부 재생성하지만, 분석 코드만 수정했다면 전처리는 건너뛰고 분석과 보고서만 다시 생성한다. 시간과 컴퓨팅 자원을 크게 절약하는 방식이다.\n\n5.3.1 Make 설치\nmake는 대부분의 운영체제에 이미 설치되어 있거나 개발 도구와 함께 제공된다. 맥OS에서는 Git 설치 시 사용한 Xcode Command Line Tools에 make가 포함되어 있고, 리눅스(우분투/데비안)에서도 기본으로 설치된 경우가 많다. 터미널에서 make --version을 실행해 설치 여부를 확인할 수 있다. 리눅스에서 make가 없다면 sudo apt-get install build-essential 명령어로 컴파일 도구 일체를 설치한다.\n윈도우는 상황이 다르다. Git for Windows를 설치했다면 Git Bash 환경에서 make를 사용할 수 있지만, 네이티브 윈도우 환경에서는 별도 설치가 필요하다. Chocolatey 패키지 매니저가 설치되어 있다면 choco install make 명령어로 간단히 설치할 수 있다.\n\n5.3.2 워크플로우 도구 진화\nmake는 1976년 Stuart Feldman이 Bell Labs에서 C 프로그램 컴파일 자동화를 위해 개발했다. 이후 50년 가까이 소프트웨어 빌드의 표준 도구로 자리잡았지만, 데이터 과학의 부상과 함께 새로운 요구가 생겼다. make의 shell 스크립트 기반 문법은 데이터 분석 파이프라인을 표현하기에 복잡하고, 크로스 플랫폼 지원도 제한적이다. 특히 R이나 Python 생태계와의 통합이 자연스럽지 않다. 이런 한계를 극복하기 위해 언어별, 용도별로 특화된 도구들이 등장했다.\n\n\n\n\n\n그림 5.2: 워크플로우 자동화 도구의 진화\n\n\n지난 50년간 워크플로우 자동화 도구는 세 번의 큰 물결을 거쳤다. 그림 5.2 은 이 진화 과정을 시간순으로 보여준다. 첫 번째 물결은 1976년 make로 시작되었다. C 프로그램 컴파일을 위해 탄생했지만, 곧 소프트웨어 빌드 전반의 표준이 되었다. 두 번째 물결은 2012년 스네이크메이크의 등장이다. 독일 뒤셀도르프 대학의 Johannes Köster가 생물정보학 연구를 위해 개발했는데, 수백 개의 샘플을 처리하는 유전체 분석 파이프라인에서 make의 한계가 명확했기 때문이다. Python 문법을 직접 사용할 수 있고, 클러스터 환경에서 자동 병렬화를 지원하는 스네이크메이크는 곧 생명과학을 넘어 데이터 과학 전반으로 확산되었다. 세 번째 물결은 2017-2020년 사이 동시다발적으로 일어났다. 2017년 Go로 작성된 Task가 YAML 기반의 간결한 문법으로 등장했고, 2018년에는 Rust 기반 Just가 명령어 실행에 특화된 미니멀한 접근으로 개발자들을 끌어모았다. 2020년 R 커뮤니티에서는 Will Landau가 targets를 발표하며 데이터 과학 워크플로우 자동화의 새 장을 열었다. drake 패키지의 후속작인 targets는 R 객체 수준에서 의존성을 추적하고, Quarto와의 완벽한 통합으로 재현가능한 연구의 표준 도구가 되었다.\n\n5.3.3 현대 데이터 과학 도구\nmake가 50년 역사를 자랑하지만, 현대 데이터 과학 프로젝트는 make가 설계되지 않았던 요구사항들을 갖는다. R 데이터 분석 프로젝트는 함수와 데이터 객체 간의 복잡한 의존성을 추적해야 하고, Python 생물정보학 파이프라인은 수천 개의 파일을 클러스터에서 병렬 처리해야 한다. 웹 기반 Quarto 프로젝트는 윈도우와 맥OS, 리눅스에서 동일한 명령어로 작동해야 한다. 이런 특수한 요구를 충족하기 위해 언어별, 용도별로 최적화된 도구들이 등장했다.\n\n\n\n\n\n그림 5.3: 데이터 과학 워크플로우 자동화 도구\n\n\n그림 5.3 는 현대 데이터 과학에서 사용되는 세 가지 워크플로우 자동화 도구를 비교한다. R 커뮤니티는 targets를 통해 데이터 분석의 재현가능성을 한 단계 높였다. 함수 하나를 수정하면 그 함수에 의존하는 모든 타겟이 자동으로 재계산되고, Quarto 보고서까지 연쇄적으로 업데이트된다. Python 생태계는 스네이크메이크로 대규모 데이터 파이프라인을 관리한다. make와 비슷한 규칙 기반 문법에 Python의 강력함을 더해, 생물정보학부터 기계학습 실험 추적까지 폭넓게 활용된다. 범용 빌드 도구로는 Task가 부상했다. YAML 파일 하나로 프로젝트의 모든 반복 작업을 정의하고, 크로스 플랫폼 환경에서 동일하게 실행할 수 있다.\nR 데이터 과학: targets\nR 프로젝트에서는 targets 패키지가 워크플로우 자동화의 표준이다. targets는 함수와 데이터 객체 간의 의존성을 자동으로 추적하고, 변경이 발생한 부분만 재실행한다. 특히 Quarto 문서와의 통합이 뛰어나 데이터 분석부터 보고서 생성까지 하나의 워크플로우로 관리할 수 있다.\nR 콘솔이나 포지트론 터미널에서 다음 명령어로 설치한다:\ninstall.packages(\"targets\")\ninstall.packages(\"tarchetypes\")  # Quarto 통합용\n\n# 설치 확인\nlibrary(targets)\npackageVersion(\"targets\")\ntarchetypes 패키지는 Quarto 문서를 targets 파이프라인에 통합하는 tar_quarto() 함수를 제공한다. 데이터 분석 결과가 변경되면 Quarto 문서도 자동으로 재렌더링된다.\nPython 데이터 과학: Snakemake\n스네이크메이크는 Python 기반 워크플로우 관리 시스템으로, 생물정보학 분야에서 시작해 데이터 과학 전반으로 확산되었다. make와 유사한 규칙 기반 문법에 Python 코드를 결합해 복잡한 파이프라인을 표현할 수 있다. 클러스터나 클라우드 환경에서 대규모 병렬 처리를 지원하며, 재현가능한 연구를 위한 표준 도구로 자리잡았다.\n스네이크메이크는 conda나 pip로 설치할 수 있다. conda를 사용하면 의존성 관리가 자동화되고, 필요한 생물정보학 도구들과 함께 환경을 구성할 수 있다:\n# conda로 설치 (권장 - 범용)\nconda install -c conda-forge snakemake\n\n# 생물정보학 프로젝트라면 bioconda 채널 사용\nconda install -c bioconda snakemake\n\n# pip로도 설치 가능\npip install snakemake\n\n# 설치 확인\nsnakemake --version\nconda-forge는 범용 데이터 과학 프로젝트에 적합하고, bioconda는 유전체 분석 같은 생물정보학 도구들을 함께 사용할 때 유용하다. conda 환경이 없다면 pip로도 충분히 설치할 수 있다.\n범용 빌드: Task\nTask는 make의 현대적 대안으로, YAML 파일에 작업을 정의하고 실행한다. make의 복잡한 문법 대신 읽기 쉬운 YAML을 사용하며, 윈도우와 맥OS, 리눅스 모두에서 동일하게 작동한다. Quarto 프로젝트의 렌더링, 테스트, 배포 같은 반복 작업을 자동화할 때 유용하다.\n운영체제별 설치 방법은 다음과 같다:\n# macOS\nbrew install go-task/tap/go-task\n\n# Windows (Chocolatey)\nchoco install go-task\n\n# Windows (Scoop)\nscoop install task\n\n# Linux\nsh -c \"$(curl --location https://taskfile.dev/install.sh)\" -- -d -b /usr/local/bin\n\n# 설치 확인\ntask --version\n프로젝트 루트에 Taskfile.yml을 생성하고 작업을 정의하면, task 작업명 명령어로 실행할 수 있다. targets나 스네이크메이크처럼 복잡한 의존성 추적은 제공하지 않지만, 간단한 빌드 스크립트를 작성할 때 make보다 훨씬 직관적이다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-isolation-comparison",
    "href": "ide_setup.html#sec-setup-isolation-comparison",
    "title": "5  개발 환경 구축",
    "section": "\n5.4 uv vs 도커",
    "text": "5.4 uv vs 도커\n파이썬 개발 환경 격리 도구인 uv와 도커는 모두 ‘재현 가능한 환경’ 구축을 목표로 하지만, 접근 방식과 범위가 다르다.\n\n\n\n\n\n그림 5.4: 환경 격리 수준 비교: uv vs 도커\n\n\n그림 5.4 는 uv와 도커의 가상화 계층 구조를 보여준다. uv는 파이썬 패키지 수준만 격리하는 반면, 도커는 OS부터 모든 시스템 의존성까지 완전히 격리한다.\n\n5.4.1 유사점\n두 도구 모두 프로젝트마다 독립적 환경을 제공해 의존성 충돌을 방지하는 환경 격리를 목표로 한다. 또한 동일한 환경을 다른 시스템에서 정확히 재현할 수 있는 재현가능성을 보장하며, 프로젝트 의존성을 파일로 명확히 정의한다. uv는 requirements.txt로, 도커는 Dockerfile로 의존성을 명시한다.\n\n5.4.2 차이점\n\n\n\n\n\n\n\n\n특성\nuv\n도커\n\n\n\n격리 수준\n파이썬 패키지 수준 (가상 환경)\nOS 수준 (완전한 컨테이너)\n\n\n범위\n파이썬 패키지만 관리\n파이썬, R, 시스템 라이브러리, OS 설정 등 전체\n\n\n무게\n매우 가볍고 빠름 (러스트 기반)\n상대적으로 무거움 (이미지 크기 수백 MB~GB)\n\n\n시작 속도\n즉시 (초 단위)\n컨테이너 시작 필요 (초~분)\n\n\n학습 곡선\n낮음 (pip/venv 익숙하면 쉬움)\n높음 (Dockerfile, 이미지, 컨테이너 개념)\n\n\n사용 시나리오\n로컬 파이썬 개발\n복잡한 멀티 언어 프로젝트, 배포, CI/CD\n\n\n시스템 의존성\n시스템 라이브러리에 의존\n시스템과 완전 독립\n\n\n\n\n\n\n\n표 5.1: uv와 도커 환경 격리 도구 비교\n\n\n\n\n5.4.3 언제 무엇을 사용하나?\nuv로 충분한 경우:\n순수 파이썬 패키지만 사용하는 프로젝트는 uv로 완벽히 재현 가능하다.\n# 예: 웹 개발, 데이터 분석 기본\npandas, requests, fastapi, pydantic, numpy, scikit-learn\n이런 패키지는 시스템 라이브러리 의존성이 없거나 최소화되어, uv가 파이썬 버전과 패키지만 관리해도 어떤 시스템에서든 동일하게 작동한다.\n도커가 필요한 경우:\n시스템 라이브러리 의존성이 있는 패키지는 도커 권장이다.\n# 예: 컴퓨터 비전, 데이터베이스, 지리정보\nopencv-python     # C++ 라이브러리 (OpenCV)\npsycopg2          # PostgreSQL 라이브러리\nGDAL              # 지리정보 시스템 라이브러리\n이런 패키지는 OS의 시스템 라이브러리가 필요하므로, 도커로 OS부터 완전히 격리하는 것이 안전하다.\n둘 다 사용: 도커 컨테이너 안에서 uv를 사용해 파이썬 패키지를 관리하는 것도 가능하다. 도커로 시스템 라이브러리 환경을 구축하고, uv로 파이썬 패키지를 빠르게 관리하는 조합이다.\n결론: 순수 파이썬 프로젝트는 uv로 시작하고, 시스템 의존성이 생기면 도커를 고려한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-languages",
    "href": "ide_setup.html#sec-setup-languages",
    "title": "5  개발 환경 구축",
    "section": "\n5.5 코딩 언어 설치",
    "text": "5.5 코딩 언어 설치\nR은 통계 분석, 데이터 시각화, 학술 연구 분야에서 전통적 강점을 가진다. ggplot2 같은 강력한 시각화 라이브러리와 수많은 통계 패키지는 R의 큰 자산이다.\n반면 파이썬은 머신러닝, 딥러닝, 웹 개발, 시스템 자동화 등 범용성과 확장성에서 뛰어나다. TensorFlow, PyTorch 같은 딥러닝 프레임워크와 방대한 커뮤니티를 자랑한다.\n두 언어는 경쟁 관계이기도 하지만, 서로의 단점을 보완하는 강력한 상보 관계이기도 하다. R로 데이터를 깊이 있게 탐색하고 시각화한 후, 파이썬으로 복잡한 머신러닝 모델을 구축하거나 서비스로 배포하는 워크플로우는 매우 효과적이다. 현대 데이터 과학자에게 두 언어 모두를 능숙하게 다루는 능력은 큰 경쟁력이 된다.\n\n5.5.1 R 설치 및 환경 관리\nR 설치\nR은 CRAN(The Comprehensive R Archive Network) 공식 네트워크로 배포된다.\nCRAN 공식 웹사이트에 접속해 자신의 운영체제(리눅스, 맥OS, 윈도우)에 맞는 R 설치 파일을 다운로드하고 실행한다. 설치 과정에서는 대부분 기본 설정을 유지하는 것이 좋다.\n\n참고: RStudio나 Positron은 R을 실행하기 위한 IDE일 뿐, R 자체는 아니다. IDE 사용 전에 반드시 시스템에 R 언어가 먼저 설치되어 있어야 한다.\n\nR 환경 관리: renv\n프로젝트마다 사용하는 R 패키지 버전이 다르면 충돌이 발생할 수 있다. renv는 프로젝트별로 독립된 패키지 라이브러리를 만들어 의존성 문제를 해결하는 도구다.\n중요한 제한사항: renv는 R 패키지만 격리한다. R 인터프리터(언어 실행기) 자체는 시스템에 설치된 것을 공유해 사용한다. renv.lock 파일에 “R 버전 4.3.0”이라고 기록은 하지만, 해당 R 버전이 시스템에 없으면 설치해주지 않고 경고만 표시한다. R 버전까지 완전히 격리하려면 rig (R Installation Manager) 같은 별도 도구와 함께 사용해야 한다.\n이는 파이썬 uv와의 큰 차이다. uv는 uv python install 3.11 명령으로 파이썬 인터프리터 자체를 다운로드하고 관리하지만, renv는 그런 기능이 없다.\n설치 및 사용:\nR 콘솔에서 install.packages(\"renv\")를 실행해 설치한다. RStudio나 Positron에서 새로운 프로젝트를 시작할 때 renv 사용 옵션을 체크하면 프로젝트 폴더에 renv 관련 파일이 생성된다. renv::snapshot()으로 패키지 목록과 버전을 기록하고, renv::restore()로 다른 환경에서 복원한다.\nrig + renv 조합으로 완전한 격리:\nR 버전까지 완전히 격리하려면 rig (R Installation Manager)와 renv를 함께 사용한다. 먼저 rig GitHub에서 운영체제에 맞는 설치 프로그램을 다운로드한다. rig add 4.3.0 명령으로 원하는 R 버전을 설치하고, rig default 4.3.0 또는 .Rprofile 파일로 프로젝트별 R 버전을 고정한다. 이후 renv로 패키지를 관리하면 파이썬 uv처럼 런타임(R 인터프리터)과 패키지 모두 프로젝트별로 격리할 수 있다.\n\n\n\n\n\n그림 5.5: uv vs rig + renv: 런타임 격리 방식 비교\n\n\n\n5.5.2 파이썬 설치 및 환경 관리\n파이썬 설치\n파이썬 설치 방법은 크게 두 가지다.\n공식 파이썬 설치 프로그램 사용 (권장): 파이썬 공식 웹사이트에 접속해 최신 안정화 버전을 다운로드한다. 윈도우 설치 시 첫 화면에서 “Add Python.exe to PATH” 옵션을 반드시 체크해야 터미널에서 python 명령어를 바로 사용할 수 있다. 이 방법은 가장 깔끔하고 표준적인 파이썬 환경을 제공한다.\n아나콘다(Anaconda) 배포판 사용: 아나콘다 배포판은 파이썬 자체뿐 아니라 numpy, pandas, scikit-learn 등 수백 개의 데이터 과학 패키지를 함께 묶어 제공한다. 초보자에게는 편리할 수 있지만, 시스템 환경을 복잡하게 만들 수 있고 용량이 크다는 단점이 있다. 이 책에서는 공식 파이썬 설치를 기준으로 설명한다.\n파이썬 환경 관리: uv\n과거에는 pip로 패키지를 설치하고 venv로 가상 환경을 만드는 등 여러 도구를 조합해야 했지만, 최근에는 uv라는 차세대 통합 도구가 등장해 파이썬 개발 환경 관리가 훨씬 빠르고 간편해졌다. uv는 러스트(Rust)로 작성되어 기존 도구보다 수십 배에서 수백 배 빠른 속도를 자랑한다.\nuv 설치: 터미널에서 운영체제에 맞는 명령어를 실행해 uv를 설치한다. 맥OS/리눅스에서는 curl -LsSf https://astral.sh/uv/install.sh | sh를, 윈도우 파워셸(PowerShell)에서는 powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"를 실행한다.\n가상 환경 생성: 프로젝트 폴더로 이동한 후 터미널에서 uv venv 명령어를 실행하면 .venv라는 폴더에 가상 환경이 생성된다.\n가상 환경 활성화: 윈도우에서는 .\\.venv\\Scripts\\activate를, 맥OS/리눅스에서는 source .venv/bin/activate를 실행한다. 활성화되면 터미널 프롬프트 앞에 (.venv)와 같은 표시가 나타난다.\n패키지 설치: 가상 환경이 활성화된 상태에서 uv pip install 명령어로 패키지를 매우 빠르게 설치할 수 있다. 예를 들어 uv pip install pandas scikit-learn 명령으로 pandas와 scikit-learn을 설치하거나, uv pip install -r requirements.txt 명령으로 requirements.txt 파일로부터 패키지를 설치한다.\n작업이 끝나면 터미널에서 deactivate 명령어를 실행해 가상 환경을 비활성화한다.\n설치 확인: 다음 명령어로 uv가 정상 설치되었는지 확인한다:\n$ uv --version\nuv 0.1.18\n\n$ uv pip list\nPackage    Version\n---------- -------\npip        24.0\nsetuptools 69.0.3",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-ide",
    "href": "ide_setup.html#sec-setup-ide",
    "title": "5  개발 환경 구축",
    "section": "\n5.6 통합 개발 환경 설치",
    "text": "5.6 통합 개발 환경 설치\n\n5.6.1 Positron IDE 설치\nPositron은 R과 파이썬을 모두 지원하는 차세대 데이터 과학 IDE다. VS Code 기반의 현대적인 인터페이스와 RStudio의 강력한 데이터 과학 기능을 결합하여 두 언어를 함께 사용하는 데이터 과학자에게 최적화된 환경을 제공한다.\nPositron 다운로드에서 운영체제(윈도우, 맥OS, 리눅스)에 맞는 설치 프로그램을 다운로드한다. Positron은 현재 베타 버전이므로 최신 정보를 확인하는 것이 중요하다. 다운로드한 파일을 실행하고 안내에 따라 설치를 진행한다. 대부분 경우 기본 설정을 따르는 것이 좋다.\nPositron은 R과 파이썬 인터프리터를 함께 사용한다. 설치 후 Positron을 실행하여 Tools → Global Options 또는 Preferences에서 R 및 파이썬 인터프리터 경로가 올바르게 설정되었는지 확인한다. 이를 통해 Positron이 시스템에 설치된 R 및 파이썬 환경을 정확히 인식하고 활용할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-quarto",
    "href": "ide_setup.html#sec-setup-quarto",
    "title": "5  개발 환경 구축",
    "section": "\n5.7 문학적 프로그래밍",
    "text": "5.7 문학적 프로그래밍\nPositron IDE는 쿼토를 잘 지원하지만, 쿼토의 모든 기능을 활용해 다양한 포맷(특히 PDF)으로 문서를 렌더링하려면 몇 가지 추가 도구가 필요할 수 있다.\n판독(Pandoc): 쿼토는 문서 변환의 핵심 엔진으로 판독을 사용한다. 대부분 경우 쿼토 설치 시 판독이 함께 번들되어 제공되므로 별도로 설치할 필요는 없다. 터미널에서 pandoc --version 명령어를 실행해 설치 여부와 버전을 확인할 수 있다.\n\\(\\LaTeX\\) 배포판 (PDF 출력을 위해 필수): 쿼토로 PDF 문서를 생성하려면 \\(\\LaTeX\\) 배포판이 시스템에 설치되어 있어야 한다. 쿼토는 자동으로 TinyTEX을 설치할 수 있도록 지원하며, 이는 가장 권장되는 방법이다. R 콘솔 또는 Positron의 터미널에서 다음 명령어를 실행해 TinyTEX을 설치한다:\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\nTinyTEX 대신 MiKTEX(윈도우)나 TEX Live(리눅스/맥OS) 같은 다른 \\(\\LaTeX\\) 배포판을 설치할 수도 있다. 하지만 TinyTEX이 가장 가볍고 쿼토와 통합이 용이하다.\n쿼토 CLI 설치 확인: Positron 자체에 쿼토 기능이 통합되어 있더라도 터미널에서 쿼토 명령어를 직접 사용하려면 쿼토 CLI가 설치되어 있어야 한다. 쿼토 공식 웹사이트에서 설치하거나 quarto install 명령어를 통해 설치할 수 있다. Positron이 쿼토를 번들하는 경우도 많으므로 먼저 quarto --version으로 확인하는 것이 좋다.\n설정 확인: 쿼토 관련 설정이 모두 완료되면 터미널에서 quarto check 명령어를 실행해 필요한 도구들이 올바르게 설정되었는지 진단할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-fonts",
    "href": "ide_setup.html#sec-setup-fonts",
    "title": "5  개발 환경 구축",
    "section": "\n5.8 개발 글꼴",
    "text": "5.8 개발 글꼴\n개발자가 마주하는 폰트 환경은 세 가지로 나뉜다. 코드 편집기와 터미널에서는 고정폭(monospace) 폰트가 필수다. 웹이나 앱의 UI를 디자인할 때는 시스템과 조화를 이루는 가변폭 산세리프 폰트를 사용한다. 기술 문서나 블로그처럼 장문을 다룰 때는 장시간 읽기에 적합한 폰트가 필요하다.\n\n\n\n\n\n그림 5.6: 개발자 폰트 생태계\n\n\n그림 5.6 은 개발자 폰트 생태계를 용도별로 정리한다. 코딩 환경에서는 JetBrains Mono, Fira Code, D2코딩이 대표적이다. 특히 D2코딩은 한글 가독성이 뛰어나 한국 개발자에게 필수로 꼽힌다. 웹과 앱 UI에서는 프리텐다드가 한국 웹 표준으로 자리잡았고, 글로벌 환경에서는 Inter가 널리 쓰인다. 구글의 Noto Sans CJK는 “No more Tofu”라는 슬로건 아래 800개 이상의 언어를 지원하며, 폰트 깨짐 없는 다국어 환경을 제공한다. 문서 작성에서는 Noto 패밀리가 Sans, Serif, Mono 전방위로 활약하며, IBM Plex Sans나 마루부리 같은 폰트도 기술 블로그와 출판물에 자주 등장한다.\nNoto 프로젝트는 구글이 시작한 범세계적 폰트 이니셔티브다. “Tofu”는 폰트가 없어서 나타나는 □ 문자를 의미하는데, Noto는 이 문제를 해결하고자 탄생했다. 한글, 중국어, 일본어를 포함한 CJK(Chinese, Japanese, Korean) 언어부터 아랍어, 히브리어, 태국어까지 모든 문자를 하나의 통일된 디자인으로 제공한다. 개발자가 다국어 환경을 구축할 때 Noto 패밀리를 사용하면 언어별로 폰트를 따로 관리할 필요 없이 일관된 타이포그래피를 유지할 수 있다.\n\n5.8.1 D2코딩 폰트 설치\n개발 환경에서 폰트를 사용하려면 두 단계를 거친다. 먼저 폰트를 운영체제에 설치하고, 그 다음 IDE 설정에서 해당 폰트를 지정한다. D2코딩은 한글과 영문이 조화롭게 어우러지도록 설계된 모노스페이스 폰트로, 한국 개발자에게 가장 많이 쓰인다.\nD2코딩 GitHub 릴리즈 페이지에서 최신 zip 파일을 다운로드한 뒤 압축을 풀면 .ttf 파일이 나타난다. 이 파일을 더블 클릭하면 윈도우에서는 ‘설치’ 버튼이, 맥OS에서는 ‘서체 설치’ 버튼이 나타난다. 버튼을 클릭하면 시스템 전체에서 D2코딩 폰트를 사용할 수 있게 된다.\n시스템 설치가 끝나면 IDE에서 이 폰트를 지정한다. Positron이나 VS Code에서 Cmd/Ctrl + ,로 설정을 열고 font family를 검색한다. ‘Editor: Font Family’ 항목의 맨 앞에 'D2Coding',을 추가하면 코드 편집기가 D2코딩을 최우선으로 사용한다. 예를 들어 다음과 같은 형태가 된다:\n'D2Coding', \"Apple SD Gothic Neo\", \"Malgun Gothic\", monospace\n폰트 목록의 맨 앞에 배치한 이유는 간단하다. IDE는 목록 순서대로 폰트를 찾아 사용하므로, D2코딩이 설치되어 있으면 이 폰트로 표시하고, 없으면 다음 폰트로 넘어간다. 설정을 저장하면 편집기 화면이 즉시 D2코딩으로 바뀐다.\n\n5.8.2 프리텐다드 가변 글꼴\n프리텐다드는 D2코딩과 달리 웹 환경을 위해 설계된 가변 글꼴이다. 가변 폰트(Variable Font)는 하나의 파일에 여러 weight(두께)를 담는 기술로, 프리텐다드는 Thin(100)부터 Black(900)까지 9단계를 지원한다. 한글, 영문, 일본어를 모두 포괄하며, 윈도우와 맥OS, 리눅스에서 일관된 렌더링을 보장한다. 특히 쿼토로 생성한 HTML 문서나 GitHub Pages, 기술 블로그처럼 웹에 게시되는 콘텐츠에서 시스템 폰트의 한계를 넘어서는 가독성을 제공한다.\n프리텐다드는 사용 목적에 따라 두 가지 방식으로 설치한다. 프리텐다드 GitHub 릴리즈에서 zip 파일을 다운로드하면 여러 형식의 폰트 파일이 들어 있다. IDE나 데스크톱 애플리케이션에서 사용하려면 public/static 폴더의 OTF나 TTF 파일을 시스템에 설치한다. D2코딩과 같은 방식이다.\n웹 페이지에 직접 삽입하려면 web/variable 폴더의 WOFF2 파일을 사용한다. 쿼토 프로젝트의 _quarto.yml이나 CSS 파일에서 @font-face로 선언하면 방문자의 시스템에 폰트가 없어도 웹 페이지에서 프리텐다드를 표시할 수 있다:\n@font-face {\n  font-family: 'Pretendard';\n  src: url('fonts/PretendardVariable.woff2') format('woff2-variations');\n  font-weight: 100 900;\n}\n\nbody {\n  font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif;\n}\n웹 폰트로 사용하면 모든 플랫폼의 방문자에게 일관된 타이포그래피를 제공할 수 있다. 시스템 폰트는 사용자의 OS에 따라 달라지지만, 웹 폰트는 제작자가 의도한 대로 정확히 표시된다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-verify",
    "href": "ide_setup.html#sec-setup-verify",
    "title": "5  개발 환경 구축",
    "section": "\n5.9 개발 환경 검증",
    "text": "5.9 개발 환경 검증\n지금까지 포지트론 IDE부터 시작해 R과 파이썬, Git과 도커, 워크플로우 자동화 도구(make, targets, 스네이크메이크, Task), 쿼토 출판 시스템, 개발 글꼴(D2코딩, 프리텐다드)까지 현대 데이터 과학 환경의 핵심 요소들을 설치했다. 각 도구는 독립적으로 작동하지만, 함께 사용할 때 시너지를 발휘한다. 포지트론에서 R 코드로 데이터를 분석하고, targets로 워크플로우를 자동화하며, 쿼토로 결과를 문서화하고, Git으로 버전을 관리하는 통합 환경이 완성된 것이다. 설치가 제대로 되었는지 확인하는 것이 다음 단계다.\n핵심 도구들의 설치 여부를 터미널에서 한번에 확인할 수 있다:\n$ git --version && docker --version && make --version | head -1 && R --version | head -1 && python --version && uv --version\ngit version 2.39.2 (Apple Git-143)\nDocker version 24.0.6, build ed223bc\nGNU Make 3.81\nR version 4.3.0 (2023-04-21) -- \"Already Tomorrow\"\nPython 3.11.5\nuv 0.1.18\n모든 명령어가 버전 정보를 출력하면 기본 환경 구축이 완료된 것이다. 워크플로우 자동화 도구는 필요에 따라 선택적으로 확인한다. R 프로젝트라면 R 콘솔에서 library(targets)를 실행해 targets 패키지가 로드되는지 확인하고, Python 생물정보학 프로젝트라면 snakemake --version으로 스네이크메이크 설치를 점검한다. 범용 빌드 도구인 Task를 설치했다면 task --version으로 확인한다.\n개발 글꼴도 IDE 설정에서 확인한다. 포지트론이나 VS Code의 설정(Cmd/Ctrl + ,)에서 ’Font Family’를 검색하면 D2코딩이나 프리텐다드가 목록 맨 앞에 있는지 확인할 수 있다. 코드 편집기에서 한글과 영문이 조화롭게 표시되면 글꼴 설정이 올바른 것이다.\n모든 검증이 완료되면 포지트론을 실행하고 R과 파이썬 인터프리터 경로를 설정해 첫 데이터 과학 프로젝트를 시작할 준비가 된다.\n💡 생각해볼 점\n개발 환경 구축은 한 번에 완성되지 않는다. Git, Docker, R, Python, Positron, Quarto, 워크플로우 자동화, 개발 글꼴까지 나열된 도구들을 보면 압도될 수 있지만, 모든 것을 한 번에 설치할 필요는 없다. 프로젝트 성격에 따라 점진적으로 추가하는 것이 효율적이다.\n첫 데이터 분석 프로젝트라면 Positron과 R 또는 Python 하나만 설치하고 시작하자. CSV 파일을 열고, 간단한 전처리를 하며, ggplot2나 matplotlib로 그래프를 그려보자. 프로젝트가 커지면서 버전 관리가 필요해지면 Git을 추가한다. 팀원과 협업하거나 재현 가능성이 중요해지면 Docker를 도입한다. 분석 보고서를 작성할 때가 되면 Quarto와 TinyTeX를 설치한다.\n환경 격리 도구 선택은 프로젝트 복잡도로 판단한다. 순수 Python 패키지만 사용하는 데이터 분석이라면 uv로 충분하다. pandas, scikit-learn, matplotlib만으로 대부분의 분석이 가능하다. 하지만 OpenCV(컴퓨터 비전), PostgreSQL(데이터베이스), GDAL(공간 데이터) 같은 시스템 라이브러리가 필요하거나, R과 Python을 함께 사용하는 멀티 언어 프로젝트라면 Docker가 더 안전하다.\nR 사용자는 특별히 주의해야 한다. renv는 패키지만 격리하고 R 버전은 격리하지 않는다. Python의 uv가 uv python install 3.11로 런타임까지 관리하는 것과 대조적이다. R 버전까지 완전히 격리하려면 rig + renv 조합을 사용하거나, 아예 Docker로 R 버전부터 시스템까지 모두 패키징하는 것이 확실하다.\n개발 글꼴은 생산성에 직접적 영향을 준다. D2코딩 하나만 설치해도 한글과 영문이 조화로운 코딩 환경을 얻는다. 1(숫자)과 l(소문자 L), 0(숫자)과 O(대문자 o)를 명확히 구분할 수 있는 글꼴은 버그를 줄이고 눈의 피로를 덜어준다.\n지금 구축한 환경은 “완벽”이 아니라 “시작점”이다. 다음 장부터는 실전 프로젝트를 진행하면서 부족한 부분을 발견하고, 필요한 도구를 추가하며, 자신만의 최적 워크플로우를 만들어간다. Git으로 실험을 추적하고, Quarto로 분석을 문서화하며, Docker로 환경을 공유하는 과정에서 각 도구의 가치를 체감하게 된다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-kernel",
    "href": "ide.html#sec-ide-kernel",
    "title": "1  IDE 선택과 발전",
    "section": "1.2 IDE 작동 원리: 커널 아키텍처",
    "text": "1.2 IDE 작동 원리: 커널 아키텍처\n60년 역사를 거치며 진화한 IDE는 어떤 구조로 파이썬, R, Julia, SQL 등 수십 가지 언어를 동시에 지원하는가? 비결은 커널(Kernel) 아키텍처에 있다.\n주피터(Jupyter) 프로젝트에서 시작해 이제는 많은 IDE 표준이 된 커널 아키텍처는 IDE(프론트엔드)와 언어 실행 엔진(백엔드)을 명확히 분리한다. 프론트엔드는 개발자가 코드를 입력하는 UI 부분이다. 주피터 노트북의 코드 셀이나 VS Code의 인터랙티브 창이 여기 해당한다. 프론트엔드 자체는 코드 실행 능력이 없고, 사용자가 입력한 코드를 커널에 전달하는 메신저 역할만 한다.\n실제 코드 실행은 커널이 담당한다. 커널은 별도 독립 프로세스로 백그라운드에서 동작한다. 파이썬 코드를 실행하면 IPython 커널이, R 코드를 실행하면 IRkernel이 작동하며, 프론트엔드로부터 받은 코드를 해당 언어 인터프리터로 실행한다. 프론트엔드와 커널은 ZeroMQ(ZMQ) 고성능 메시징 라이브러리로 통신한다. 메시지 종류와 형식은 주피터 메시징 프로토콜로 표준화되어 있다.\n주요 메시지 4가지가 있다. execute_request로 프론트엔드가 코드 실행을 요청하면, 커널은 실행 과정에서 stream으로 print() 같은 텍스트 출력을 실시간 전송하고, display_data로 그래프, 이미지, 표를 특정 포맷(image/png, text/html)으로 포장해 보낸다. 모든 실행이 끝나면 execute_reply로 완료결과를 전송한다.\n커널 아키텍처의 가장 큰 장점은 확장성이다. 새로운 언어를 지원하려면 주피터 메시징 프로토콜을 따르는 커널만 만들면 된다. IDE 프론트엔드는 수정할 필요가 없다. 주피터 생태계가 수백 개 언어 커널을 가질 수 있고, VS Code가 파이썬 확장 프로그램 하나로 복잡한 데이터 과학 워크플로우를 지원하는 비결이 여기 있다. 언어 서버 프로토콜(LSP, Language Server Protocol)이 언어 ‘분석’ 기능을 분리하고 표준화한 것처럼, 커널 아키텍처는 언어 ‘실행’ 기능을 분리하고 표준화해 놀라운 유연성과 확장성을 제공한다.\n\n\n\n\n\n\n그림 1.3: 커널 아키텍처 - 프론트엔드와 실행 엔진의 분리\n\n\n\n그림 1.3 는 IDE 프론트엔드(사용자 인터페이스)와 커널(언어 실행 엔진) 분리 구조와 ZeroMQ, 주피터 메시징 프로토콜을 통한 통신을 보여준다. 이러한 분리 덕분에 하나의 IDE가 여러 프로그래밍 언어를 지원한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-install",
    "href": "ide_positron.html#sec-positron-install",
    "title": "2  포지트론",
    "section": "\n2.3 포지트론 설치",
    "text": "2.3 포지트론 설치\n포지트론을 설치하기 전에 시스템이 최소 요구사항을 충족하는지 확인한다. 윈도우(Windows) 10 이상, 맥OS(macOS) 11 이상, 리눅스(Linux)(우분투(Ubuntu) 20.04+)를 지원한다. 메모리는 최소 4GB지만 8GB 이상을 권장한다. 디스크 여유 공간은 500MB 이상 필요하다. R 버전은 4.0 이상, 파이썬(Python) 버전은 3.8 이상이 필요하며, 각각 4.3+와 3.11+를 권장한다.\n포지트론은 포짓 공식 웹사이트에서 무료로 다운로드할 수 있다. https://positron.posit.co에 접속해 운영체제에 맞는 설치 파일을 받는다. 맥OS는 .dmg 파일을 열고 Applications 폴더로 드래그한다. 윈도우는 .exe 설치 파일 실행 후 기본 설정으로 진행한다. 리눅스는 .deb 또는 .rpm 패키지를 설치한다.\n첫 실행 시 초기 설정 마법사가 나타난다. R과 파이썬 인터프리터를 자동으로 감지하며, 없다면 설치를 안내한다. 인터프리터 경로가 자동으로 감지되지 않으면 수동으로 지정할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-features",
    "href": "ide_positron.html#sec-positron-features",
    "title": "2  포지트론",
    "section": "\n2.4 주요 기능 활용 사례",
    "text": "2.4 주요 기능 활용 사례\n포지트론 핵심 기능을 실제 데이터 과학 워크플로우에서 어떻게 활용하는지 살펴보자. 다언어 콘솔 전환부터 변수 탐색기, AI 어시스턴트까지 세 가지 핵심 기능을 통해 포지트론이 제공하는 생산성 향상을 직접 경험할 수 있다.\n\n2.4.1 다언어 콘솔 전환\n포지트론 핵심 강점은 R과 파이썬을 즉시 전환하며 작업하는 것이다. 화면 하단 콘솔 영역 오른쪽 상단에 언어 선택 드롭다운이 있다. 여기서 “R” 또는 “Python”을 선택하면 즉시 해당 언어의 REPL(Read-Eval-Print Loop) 환경으로 전환된다.\n데이터 과학에서 가장 흔한 사례를 살펴보자. R 콘솔에서 ggplot2로 시각화를 그린다. 파이썬 콘솔로 전환해 scikit-learn으로 머신러닝 모델을 훈련한다. 다시 R로 전환해 통계 모델을 검증한다. 세션 전환 없이 모든 작업이 동일 IDE 내에서 이뤄진다.\n\n2.4.2 변수 탐색기\n화면 오른쪽 사이드바에 변수 탐색기가 있다. 현재 실행 중인 R/파이썬 세션 모든 변수, 데이터프레임, 리스트를 실시간으로 보여준다. 데이터프레임 이름을 클릭하면 테이블 뷰어가 열린다. 데이터 정렬, 필터링, 열 타입 확인이 가능하다. 대용량 데이터(수백만 행)도 가상화 기술로 빠르게 탐색할 수 있다.\n\n2.4.3 AI 어시스턴트 사용법\n포지트론 AI 어시스턴트는 단순한 코드 자동완성을 넘어 세션 상태를 이해하는 지능형 도우미다. 현재 메모리에 로드된 데이터, 설치된 패키지, 변수 구조를 직접 파악하기 때문에 자연어 요청만으로도 즉시 실행 가능한 코드를 생성한다.\n\n\n\n\n\n그림 2.2: 포지트론 AI 워크플로우 - 세션 상태 인식 기반 코드 생성\n\n\n그림 2.2 는 포지트론 AI 어시스턴트 작동 방식을 보여준다. 사용자가 자연어로 요청하면, AI는 현재 R/파이썬 세션의 메모리 데이터, 설치된 패키지, 변수 구조를 직접 파악할 수 있다. 파악된 정보를 바탕으로 즉시 실행 가능한 코드를 생성하고, 실행 결과를 플롯 창에 시각화한다. 일반 AI 챗봇과 달리 세션 상태를 알기 때문에 “penguins가 무엇인지” 따로 설명할 필요가 없다.\n자연어 요청 예시를 살펴보자. “mtcars 데이터셋에서 mpg와 wt의 상관관계를 산점도로 그려줘”라고 입력하면, AI는 다음 R 코드를 자동생성한다.\nlibrary(ggplot2)\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"MPG vs Weight\",\n       x = \"Weight (1000 lbs)\",\n       y = \"Miles per Gallon\")\nAI는 현재 메모리에 mtcars가 로드되어 있는지 확인하고, ggplot2 패키지가 설치되었는지 검증한 후 코드를 생성한다. 바로 실행하면 플롯 창에 결과가 나타난다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-shortcuts",
    "href": "ide_positron.html#sec-positron-shortcuts",
    "title": "2  포지트론",
    "section": "\n2.6 키보드 단축키",
    "text": "2.6 키보드 단축키\nPositron은 VS Code 단축키를 대부분 상속하며, 데이터 과학 전용 단축키를 추가했다.\n\n\n기능\nmacOS\nWindows/Linux\n\n\n\n명령 팔레트\nCmd+Shift+P\nCtrl+Shift+P\n\n\nAI 어시스턴트\nCmd+Shift+A\nCtrl+Shift+A\n\n\n파일 찾기\nCmd+P\nCtrl+P\n\n\n코드 실행 (현재 줄)\nCmd+Enter\nCtrl+Enter\n\n\n코드 실행 (선택 영역)\nCmd+Shift+Enter\nCtrl+Shift+Enter\n\n\n변수 탐색기 열기\nCmd+Shift+V\nCtrl+Shift+V\n\n\n플롯 창 열기\nCmd+Shift+G\nCtrl+Shift+G\n\n\n터미널 열기\nCtrl+`\nCtrl+`",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-migration",
    "href": "ide_positron.html#sec-positron-migration",
    "title": "2  포지트론",
    "section": "\n2.5 RStudio에서 포지트론 전환",
    "text": "2.5 RStudio에서 포지트론 전환\nRStudio를 오랫동안 사용해온 데이터 과학자라면 포지트론 전환이 생각보다 자연스럽다. 두 IDE 모두 데이터 과학자를 염두에 두고 포짓에서 개발했기 때문에 화면 레이아웃 구성이 유사하고, 익숙한 단축키도 대부분 그대로 작동한다. RStudio에서 쌓아온 작업 습관을 버리지 않고도 포지트론 다언어 지원과 AI 통합 기능을 즉시 무리없이 활용할 수 있다.\n\n\n\n\n\n그림 2.3: 포지트론 vs RStudio 레이아웃 비교\n\n\n그림 2.3 는 RStudio와 포지트론의 화면 레이아웃 차이를 보여준다. RStudio는 4개 패널(Source, Console, Environment, Files)로 R 중심 워크플로우에 최적화되어 있다. 포지트론은 VS Code 기반으로 왼쪽 탐색기, 중앙 편집기, 오른쪽 변수/플롯 패널, 하단 콘솔 구조를 가지며, 콘솔에서 R과 파이썬을 드롭다운으로 즉시 전환할 수 있다.\n포지트론 설치 후 기존 R 프로젝트 폴더를 연다. .Rproj 파일이 있다면 자동으로 프로젝트로 인식한다. R 콘솔에서 renv::restore()로 패키지 복원한다. 단축키 설정을 “RStudio” 프리셋으로 변경할 수 있다(설정 → Keybindings → “RStudio”).\n현재(2025년 베타) 포지트론은 일부 기능이 아직 구현되지 않았다. R Markdown 프로파일링(메모리, 성능 분석), Shiny 앱 배포 버튼(shinyapps.io, Posit Connect), R 패키지 개발 전용 도구(devtools 통합), .Rproj 설정 일부 옵션이 개발중에 있다.\n포지트론은 아직 베타 버전이며 RStudio 일부 기능(예: R Markdown 프로파일링, 간편한 앱 배포)이 아직 완전히 구현되지 않았다는 한계가 있다. 하지만 R과 파이썬이 공존하는 현대 데이터 과학 흐름을 가장 잘 반영하고, AI를 개발 워크플로우 핵심으로 가져왔다는 점에서 미래가 기대된다.\n포지트론은 단순히 새로운 도구가 아니다. 포짓 팀이 생각하는 미래 데이터 과학 작업 환경의 구체적 실험이다. AI와 함께 더 빠르고 깊이 있게 데이터 문제를 해결하고 싶은 데이터 과학자라면, 포지트론은 여정을 함께할 흥미로운 파트너가 될 수 있다.\n💡 생각해볼 점\n포지트론은 AI가 촉발시킨 데이터 과학 워크플로우의 근본적 변화를 반영한다. 과거에는 “R 또는 파이썬” 중 하나를 선택해야 했지만, 이제는 “R과 파이썬 모두”를 사용하는 것이 표준이 되었다. 포지트론은 이러한 변화를 받아들이고, 두 언어를 동등하게 지원하며, AI로 생산성을 극대화하는 첫 번째 IDE 중 하나다.\n전환은 점진적으로 시작한다. 작은 EDA 프로젝트에서 포지트론을 시도해보자. R로 통계 분석을 하다가 파이썬 scikit-learn이 필요하면 콘솔을 전환한다. AI 어시스턴트에게 자연어로 요청하고, 생성된 코드를 즉시 실행한다. 이러한 과정을 몇 번 반복하면 포지트론 없이는 일하기 힘들어진다.\n다음 장에서는 포지트론의 진정한 힘을 발휘하는 확장 프로그램(extension) 설치와 설정을 다룬다. 포지트론 기본 설치만으로는 부족하며, R과 파이썬 언어 서버, 쿼토, 린터 등 필수 확장 프로그램을 설치해야 완전한 개발 환경이 갖춰진다. 이론을 넘어 실제로 작동하는 포지트론 환경을 구축한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#footnotes",
    "href": "ide_positron.html#footnotes",
    "title": "2  포지트론",
    "section": "",
    "text": "일급 시민(first-class citizen)은 시스템에서 완전한 지원을 받는 대상을 의미한다. 포지트론에서 R과 파이썬 모두 동등하게 완전한 기능을 제공받으며, 어느 한쪽이 부차적으로 취급되지 않는다.↩︎",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-positron-extensions",
    "href": "ide_extension.html#sec-positron-extensions",
    "title": "3  IDE 확장 프로그램",
    "section": "3.2 포지트론 필수 확장 프로그램",
    "text": "3.2 포지트론 필수 확장 프로그램\n포지트론이 데이터 과학 IDE로서 진정한 힘을 발휘하려면 핵심 확장 프로그램들을 설치해야 한다. 포지트론은 VS Code 기반이므로 VS Code 확장 생태계를 그대로 활용하면서, 데이터 과학에 특화된 확장들을 추가로 제공한다.\n\n\n\n\n\n\n노트Positron vs VS Code: 내장 기능 차이\n\n\n\nPositron IDE는 R (Ark Kernel), Python, Jupyter 기능이 이미 내장되어 있다. VS Code 사용자는 이 확장들을 별도로 설치해야 하지만, Positron 사용자는 설치 없이도 즉시 사용할 수 있다. 아래 목록에서 “* Positron 내장” 표시가 있는 확장은 Positron에서 이미 제공되므로, VS Code에서만 추가 설치가 필요하다.\n\n\n\n\n\n\n\n\n그림 3.3: 포지트론 데이터 과학 확장 프로그램 생태계\n\n\n\n그림 3.3 는 포지트론에서 실제로 사용하는 15종 핵심 확장 프로그램을 3개 그룹으로 보여준다. 1) 엔진 & 앱 개발: R, Python, Shiny Publisher, Quarto, Thunder Client로 Shiny/Streamlit 앱 개발과 배포를 지원한다. 2) 인터랙티브 데이터 분석: SandDance, Data Wrangler, SQLTools, Geo Data Viewer, Rainbow CSV로 다양한 데이터 탐색과 변환을 수행한다. 3) AI, 협업 & 운영: Jupyter, GitHub Copilot, Live Share, Remote-SSH, Docker로 노트북, AI 코딩, 원격 협업, 컨테이너화를 통합한다.\n\n3.2.1 언어 지원: R & Python\nR (Positron 내장, VS Code: REditorSupport.r)는 R 언어 지원의 핵심이다. Positron은 자체 개발한 Ark Kernel로 R을 실행하며, VS Code보다 훨씬 빠르고 안정적이다. R 언어 서버(LSP)를 통해 코드 자동완성, 함수 시그니처 도움말, 정의로 이동 기능을 제공한다. R 콘솔에서 install.packages(c(\"lintr\", \"styler\"))로 린터와 포맷터를 설치하면, 코드 스타일 문제를 실시간으로 감지하고 tidyverse 스타일로 자동 정리한다.\nPython (Positron 내장, VS Code: ms-python.python)은 파이썬 개발 환경을 완성한다. Pylance 언어 서버로 빠른 타입 체크와 자동완성을 지원하고, venv, conda 환경을 자동 감지한다. 파이썬 디버거는 중단점, 변수 검사, 단계별 실행을 제공한다.\n\n\n3.2.2 앱 배포: Shiny Publisher\nShiny & Publisher (posit.publisher)는 Shiny 앱과 Streamlit 앱을 Posit Connect 또는 shinyapps.io에 원클릭으로 배포한다. 로컬에서 개발한 인터랙티브 대시보드를 프로덕션 환경에 즉시 올리고, 팀원들과 공유하며, 버전 관리와 롤백을 지원한다.\n설치는 “Posit Publisher”를 검색해 설치한다. Shiny 앱 디렉토리에서 Cmd+Shift+P → “Publish Content”를 실행하면 배포 대상(Connect, shinyapps.io)을 선택하고, 계정 인증 후 자동으로 배포된다. 배포 히스토리를 추적하고 이전 버전으로 롤백할 수 있다.\n\n\n3.2.3 API 테스트: Thunder Client\nThunder Client (rangav.vscode-thunder-client)는 Postman처럼 API 엔드포인트를 테스트하는 도구다. R Plumber나 Python FastAPI로 만든 모델 API를 IDE 내에서 바로 테스트한다. GET/POST 요청을 보내고, JSON 응답을 확인하며, 환경 변수를 관리한다.\n설치는 “Thunder Client”를 검색해 설치한다. 좌측 사이드바에 번개 아이콘이 생기며, 클릭하면 REST 클라이언트가 열린다. “New Request” → URL 입력 → Send로 API를 테스트한다. 요청을 컬렉션으로 저장해 재사용한다.\n\n\n3.2.4 문서 작성: Quarto\nQuarto (quarto.quarto)는 재현가능한 데이터 분석 보고서 작성의 핵심이다. .qmd 파일에서 R과 파이썬 코드 청크를 실행하고, 결과를 즉시 미리보기로 확인한다. Render 버튼 클릭으로 HTML, PDF, Word, 슬라이드로 변환한다. 실시간 미리보기는 수정 사항을 즉시 반영하며, 코드, 텍스트, 시각화, 표를 하나의 문서로 엮어 논문, 기술 보고서, 블로그 포스트를 작성한다.\n설치는 확장 마켓플레이스에서 “Quarto”를 검색해 설치한다. .qmd 파일을 열면 자동으로 활성화되며, Cmd+Shift+K (macOS) 또는 Ctrl+Shift+K (Windows/Linux)로 렌더링한다. YAML 헤더에서 출력 형식(format: html, format: pdf)을 지정하고, R/파이썬 코드 청크는 ```{r} 또는 ```{python}로 시작한다.\n\n\n3.2.5 시각적 탐색: SandDance\nSandDance (msrvida.vscode-sanddance)는 마이크로소프트 리서치가 개발한 혁신적인 3D/2D 데이터 시각화 도구다. 코드 없이 데이터를 드래그 앤 드롭으로 탐색하며, 산점도, 바차트, 밀도 플롯을 실시간으로 전환해 데이터 패턴을 발견한다. 수십만 행 데이터도 WebGL로 부드럽게 렌더링한다.\n설치는 “SandDance”를 검색해 설치한다. CSV나 JSON 파일을 우클릭 → “View in SandDance”를 선택하면 인터랙티브 시각화 창이 열린다. 축을 변경하고, 색상을 매핑하며, 필터를 적용해 탐색적 데이터 분석(EDA)을 몇 초 만에 수행한다.\n\n\n3.2.6 데이터베이스: SQLTools\nSQLTools (mtxr.sqltools)는 PostgreSQL, MySQL, SQLite 등 다양한 데이터베이스에 연결해 쿼리를 실행하고 결과를 시각화한다. IDE 내에서 데이터베이스 탐색, 테이블 스키마 확인, SQL 자동완성, 쿼리 히스토리 관리를 수행한다.\n설치는 “SQLTools”를 검색해 설치한다. 좌측 사이드바에 데이터베이스 아이콘이 생기며, “Add New Connection”으로 DB 연결 정보를 입력한다. SQL 파일을 열고 Cmd+E Cmd+E로 쿼리를 실행하면 결과가 테이블로 표시된다.\n\n\n3.2.7 지도 시각화: Geo Data Viewer\nGeo Data Viewer (randomfractals.geo-data-viewer)는 GeoJSON, Shapefile, KML 같은 지리 데이터를 즉시 지도로 시각화한다. 공간 데이터 분석 프로젝트에서 지도를 코드 없이 확인하고, 레이어를 토글하며, 속성을 검사한다.\n설치는 “Geo Data Viewer”를 검색해 설치한다. .geojson 파일을 열면 자동으로 지도가 표시되며, 줌/팬으로 탐색한다. 속성 테이블을 클릭해 각 지형지물의 메타데이터를 확인한다.\n\n\n3.2.8 데이터 탐색: Rainbow CSV\nRainbow CSV (mechatroner.rainbow-csv)는 CSV 파일을 다루는 필수 도구다. CSV 파일을 열면 각 열을 다른 색으로 표시해 가독성을 높인다. SQL 쿼리로 CSV를 탐색하고(SELECT * FROM this WHERE age &gt; 30), 열 정렬, 필터링, 통계 요약을 제공한다. 큰 CSV 파일(수백만 행)도 가상화 기술로 빠르게 열린다.\n설치는 “Rainbow CSV”를 검색해 설치한다. CSV 파일을 열면 자동으로 각 열에 색상이 적용된다. 열 구분자(쉼표, 탭, 파이프 등)를 자동 감지하며, Cmd+Shift+P → “Rainbow CSV: Query”로 SQL 쿼리 모드를 연다. SELECT name, age FROM this WHERE age &gt; 25 ORDER BY age DESC 같은 쿼리로 데이터를 탐색하고, 결과를 새 창에 표시한다.\n\n\n3.2.9 AI 코딩: GitHub Copilot\nGitHub Copilot (GitHub.copilot)은 포지트론에서도 그대로 작동한다. 주석이나 함수 이름을 입력하면 전체 함수 구현을 제안하고, Tab 키로 수락한다. 데이터 과학 코드에 특화되어 ggplot2, dplyr, pandas, scikit-learn 패턴을 잘 이해한다. “결측치 제거하고 표준화”처럼 자연어 주석을 입력하면 즉시 코드를 생성한다.\n설치는 GitHub 계정으로 로그인하고 Copilot 구독이 필요하다. 확장 마켓플레이스에서 “GitHub Copilot”을 설치하고, GitHub 계정으로 인증한다. 회색 텍스트로 표시되는 제안을 Tab으로 수락하고, Esc로 거부한다. Alt+]로 다음 제안을, Alt+[로 이전 제안을 확인한다.\n\n\n3.2.10 데이터 변환: Data Wrangler\nData Wrangler (ms-toolsai.datawrangler)는 데이터 탐색과 변환을 시각적으로 수행하는 마이크로소프트 확장이다. 변수 탐색기에서 데이터프레임을 클릭하고 “Open in Data Wrangler”를 선택하면 그래픽 인터페이스가 열린다. 필터링, 정렬, 그룹화, 피벗 작업을 드래그 앤 드롭으로 수행하고, 모든 작업은 자동으로 R 또는 파이썬 코드로 변환된다.\n설치는 “Data Wrangler”를 검색해 설치한다. 복잡한 전처리 파이프라인을 GUI로 만들고, “Export Code” 버튼으로 dplyr이나 pandas 코드를 생성한다. 코드를 복사해 스크립트에 붙여넣으면 재현 가능한 전처리 워크플로우가 완성된다.\n\n\n3.2.11 노트북: Jupyter\nJupyter (Positron 내장, VS Code: ms-toolsai.jupyter)는 .ipynb 노트북 파일을 네이티브로 실행한다. 코드 셀, 마크다운 셀, 출력 결과를 하나의 문서로 통합하며, 변수 탐색기와 연동해 노트북 실행 중 생성된 변수를 실시간으로 확인한다. Jupyter 커널(IPython, IRkernel)을 자동 감지하고 전환한다.\nPositron은 Jupyter를 내장하므로 별도 설치가 필요 없다. VS Code 사용자는 “Jupyter”를 검색해 설치한다. .ipynb 파일을 열면 자동으로 활성화되며, Shift+Enter로 셀을 실행한다. 상단 커널 선택 드롭다운에서 Python/R 커널을 전환하고, 노트북 결과를 HTML/PDF로 내보낼 수 있다.\n\n\n3.2.12 실시간 협업: Live Share\nLive Share (ms-vsliveshare.vsliveshare)는 실시간 동시 편집을 가능하게 한다. Google Docs처럼 여러 개발자가 동일 코드를 동시에 편집하고, 디버깅 세션을 공유하며, 터미널까지 함께 사용한다. 원격 페어 프로그래밍과 코드 리뷰에 혁명을 일으킨 도구다.\n설치는 “Live Share”를 검색해 설치한다. Cmd+Shift+P → “Live Share: Start Collaboration Session”으로 세션을 시작하고, 공유 링크를 팀원에게 전송한다. 팀원이 링크로 접속하면 실시간으로 코드를 함께 편집하고, 커서 위치와 선택 영역이 실시간으로 동기화된다.\n\n\n3.2.13 원격 개발: Remote-SSH\nRemote - SSH (ms-vscode-remote.remote-ssh)는 고성능 GPU 서버에 SSH로 연결해 원격 개발 환경을 로컬처럼 사용한다. 딥러닝 모델 훈련처럼 고사양 컴퓨팅이 필요한 작업을 원격 서버에서 수행하면서도, IDE는 로컬 컴퓨터에서 부드럽게 작동한다.\n설치는 “Remote - SSH”를 검색해 설치한다. Cmd+Shift+P → “Remote-SSH: Connect to Host”로 서버 정보를 입력한다. 연결되면 좌측 하단에 “SSH: 서버명”이 표시되며, 모든 파일 탐색, 편집, 터미널 명령이 원격 서버에서 실행된다.\n\n\n3.2.14 컨테이너화: Docker\nDocker (ms-azuretools.vscode-docker)는 분석 환경을 컨테이너로 패키징해 재현성을 보장한다. Dockerfile로 R/Python 패키지, 시스템 라이브러리를 정의하면, 어디서나 동일한 환경을 재현할 수 있다. 컨테이너 빌드, 실행, 디버깅을 IDE 내에서 수행한다.\n설치는 “Docker”를 검색해 설치한다. Dockerfile을 우클릭 → “Build Image”로 이미지를 빌드하고, 좌측 사이드바 Docker 아이콘에서 컨테이너를 관리한다. 컨테이너 내부 터미널을 열어 환경을 테스트하고, Docker Compose로 다중 컨테이너를 오케스트레이션한다.\n\n\n3.2.15 확장 설치 및 관리\n포지트론에서 확장을 설치하는 방법은 간단하다. 좌측 사이드바에서 확장 아이콘(네모 4개)을 클릭하고, 검색창에 확장 이름을 입력한다. “Install” 버튼을 누르면 자동으로 다운로드되고 활성화된다.\n데이터 과학자를 위한 필수 확장 15종 (그룹별 설치 권장):\n1) 엔진 & 앱 개발: 1. R (REditorSupport.r) - R 언어 지원, Shiny 실행 2. Python (ms-python.python) - Python 언어, Streamlit 지원 3. Shiny Publisher (posit.publisher) - 앱 배포 (Connect/ShinyApps) 4. Quarto (quarto.quarto) - 재현가능한 문서, 대시보드 5. Thunder Client (rangav.vscode-thunder-client) - API 테스트\n2) 인터랙티브 데이터 분석: 6. SandDance (msrvida.vscode-sanddance) - 3D/2D 시각화 7. Data Wrangler (ms-toolsai.datawrangler) - GUI 데이터 변환 8. SQLTools (mtxr.sqltools) - DB 연결 & 쿼리 9. Geo Data Viewer (randomfractals.geo-data-viewer) - 지도 시각화 10. Rainbow CSV (mechatroner.rainbow-csv) - CSV 탐색\n3) AI, 협업 & 운영: 11. Jupyter (ms-toolsai.jupyter) - 노트북 실행 12. GitHub Copilot (GitHub.copilot) - AI 코딩 (유료) 13. Live Share (ms-vsliveshare.vsliveshare) - 실시간 협업 14. Remote-SSH (ms-vscode-remote.remote-ssh) - 원격 GPU 서버 15. Docker (ms-azuretools.vscode-docker) - 컨테이너화\n확장 충돌이나 성능 문제가 발생하면 Cmd+Shift+P → “Extensions: Disable All Installed Extensions”으로 모든 확장을 비활성화한 후, 하나씩 다시 활성화하며 문제를 찾는다. 확장 개수가 너무 많으면 IDE 시작 속도가 느려질 수 있으므로, 실제 사용하는 확장만 활성화하고 나머지는 비활성화한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "docker_concept.html",
    "href": "docker_concept.html",
    "title": "1  도커: 재현가능한 환경",
    "section": "",
    "text": "1.1 가상화 기술의 진화\n2023년 어느 연구팀의 이야기다. 논문 심사 과정에서 심사위원이 “분석 결과를 재현할 수 없습니다”라고 지적했다. 연구자는 당황했다. 6개월 전 자신의 컴퓨터에서는 완벽히 작동했기 때문이다. 코드와 데이터를 다시 실행했지만, 결과 그래프가 달랐다. 그 사이 R이 4.2에서 4.3으로 업그레이드되었고, ggplot2 패키지가 3.4에서 3.5로 바뀌면서 테마 기본값이 변경되었다. 맥OS도 Monterey에서 Sonoma로 업데이트되었다. 원본 환경을 복구하려 했지만, 구버전 R과 패키지를 다시 설치하는 과정에서 새로운 오류들이 발생했다. 결국 논문 게재는 6개월 지연되었다.\n이것이 재현가능성 위기다. “내 컴퓨터에서는 되는데요”는 개발자가 가장 두려워하는 말이다. 동일한 코드, 동일한 데이터인데도 환경 차이로 결과가 달라진다. 의존성(dependency) 문제는 과학 연구의 신뢰성을 위협한다.\n도커(Docker)는 이 문제를 근본적으로 해결한다. 분석 환경 전체를 “스냅샷”으로 저장한다. Ubuntu 20.04, R 4.3.0, ggplot2 3.4.2, 시스템 라이브러리, 데이터까지 모든 것을 하나의 컨테이너로 패키징한다. 이 컨테이너는 어디서나 동일하게 실행된다. 5년이 지나도, 다른 컴퓨터에서도, 클라우드 서버에서도 정확히 같은 결과를 재현한다.\n도커를 이해하려면 가상화 기술의 역사를 알아야 한다. 도커는 갑자기 등장한 기술이 아니라, 50년 가상화 역사의 최신 진화다.\n가상화(Virtualization)는 “하나의 물리적 컴퓨터에서 여러 개의 독립적인 컴퓨터를 실행”하는 기술이다. 1960년대 IBM 메인프레임에서 시작해, 2000년대 VMware가 대중화했고, 2013년 도커가 혁명을 일으켰다.\n1) 가상 머신 (VM) 시대 (1999-2010)\nVMware, VirtualBox 같은 도구는 하드웨어 가상화를 제공한다. 윈도우 위에서 리눅스를 실행하거나, 맥OS 위에서 윈도우를 실행한다. 각 VM은 완전한 OS를 포함하므로 무겁고 느리다. Windows 10 VM 하나가 20GB 디스크를 차지하고, 4GB 메모리를 사용하며, 부팅에 30초가 걸린다. 노트북에서 3개의 VM을 동시에 실행하면 시스템이 느려진다.\n2) 컨테이너 등장 (2008-2012)\n리눅스 컨테이너(LXC)는 OS 수준 가상화를 제공한다. 하나의 리눅스 커널을 여러 컨테이너가 공유하므로 VM보다 훨씬 가볍다. 컨테이너 하나가 몇 MB에서 수백 MB이고, 부팅은 1초 이내다. 하지만 사용법이 복잡하고, 리눅스에서만 작동했다.\n3) 도커 혁명 (2013-현재)\n도커는 컨테이너를 누구나 쉽게 사용할 수 있게 만들었다. 간단한 명령어, 이미지 공유 플랫폼(Docker Hub), 크로스 플랫폼 지원(윈도우/맥OS/리눅스)으로 컨테이너 기술을 대중화했다. 2013년 Solomon Hykes가 PyCon에서 5분 데모를 선보인 후, 몇 년 만에 업계 표준이 되었다.\n그림 1.1 은 가상화 기술의 50년 진화를 보여준다. 가상 머신(VM)은 완전한 OS를 포함해 무겁지만(20GB+, 4GB RAM) 완벽한 격리를 제공한다. 컨테이너는 OS 커널을 공유해 가볍지만(수십 MB, 실사용 메모리만) 리눅스에서만 작동했다. 도커는 컨테이너의 가벼움을 유지하면서도, Windows/macOS에서도 사용할 수 있게 만들었다. Docker Hub로 이미지를 공유하고, 간단한 명령어로 누구나 컨테이너를 사용하게 되었다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-concepts",
    "href": "docker_concept.html#sec-docker-concepts",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.2 이미지와 컨테이너",
    "text": "1.2 이미지와 컨테이너\n도커를 처음 접하면 “이미지”와 “컨테이너”라는 용어가 혼란스럽다. 둘 다 “가상 환경”처럼 들리지만, 역할이 완전히 다르다. 이미지(Image)는 컴퓨팅 환경 “설계도”다. 프로그래밍 클래스(Class)처럼 “무엇을 포함할지” 정의한 템플릿이다. 컨테이너(Container)는 설계도로 만든 “실제 작동하는 컴퓨팅 환경”이다. 클래스에서 new로 인스턴스를 생성하듯, 이미지에서 docker run으로 컨테이너를 생성한다. 하나의 이미지에서 여러 컨테이너를 만들 수 있고, 각 컨테이너는 독립적으로 실행/중지/삭제할 수 있다.\n\n\n\n\n\n그림 1.2: 도커 이미지와 컨테이너 관계\n\n\n그림 1.2 는 이미지와 컨테이너의 관계를 보여준다. 왼쪽의 rocker/rstudio:4.3.0 이미지 하나에서 오른쪽의 여러 컨테이너가 생성된다. 각 컨테이너는 독립적으로 실행되며, 서로 다른 포트(8787, 8788, 8789)에서 접속할 수 있다. 프로그래밍의 Class와 Instance 관계와 동일하다.\n도커 이미지는 가상 컴퓨터의 “설계도”다. Ubuntu 20.04, R 4.3.0, tidyverse 패키지, 데이터 파일이 포함된 완전한 환경 스냅샷이다. 이미지는 읽기 전용(read-only)이며, 파일로 저장되고 공유된다. Docker Hub에서 전 세계 개발자가 만든 이미지를 다운로드하거나, 자신의 이미지를 업로드해 공유한다.\n도커 컨테이너는 이미지를 “실행한 것”이다. 이미지가 “프로그램 파일”이라면, 컨테이너는 “실행 중인 프로세스”다. 하나의 이미지에서 여러 컨테이너를 동시에 실행할 수 있다. 예를 들어, rocker/rstudio 이미지 하나로 3개의 RStudio 컨테이너를 각각 다른 포트에서 실행할 수 있다.\n\n\n\n\n\n\n힌트데이터 과학 도커 핵심 가치\n\n\n\n1. 재현성: 논문, 보고서, 분석 결과를 도커 이미지와 함께 제공하면, 누구나 정확히 동일한 환경에서 결과를 재현할 수 있다. 5년 후에도, 다른 컴퓨터에서도 같은 결과가 나온다.\n2. 이식성: 로컬 컴퓨터에서 개발한 환경을 GPU 서버로, AWS/GCP 클라우드로, 동료 컴퓨터로 그대로 이동한다. “로컬에서는 되는데 서버에서는 안 돼요” 문제가 사라진다.\n3. 공유성: 팀원에게 코드와 README만 주면 환경 설정에 반나절이 걸린다. 도커 이미지를 주면 docker run 명령 하나로 5분 안에 작업을 시작한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-usecases",
    "href": "docker_concept.html#sec-docker-usecases",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.4 도커 활용 사례",
    "text": "1.4 도커 활용 사례\n도커가 데이터 과학에서 해결하는 문제는 크게 세 가지다.\n\n1.4.1 로컬 개발 환경 격리\n여러 프로젝트를 동시에 진행할 때, 프로젝트 A는 R 4.2가 필요하고 프로젝트 B는 R 4.3이 필요하다면? 도커 컨테이너로 각 프로젝트를 완전히 분리한다. 프로젝트 A는 R 4.2 컨테이너에서, 프로젝트 B는 R 4.3 컨테이너에서 실행한다. 서로 영향을 주지 않는다.\n\n\n1.4.2 Shiny 앱 배포\n로컬에서 개발한 Shiny 대시보드를 프로덕션 서버에 배포할 때, 환경 차이로 인한 오류가 빈번하다. 도커로 로컬 환경을 그대로 이미지로 만들고, 서버에서 해당 이미지를 실행한다. “로컬에서는 되는데 서버에서는 안 돼요” 문제가 사라진다.\nRocker 프로젝트는 R 전용 도커 이미지를 제공한다: - rocker/rstudio: RStudio Server 포함 - rocker/tidyverse: tidyverse 패키지 사전 설치 - rocker/shiny: Shiny Server 포함 - rocker/verse: RStudio + tidyverse + 출판 도구\n# RStudio를 도커로 실행\ndocker run -d -p 8787:8787 -e PASSWORD=mypassword rocker/rstudio\n\n# 웹브라우저에서 http://localhost:8787 접속\n# ID: rstudio, PW: mypassword\n\n\n1.4.3 머신러닝 모델 API 배포\n학습한 머신러닝 모델을 FastAPI나 Plumber로 API화하고, 도커 컨테이너로 패키징한다. Python 3.11, TensorFlow 2.14, 모델 가중치 파일을 모두 포함한 이미지를 만들고, AWS/GCP에 배포한다. 서버 환경 설정 없이 docker run 하나로 API가 작동한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-dockerfile",
    "href": "docker_concept.html#sec-docker-dockerfile",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.5 Dockerfile 작성",
    "text": "1.5 Dockerfile 작성\nDockerfile은 도커 이미지를 만드는 레시피다. 기본 이미지에서 시작해, 패키지를 설치하고, 파일을 추가하는 과정을 코드로 정의한다.\n\n\n\n\n\n\n노트언제 도커를 사용해야 하나?\n\n\n\n도커는 환경 격리의 최상위 계층이다. 다음 표는 격리 도구 선택 기준을 보여준다:\n\n\n\n상황\n도구 선택\n\n\n\n\n순수 Python/R 패키지\nuv / renv\n\n\n시스템 라이브러리 의존 (OpenCV, PostgreSQL)\n도커\n\n\n멀티 언어 (R + Python + SQL)\n도커\n\n\n로컬 개발만\nuv / renv\n\n\n프로덕션 배포 (Shiny, API)\n도커\n\n\n5년 후 재현 보장\n도커\n\n\n팀 협업 (동일 환경)\n도커\n\n\n\nuv/renv로 시작하고, 시스템 의존성이나 배포가 필요해지면 도커로 전환하는 것이 일반적 경로다.\n\n\n💡 생각해볼 점\n도커는 “필요할 때” 배우는 것이 가장 효과적이다. 로컬 개발만 한다면 uv나 renv로 충분하다. 하지만 다음 상황이 오면 도커를 시작하자:\n\n팀원과 환경이 달라 오류가 발생할 때 - 모두 같은 도커 이미지 사용\nShiny 앱을 서버에 배포할 때 - 로컬 환경을 그대로 이미지로\n1년 전 분석을 재현해야 할 때 - Dockerfile로 환경 복구\n고성능 서버에서 실행할 때 - 로컬 이미지를 서버로 전송\n\n도커 학습 곡선은 가파르다. Dockerfile 문법, 이미지 레이어, 볼륨 마운트, 네트워크 설정 등 새로운 개념이 많다. 하지만 한 번 익히면 환경 문제로 고생하는 시간이 사라진다. “내 컴퓨터에서는 되는데”라는 말을 더 이상 하지 않게 된다.\nDocker Desktop을 설치하고, rocker/rstudio를 실행해보자. 웹브라우저에서 RStudio가 뜨는 것을 확인하면, 도커의 첫 걸음을 뗀 것이다. 다음 프로젝트에서 Dockerfile을 하나 만들어보고, 동료와 이미지를 공유해보자. 실전에서 도커의 가치를 체감하게 된다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-volumes",
    "href": "docker_concept.html#sec-docker-volumes",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.8 데이터와 볼륨",
    "text": "1.8 데이터와 볼륨\n컨테이너는 격리된 환경이라는 장점이 있지만, 이 격리가 데이터 처리에서는 문제가 된다. 컨테이너 내부에서 생성한 파일은 컨테이너를 삭제하면 함께 사라진다. 밤새 돌린 분석 결과가 docker rm 한 줄로 증발하는 것이다. 데이터 과학자에게 이보다 끔찍한 시나리오는 없다.\n볼륨(Volume)과 바인드 마운트(Bind Mount)는 이 문제를 해결한다. 호스트 시스템의 폴더를 컨테이너 내부에 “연결”하면, 컨테이너에서 생성한 파일이 호스트에 직접 저장된다. 컨테이너가 삭제되어도 데이터는 호스트에 그대로 남는다. 반대로 호스트의 데이터 파일을 컨테이너에서 불러와 분석하는 것도 가능하다.\n\n\n\n\n\n그림 1.9: 도커 볼륨과 바인드 마운트\n\n\n그림 1.9 는 호스트와 컨테이너 간 데이터 흐름을 보여준다. -v 옵션으로 호스트 경로와 컨테이너 경로를 연결하면, 양쪽에서 동일한 파일에 접근할 수 있다. 바인드 마운트는 호스트의 특정 폴더를 직접 연결하고, 네임드 볼륨은 도커가 관리하는 저장소를 사용한다. 읽기 전용(:ro) 옵션은 원본 데이터를 실수로 덮어쓰는 것을 방지한다.\n# 바인드 마운트: 호스트 폴더를 컨테이너에 연결\ndocker run -d -p 8787:8787 \\\n  -v /Users/me/project:/home/rstudio/project \\\n  -e PASSWORD=rstudio \\\n  rocker/rstudio:4.3.0\n\n# 컨테이너 내부에서 /home/rstudio/project 접근 가능\n# 분석 결과를 이 경로에 저장하면 호스트에도 저장됨\n데이터 분석 워크플로우에서는 프로젝트 폴더 전체를 마운트하는 것이 일반적이다. data/ 폴더에 원본 데이터를 두고, scripts/ 폴더에 분석 코드를, output/ 폴더에 결과물을 저장한다. 컨테이너 안에서 RStudio로 작업하면 모든 변경사항이 호스트에 실시간으로 반영된다. Git으로 버전 관리도 가능하고, 컨테이너를 삭제했다가 다시 만들어도 데이터는 그대로다.\n# 실전 예시: 현재 디렉토리를 프로젝트 폴더로 마운트\ndocker run -d -p 8787:8787 \\\n  -v $(pwd):/home/rstudio/project \\\n  -e PASSWORD=rstudio \\\n  rocker/tidyverse:4.3.0\n\n# $(pwd): 현재 작업 디렉토리\n# 프로젝트 내 data/, scripts/, output/ 폴더 모두 접근 가능\n대용량 데이터를 다룰 때는 네임드 볼륨이 유용하다. docker volume create 명령으로 볼륨을 생성하면 도커가 최적화된 저장소를 관리한다. 여러 컨테이너가 같은 볼륨을 공유할 수도 있어, R 컨테이너에서 전처리한 데이터를 Python 컨테이너에서 분석하는 파이프라인도 구성할 수 있다.\n# 네임드 볼륨 생성\ndocker volume create analysis_data\n\n# R 컨테이너에서 데이터 전처리\ndocker run -v analysis_data:/data rocker/tidyverse:4.3.0 \\\n  Rscript -e \"saveRDS(mtcars, '/data/processed.rds')\"\n\n# Python 컨테이너에서 동일 데이터 접근\ndocker run -v analysis_data:/data python:3.11 \\\n  python -c \"import pyreadr; df = pyreadr.read_r('/data/processed.rds')\"\n볼륨을 사용할 때 한 가지 주의할 점은 파일 권한이다. 컨테이너 내부 사용자(보통 rstudio 또는 root)와 호스트 사용자의 UID가 다르면 권한 문제가 발생할 수 있다. Rocker 이미지는 이 문제를 대부분 자동 처리하지만, 권한 오류가 발생하면 --user 옵션으로 UID를 맞추거나 호스트에서 폴더 권한을 조정해야 한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-vs-alternatives",
    "href": "docker_concept.html#sec-docker-vs-alternatives",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.9 도커 vs 다른 격리 도구",
    "text": "1.9 도커 vs 다른 격리 도구\n환경 격리 도구는 크게 세 가지 계층으로 나뉜다. 가장 가벼운 것은 패키지 수준 격리다. Python의 uv나 R의 renv가 여기에 해당한다. 프로젝트별로 패키지 버전을 고정하고, requirements.txt나 renv.lock 파일로 의존성을 기록한다. 설정이 간단하고 빠르지만, 시스템 라이브러리나 OS에 의존하는 패키지는 여전히 문제가 된다. sf 패키지가 GDAL 버전에 따라 다르게 동작하거나, macOS와 Linux에서 결과가 달라지는 상황은 패키지 격리만으로 해결할 수 없다.\n한 단계 위가 런타임 수준 격리다. pyenv나 rig 같은 도구로 Python이나 R 버전 자체를 프로젝트별로 전환한다. 패키지뿐 아니라 언어 런타임까지 격리되므로 R 4.2와 R 4.3을 오가며 작업할 수 있다. 하지만 여전히 시스템 라이브러리에는 손을 대지 못한다. Ubuntu에서 만든 코드가 macOS에서 실패하는 문제는 그대로다.\nOS 수준 격리가 도커의 영역이다. 운영체제, 시스템 라이브러리, 런타임, 패키지를 모두 포함한 완전한 환경을 패키징한다. Ubuntu 20.04 + GDAL 3.4 + R 4.3.0 + sf 1.0 조합을 그대로 보존하고 어디서든 재현한다. 초기 학습 곡선이 있지만, 한 번 익히면 환경 문제로 고생할 일이 사라진다.\n어떤 도구를 선택할지는 상황에 따라 다르다. 순수 R/Python 패키지만 사용하는 로컬 분석이라면 renv나 uv로 충분하다. 하지만 GDAL, PostgreSQL, OpenCV 같은 시스템 라이브러리에 의존하거나, R과 Python을 함께 사용하거나, Shiny 앱이나 API를 프로덕션에 배포하거나, 5년 후에도 재현을 보장해야 한다면 도커가 답이다. 일반적인 경로는 renv/uv로 시작해 시스템 의존성이나 배포 요구가 생기면 도커로 전환하는 것이다.\n💡 생각해볼 점\n도커가 필요한 순간은 명확하다. 팀원이 “환경 설정이 안 돼요”라고 할 때, Shiny 앱을 서버에 배포할 때, 1년 전 분석을 재현해야 할 때, OpenCV나 GDAL 같은 시스템 라이브러리가 필요할 때, 논문 제출 시 재현성을 증명해야 할 때다. 이런 상황이 오면 도커를 시작하자.\n이미지와 컨테이너 구분은 도커 이해의 핵심이다. 이미지는 설계도(Class)이고, 컨테이너는 실행 인스턴스(Object)다. docker pull로 이미지를 받고, docker run으로 컨테이너를 실행한다. 하나의 이미지에서 여러 컨테이너를 만들 수 있고, 컨테이너를 삭제해도 이미지는 남는다. Rocker 이미지(rocker/rstudio, rocker/tidyverse, rocker/verse)는 R 사용자의 출발점이다. 버전 태그(:4.3.0)를 명시하면 5년 후에도 동일한 환경을 보장받는다.\n볼륨(-v)은 데이터 영속성의 열쇠다. 컨테이너는 삭제되면 내부 데이터도 사라지지만, 호스트 폴더를 마운트하면 분석 결과가 호스트에 남는다. 밤새 돌린 분석이 docker rm 한 줄로 증발하는 비극을 막으려면 반드시 볼륨을 사용해야 한다.\n도커 학습 곡선은 가파르다. 하지만 한 번 익히면 환경 문제로 고생하는 시간이 사라진다. “내 컴퓨터에서는 되는데”라는 말을 더 이상 하지 않게 된다. 다음 장에서는 이론을 넘어 실전으로 들어간다. Docker Desktop 설치, rocker/rstudio 실행, Dockerfile 작성, 이미지 빌드까지 전 과정을 직접 수행한다. 첫 번째 컨테이너를 만들고, 웹브라우저에서 localhost:8787을 열어 RStudio가 뜨는 것을 확인하면, 도커의 가치를 체감하게 된다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-shiny-deploy",
    "href": "docker_concept.html#sec-docker-shiny-deploy",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.8 실전 활용: Shiny 앱 배포",
    "text": "1.8 실전 활용: Shiny 앱 배포\nShiny 앱을 도커로 배포하는 전체 워크플로우를 살펴보자.\n\n1.8.1 1. Dockerfile 작성\nFROM rocker/shiny:4.3.0\n\n# 필요한 R 패키지 설치\nRUN R -e \"install.packages(c('ggplot2', 'dplyr', 'plotly'), repos='https://cran.r-project.org')\"\n\n# Shiny 앱 파일 추가\nADD app.R /srv/shiny-server/myapp/\nADD data/ /srv/shiny-server/myapp/data/\n\n# Shiny Server 설정\nEXPOSE 3838\n\n# Shiny Server 실행\nCMD [\"/usr/bin/shiny-server\"]\n\n\n1.8.2 2. 이미지 빌드\ndocker build -t myshinyapp:v1.0 .\n\n\n1.8.3 3. 로컬 테스트\ndocker run -d -p 3838:3838 myshinyapp:v1.0\n\n# http://localhost:3838/myapp 접속\n\n\n1.8.4 4. 서버 배포\n# Docker Hub에 푸시 (공유)\ndocker tag myshinyapp:v1.0 username/myshinyapp:v1.0\ndocker push username/myshinyapp:v1.0\n\n# 서버에서 실행\ndocker pull username/myshinyapp:v1.0\ndocker run -d -p 3838:3838 myshinyapp:v1.0",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-commands",
    "href": "docker_concept.html#sec-docker-commands",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.9 도커 명령어 핵심",
    "text": "1.9 도커 명령어 핵심\n# 이미지 관리\ndocker images                    # 이미지 목록\ndocker pull rocker/rstudio       # 이미지 다운로드\ndocker build -t myimage .        # 이미지 빌드\ndocker rmi myimage               # 이미지 삭제\n\n# 컨테이너 관리\ndocker ps                        # 실행 중인 컨테이너\ndocker ps -a                     # 모든 컨테이너\ndocker run -d -p 8787:8787 img   # 컨테이너 실행\ndocker stop container_id         # 컨테이너 정지\ndocker rm container_id           # 컨테이너 삭제\ndocker rm -f $(docker ps -a -q)  # 모든 컨테이너 삭제\n\n# 컨테이너 내부 접근\ndocker exec -it container_id bash   # 컨테이너 쉘 접속\ndocker logs container_id            # 로그 확인\ndocker cp file.csv container_id:/path  # 파일 복사",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-extension",
    "href": "docker_concept.html#sec-docker-extension",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.10 도커 확장 프로그램",
    "text": "1.10 도커 확장 프로그램\nPositron이나 VS Code에서 Docker 확장 (ms-azuretools.vscode-docker)을 설치하면 도커를 GUI로 관리한다. 좌측 사이드바에 Docker 아이콘이 생기며, 이미지 목록, 실행 중인 컨테이너, Dockerfile 편집을 한 곳에서 수행한다.\nDockerfile을 우클릭 → “Build Image”로 이미지를 빌드하고, 이미지를 우클릭 → “Run”으로 컨테이너를 실행한다. 컨테이너 내부 터미널을 열어 디버깅하고, 로그를 실시간으로 확인한다. 명령줄을 외우지 않아도 도커를 사용할 수 있다.\n💡 생각해볼 점\n도커는 “필요할 때” 배우는 것이 가장 효과적이다. 로컬 개발만 한다면 uv나 renv로 충분하다. 하지만 다음 상황이 오면 도커를 시작하자:\n\n팀원과 환경이 달라 오류가 발생할 때 - 모두 같은 도커 이미지 사용\nShiny 앱을 서버에 배포할 때 - 로컬 환경을 그대로 이미지로\n1년 전 분석을 재현해야 할 때 - Dockerfile로 환경 복구\n고성능 서버에서 실행할 때 - 로컬 이미지를 서버로 전송\n\n도커 학습 곡선은 가파르다. Dockerfile 문법, 이미지 레이어, 볼륨 마운트, 네트워크 설정 등 새로운 개념이 많다. 하지만 한 번 익히면 환경 문제로 고생하는 시간이 사라진다. “내 컴퓨터에서는 되는데”라는 말을 더 이상 하지 않게 된다.\nDocker Desktop을 설치하고, rocker/rstudio를 실행해보자. 웹브라우저에서 RStudio가 뜨는 것을 확인하면, 도커의 첫 걸음을 뗀 것이다. 다음 프로젝트에서 Dockerfile을 하나 만들어보고, 동료와 이미지를 공유해보자. 실전에서 도커의 가치를 체감하게 된다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-history",
    "href": "docker_concept.html#sec-docker-history",
    "title": "1  도커: 재현가능한 환경",
    "section": "",
    "text": "그림 1.1: 가상화 기술 진화 - VM → 컨테이너 → 도커\n\n\n\n\n\n\n\n\n\n노트도커 vs 쿠버네티스: 데이터 과학자 선택\n\n\n\n그림 1.1 에서 보았듯이 도커(2013) 이후 쿠버네티스(2015)가 등장했다. 쿠버네티스가 더 최신 기술인데, 왜 데이터 과학은 도커에 초점을 맞추는가?\n해결하는 문제가 다르다. 도커는 “환경을 패키징”하는 도구다. 쿠버네티스는 “수백 개 컨테이너를 자동으로 운영”하는 도구다. 넷플릭스가 수천 대 서버에서 마이크로서비스를 운영하거나, 구글이 트래픽 급증 시 자동으로 서버를 늘리는 상황에 필요하다.\n\n\n\n\n\n\n\n\n구분\n도커\n쿠버네티스\n\n\n\n주 사용자\n개발자, 데이터 과학자\nDevOps, 인프라 엔지니어\n\n\n학습 곡선\n몇 시간~며칠\n몇 주~몇 달\n\n\n시작 명령\ndocker run\n클러스터 설정부터\n\n\n운영 규모\n1~10개 컨테이너\n수십~수천 개 컨테이너\n\n\n\n\n\n\n\n표 1.1: 도커와 쿠버네티스 비교\n\n\n\n데이터 과학자 대부분은 개인 또는 소규모 팀으로 작업한다. 탐색적 분석을 빠르게 실행하고 중지하며, 자동 스케일링보다는 “동일 환경 재현”이 핵심 목표다. 노트북에서 docker run 한 줄이면 작업을 시작할 수 있다. 반면 쿠버네티스는 Shiny 앱 동시 접속자가 수천 명에 달하거나, ML API가 초당 수만 건 요청을 처리해야 하거나, 24시간 무중단 서비스가 필요한 상황에 적합하다. 대부분의 데이터 과학자에게 쿠버네티스는 “알면 좋지만 당장 필요하지 않은” 기술이다. 도커만으로 재현가능성, 이식성, 공유성 문제를 충분히 해결할 수 있다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-value",
    "href": "docker_concept.html#sec-docker-value",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.3 도커의 핵심 가치",
    "text": "1.3 도커의 핵심 가치\n\n\n\n\n\n\n힌트도커가 데이터 과학에 가져온 세 가지 핵심 가치\n\n\n\n1. 재현가능성 (Reproducibility): 논문, 보고서, 분석 결과를 도커 이미지와 함께 제공하면, 누구나 정확히 동일한 환경에서 결과를 재현할 수 있다. 5년 후에도, 다른 컴퓨터에서도 같은 결과가 나온다.\n2. 이식성 (Portability): 로컬 컴퓨터에서 개발한 환경을 GPU 서버로, AWS/GCP 클라우드로, 동료 컴퓨터로 그대로 이동한다. “로컬에서는 되는데 서버에서는 안 돼요” 문제가 사라진다.\n3. 공유성 (Sharability): 팀원에게 코드와 README만 주면 환경 설정에 반나절이 걸린다. 도커 이미지를 주면 docker run 명령 하나로 5분 안에 작업을 시작한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-why",
    "href": "docker_concept.html#sec-docker-why",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.4 도커의 존재 이유",
    "text": "1.4 도커의 존재 이유\n도커가 다른 가상화 기술보다 데이터 과학에 적합한 이유는 무엇인가?\n\n1.4.1 VM과의 차이: 가벼움\n가상 머신(VM)은 완전한 OS를 포함한다. Windows 10 VM 하나가 20GB 디스크를 차지하고, 4GB 메모리를 사용하며, 부팅에 30초가 걸린다. 노트북에서 3개의 VM을 동시에 실행하면 시스템이 느려진다.\n도커 컨테이너는 OS 커널을 호스트와 공유한다. Ubuntu 컨테이너를 macOS에서 실행해도, Linux 커널은 하나만 사용한다. 컨테이너 하나가 몇 MB에서 수백 MB이고, 메모리는 실제 사용량만큼만 차지하며, 부팅은 1초 이내다. 노트북에서 10개 컨테이너를 가볍게 실행한다.\n\n\n1.4.2 uv/renv와의 차이: 완전한 격리\nuv(Python)와 renv(R)는 패키지 수준만 격리한다. 패키지 버전은 고정하지만, Python/R 인터프리터 버전, 시스템 라이브러리는 호스트에 의존한다. opencv-python처럼 C++ 라이브러리가 필요한 패키지는 시스템에 OpenCV가 설치되어 있어야 작동한다.\n도커는 OS부터 시스템 라이브러리까지 모두 격리한다. OpenCV, PostgreSQL, CUDA 드라이버를 이미지에 포함시키면, 호스트 시스템과 무관하게 작동한다. 멀티 언어 프로젝트(R + Python + SQL)도 하나의 컨테이너로 관리한다.\n\n\n1.4.3 Docker Hub: 이미지 공유 플랫폼\nDocker Hub는 “이미지의 GitHub”다. 전 세계 개발자가 만든 이미지를 검색하고, 다운로드하며, 자신의 이미지를 공유한다. Rocker 프로젝트는 R 전용 이미지를 제공하며, rocker/rstudio, rocker/tidyverse, rocker/shiny는 즉시 사용 가능한 완전한 R 환경이다. 환경 설정 없이 docker run 하나로 RStudio가 웹브라우저에 뜬다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-rocker",
    "href": "docker_concept.html#sec-docker-rocker",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.6 Rocker 프로젝트",
    "text": "1.6 Rocker 프로젝트\nR 환경 설정은 악명 높다. 운영체제마다 다른 설치 방법, 시스템 라이브러리 의존성, 패키지 버전 충돌까지 초보자는 물론 숙련된 개발자도 시간을 허비한다. 특히 sf, terra 같은 지리공간 패키지나 rJava 같은 시스템 의존 패키지는 설치 자체가 하루 일과가 되기도 한다.\nRocker 프로젝트는 이 문제를 해결하기 위해 2014년 Carl Boettiger와 Dirk Eddelbuettel이 시작했다. R 커뮤니티를 위한 공식 도커 이미지를 제공하며, Docker Hub에서 가장 많이 다운로드되는 R 이미지 시리즈다. docker pull rocker/rstudio 한 줄이면 RStudio가 포함된 완전한 R 개발 환경이 준비된다. 시스템 라이브러리 설치, 의존성 해결, 버전 충돌 걱정 없이 바로 분석을 시작할 수 있다.\n\n\n\n\n\n그림 1.7: Rocker 프로젝트 이미지\n\n\n그림 1.7 는 Rocker 이미지 계층 구조를 보여준다. 가장 기본이 되는 rocker/r-ver는 Ubuntu LTS와 R만 포함한 최소 이미지로, R 스크립트 실행에 적합하다. 여기에 RStudio Server를 추가한 rocker/rstudio는 웹 브라우저에서 8787 포트로 접속하는 IDE 환경을 제공한다. 반면 rocker/shiny는 Shiny Server를 포함해 3838 포트에서 앱을 배포한다.\n데이터 분석 작업에는 rocker/tidyverse가 적합하다. tidyverse와 devtools가 사전 설치되어 패키지 설치 시간을 절약한다. 논문이나 보고서 출판이 필요하다면 rocker/verse를 선택한다. Quarto, LaTeX, 폰트가 모두 포함되어 PDF 출력까지 한 번에 해결한다. 머신러닝 작업에는 rocker/ml, 지리공간 분석에는 rocker/geospatial처럼 특화된 이미지도 제공된다.\n모든 Rocker 이미지는 R 버전별 태그를 지원한다. rocker/tidyverse:4.5.0은 R 4.5.0 환경을, rocker/tidyverse:4.3.0은 R 4.3.0 환경을 제공한다. 버전을 명시하지 않으면 latest 태그가 적용되어 최신 버전이 설치된다. 재현성이 중요한 프로젝트에서는 반드시 특정 버전 태그를 사용해야 한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-how",
    "href": "docker_concept.html#sec-docker-how",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.3 도커의 작동 원리",
    "text": "1.3 도커의 작동 원리\n도커가 “컴퓨터 안의 컴퓨터”를 만드는 방식은 가상 머신(VM)과 근본적으로 다르다. VM은 하드웨어를 가상화해 완전한 운영체제를 실행하지만, 도커 컨테이너는 호스트의 리눅스 커널을 공유하면서 네임스페이스로 프로세스를 격리하고 cgroups로 자원을 제한한다. 커널을 공유하기 때문에 VM처럼 수십 GB의 디스크와 수 GB의 메모리가 필요하지 않다. 컨테이너는 수십 MB에서 수백 MB로 가볍고, 부팅 시간도 1초 이내다.\n\n\n\n\n\n그림 1.3: 도커 내부 구조\n\n\n그림 1.3 는 컨테이너가 호스트 커널 위에서 작동하는 방식을 보여준다. 컨테이너 A와 B는 각각 독립된 네임스페이스를 갖지만, 맨 아래 리눅스 커널은 공유한다. 이미지 레이어도 공유된다. 두 컨테이너가 같은 Ubuntu 베이스 이미지를 사용하면, 해당 레이어는 디스크에 한 번만 저장된다. cgroups는 각 컨테이너가 사용할 수 있는 CPU와 메모리를 제한해 한 컨테이너가 시스템 자원을 독점하지 못하게 한다.\n도커 이미지는 레이어(layer) 구조로 이루어진다. 마치 투명 필름을 겹치듯 Ubuntu 레이어 위에 R 설치 레이어가 올라가고, 그 위에 tidyverse 레이어가 쌓인다. 각 레이어는 읽기 전용이며, 컨테이너가 실행될 때 맨 위에 쓰기 가능한 얇은 레이어가 추가된다. 컨테이너 안에서 파일을 수정하면 쓰기 레이어에만 기록되고, 원본 이미지는 변경되지 않는다. 레이어 구조의 장점은 캐싱에 있다. Dockerfile에서 코드 파일만 수정했다면 OS와 패키지 레이어는 그대로 재사용되어 빌드 시간이 몇 분에서 몇 초로 단축된다. 여러 이미지가 같은 베이스 레이어를 공유하면 디스크 공간도 절약된다.\n네임스페이스(namespace)는 컨테이너가 마치 독립된 시스템처럼 보이게 하는 리눅스 커널 기능이다. PID 네임스페이스 덕분에 컨테이너 내부에서는 프로세스 ID가 1번부터 시작하고, 다른 컨테이너의 프로세스는 보이지 않는다. NET 네임스페이스는 각 컨테이너에 독립된 네트워크 인터페이스를 제공해 IP 주소와 포트가 충돌하지 않게 한다. MNT 네임스페이스는 파일시스템을 격리해 컨테이너가 호스트의 다른 파일에 접근하지 못하게 한다. cgroups(control groups)는 자원 할당을 제어한다. docker run --cpus=2 --memory=4g 명령으로 컨테이너가 최대 2개 CPU 코어와 4GB 메모리만 사용하도록 제한할 수 있다. 한 컨테이너에서 무한 루프가 돌거나 메모리 누수가 발생해도 다른 컨테이너와 호스트 시스템은 영향받지 않는다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-limitations",
    "href": "docker_concept.html#sec-docker-limitations",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.9 도커의 한계",
    "text": "1.9 도커의 한계\n도커는 완벽하지 않다. 한계를 이해하고 적절히 사용해야 한다.\n\n1.9.1 학습 곡선\n도커는 배우기 어렵다. Dockerfile 문법, 이미지 레이어, 볼륨 마운트, 네트워크 설정, 포트 매핑 등 새로운 개념이 많다. 로컬 개발만 한다면 uv나 renv로 충분하다. “필요할 때” 배우는 것이 효율적이다.\n\n1.9.2 성능 오버헤드\n컨테이너는 네이티브에 비해 약간의 성능 오버헤드가 있다. CPU 집약적 작업(수치 계산, 시뮬레이션)에서는 5-10% 느릴 수 있다. I/O 작업(파일 읽기/쓰기)도 볼륨 마운트를 사용하면 약간 느려진다. 대부분 경우 무시할 수준이지만, 초고성능이 필요한 HPC 환경에서는 고려해야 한다.\n\n1.9.3 윈도우/맥OS 제약\n도커 컨테이너는 리눅스 기술이다. Windows/macOS에서는 Docker Desktop이 내부적으로 Linux VM을 실행하고, 그 위에서 컨테이너를 돌린다. 순수 리눅스 환경보다 약간의 오버헤드가 있고, 파일 시스템 권한 문제가 발생할 수 있다.\n💡 생각해볼 점\n도커는 “필요할 때” 배우는 것이 가장 효과적이다. 다음 상황이 오면 도커를 시작하자:\n\n\n팀원이 “환경 설정이 안 돼요”라고 할 때 - 모두 같은 도커 이미지 사용\n\nShiny 앱을 서버에 배포할 때 - 로컬 환경을 그대로 이미지로\n\n1년 전 분석을 재현해야 할 때 - 도커 이미지로 환경 복구\n\nOpenCV, GDAL 같은 시스템 라이브러리가 필요할 때 - OS부터 패키징\n\n논문 제출 시 재현성을 증명해야 할 때 - 이미지와 함께 제출\n\n도커 학습 곡선은 가파르다. 하지만 한 번 익히면 환경 문제로 고생하는 시간이 사라진다. “내 컴퓨터에서는 되는데”라는 말을 더 이상 하지 않게 된다.\n다음 장에서는 이론을 넘어 실전으로 들어간다. Docker Desktop 설치, rocker/rstudio 실행, Dockerfile 작성, 이미지 빌드, Shiny 앱 배포까지 전 과정을 직접 수행한다. 첫 번째 도커 컨테이너를 만들고, 웹브라우저에서 RStudio가 뜨는 것을 확인하면, 도커의 가치를 체감하게 된다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-vs-k8s",
    "href": "docker_concept.html#sec-docker-vs-k8s",
    "title": "1  도커: 재현가능한 환경",
    "section": "1.5 왜 도커인가, 쿠버네티스가 아닌가?",
    "text": "1.5 왜 도커인가, 쿠버네티스가 아닌가?\n그림 1.1 에서 보았듯이 도커(2013) 이후 쿠버네티스(2015)가 등장했다. 쿠버네티스가 더 최신 기술인데, 왜 데이터 과학은 도커에 초점을 맞추는가?\n해결하는 문제가 다르다.\n도커는 “환경을 패키징”하는 도구다. “내 분석 환경을 그대로 담아서 어디서나 실행”이 목표다. 개인 노트북에서 분석하고, 동료에게 공유하고, 서버에 배포하는 워크플로우에 적합하다.\n쿠버네티스는 “수백 개 컨테이너를 자동으로 운영”하는 도구다. 넷플릭스가 수천 대 서버에서 마이크로서비스를 운영하거나, 구글이 검색 요청 급증 시 자동으로 서버를 늘리는 상황에 필요하다. 컨테이너가 죽으면 자동 재시작하고, 트래픽이 늘면 자동 확장하며, 무중단 배포를 지원한다.\n사용자 대상이 다르다.\n\n\n\n구분\n도커\n쿠버네티스\n\n\n\n\n주 사용자\n개발자, 데이터 과학자\nDevOps, 인프라 엔지니어\n\n\n학습 곡선\n몇 시간~며칠\n몇 주~몇 달\n\n\n시작 명령\ndocker run\n클러스터 설정부터\n\n\n설정 파일\nDockerfile (수십 줄)\nYAML 매니페스트 (수백 줄)\n\n\n운영 규모\n1~10개 컨테이너\n수십~수천 개 컨테이너\n\n\n\n데이터 과학 워크플로우에 도커가 적합한 이유:\n\n개인 작업 중심: 데이터 분석은 대부분 개인 또는 소규모 팀 작업이다. 수천 개 컨테이너를 동시에 운영할 일이 없다.\n실험적 특성: 분석은 탐색적이다. 코드를 수정하고, 결과를 확인하고, 다시 수정한다. 컨테이너 하나를 빠르게 실행/중지하는 도커가 적합하다.\n재현성이 핵심: 데이터 과학의 목표는 “동일 환경 재현”이지, “자동 스케일링”이 아니다. 도커 이미지 하나로 목표를 달성한다.\n로컬 개발 친화적: 노트북에서 docker run으로 RStudio를 띄우는 건 간단하다. 노트북에 쿠버네티스 클러스터를 구축하는 건 과잉이다.\n\n쿠버네티스가 필요한 경우:\n\nShiny 앱에 동시 접속자가 수천 명일 때\nML 모델 API가 초당 수만 건 요청을 처리할 때\n24/7 무중단 서비스가 필수일 때\n여러 마이크로서비스가 상호작용하는 복잡한 시스템일 때\n\n대부분의 데이터 과학자에게 쿠버네티스는 “알면 좋지만 당장 필요하지 않은” 기술이다. 도커만으로 재현가능성, 이식성, 공유성 문제를 해결할 수 있다. 쿠버네티스는 프로덕션 규모가 커지고, 운영 자동화가 필요해질 때 배워도 늦지 않다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-hub",
    "href": "docker_concept.html#sec-docker-hub",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.5 Docker Hub",
    "text": "1.5 Docker Hub\nGitHub이 소스 코드를 저장하고 공유하는 플랫폼이라면, 도커 허브(Docker Hub)는 도커 이미지를 저장하고 공유하는 플랫폼이다. 개발자가 GitHub에서 git clone으로 코드를 받듯, Docker Hub에서 docker pull로 이미지를 받는다. 프로젝트의 완전한 재현을 위해서는 코드(GitHub)와 실행 환경(Docker Hub) 둘 다 필요하다.\n\n\n\n\n\n그림 1.6: Docker Hub 구조\n\n\n그림 1.6 는 Docker Hub의 구조를 보여준다. 로컬에서 빌드한 이미지를 docker push로 업로드하면, 서버나 동료가 docker pull로 동일한 이미지를 다운로드한다. Docker Hub에는 rocker/rstudio, python, postgres 같은 공식 이미지와 사용자가 만든 커스텀 이미지가 함께 존재한다.\n버전 태그 시스템은 재현가능성의 핵심이다. rocker/rstudio:4.3.0처럼 특정 버전을 명시하면 5년 후에도 동일한 환경을 보장받는다. 반면 latest 태그는 최신 버전을 가리키므로 시간이 지나면 내용이 바뀔 수 있다. 재현성이 중요한 프로젝트에서는 반드시 특정 버전 태그를 사용해야 한다.\n# Docker Hub에서 이미지 다운로드\ndocker pull rocker/rstudio:4.3.0\n\n# 내 이미지를 Docker Hub에 업로드\ndocker push myname/myimage:1.0",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-desktop",
    "href": "docker_concept.html#sec-docker-desktop",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.4 Docker Desktop",
    "text": "1.4 Docker Desktop\n도커 데스크톱(Docker Desktop)은 Windows와 macOS 사용자가 도커를 경험하는 첫 관문이다. 도커 컨테이너는 리눅스 커널의 네임스페이스와 cgroups 기술을 기반으로 작동하기 때문에, 리눅스가 아닌 운영체제에서는 직접 실행할 수 없다. Docker Desktop은 내부적으로 경량 리눅스 가상 머신을 실행하고 그 위에서 컨테이너를 구동함으로써 이 문제를 해결한다.\n\n\n\n\n\n그림 1.4: Docker Desktop 아키텍처\n\n\n그림 1.4 은 세 가지 운영체제에서 도커가 작동하는 방식을 보여준다. Windows에서는 WSL 2(Windows Subsystem for Linux 2)와 통합되어 네이티브에 가까운 성능을 제공하고, macOS에서는 Apple Silicon의 Virtualization.framework를 활용한다. 두 환경 모두 사용자가 내부 구조를 의식할 필요 없이 터미널에서 docker run 명령만 실행하면 된다. 리눅스에서는 VM 없이 Docker Engine만 설치해 커널과 직접 통신하므로 가장 효율적이다.\n\n\n\n\n\n그림 1.5: Docker Desktop GUI\n\n\n그림 1.5 는 Docker Desktop 앱의 실제 화면을 보여준다. 왼쪽 사이드바에서 Containers, Images, Volumes 메뉴를 선택하고, 중앙 영역에서 각 컨테이너의 실행 상태, 사용 중인 이미지, 포트 매핑을 한눈에 확인할 수 있다. 녹색 원은 실행 중인 컨테이너, 회색 원은 종료된 컨테이너를 나타낸다. 오른쪽 버튼으로 컨테이너를 시작하거나 중지할 수 있어, 명령어를 외우지 않아도 마우스 클릭만으로 컨테이너를 관리할 수 있다. Docker Compose, Kubernetes(선택) 등 도커 생태계의 핵심 도구도 함께 설치된다.\n# Docker Desktop 설치 후 터미널에서 확인\ndocker --version\n# Docker version 24.0.7, build afdd53b\n\n# 첫 번째 컨테이너 실행 테스트\ndocker run hello-world\n라이선스 정책은 사용 규모에 따라 달라진다. 개인 사용자, 교육 목적, 소규모 기업(직원 250명 미만, 연매출 1,000만 달러 미만)은 무료로 사용할 수 있고, 대기업 환경에서만 유료 구독이 필요하다. 리눅스 서버에서는 Docker Desktop 없이 Docker Engine만 설치하면 되므로 프로덕션 환경에서 라이선스 비용은 발생하지 않는다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-dockerfile",
    "href": "docker_concept.html#sec-dockerfile",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.7 Dockerfile",
    "text": "1.7 Dockerfile\nRocker 이미지는 훌륭한 출발점이지만, 실제 프로젝트에서는 추가 패키지나 설정이 필요하다. Dockerfile은 이미지를 만드는 “레시피”다. 어떤 베이스 이미지에서 시작할지, 어떤 패키지를 설치할지, 어떤 파일을 복사할지 순서대로 기술한다. 요리 레시피처럼 누구나 같은 Dockerfile로 동일한 이미지를 빌드할 수 있다.\n\n\n\n\n\n그림 1.8: Dockerfile 워크플로우\n\n\n그림 1.8 는 Dockerfile에서 커스텀 이미지가 만들어지는 과정을 보여준다. Dockerfile의 각 명령어가 하나의 레이어로 변환되고, 레이어들이 쌓여 최종 이미지가 완성된다. 레이어는 캐시되므로, 코드만 수정했다면 OS와 패키지 레이어는 재사용되어 빌드 시간이 단축된다.\nDockerfile의 핵심 명령어는 다섯 가지다. FROM은 베이스 이미지를 지정한다. RUN은 셸 명령어를 실행해 패키지를 설치하거나 설정을 변경한다. COPY는 로컬 파일을 이미지 안으로 복사한다. WORKDIR은 작업 디렉토리를 설정하고, CMD는 컨테이너 시작 시 실행할 기본 명령을 정의한다.\n# Dockerfile 예시: 데이터 분석 환경\nFROM rocker/rstudio:4.3.0\n\n# 시스템 라이브러리 설치 (sf, terra 패키지용)\nRUN apt-get update && apt-get install -y \\\n    libgdal-dev \\\n    libgeos-dev \\\n    libproj-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# R 패키지 설치\nRUN R -e \"install.packages(c('tidyverse', 'sf', 'terra', 'gt'), repos='https://cloud.r-project.org/')\"\n\n# 프로젝트 파일 복사\nCOPY . /home/rstudio/project\n\n# 작업 디렉토리 설정\nWORKDIR /home/rstudio/project\n\n# RStudio 포트 노출\nEXPOSE 8787\n이미지를 빌드하려면 Dockerfile이 있는 디렉토리에서 docker build 명령을 실행한다. -t 옵션으로 이미지 이름과 태그를 지정한다.\n# 이미지 빌드\ndocker build -t myproject:1.0 .\n\n# 빌드한 이미지 확인\ndocker images\n\n# 컨테이너 실행\ndocker run -d -p 8787:8787 -e PASSWORD=rstudio myproject:1.0\n\n# 브라우저에서 localhost:8787 접속\n포트 매핑(-p)은 컨테이너 내부 포트를 호스트에 노출한다. -p 8787:8787에서 콜론 왼쪽은 호스트 포트, 오른쪽은 컨테이너 포트다. RStudio Server가 컨테이너 내부에서 8787 포트로 실행되고, 이를 호스트의 8787 포트에 연결한다. 호스트 포트를 8888로 바꾸면(-p 8888:8787) 브라우저에서 localhost:8888로 접속한다. 환경 변수(-e)는 컨테이너 실행 시 설정값을 전달한다. Rocker 이미지에서 -e PASSWORD=rstudio는 RStudio 로그인 비밀번호를 지정한다. -e DISABLE_AUTH=true로 인증을 끄거나, -e ROOT=true로 sudo 권한을 부여하는 것도 가능하다.\nDockerfile을 Git으로 버전 관리하면 환경 설정 변경 이력이 남는다. 코드와 함께 Dockerfile을 공유하면 동료는 docker build 한 줄로 동일한 개발 환경을 구축한다. 6개월 후 논문 심사위원이 재현을 요청해도, Dockerfile과 코드만 있으면 정확히 같은 환경에서 분석을 실행할 수 있다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-summary",
    "href": "docker_concept.html#sec-docker-summary",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.10 핵심 정리",
    "text": "1.10 핵심 정리\n이번 장에서 다룬 도커의 핵심 개념을 정리한다.\n재현가능성 문제와 해결\n데이터 분석의 가장 큰 적은 “내 컴퓨터에서는 되는데”다. R 버전, 패키지 버전, 시스템 라이브러리가 조금만 달라져도 결과가 바뀌거나 오류가 발생한다. 도커는 OS부터 패키지까지 전체 환경을 스냅샷으로 저장해 이 문제를 근본적으로 해결한다.\n이미지와 컨테이너\n도커의 두 핵심 개념은 명확히 구분해야 한다. 이미지는 환경의 설계도이고, 컨테이너는 그 설계도로 실행한 인스턴스다. 하나의 이미지에서 여러 컨테이너를 생성할 수 있고, 각 컨테이너는 독립적으로 작동한다. docker pull로 이미지를 받고, docker run으로 컨테이너를 실행한다.\nRocker: R 사용자의 출발점\nR 환경 구축의 복잡함을 Rocker 프로젝트가 해결한다. rocker/rstudio는 RStudio Server가 포함된 개발 환경, rocker/tidyverse는 데이터 분석 환경, rocker/verse는 출판까지 가능한 완전한 환경을 제공한다. 버전 태그(:4.3.0)로 재현성을 보장받는다.\nDockerfile: 환경의 코드화\nDockerfile은 이미지를 만드는 레시피다. FROM으로 베이스 이미지를 지정하고, RUN으로 패키지를 설치하고, COPY로 파일을 복사한다. Git으로 버전 관리하면 환경 설정도 코드처럼 추적하고 공유할 수 있다.\n볼륨: 데이터 영속성\n컨테이너는 삭제되면 내부 데이터도 사라진다. -v 옵션으로 호스트 폴더를 마운트하면 데이터가 호스트에 저장되어 컨테이너 생명주기와 무관하게 유지된다. 분석 결과를 잃지 않으려면 반드시 볼륨을 사용해야 한다.\n작동 원리: 가볍고 빠른 이유\n도커 컨테이너는 VM과 달리 호스트 커널을 공유한다. 네임스페이스로 프로세스를 격리하고, cgroups로 자원을 제한한다. 이미지는 레이어 구조로 저장되어 공통 부분을 재사용한다. 그래서 수십 MB로 가볍고, 1초 만에 시작한다.\n\n\n\n\n\n\n\n\n명령어\n설명\n예시\n\n\n\ndocker pull\n이미지 다운로드\ndocker pull rocker/rstudio:4.3.0\n\n\ndocker run\n컨테이너 생성/실행\ndocker run -p 8787:8787 rocker/rstudio\n\n\ndocker ps\n실행 중인 컨테이너 목록\ndocker ps -a\n\n\ndocker stop\n컨테이너 중지\ndocker stop [컨테이너ID]\n\n\ndocker rm\n컨테이너 삭제\ndocker rm [컨테이너ID]\n\n\ndocker build\nDockerfile로 이미지 빌드\ndocker build -t myimage:1.0 .\n\n\n\n\n\n\n\n표 1.2: 도커 핵심 명령어 요약",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-next",
    "href": "docker_concept.html#sec-docker-next",
    "title": "1  도커: 재현가능한 환경",
    "section": "\n1.11 다음 단계",
    "text": "1.11 다음 단계\n이번 장에서는 도커가 왜 필요하고 어떻게 작동하는지 개념을 다뤘다. 다음 장에서는 직접 손으로 익힌다. Docker Desktop을 설치하고, 첫 번째 rocker/rstudio 컨테이너를 실행한다. 웹브라우저에서 localhost:8787을 열고 RStudio가 뜨는 순간, 도커의 가치를 체감하게 된다. 이어서 Dockerfile을 작성해 나만의 분석 환경을 만들고, Shiny 앱을 컨테이너로 배포하는 실전 워크플로우까지 진행한다.",
    "crumbs": [
      "**6부** 도커",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>도커: 재현가능한 환경</span>"
    ]
  }
]
[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "챗GPT 코딩2",
    "section": "",
    "text": "서문\n지난 몇 년간, 인공지능(AI)의 발전은 우리가 코드를 이해하고 데이터를 바라보는 방식을 근본적으로 바꾸어 놓았습니다. AI가 코드 초안을 작성해주고, 막혔던 질문에 길을 터주는 시대에, 어떤 역량을 갖춰야 할까요? 넘쳐나는 정보와 도구 속에서 길을 잃지 않고, 데이터로부터 진정한 가치를 만들어내는 전문가로 성장하려면 무엇을 배워야 할까요?\n많은 이들이 데이터 과학 프로젝트를 ’일회성 실험’으로 생각합니다. 데이터를 가져와 모델을 만들고, 결과를 보고하는 작업은 분명 중요합니다. 하지만 거기서 멈춘다면, 그 노력은 파편적인 코드와 지식으로만 남게 됩니다. AI에게 복잡한 작업을 맡기더라도, 그 결과가 얼마나 믿을 수 있는지, 내일 또 다른 데이터가 들어왔을 때 전체 과정을 손쉽게 반복할 수 있는지 확신하기 어렵습니다.\n이 책은 그 한계를 넘어서기 위한 여정으로의 초대입니다.\n단순히 코딩 문법이나 AI 도구 사용법을 나열하는 데 그치지 않고, 이 책은 ‘스스로 살아 움직이며 가치를 창출하는 지능형 데이터 시스템’ 을 구축하는 전체 과정을 안내합니다.",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "index.html#ai-네이티브-시스템의-구성-요소",
    "href": "index.html#ai-네이티브-시스템의-구성-요소",
    "title": "챗GPT 코딩2",
    "section": "AI 네이티브 시스템의 구성 요소",
    "text": "AI 네이티브 시스템의 구성 요소\n현대적인 AI 시스템은 하나의 언어나 도구로 만들어지지 않습니다. 여러 기술이 각자의 역할을 수행하며 유기적으로 연결된 ’스택(Stack)’의 형태를 띱니다. 이 책에서 우리는 AI 네이티브 시스템을 구성하는 네 개의 핵심 계층을 탐험할 것이며, 각 계층은 다음과 같은 근본적인 질문에 답합니다.\n\n\n\n\n\n\n그림 1: AI 네이티브 시스템 스택\n\n\n\n\n기반 계층 (Foundation Layer): Git, Docker, Shell “이 코드가 1년 뒤 내 동료의 컴퓨터에서도 똑같이 작동한다고 어떻게 확신할 수 있는가?” 모든 것의 기반이 되는 재현성과 환경의 기술입니다. 코드를 관리하고, 협업하며, 어떤 컴퓨터에서든 동일한 환경을 보장하는 단단한 암반과 같습니다.\n처리 계층 (Processing Layer): R & Python “이 지저분한 원본 데이터를 어떻게 의미 있는 형태로 가장 효율적으로 바꿀 수 있는가?” 데이터를 읽고, 변형하며, 비즈니스 로직을 구현하는 논리와 연산의 엔진입니다.\n지능 계층 (Intelligence Layer): LLM APIs, Vector DBs “수만 개의 고객 리뷰를 모두 읽지 않고도, 핵심적인 불만 사항과 긍정적인 반응을 어떻게 추출할 수 있는가?” 시스템에 ’생각하는 능력’을 부여하는 인지의 코어입니다.\n조율 계층 (Orchestration Layer): Make, GitHub Actions “매일 아침 9시, 내가 키보드에 손대지 않고도 이 모든 과정이 자동으로 실행되게 하려면 어떻게 해야 하는가?” 각 계층의 작업을 정해진 순서에 따라 자동으로 실행하도록 지휘하는 오케스트라 지휘자입니다.\n\n이 책의 최종 목표는, 이 모든 것을 통합하여 매일 새로운 데이터를 바탕으로 AI의 지능을 빌려 새로운 지식을 창출하고, 그 결과를 정해진 형태로 만들어내는 하나의 완전한 ’자동화된 지능형 시스템’을 완성하는 것입니다.\n이 책을 덮을 때쯤, 독자 여러분은 단순히 코드를 작성하는 사람을 넘어, 신뢰할 수 있고 자동화된 데이터 시스템을 설계하고 구축하는 전문가로 성장해 있을 것입니다. AI의 시대, 데이터로 진짜 문제를 해결하는 전문가가 되기 위한 여정을 이제 시작하겠습니다.",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "index.html#감사의-글",
    "href": "index.html#감사의-글",
    "title": "챗GPT 코딩2",
    "section": "감사의 글",
    "text": "감사의 글\n\n이 책이 탄생할 수 있도록 도움을 주신 여러분께 깊은 감사의 마음을 표합니다.\n공익법인 한국 R 사용자회가 없었다면 데이터 과학분야 챗GPT 시리즈가 세상에 나오지 못했을 것입니다. 한국 R 사용자회의 유충현 회장님, 신종화 사무처장님, 홍성학 감사님, 올해부터 새롭게 공익법인 한국 R 사용자를 이끌어주실 형환희 회장님께 감사드립니다.\n또한 이 책은 2014년 처음 몸담게 된 소프트웨어 카펜트리 그렉 윌슨 박사님과 Python for Informatics 저자인 미시건 대학 찰스 세브란스 교수님을 비롯한 전세계 수많은 익명의 기여자들의 노력과 지원이 있었고, 서울 R 미트업에서 발표해주시고 참여해주신 수많은 분들이 격려와 영감을 주셨기에 가능했습니다.\n이 책이 출간되는데 있어 이들 모든 분들의 도움 없이는 어려웠을 것입니다. 그동안의 관심과 지원에 깊은 감사를 드리며, 이 책이 데이터 과학의 발전과 독자들에게 도움이 될 수 있기를 바라는 마음으로 마무리하겠습니다.\n\n2024년 3월 속초 청초호\n이광춘",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  프로그래밍 시작하기",
    "section": "",
    "text": "1.1 왜 지금인가\n2022년 11월, OpenAI가 챗GPT(ChatGPT)를 공개하면서 세상이 바뀌었다. 코드 작성, 글쓰기, 이미지 생성까지 해내는 인공지능(AI)이 공상과학에서 현실로 넘어온 순간이다. AI가 자연어 질문에 막힘없이 답하고, 복잡한 코드 초안을 순식간에 만들어내는 시대가 열렸다.\n“왜 여전히 코딩을 배워야 하는가?”\n계산기가 발명되었을 때 “왜 산수를 배워야 하는가?”라고 물었고, 스프레드시트가 등장했을 때 “왜 회계를 배워야 하는가?”라고 물었다. 계산기는 수학자를 대체하지 않았다. 단순 반복 계산에서 해방시켜 고차원적 문제에 집중하게 했을 뿐이다. 스프레드시트도 회계사를 없애지 않았다. 재무 데이터를 분석하고 미래를 예측하는 ’금융 모델러’로 진화시켰다.\nAI도 마찬가지다. 개발자를 대체하는 것이 아니라, 한 줄 한 줄 코드를 타이핑하는 고된 노동에서 해방시킨다. 전체 시스템을 구상하고 더 큰 그림을 그리는 설계자(Architect)로 거듭나게 한다.\n진짜 문제는 ’AI가 코딩을 할 수 있는가’가 아니다. “AI를 포함한 복잡한 시스템을 어떻게 신뢰하고, 관리하며, 자동화할 것인가?”가 핵심이다. AI라는 강력한 엔진을 장착한 자동차의 운전석에 앉아 있다고 생각해보라. 엔진의 힘을 최대한 활용하되, 핸들을 굳게 잡고 브레이크를 밟을 준비를 해야 한다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "01-intro.html#sec-intro-why",
    "href": "01-intro.html#sec-intro-why",
    "title": "1  프로그래밍 시작하기",
    "section": "",
    "text": "1.1.1 개발자의 새로운 역할\nAI 시대에 인간 개발자의 역할이 바뀌고 있다. ‘코드를 쌓는 벽돌공’에서 ‘도시를 설계하는 건축가’로.\nAI는 지금까지 본 적 없는 뛰어난 벽돌공이다. 지치지 않고, 불평하지 않으며, 놀라운 속도로 벽돌(코드)을 쌓아 올린다. 하지만 어떤 건물을 지어야 할지, 도시의 맥락과 조화를 이루는지, 사람들에게 어떤 영향을 미칠지는 모른다. 그림 1.1 는 벽돌공에서 건축가로의 전환을 보여준다.\n\n\n\n\n\n그림 1.1: 프로그래밍 패러다임 변화 - 벽돌공에서 건축가로\n\n\n그림 1.1 왼쪽에서 과거의 개발자는 망치를 들고 직접 벽돌을 쌓는다. 오른쪽에서 AI 시대의 개발자는 설계도를 들고 AI에게 지시한다. 건축가는 어떤 문제를 풀 것인지 정의하고, 청사진을 그린다. AI가 쌓은 벽이 튼튼한지, 설계도대로 지어졌는지 끊임없이 의심하고 검증한다. 건물이 사람들과 사회에 긍정적인 영향을 미치는지 성찰하고, 잠재적 위험을 관리한다. AI의 도움을 받았더라도 완성된 건물에 대한 최종 책임은 건축가에게 있다.\n더 이상 단순히 ’코딩’을 배우는 것이 아니다. 시스템을 설계하고 AI와 협업하는 법을 배운다.\n\n1.1.2 프로그래밍 매력\n프로그래밍은 개인적으로나 경제적으로 매력적인 활동이다. 유용하고, 아름답고, 똑똑한 프로그램을 만들어 다른 사람이 쓰게 하는 것은 창의적인 작업이다. 스마트폰에 설치된 수많은 앱을 보라. 프로그래머들이 사용자의 관심을 얻기 위해 경쟁하며 만든 결과물이다.\n이 책에서는 사업이나 사용자를 기쁘게 하는 것보다, 일상에서 맞닥뜨리는 자료와 정보를 다뤄 삶을 생산적으로 만드는 데 초점을 맞춘다. 프로그램을 만들기 시작하면, 프로그래머이면서 동시에 자신이 만든 프로그램의 사용자가 된다. 기술을 습득하고 프로그래밍이 창의적으로 느껴지기 시작하면, 다른 사람을 위해 프로그램을 개발할 준비가 된 것이다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "01-intro.html#sec-intro-what",
    "href": "01-intro.html#sec-intro-what",
    "title": "1  프로그래밍 시작하기",
    "section": "\n1.2 컴퓨터란 무엇인가",
    "text": "1.2 컴퓨터란 무엇인가\n \n컴퓨터는 다섯 가지 요소로 이루어진 시스템이다. 하드웨어가 물리적 기반을 제공하고, 소프트웨어가 하드웨어에 명령을 내린다. 네트워크로 다른 컴퓨터와 연결되고, 데이터를 저장하고 처리한다. 최근에는 AI가 다섯 번째 요소로 추가되어, 사람의 판단이 필요했던 영역까지 자동화하고 있다.\n프로그래머는 다섯 요소를 조합해 문제를 해결한다. 하드웨어의 한계를 이해하고, 소프트웨어로 논리를 구현하며, 네트워크로 서비스를 연결하고, 데이터에서 의미를 추출한다. AI 시대에는 AI를 언제 어떻게 활용할지 판단하는 능력까지 요구된다.\n\n1.2.1 하드웨어 구조\n일상은 노트북에서 스마트폰까지 다양한 컴퓨터에 둘러싸여 있다. 컴퓨터를 많은 일을 대신해 주는 “개인비서”로 생각해보자. 컴퓨터 하드웨어는 끊임없이 “다음에 무엇을 할까요?”라고 묻도록 설계되어 있다. 그림 1.2 는 컴퓨터가 수행하는 기본 작업을 보여준다.\n\n\n\n\n\n그림 1.2: 컴퓨터 소개\n\n\n그림 1.2 에서 보듯이 컴퓨터는 입력을 받아 처리하고 출력한다. 텍스트와 클릭부터 음성과 이미지까지 다양한 형태의 입력을 받아들이고, “다음에 무엇을 할까요?”라는 질문에 답하며, 결과를 화면이나 파일로 내보낸다. 컴퓨터가 질문에 답하려면 여러 부품이 협력해야 한다. 노트북이나 스마트폰을 분해하면 여섯 가지 핵심 부품을 발견할 수 있다. 각 부품은 고유한 역할을 맡아 전체 시스템이 작동하도록 돕는다. 그림 1.3 는 부품 간 연결 구조를 보여준다.\n\n\n\n\n\n그림 1.3: 컴퓨터 아키텍처\n\n\n그림 1.3 에서 CPU가 중심에 위치하고, 입출력장치, 네트워크, GPU, 메모리가 연결된다. 중앙처리장치(CPU)는 “다음에 뭘 할까?”라는 질문에 답하는 두뇌다. 순차적으로 명령을 처리하며, 3.0 GHz CPU라면 초당 30억 개의 범용 연산을 수행한다. GPU는 CPU와 다른 방식으로 일한다. 수천 개의 작은 코어가 동시에 계산을 처리하는 병렬 처리에 특화되어 있어, AI 모델 학습과 추론에 필수적인 부품이 되었다.\n주기억장치(RAM)는 CPU가 즉시 필요한 정보를 저장한다. 빠르지만 전원이 꺼지면 내용이 사라진다. 보조기억장치(SSD/HDD)는 느리지만 전원이 꺼져도 정보가 유지된다. 입출력장치는 키보드와 마우스로 텍스트와 클릭을 입력받고, 화면과 파일로 결과를 출력한다. AI 시대에는 음성과 이미지도 자연스러운 입출력 수단이 되었다. 네트워크는 인터넷과 클라우드를 통해 외부 데이터를 주고받으며, 최근에는 AI API 호출의 통로 역할까지 담당한다.\n프로그래머는 CPU에 “다음에 무엇을 실행하라”고 지시한다. 필요에 따라 GPU에 병렬 연산을 맡기고, 메모리에 데이터를 저장하며, 네트워크를 통해 외부 서비스와 통신한다.\n과거에는 프로그래머가 컴퓨터와 직접 대화했다. 문법을 외우고, 한 줄 한 줄 코드를 작성해야 했다. AI 시대에는 중간에 새로운 계층이 등장했다. 프로그래머는 자연어로 의도를 전달하고, AI 에이전트가 맥락을 이해해 파이썬이나 R 코드로 번역한다. 컴퓨터는 여전히 코드를 실행하지만, 코드를 작성하는 주체가 달라졌다. 그림 1.4 은 사람 → AI → 기계로 이어지는 새로운 흐름을 보여준다.\n\n\n\n\n\n그림 1.4: AI 시대 컴퓨팅 스택\n\n\n그림 1.4 에서 사용자는 자연어와 테스트로 의도를 전달하고, AI 에이전트가 파이썬이나 R 코드로 변환해 컴퓨터에 전달한다. 프로그래머의 역할은 코드 작성에서 의도 정의와 검증으로 이동했다. AI가 생성한 코드가 원래 의도와 맞는지 확인하고, 오류가 있으면 수정을 요청한다. “의도”만 명확하면 실행 가능한 프로그램이 나온다. 문법 암기보다 문제 정의와 결과 검증 능력이 중요해진 이유다.\n\n1.2.2 프로그램이란\n프로그램(Program)은 특정 작업을 수행하는 파이썬 문장의 집합이다. hello.py처럼 한 줄짜리도 프로그램이고, 수천 줄에 달하는 복잡한 시스템도 프로그램이다. 프로그램의 핵심은 반복적인 작업을 자동화한다는 데 있다.\n소셜 미디어 게시물에서 가장 자주 사용된 단어를 찾는 연구를 한다고 가정하자. 아래 텍스트에서 가장 많이 나오는 단어와 빈도를 손으로 세어보라.\nthe clown ran after the car and the car ran into the tent\nand the tent fell down on the clown and the car\n두 줄짜리 문장도 손으로 세면 시간이 걸리고 실수하기 쉽다. 수백만 줄이라면 어떨까? 파이썬 프로그램은 이러한 단순 반복 작업을 순식간에 처리한다.\ntext = 'the clown ran after the car and the car ran into the tent and the tent fell down on the clown and the car'\n\nwords = text.split()\ncounts = dict()\n\nfor word in words:\n    counts[word] = counts.get(word, 0) + 1\n\nbigcount = None\nbigword = None\n\nfor word, count in counts.items():\n    if bigcount is None or count &gt; bigcount:\n        bigword = word\n        bigcount = count\n\nprint(bigword, bigcount)\n# 출력: the 7\n위 코드는 텍스트를 단어로 쪼개고, 각 단어가 몇 번 등장했는지 세어, 가장 많이 나온 단어를 출력한다. 지금 당장 모든 문법을 이해할 필요는 없다. 프로그램이 어떤 일을 하는지 대략적인 흐름만 파악하면 된다. 파이썬 문법은 앞으로 여러 장에 걸쳐 차근차근 배운다.\n\n1.2.3 프로그램 구성요소\n프로그램 작성에 사용되는 기본 패턴이 있다. 파이썬만이 아니라 기계어부터 고수준 언어까지 모든 언어에 공통된다. 그림 1.5 는 여섯 가지 핵심 구성요소를 보여준다.\n\n\n\n\n\n그림 1.5: 프로그램 구성요소\n\n\n그림 1.5 에서 프로그램은 입력에서 시작해 출력으로 끝난다. 입력은 파일, 키보드, 센서, API 등 외부에서 데이터를 가져오는 것이다. 순차 실행은 작성된 순서대로 위에서 아래로 한 줄씩 명령을 처리한다. 조건 실행은 특정 조건을 확인하고 분기를 선택해 실행하거나 건너뛴다. 반복 실행은 조건이 충족될 때까지 같은 명령을 되풀이한다. 출력은 처리 결과를 화면, 파일, 네트워크 등으로 내보낸다.\n그림 1.5 하단 재사용(함수)은 특별한 패턴이다. 자주 쓰는 명령문 묶음에 이름을 붙여 저장하고, 필요할 때 불러 쓴다. 순차, 조건, 반복 실행 어디서든 호출할 수 있어 코드 중복을 줄이고 구조를 명확하게 만든다.\n간단해 보이지만 그렇지 않다. 프로그래밍의 예술은 기본 요소를 조합해 사용자에게 유용한 것을 만드는 데 있다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "01-intro.html#sec-intro-how",
    "href": "01-intro.html#sec-intro-how",
    "title": "1  프로그래밍 시작하기",
    "section": "\n1.3 파이썬으로 대화하기",
    "text": "1.3 파이썬으로 대화하기\n \n프로그래밍 언어도 “언어”다. 한국어나 영어처럼 단어가 있고, 단어를 배열하는 규칙이 있으며, 단어 배열에는 특정한 의미가 전달된다. 다만 대화 상대가 사람이 아니라 컴퓨터라는 점이 다르다. 컴퓨터는 모호함을 이해하지 못하기 때문에, 프로그래밍 언어는 인간 언어보다 훨씬 단순하지만 엄격하다.\n\n1.3.1 언어의 구성요소\n인간 언어든 프로그래밍 언어든 모든 언어는 세 가지 요소로 이루어진다. 사용할 수 있는 단어 목록이 있고, 단어를 배열하는 규칙이 있으며, 배열된 문장이 전달하는 의미가 있다. 그림 1.6 는 어휘, 문법, 의미라는 공통 구성요소를 보여준다.\n\n\n\n\n\n그림 1.6: 언어의 구성요소\n\n\n그림 1.6 에서 어휘(Vocabulary)는 언어가 사용하는 단어 목록이다. 한국어에는 수십만 개의 단어가 있고, 파이썬 3.10+ 기준 35개 예약어가 있다. 문법(Syntax)은 단어를 배열하는 규칙이다. “나는 밥을 먹는다”는 올바른 한국어 문장이고, if x &gt; 0:은 올바른 파이썬 문장이다. 의미(Semantics)는 문장이 전달하는 뜻이다. 문법적으로 올바른 문장이라도 의미가 없을 수 있다. “무색의 녹색 아이디어가 맹렬히 잠든다”는 문법적으로 완벽하지만 의미를 파악하기 어렵다.\n\n1.3.2 인간 언어와 프로그래밍 언어\n어휘, 문법, 의미라는 구성요소는 같지만, 인간 언어와 프로그래밍 언어는 성격이 크게 다르다. 인간 언어는 수십만 개의 단어를 유연한 규칙으로 조합하고, 맥락에 따라 의미가 달라지는 것을 허용한다. 프로그래밍 언어는 수십 개의 단어를 엄격한 규칙으로 조합하고, 의미는 항상 하나로 고정된다. 그림 1.7 은 네 가지 측면에서 차이를 비교한다.\n\n\n\n\n\n그림 1.7: 인간 언어와 프로그래밍 언어 비교\n\n\n그림 1.7 에서 가장 눈에 띄는 차이는 어휘의 크기다. 한국어 화자는 평균 5만 개 이상의 단어를 알고, 영어 원어민은 2만~3만 개를 구사한다. 반면 파이썬 예약어는 35개에 불과하다. 문법도 다르다. “나 밥 먹었어”처럼 조사를 생략해도 의사소통이 되지만, 파이썬에서 콜론 하나를 빠뜨리면 프로그램이 멈춘다. 의미 해석도 차이가 크다. “배가 아프다”에서 “배”가 신체 부위인지 과일인지 선박인지는 맥락에 따라 달라지지만, 파이썬에서 bae는 항상 같은 변수를 가리킨다.\n\n\n\n\n\n\n노트프로그래밍 언어가 엄격한 이유\n\n\n\n컴퓨터는 초당 수십억 번의 연산을 수행한다. 모호함이 허용되면 매 연산마다 “어떤 의미로 해석할까?”를 판단해야 하고, 속도가 급격히 떨어진다. 프로그래밍 언어가 엄격한 이유는 컴퓨터의 한계 때문이 아니라, 빠른 실행을 위한 설계 선택이다. 인간이 모호함을 해결하고, 컴퓨터는 명확한 지시만 실행한다.\n\n\n\n1.3.3 예약어와 문법\n파이썬 어휘의 핵심은 예약어(reserved words)다. 예약어는 파이썬이 특별한 의미로 인식하는 단어로, if를 만나면 “조건을 검사하라”는 뜻으로만 해석한다. 프로그래머는 예약어 외에 자신만의 단어도 만들 수 있는데, 이를 변수(Variable)라 부른다. 변수 이름은 my_data, total_count처럼 자유롭게 지을 수 있지만, 예약어를 변수 이름으로 쓸 수는 없다. if = 10이라고 쓰면 파이썬은 혼란에 빠진다.\n강아지 훈련에 비유하면 이해가 쉽다. 강아지에게 “앉아”, “기다려”, “가져와” 같은 특별한 명령어가 있듯이, 파이썬에도 정해진 명령어가 있다. 예약어가 아닌 말을 하면 강아지는 물끄러미 쳐다볼 뿐이고, 파이썬은 오류를 뱉는다. 다만 강아지와 달리 파이썬은 이미 완벽하게 훈련되어 있어서, try라고 말하면 매번 정확히 같은 동작을 수행한다.\n표 1.1 은 파이썬 3.10+ 기준 35개 예약어를 분류별로 정리한 것이다. 파이썬 REPL에서 help(\"keywords\")를 입력하면 전체 목록을 확인할 수 있다.\n\n\n\n\n\n\n\n\n분류\n예약어\n용도\n\n\n\n제어 흐름\nif, elif, else, for, while, break, continue\n조건 분기와 반복 제어\n\n\n함수\ndef, return, lambda\n함수 정의와 반환\n\n\n클래스\nclass\n객체 지향 클래스 정의\n\n\n모듈\nimport, from, as\n외부 모듈 가져오기\n\n\n예외 처리\ntry, except, finally, raise\n오류 감지와 처리\n\n\n상수\nTrue, False, None\n논리값과 빈 값\n\n\n연산자\nand, or, not, in, is\n논리 연산과 포함 검사\n\n\n기타\nwith, pass, yield, assert, del, global, nonlocal, async, await\n컨텍스트 관리, 비동기 등\n\n\n\n\n\n\n\n표 1.1: 파이썬 3.10+ 예약어 35개\n\n\n\n예약어 35개를 모두 외울 필요는 없다. 프로그램을 작성하면서 자연스럽게 익히게 된다. 지금은 파이썬에 말을 거는 가장 간단한 방법부터 시작하자. 내장 함수 print에 따옴표로 감싼 메시지를 전달하면, 파이썬이 해당 메시지를 화면에 출력한다.\nprint(\"헬로 월드!\")\n위 코드는 파이썬 문법에 맞는 완전한 문장이다. print는 “출력하라”는 명령이고, 괄호 안의 \"헬로 월드!\"는 출력할 내용이다. 따옴표는 “이것은 텍스트 데이터다”라고 파이썬에게 알려주는 역할을 한다. 따옴표 없이 print(헬로 월드!)라고 쓰면 파이썬은 헬로라는 변수를 찾으려 하고, 찾지 못하면 오류를 낸다.\n\n1.3.4 인터프리터와 대화\n \n간단한 문장을 만들었으니, 이제 파이썬과 대화를 시작해보자. 파이썬을 공식 웹사이트에서 설치한 뒤, 터미널이나 명령 프롬프트에서 python을 입력하면 인터프리터가 인터랙티브 모드로 시작된다. 화면에 &gt;&gt;&gt; 프롬프트가 나타나면 파이썬이 대화할 준비가 된 것이다.\nPython 3.11.8 (tags/v3.11.8:db85d51, Feb  6 2024, 22:03:32) [MSC v.1937 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\n인터랙티브 모드는 REPL(Read-Eval-Print Loop)이라고도 부른다. 그림 1.8 에서 볼 수 있듯이, 사용자가 코드를 입력하면(Read), 파이썬이 이를 실행하고(Eval), 결과를 출력한 뒤(Print), 다시 입력을 기다리는(Loop) 과정이 끊임없이 반복된다. 이 순환 구조 덕분에 코드를 한 줄씩 실행하며 즉각적인 피드백을 받을 수 있어, 새로운 문법을 익히거나 아이디어를 빠르게 시험해보기에 안성맞춤이다.\n\n\n\n\n\n그림 1.8: REPL: 인터랙티브 모드의 순환 구조\n\n\n파이썬 언어를 전혀 모른다고 가정하고, 외계 행성에 착륙한 우주비행사처럼 말을 걸어보자.\n&gt;&gt;&gt; I come in peace, please take me to your leader\n  File \"&lt;stdin&gt;\", line 1\n    I come in peace, please take me to your leader\n      ^^^^^\nSyntaxError: invalid syntax\n영어로 말을 걸었지만 파이썬은 알아듣지 못한다. 파이썬 문법에 맞게 다시 시도해보자.\n&gt;&gt;&gt; print(\"헬로 파이썬!\")\n헬로 파이썬!\n&gt;&gt;&gt; print('당신은 하늘에서 온 전설적인 신이 분명합니다')\n당신은 하늘에서 온 전설적인 신이 분명합니다\n이번에는 대화가 잘 진행된다. 하지만 사소한 실수를 저지르면 파이썬은 곧바로 오류를 내며 대화를 중단한다. 파이썬은 복잡하고 강력하지만 구문(Syntax)에 엄격하기 때문에, 정해진 규칙대로 말해야만 알아듣는다. 대화를 끝내려면 exit() 또는 quit()를 입력한다.\n&gt;&gt;&gt; good-bye\nNameError: name 'good' is not defined\n&gt;&gt;&gt; exit()\ngood-bye가 오류를 낸 이유는 파이썬이 good이라는 변수를 찾으려 했기 때문이다. 하이픈(-)은 파이썬에서 빼기 연산자이므로, good - bye는 “good이라는 변수에서 bye라는 변수를 빼라”는 뜻으로 해석된다.\n\n\n\n\n\n\n힌트인터프리터와 컴파일러\n\n\n\n \n파이썬은 사람이 읽고 쓸 수 있으면서 컴퓨터도 처리할 수 있는 고수준(High-level) 언어다. 자바, C++, PHP, 루비, 자바스크립트 등도 고수준 언어에 속한다. 하지만 CPU가 이해하는 것은 0과 1로만 이루어진 기계어(machine language)뿐이다. 기계어는 01010001110100100101010000001111처럼 생겼는데, 단순해 보여도 실제로는 파이썬보다 훨씬 복잡하다. 기계어로 직접 코드를 작성하는 프로그래머는 극소수이며, 대신 고수준 언어를 기계어로 변환하는 번역기(translator)를 사용한다.\n\n\n\n\n\n그림 1.9: 인터프리터와 컴파일러 비교\n\n\n그림 1.9 에서 보듯이 번역기는 인터프리터(Interpreter)와 컴파일러(Compiler) 두 종류로 나뉜다. 인터프리터는 소스 코드를 한 줄씩 읽고 즉석에서 실행하며, 파이썬이 여기에 속한다. 컴파일러는 전체 소스 코드를 먼저 기계어로 번역해 실행 파일을 만든 뒤 실행한다. C, C++, Go, Rust 등이 컴파일러 방식을 사용한다.\n인터프리터가 즉각적인 피드백을 제공한다면, 컴파일러는 왜 여전히 쓰일까? 핵심은 실행 속도다. 컴파일러는 실행 전에 전체 코드를 분석하고 최적화하므로, 같은 작업을 수십~수백 배 빠르게 처리한다. 운영체제, 게임 엔진, 데이터베이스처럼 성능이 생명인 소프트웨어는 컴파일러 언어로 작성된다. 파이썬 인터프리터 자체도 C 언어로 만들어졌다(CPython). 결국 두 방식은 “개발 속도 vs 실행 속도”라는 상충 관계에 있으며, 용도에 따라 선택한다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "01-intro.html#sec-intro-challenge",
    "href": "01-intro.html#sec-intro-challenge",
    "title": "1  프로그래밍 시작하기",
    "section": "\n1.4 오류와 디버깅",
    "text": "1.4 오류와 디버깅\n \n앞서 보았듯이 파이썬 코드는 명확하게 작성해야 한다. 작은 실수 하나가 프로그램 전체를 멈추게 만들기도 한다. 초보자는 파이썬이 냉정하다고 느끼지만, 파이썬은 감정 없는 도구일 뿐이다. 오류 메시지는 비난이 아니라 도움 요청이다. “입력한 것을 이해하지 못하겠다”고 말하는 것뿐이므로, 파이썬과 싸워봐야 소용없다.\n&gt;&gt;&gt; primt(\"안녕 세상!\")\nNameError: name 'primt' is not defined\n&gt;&gt;&gt; 나는 파이썬이 싫어!\nSyntaxError: invalid syntax\n프로그램이 복잡해지면 그림 1.10 에서 보는 것처럼 세 종류의 오류를 만나게 된다. 구문 오류(Syntax Error)는 가장 흔하고 고치기 쉽다. 파이썬 문법에 맞지 않는다는 뜻이며, 오류 위치를 알려주지만 실제 원인은 앞줄에 있을 수도 있다. 논리 오류(Logic Error)는 구문은 맞지만 실행 순서가 잘못된 경우다. “물병에서 한 모금 마시고, 가방에 넣고, 도서관으로 걸어가서, 물병을 닫는다”처럼 순서가 뒤바뀌면 원하는 결과를 얻지 못한다. 의미론적 오류(Semantic Error)는 구문도 맞고 순서도 맞지만 의도한 대로 동작하지 않는 경우다. 식당 가는 길을 알려주면서 “왼쪽”이라고 해야 할 곳에서 “오른쪽”이라고 말한 것과 같다. 어떤 오류든 파이썬은 요청받은 대로 충실히 실행할 뿐이다.\n\n\n\n\n\n그림 1.10: 세 가지 오류 유형\n\n\n처음에 개념이 잘 와닿지 않아도 기죽을 필요 없다. 말하기를 배울 때도 처음 몇 년은 옹알이를 하고, 어휘에서 문장으로, 문장에서 문단으로 넘어가는 데 몇 년이 걸린다. 프로그래밍도 마찬가지다. 이 책은 파이썬을 빠르게 배울 수 있도록 정보를 제공하지만, 새 언어를 익히는 것처럼 자연스럽게 느껴지기까지 시간이 필요하다. 꼭 순서대로 읽을 필요는 없으니 앞뒤를 넘나들며 읽어도 좋다.\n첫 프로그래밍 언어를 배울 때는 “유레카!” 순간이 몇 번 찾아온다. 망치와 끌로 돌을 깎아 조각품을 만드는 과정과 비슷하다. 뭔가 특별히 어렵다면 밤새 붙잡고 있지 말고, 쉬거나 낮잠을 자거나 간식을 먹거나 다른 사람(또는 강아지)에게 문제를 설명해보라. 머리를 식힌 뒤 다시 시도하면 의외로 쉽게 풀리는 경우가 많다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "01-intro.html#생각해볼-점",
    "href": "01-intro.html#생각해볼-점",
    "title": "1  프로그래밍 시작하기",
    "section": "💡 생각해볼 점",
    "text": "💡 생각해볼 점\n컴퓨터는 “다음에 무엇을 할까?”라는 질문을 끊임없이 던지는 기계이고, 프로그래머는 질문에 대한 답을 미리 작성해두는 사람이다. CPU가 연산을 수행하고, 메모리가 데이터를 보관하며, 저장장치가 전원이 꺼져도 정보를 유지한다는 사실은 변하지 않는다. 달라진 것은 답을 작성하는 방식이다.\n전통적인 프로그래밍 학습에서는 구문을 암기하고 직접 코드를 타이핑하는 것이 핵심이었다. 하지만 AI 시대에 접어들면서 프로그래머 역할이 “코드 작성자”에서 “의도 설계자”이자 “코드 검토자”로 이동하고 있다. 키보드로 코드를 얼마나 빨리 칠 수 있느냐보다, 원하는 동작을 얼마나 명확하게 정의할 수 있느냐가 중요해졌다.\n다음 장에서는 의도를 명확하게 정의하는 방법을 다룬다. 테스트 코드를 통해 “이렇게 동작해야 한다”는 명세를 작성하고, AI에게 전달하여 실제 코드를 생성받는 워크플로우를 배운다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>프로그래밍 시작하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html",
    "href": "02-spec.html",
    "title": "2  의도 명세하기",
    "section": "",
    "text": "2.1 AI 시대 프로그래밍 패러다임\n프로그래밍의 본질은 “컴퓨터에게 원하는 일을 시키는 것”이다. 전통적으로 이 과정은 프로그래밍 언어의 구문(syntax)을 배우고, 그 구문으로 코드를 직접 작성하는 방식으로 진행되었다. 그러나 AI 시대에는 근본적인 전환이 일어났다. 이제 코드 작성은 AI가 더 빠르고 정확하게 수행한다. 그렇다면 인간의 역할은 무엇인가?\n의도를 명확하게 표현하는 것이다.\n기존 프로그래밍 교육은 구문 암기 → 예제 따라하기 → 연습 문제 풀기 → 디버깅의 순서로 진행되었다. 이 방식의 문제점은 “왜 이렇게 짜는가”보다 “어떻게 쓰는가”에 집중한다는 것이다.\nAI 시대 프로그래밍은 순서가 바뀐다:\n이 패러다임에서 인간의 핵심 역량은 의도를 명확하게 표현하는 능력이다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-paradigm",
    "href": "02-spec.html#sec-spec-paradigm",
    "title": "2  의도 명세하기",
    "section": "",
    "text": "그림 2.1: 전통적 학습과 AI 시대 학습의 비교\n\n\n\n\n\n의도 명세 - “무엇을 원하는가”를 명확히 정의\nAI 코드 생성 - AI에게 구현을 위임\n코드 이해 - 생성된 코드의 동작 원리 파악\n검증과 개선 - 의도대로 동작하는지 확인",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-test-is-spec",
    "href": "02-spec.html#sec-spec-test-is-spec",
    "title": "2  의도 명세하기",
    "section": "2.2 테스트는 명세서다",
    "text": "2.2 테스트는 명세서다\n의도를 표현하는 가장 효과적인 방법은 테스트 코드를 작성하는 것이다. 테스트는 단순히 코드의 정확성을 검증하는 도구가 아니다. AI 시대에 테스트는 “내가 원하는 것”을 AI가 이해할 수 있는 형식으로 표현한 명세서(Specification)가 된다.\n\n\n\n\n\n\n그림 2.2: 테스트 = AI에게 의도를 전달하는 명세서\n\n\n\n\n2.2.1 명세서가 담아야 할 정보\n좋은 테스트(명세서)는 다음 정보를 담아야 한다:\n\n함수/기능의 이름: 무엇을 하는 기능인가\n입력(Input): 어떤 데이터를 받는가\n출력(Output): 어떤 결과를 반환하는가\n경계 조건: 특수한 상황에서 어떻게 동작해야 하는가",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-calculator",
    "href": "02-spec.html#sec-spec-calculator",
    "title": "2  의도 명세하기",
    "section": "2.3 관통 예제: 간단한 계산기",
    "text": "2.3 관통 예제: 간단한 계산기\n이 책 전체를 관통하는 예제로 간단한 계산기를 만들어 보자. 계산기는 단순해 보이지만, 프로그래밍의 핵심 개념을 모두 담고 있다.\n\n2.3.1 덧셈 기능의 의도 명세\n“두 숫자를 더하는 기능이 필요해.”\n이 의도를 테스트 코드로 표현하면:\n#| eval: false\ndef test_add():\n    \"\"\"덧셈 기능에 대한 명세서\"\"\"\n\n    # 기본 덧셈\n    assert add(2, 3) == 5\n    assert add(0, 0) == 0\n    assert add(100, 200) == 300\n\n    # 음수 처리\n    assert add(-1, 1) == 0\n    assert add(-2, -3) == -5\n\n    # 소수점\n    assert add(1.5, 2.5) == 4.0\n이 테스트 코드가 담고 있는 명세:\n\n\n\n\n\n\n항목\n내용\n\n\n\n\n함수 이름\nadd\n\n\n입력\n두 개의 숫자 (정수, 음수, 소수 모두 가능)\n\n\n출력\n두 수의 합\n\n\n특이사항\n음수와 소수점도 올바르게 처리해야 함\n\n\n\n\n\n표 2.1: 테스트 코드에서 추출한 명세서\n\n\n\n\n\n2.3.2 왜 테스트가 먼저인가?\n전통적 프로그래밍에서는 코드를 먼저 작성하고 테스트는 나중에(혹은 아예 안) 작성했다. AI 시대에는 순서가 바뀐다:\nRed:     실패하는 테스트 작성 (인간) ← 핵심 역량\nGreen:   테스트 통과하는 코드 생성 (AI)\nRefactor: 코드 리뷰 및 개선 (인간 + AI 협업)\n\n\n\n\n\n\n그림 2.3: AI 시대 TDD 워크플로우\n\n\n\n테스트를 먼저 작성하면:\n\n의도가 명확해진다 - “무엇을 원하는가”를 구체적으로 생각하게 됨\nAI 소통이 정확해진다 - 모호한 자연어 대신 정확한 코드로 의도 전달\n검증이 자동화된다 - AI가 생성한 코드가 맞는지 즉시 확인 가능",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-basics",
    "href": "02-spec.html#sec-spec-basics",
    "title": "2  의도 명세하기",
    "section": "2.4 테스트 작성의 기초",
    "text": "2.4 테스트 작성의 기초\n\n2.4.1 assert 문 이해하기\nassert는 “이것이 참이어야 한다”는 선언이다:\n#| eval: false\n# 기본 형태\nassert 1 + 1 == 2          # 통과: 참이므로\n# assert 1 + 1 == 3        # 실패: AssertionError 발생\n#| eval: false\n# 변수와 함께\nresult = 10 * 5\nassert result == 50        # result가 50인지 확인\n\n\n2.4.2 좋은 테스트의 특징\n1. 하나의 테스트는 하나의 동작을 검증한다\n#| eval: false\n# 좋은 예: 각각 분리\ndef test_add_positive_numbers():\n    assert add(2, 3) == 5\n\ndef test_add_negative_numbers():\n    assert add(-2, -3) == -5\n2. 테스트 이름이 의도를 설명한다\n#| eval: false\n# 나쁜 예\ndef test1():\n    assert add(2, 3) == 5\n\n# 좋은 예\ndef test_add_returns_sum_of_two_positive_integers():\n    assert add(2, 3) == 5\n3. 경계 조건을 포함한다\n#| eval: false\ndef test_add_edge_cases():\n    assert add(0, 0) == 0              # 영(零)\n    assert add(-1, 1) == 0             # 상쇄\n    assert add(999999, 1) == 1000000   # 큰 수",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-practice",
    "href": "02-spec.html#sec-spec-practice",
    "title": "2  의도 명세하기",
    "section": "2.5 실습: 뺄셈 기능 명세하기",
    "text": "2.5 실습: 뺄셈 기능 명세하기\n계산기에 뺄셈 기능을 추가해보자. 먼저 테스트(명세서)를 작성한다:\n#| eval: false\ndef test_subtract():\n    \"\"\"뺄셈 기능에 대한 명세서\"\"\"\n\n    # 기본 뺄셈\n    assert subtract(5, 3) == 2\n    assert subtract(10, 10) == 0\n\n    # 음수 결과\n    assert subtract(3, 5) == -2\n\n    # 음수 입력\n    assert subtract(-3, -5) == 2    # -3 - (-5) = 2\n    assert subtract(-3, 5) == -8    # -3 - 5 = -8\n이 테스트가 담고 있는 명세를 정리해보면:\n\n함수 이름: subtract\n입력: 두 개의 숫자 (첫 번째에서 두 번째를 뺌)\n출력: 차이 값\n특이사항: 음수 입력과 음수 결과를 올바르게 처리",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "02-spec.html#sec-spec-summary",
    "href": "02-spec.html#sec-spec-summary",
    "title": "2  의도 명세하기",
    "section": "2.6 핵심 정리",
    "text": "2.6 핵심 정리\n\n\n\n\n\n\n힌트AI 시대 프로그래밍의 핵심\n\n\n\n\n테스트 = 명세서: 테스트는 “내가 원하는 것”을 정확히 표현한 문서다\n의도 먼저: 코드 작성 전에 의도를 명확히 정의한다\nAI는 실행자: 명세(테스트)를 주면 AI가 코드를 생성한다\n인간은 설계자: 무엇을 만들지 결정하고, 결과를 검증하는 것이 인간의 역할\n\n\n\n다음 장에서는 이렇게 작성한 테스트를 AI에게 전달하여 실제 코드를 생성받는 방법을 알아본다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>의도 명세하기</span>"
    ]
  },
  {
    "objectID": "03-ai-request.html",
    "href": "03-ai-request.html",
    "title": "3  AI에게 코드 요청하기",
    "section": "",
    "text": "3.1 효과적인 프롬프트 작성법\n앞 장에서 테스트를 통해 “원하는 것”을 명세했다. 이제 이 명세를 AI에게 전달하여 실제 코드를 생성받는 방법을 알아본다.\nAI에게 코드를 요청할 때 가장 중요한 것은 맥락(Context)을 제공하는 것이다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI에게 코드 요청하기</span>"
    ]
  },
  {
    "objectID": "03-ai-request.html#sec-ai-request-prompt",
    "href": "03-ai-request.html#sec-ai-request-prompt",
    "title": "3  AI에게 코드 요청하기",
    "section": "",
    "text": "3.1.1 맥락 전달의 3요소\n\n무엇을 만들려 하는가 (목적)\n어떤 제약이 있는가 (조건)\n어떻게 동작해야 하는가 (명세/테스트)",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI에게 코드 요청하기</span>"
    ]
  },
  {
    "objectID": "03-ai-request.html#sec-ai-request-add",
    "href": "03-ai-request.html#sec-ai-request-add",
    "title": "3  AI에게 코드 요청하기",
    "section": "3.2 계산기 예제: 덧셈 구현 요청",
    "text": "3.2 계산기 예제: 덧셈 구현 요청\n2장에서 작성한 테스트를 기반으로 AI에게 코드를 요청해보자.\n\n3.2.1 테스트 기반 프롬프트\n다음 테스트를 통과하는 add 함수를 작성해주세요:\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(0, 0) == 0\n    assert add(-1, 1) == 0\n    assert add(-2, -3) == -5\n    assert add(1.5, 2.5) == 4.0\n\n\n3.2.2 AI의 응답\n#| eval: false\ndef add(a, b):\n    \"\"\"두 수를 더한 값을 반환한다.\"\"\"\n    return a + b\n테스트 실행으로 검증:\n#| eval: false\n# 테스트 실행\nassert add(2, 3) == 5\nassert add(0, 0) == 0\nassert add(-1, 1) == 0\nassert add(-2, -3) == -5\nassert add(1.5, 2.5) == 4.0\n\nprint(\"모든 테스트 통과!\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI에게 코드 요청하기</span>"
    ]
  },
  {
    "objectID": "03-ai-request.html#sec-ai-request-rich-context",
    "href": "03-ai-request.html#sec-ai-request-rich-context",
    "title": "3  AI에게 코드 요청하기",
    "section": "3.3 맥락을 풍부하게 제공하기",
    "text": "3.3 맥락을 풍부하게 제공하기\n단순한 테스트만 전달하는 것보다 더 풍부한 맥락을 제공하면 더 좋은 코드를 받을 수 있다:\n# 프로젝트 맥락\nPython으로 간단한 계산기를 만들고 있습니다.\n초보자도 이해할 수 있는 깔끔한 코드가 필요합니다.\n\n# 요구사항\n- 덧셈 함수 구현\n- 정수, 실수, 음수 모두 처리\n- 타입 힌트 포함\n- docstring 포함\n\n# 테스트 (명세)\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(1.5, 2.5) == 4.0",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI에게 코드 요청하기</span>"
    ]
  },
  {
    "objectID": "03-ai-request.html#sec-ai-request-summary",
    "href": "03-ai-request.html#sec-ai-request-summary",
    "title": "3  AI에게 코드 요청하기",
    "section": "3.4 핵심 정리",
    "text": "3.4 핵심 정리\n\n\n\n\n\n\n힌트AI 코드 요청의 핵심\n\n\n\n\n테스트를 먼저 보여준다 - 가장 정확한 명세\n맥락을 제공한다 - 프로젝트 목적, 제약조건\n구체적으로 요청한다 - 모호함을 피한다\n\n\n\n다음 장에서는 AI가 생성한 코드를 읽고 이해하는 방법을 알아본다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI에게 코드 요청하기</span>"
    ]
  },
  {
    "objectID": "04-verify.html",
    "href": "04-verify.html",
    "title": "4  코드 읽기와 검증",
    "section": "",
    "text": "4.1 왜 코드를 읽어야 하는가\nAI가 생성한 코드를 무조건 신뢰해서는 안 된다. 코드가 의도대로 동작하는지 검증하고, 어떻게 동작하는지 이해하는 것이 AI 시대 프로그래머의 핵심 역량이다.\nAI가 코드를 생성해주지만, 그 코드에는 여전히 문제가 있을 수 있다:",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "04-verify.html#sec-verify-why-read",
    "href": "04-verify.html#sec-verify-why-read",
    "title": "4  코드 읽기와 검증",
    "section": "",
    "text": "잘못된 이해 - AI가 의도를 오해했을 수 있다\n엣지 케이스 누락 - 명세하지 않은 상황에서 오류 발생 가능\n비효율적 구현 - 동작하지만 성능이 나쁜 코드\n보안 취약점 - 의도치 않은 보안 문제",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "04-verify.html#sec-verify-calculator",
    "href": "04-verify.html#sec-verify-calculator",
    "title": "4  코드 읽기와 검증",
    "section": "4.2 계산기 예제: 코드 검증",
    "text": "4.2 계산기 예제: 코드 검증\nAI가 생성한 덧셈 함수를 검증해보자.\n\n4.2.1 기본 테스트 실행\n#| eval: false\ndef add(a, b):\n    return a + b\n\n# 기본 테스트\nassert add(2, 3) == 5\nassert add(-1, 1) == 0\nprint(\"기본 테스트 통과!\")\n\n\n4.2.2 엣지 케이스 추가\n명세에 없던 상황을 테스트해본다:\n#| eval: false\n# 큰 수\nassert add(10**10, 10**10) == 2 * 10**10\n\n# 아주 작은 소수\nresult = add(0.1, 0.2)\nprint(f\"0.1 + 0.2 = {result}\")  # 부동소수점 주의!\n부동소수점 연산의 특성상 0.1 + 0.2가 정확히 0.3이 아닐 수 있다. 이런 발견이 코드 읽기와 검증의 가치다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "04-verify.html#sec-verify-understand",
    "href": "04-verify.html#sec-verify-understand",
    "title": "4  코드 읽기와 검증",
    "section": "4.3 코드 이해하기",
    "text": "4.3 코드 이해하기\n\n4.3.1 단계별 실행 추적\n코드가 어떻게 동작하는지 단계별로 추적해본다:\n#| eval: false\ndef add_with_trace(a, b):\n    print(f\"입력: a={a}, b={b}\")\n    result = a + b\n    print(f\"계산: {a} + {b} = {result}\")\n    return result\n\nadd_with_trace(3, 5)\n\n\n4.3.2 타입 확인\n입력과 출력의 타입을 확인한다:\n#| eval: false\ndef check_types():\n    # 정수 + 정수\n    r1 = add(3, 5)\n    print(f\"3 + 5 = {r1}, type: {type(r1)}\")\n\n    # 실수 + 실수\n    r2 = add(3.0, 5.0)\n    print(f\"3.0 + 5.0 = {r2}, type: {type(r2)}\")\n\n    # 정수 + 실수\n    r3 = add(3, 5.0)\n    print(f\"3 + 5.0 = {r3}, type: {type(r3)}\")\n\ncheck_types()",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "04-verify.html#sec-verify-checklist",
    "href": "04-verify.html#sec-verify-checklist",
    "title": "4  코드 읽기와 검증",
    "section": "4.4 검증 체크리스트",
    "text": "4.4 검증 체크리스트\nAI 생성 코드를 받았을 때 확인할 사항:\n\n\n\n\n\n\n노트코드 검증 체크리스트\n\n\n\n\n원래 테스트가 모두 통과하는가?\n엣지 케이스에서도 동작하는가?\n예상치 못한 입력에 어떻게 반응하는가?\n코드가 읽기 쉽고 이해 가능한가?\n불필요하게 복잡하지 않은가?",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "04-verify.html#sec-verify-summary",
    "href": "04-verify.html#sec-verify-summary",
    "title": "4  코드 읽기와 검증",
    "section": "4.5 핵심 정리",
    "text": "4.5 핵심 정리\n\n\n\n\n\n\n힌트코드 검증의 핵심\n\n\n\n\n테스트 실행 - 명세한 테스트를 먼저 실행\n엣지 케이스 - 명세에 없던 상황도 테스트\n코드 이해 - 동작 원리를 파악\n개선 요청 - 문제 발견 시 AI에게 수정 요청\n\n\n\n다음 장부터는 AI가 생성한 코드를 뜯어보며 프로그래밍의 핵심 개념들을 학습한다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>코드 읽기와 검증</span>"
    ]
  },
  {
    "objectID": "05-data.html",
    "href": "05-data.html",
    "title": "5  데이터와 타입",
    "section": "",
    "text": "5.1 데이터란 무엇인가\nAI가 생성한 계산기 코드를 분석하면서 프로그래밍의 기본 요소인 데이터와 타입을 이해해보자.\n프로그램은 데이터를 처리하는 도구다. 계산기 예제에서:",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "05-data.html#sec-data-what",
    "href": "05-data.html#sec-data-what",
    "title": "5  데이터와 타입",
    "section": "",
    "text": "입력 데이터: 사용자가 입력한 숫자 (2, 3)\n출력 데이터: 계산 결과 (5)\n\n#| eval: false\ndef add(a, b):\n    return a + b\n\n# a와 b는 입력 데이터, 결과는 출력 데이터\nresult = add(2, 3)\nprint(f\"결과: {result}\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "05-data.html#sec-data-variable",
    "href": "05-data.html#sec-data-variable",
    "title": "5  데이터와 타입",
    "section": "5.2 변수: 데이터에 이름 붙이기",
    "text": "5.2 변수: 데이터에 이름 붙이기\na, b, result는 모두 변수(Variable)다. 변수는 데이터를 담는 이름표가 붙은 상자라고 생각하면 된다.\n#| eval: false\n# 변수에 값 할당\nfirst_number = 10\nsecond_number = 20\n\n# 변수 사용\ntotal = add(first_number, second_number)\nprint(f\"{first_number} + {second_number} = {total}\")\n\n5.2.1 변수 명명 규칙\n좋은 변수 이름은 코드의 의도를 드러낸다:\n#| eval: false\n# 나쁜 예\nx = 100\ny = 15\nz = x + y\n\n# 좋은 예\nprice = 100\ntax_rate = 15\ntotal_price = price + tax_rate",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "05-data.html#sec-data-type",
    "href": "05-data.html#sec-data-type",
    "title": "5  데이터와 타입",
    "section": "5.3 타입: 데이터의 종류",
    "text": "5.3 타입: 데이터의 종류\nPython의 기본 데이터 타입:\n\n5.3.1 숫자 타입\n#| eval: false\n# 정수 (int)\ncount = 42\nprint(f\"count의 타입: {type(count)}\")\n\n# 실수 (float)\nprice = 19.99\nprint(f\"price의 타입: {type(price)}\")\n\n\n5.3.2 문자열 타입\n\n#| eval: false\n# 문자열 (str)\nname = \"계산기\"\nmessage = '두 수를 더합니다'\nprint(f\"name의 타입: {type(name)}\")\n\n\n5.3.3 리스트 타입\n여러 값을 담는 자료구조:\n#| eval: false\n# 리스트 (list)\nnumbers = [1, 2, 3, 4, 5]\nprint(f\"numbers의 타입: {type(numbers)}\")\nprint(f\"첫 번째 요소: {numbers[0]}\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "05-data.html#sec-data-extend",
    "href": "05-data.html#sec-data-extend",
    "title": "5  데이터와 타입",
    "section": "5.4 계산기 확장: 여러 숫자 더하기",
    "text": "5.4 계산기 확장: 여러 숫자 더하기\n리스트를 활용해 계산기를 확장해보자.\n\n5.4.1 테스트 먼저 작성\n#| eval: false\ndef test_add_many():\n    \"\"\"여러 숫자를 더하는 기능 명세\"\"\"\n    assert add_many([1, 2, 3]) == 6\n    assert add_many([10]) == 10\n    assert add_many([]) == 0\n    assert add_many([-1, 1, -1, 1]) == 0\n\n\n5.4.2 AI 생성 코드\n#| eval: false\ndef add_many(numbers):\n    \"\"\"리스트에 있는 모든 숫자를 더한다.\"\"\"\n    total = 0\n    for num in numbers:\n        total = total + num\n    return total\n\n# 테스트\nassert add_many([1, 2, 3]) == 6\nassert add_many([10]) == 10\nassert add_many([]) == 0\nprint(\"모든 테스트 통과!\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "05-data.html#sec-data-summary",
    "href": "05-data.html#sec-data-summary",
    "title": "5  데이터와 타입",
    "section": "5.5 핵심 정리",
    "text": "5.5 핵심 정리\n\n\n\n\n\n\n힌트데이터와 타입의 핵심\n\n\n\n\n변수 - 데이터에 의미 있는 이름을 붙인다\n타입 - 데이터의 종류를 구분한다 (정수, 실수, 문자열, 리스트)\n의미 있는 이름 - 변수명으로 코드의 의도를 전달한다",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>데이터와 타입</span>"
    ]
  },
  {
    "objectID": "06-logic.html",
    "href": "06-logic.html",
    "title": "6  논리와 흐름",
    "section": "",
    "text": "6.1 조건문: 분기 만들기\n프로그램은 순차적으로만 실행되지 않는다. 조건에 따라 다른 경로를 선택하고, 같은 작업을 반복해야 할 때가 있다. 계산기 코드를 확장하면서 조건문과 반복문을 이해해보자.\n계산기에 나눗셈 기능을 추가할 때, 0으로 나누는 경우를 처리해야 한다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>논리와 흐름</span>"
    ]
  },
  {
    "objectID": "06-logic.html#sec-logic-condition",
    "href": "06-logic.html#sec-logic-condition",
    "title": "6  논리와 흐름",
    "section": "",
    "text": "6.1.1 테스트 먼저\n#| eval: false\ndef test_divide():\n    \"\"\"나눗셈 기능 명세\"\"\"\n    assert divide(10, 2) == 5\n    assert divide(7, 2) == 3.5\n    assert divide(0, 5) == 0\n\n    # 0으로 나누기\n    assert divide(5, 0) is None  # 또는 에러 처리\n\n\n6.1.2 조건문 구현\n#| eval: false\ndef divide(a, b):\n    \"\"\"a를 b로 나눈다. b가 0이면 None 반환.\"\"\"\n    if b == 0:\n        return None\n    else:\n        return a / b\n\n# 테스트\nassert divide(10, 2) == 5\nassert divide(7, 2) == 3.5\nassert divide(5, 0) is None\nprint(\"나눗셈 테스트 통과!\")\n\n\n6.1.3 if-elif-else 구조\n여러 조건을 검사할 때:\n#| eval: false\ndef calculate(a, b, operation):\n    \"\"\"두 수와 연산자를 받아 계산한다.\"\"\"\n    if operation == \"+\":\n        return a + b\n    elif operation == \"-\":\n        return a - b\n    elif operation == \"*\":\n        return a * b\n    elif operation == \"/\":\n        if b == 0:\n            return None\n        return a / b\n    else:\n        return None  # 알 수 없는 연산자\n\n# 테스트\nassert calculate(10, 3, \"+\") == 13\nassert calculate(10, 3, \"-\") == 7\nassert calculate(10, 3, \"*\") == 30\nassert calculate(10, 2, \"/\") == 5\nprint(\"계산기 테스트 통과!\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>논리와 흐름</span>"
    ]
  },
  {
    "objectID": "06-logic.html#sec-logic-loop",
    "href": "06-logic.html#sec-logic-loop",
    "title": "6  논리와 흐름",
    "section": "6.2 반복문: 작업 되풀이하기",
    "text": "6.2 반복문: 작업 되풀이하기\n같은 작업을 여러 번 해야 할 때 반복문을 사용한다.\n\n6.2.1 for 반복문\n#| eval: false\ndef add_many(numbers):\n    \"\"\"리스트의 모든 숫자를 더한다.\"\"\"\n    total = 0\n    for num in numbers:\n        total = total + num\n    return total\n\nresult = add_many([1, 2, 3, 4, 5])\nprint(f\"1+2+3+4+5 = {result}\")\n\n\n6.2.2 while 반복문\n조건이 참인 동안 반복:\n#| eval: false\ndef countdown(n):\n    \"\"\"n부터 1까지 카운트다운한다.\"\"\"\n    while n &gt; 0:\n        print(n)\n        n = n - 1\n    print(\"발사!\")\n\ncountdown(3)",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>논리와 흐름</span>"
    ]
  },
  {
    "objectID": "06-logic.html#sec-logic-expression",
    "href": "06-logic.html#sec-logic-expression",
    "title": "6  논리와 흐름",
    "section": "6.3 계산기 확장: 수식 계산",
    "text": "6.3 계산기 확장: 수식 계산\n여러 연산을 연속으로 처리해보자.\n\n6.3.1 테스트 먼저\n#| eval: false\ndef test_calculate_expression():\n    \"\"\"수식 계산 명세\"\"\"\n    # \"2 + 3 * 4\" 같은 수식은 복잡하므로\n    # 단순화: [(숫자, 연산자), ...] 형태\n    assert calculate_sequence([(2, None), (3, \"+\")]) == 5  # 2 + 3\n\n\n6.3.2 구현\n#| eval: false\ndef calculate_sequence(operations):\n    \"\"\"순차적 계산을 수행한다.\n    operations: [(값, 연산자), ...] 형태\n    첫 번째 연산자는 None (초기값)\n    \"\"\"\n    if not operations:\n        return 0\n\n    result, _ = operations[0]  # 첫 번째 값이 시작점\n\n    for i in range(1, len(operations)):\n        value, operator = operations[i]\n        if operator == \"+\":\n            result = result + value\n        elif operator == \"-\":\n            result = result - value\n        elif operator == \"*\":\n            result = result * value\n        elif operator == \"/\":\n            if value != 0:\n                result = result / value\n\n    return result\n\n# 테스트: 2 + 3 - 1 = 4\nops = [(2, None), (3, \"+\"), (1, \"-\")]\nprint(f\"2 + 3 - 1 = {calculate_sequence(ops)}\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>논리와 흐름</span>"
    ]
  },
  {
    "objectID": "06-logic.html#sec-logic-summary",
    "href": "06-logic.html#sec-logic-summary",
    "title": "6  논리와 흐름",
    "section": "6.4 핵심 정리",
    "text": "6.4 핵심 정리\n\n\n\n\n\n\n힌트논리와 흐름의 핵심\n\n\n\n\n조건문 (if) - 조건에 따라 다른 코드를 실행\n반복문 (for, while) - 같은 작업을 여러 번 반복\n흐름 제어 - 프로그램의 실행 순서를 조절",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>논리와 흐름</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html",
    "href": "07-abstraction.html",
    "title": "7  추상화",
    "section": "",
    "text": "7.1 함수: 코드에 이름 붙이기\n프로그래밍의 핵심 기술 중 하나는 추상화(Abstraction)다. 복잡한 것을 단순하게, 반복되는 것을 재사용 가능하게 만드는 것이다. 계산기 예제를 통해 함수와 모듈화를 이해해보자.\n함수는 특정 작업을 수행하는 코드 블록에 이름을 붙인 것이다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html#sec-abstraction-function",
    "href": "07-abstraction.html#sec-abstraction-function",
    "title": "7  추상화",
    "section": "",
    "text": "7.1.1 함수의 구조\n#| eval: false\ndef add(a, b):\n    \"\"\"두 수를 더한다.\n\n    Args:\n        a: 첫 번째 숫자\n        b: 두 번째 숫자\n\n    Returns:\n        두 수의 합\n    \"\"\"\n    return a + b\n\ndef: 함수 정의 시작\nadd: 함수 이름\n(a, b): 매개변수 (입력)\n\"\"\"...\"\"\": 문서화 문자열 (docstring)\nreturn: 반환값 (출력)\n\n\n\n7.1.2 함수를 만드는 이유\n\n재사용 - 같은 코드를 여러 번 쓰지 않아도 된다\n추상화 - 복잡한 내용을 숨기고 이름으로 의미 전달\n테스트 - 독립적으로 테스트 가능\n유지보수 - 한 곳만 수정하면 모든 곳에 적용",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html#sec-abstraction-module",
    "href": "07-abstraction.html#sec-abstraction-module",
    "title": "7  추상화",
    "section": "7.2 계산기 모듈화",
    "text": "7.2 계산기 모듈화\n지금까지 만든 계산기 함수들을 정리해보자.\n\n7.2.1 calculator.py\n#| eval: false\n# calculator.py\n\ndef add(a, b):\n    \"\"\"두 수를 더한다.\"\"\"\n    return a + b\n\ndef subtract(a, b):\n    \"\"\"첫 번째 수에서 두 번째 수를 뺀다.\"\"\"\n    return a - b\n\ndef multiply(a, b):\n    \"\"\"두 수를 곱한다.\"\"\"\n    return a * b\n\ndef divide(a, b):\n    \"\"\"첫 번째 수를 두 번째 수로 나눈다.\n    0으로 나누면 None을 반환한다.\n    \"\"\"\n    if b == 0:\n        return None\n    return a / b\n\ndef calculate(a, b, operation):\n    \"\"\"두 수와 연산자를 받아 계산한다.\"\"\"\n    operations = {\n        \"+\": add,\n        \"-\": subtract,\n        \"*\": multiply,\n        \"/\": divide\n    }\n    if operation in operations:\n        return operations[operation](a, b)\n    return None\n\n\n7.2.2 모듈 사용하기\n#| eval: false\n# main.py\nfrom calculator import add, subtract, calculate\n\nresult = calculate(10, 3, \"+\")\nprint(f\"10 + 3 = {result}\")",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html#sec-abstraction-principles",
    "href": "07-abstraction.html#sec-abstraction-principles",
    "title": "7  추상화",
    "section": "7.3 좋은 함수 설계 원칙",
    "text": "7.3 좋은 함수 설계 원칙\n\n7.3.1 1. 한 가지 일만 한다\n#| eval: false\n# 나쁜 예: 너무 많은 일을 함\ndef process_and_print_and_save(data):\n    processed = data * 2\n    print(processed)\n    # save_to_file(processed)\n    return processed\n\n# 좋은 예: 각각 분리\ndef process(data):\n    return data * 2\n\ndef display(data):\n    print(data)\n\n\n7.3.2 2. 이름이 동작을 설명한다\n#| eval: false\n# 나쁜 예\ndef do_it(x, y):\n    return x + y\n\n# 좋은 예\ndef add_numbers(first, second):\n    return first + second\n\n\n7.3.3 3. 입력과 출력이 명확하다\n#| eval: false\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"두 정수를 더한다.\n\n    Args:\n        a: 첫 번째 정수\n        b: 두 번째 정수\n\n    Returns:\n        두 수의 합\n    \"\"\"\n    return a + b",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html#sec-abstraction-test",
    "href": "07-abstraction.html#sec-abstraction-test",
    "title": "7  추상화",
    "section": "7.4 테스트와 함수",
    "text": "7.4 테스트와 함수\n좋은 함수는 테스트하기 쉽다:\n#| eval: false\ndef test_calculator():\n    \"\"\"계산기 모듈 테스트\"\"\"\n    # add\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n\n    # subtract\n    def subtract(a, b): return a - b  # 임시 정의\n    assert subtract(5, 3) == 2\n\n    # divide (0으로 나누기)\n    def divide(a, b):\n        return None if b == 0 else a / b\n    assert divide(10, 2) == 5\n    assert divide(5, 0) is None\n\n    print(\"모든 테스트 통과!\")\n\ntest_calculator()",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "07-abstraction.html#sec-abstraction-summary",
    "href": "07-abstraction.html#sec-abstraction-summary",
    "title": "7  추상화",
    "section": "7.5 핵심 정리",
    "text": "7.5 핵심 정리\n\n\n\n\n\n\n힌트추상화의 핵심\n\n\n\n\n함수 - 반복되는 코드에 이름을 붙여 재사용\n모듈 - 관련 함수들을 파일로 묶어 정리\n단일 책임 - 함수는 한 가지 일만 잘 해야 한다\n명확한 인터페이스 - 입력과 출력이 분명해야 한다\n\n\n\n이로써 AI 시대 프로그래밍의 기초를 마쳤다. 다음 파트에서는 버전 관리와 협업을 통해 AI와 인간이 함께 코드를 발전시키는 방법을 알아본다.",
    "crumbs": [
      "**1부** AI 시대 프로그래밍",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>추상화</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html",
    "href": "10-data-intro.html",
    "title": "8  데이터, AI의 식량",
    "section": "",
    "text": "8.1 데이터의 두 얼굴\n1부에서 프로그래밍의 핵심이 “의도를 명확히 전달하는 것”임을 배웠다. 테스트로 원하는 결과를 정의하고, AI에게 코드를 요청하고, 생성된 코드를 검증하는 흐름이었다. 이제 실제 데이터를 다룰 차례다.\n프로그램은 데이터를 처리한다. 사용자 입력, 파일, 웹 API, 데이터베이스 등 다양한 곳에서 데이터가 들어오고, 프로그램은 이를 변환하여 유용한 결과물을 만들어낸다. AI도 마찬가지다. AI에게 작업을 요청할 때, 데이터의 형태와 구조를 명확히 전달해야 원하는 결과를 얻을 수 있다.\n이 부를 마치면, 지저분한 텍스트 파일 하나를 AI에게 던져주고 “이 로그에서 에러만 추출해서 날짜별로 정리해줘”라고 요청할 수 있게 된다.\n데이터는 크게 두 가지 형태로 나뉜다.\n비정형 데이터(Unstructured Data)는 자유로운 형식의 데이터다. 이메일 본문, 채팅 로그, 웹페이지 HTML, 자연어 텍스트 등이 해당한다. 사람은 읽을 수 있지만, 컴퓨터가 바로 처리하기엔 구조가 없다.\n정형 데이터(Structured Data)는 미리 정해진 구조를 따르는 데이터다. CSV 파일, JSON, 데이터베이스 테이블, 엑셀 시트 등이 해당한다. 행과 열, 또는 키와 값으로 명확히 구분되어 있어 컴퓨터가 바로 처리할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-types",
    "href": "10-data-intro.html#data-intro-types",
    "title": "8  데이터, AI의 식량",
    "section": "",
    "text": "From: user@example.com\nDate: 2024-01-15\nSubject: 프로젝트 회의 결과\n\n오늘 회의에서 다음 주 마감을 3월 20일로 확정했습니다.\n참석자: 홍길동, 김철수, 이영희\n\n{\n  \"meeting\": {\n    \"date\": \"2024-01-15\",\n    \"deadline\": \"2024-03-20\",\n    \"participants\": [\"홍길동\", \"김철수\", \"이영희\"]\n  }\n}",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-ai-role",
    "href": "10-data-intro.html#data-intro-ai-role",
    "title": "8  데이터, AI의 식량",
    "section": "\n8.2 AI의 역할: 변환과 분석",
    "text": "8.2 AI의 역할: 변환과 분석\n \nAI 코딩 도구가 데이터 처리에서 하는 역할은 크게 두 가지다.\n변환(Transformation): 비정형 데이터를 정형 데이터로 바꾸는 작업이다. 로그 파일에서 특정 패턴을 추출하거나, 이메일에서 날짜와 발신자를 파싱하거나, 웹페이지에서 표를 긁어오는 작업이 해당한다.\n분석(Analysis): 정형 데이터를 집계, 필터링, 시각화하는 작업이다. 월별 매출 합계를 구하거나, 특정 조건을 만족하는 행만 추출하거나, 데이터 분포를 차트로 그리는 작업이 해당한다.\n이 두 역할을 수행하려면, AI에게 데이터의 현재 구조와 원하는 결과 구조를 명확히 전달해야 한다. 바로 여기서 자료구조 지식이 필요하다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-preview",
    "href": "10-data-intro.html#data-intro-preview",
    "title": "8  데이터, AI의 식량",
    "section": "\n8.3 핵심 자료구조 미리보기",
    "text": "8.3 핵심 자료구조 미리보기\n프로그래밍에서 자료구조는 데이터를 담는 그릇이다. 어떤 그릇을 선택하느냐에 따라 할 수 있는 작업이 달라진다. AI에게 요청할 때도 적절한 자료구조를 언급하면 더 정확한 결과를 얻는다.\n\n8.3.1 순서가 중요하면: 리스트\n\n리스트(List)는 순서가 있는 데이터 모음이다. 첫 번째, 두 번째, 세 번째 등 위치가 의미를 갖는다.\n# 할 일 목록 - 순서대로 처리해야 함\ntasks = [\"데이터 수집\", \"전처리\", \"분석\", \"시각화\", \"보고서 작성\"]\n\n# 월별 매출 - 시간 순서가 중요함\nmonthly_sales = [1200, 1500, 1350, 1800, 2100]\nAI에게 요청할 때: “파일의 각 라인을 리스트로 읽어서 처리해줘”\n\n8.3.2 이름표가 중요하면: 딕셔너리\n\n딕셔너리(Dictionary)는 키-값 쌍의 모음이다. 이름표(키)로 값을 찾는다.\n# 사용자 정보 - 필드명으로 접근\nuser = {\n    \"name\": \"홍길동\",\n    \"email\": \"hong@example.com\",\n    \"age\": 30\n}\n\n# 설정 파일 - 키로 값 조회\nconfig = {\n    \"database_host\": \"localhost\",\n    \"port\": 5432,\n    \"debug\": True\n}\nAI에게 요청할 때: “JSON 응답에서 user.email 필드를 추출해줘”\n\n8.3.3 표 형태면: 데이터프레임\n\n데이터프레임(DataFrame)은 행과 열로 구성된 표 형식 데이터다. 엑셀 시트와 유사하다.\n   이름      부서      급여\n0  홍길동    개발팀   5000\n1  김철수    기획팀   4500\n2  이영희    마케팅   4800\nAI에게 요청할 때: “이 CSV를 데이터프레임으로 읽고, 급여가 4500 이상인 행만 필터링해줘”",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-workflow",
    "href": "10-data-intro.html#data-intro-workflow",
    "title": "8  데이터, AI의 식량",
    "section": "\n8.4 데이터 처리 워크플로우",
    "text": "8.4 데이터 처리 워크플로우\n실제 데이터 처리는 다음과 같은 흐름을 따른다.\n\n\n\n\n\n그림 8.1: 데이터 처리 워크플로우\n\n\n데이터 처리는 혼돈에서 질서로 나아가는 과정이다. 처음에는 로그 파일, CSV, 이메일 등 형식이 제각각인 원시 데이터가 있다. 이 비정형 데이터를 그대로 분석에 사용할 수는 없다.\n여기서 AI와 프로그래밍 언어가 등장한다. “JSON으로 변환해줘”라고 요청하면, AI가 Python이나 R 코드를 생성하고 실행한다. 사용자는 원하는 결과만 말하고, 구체적인 구현은 AI가 담당하는 구조다.\nAI가 생성한 코드는 원시 데이터를 구조화된 형태로 변환한다. 순서가 중요하면 리스트, 이름표로 접근해야 하면 딕셔너리, 행과 열로 구성된 표 형식이면 데이터프레임이 된다. 자료구조를 알면 AI에게 더 정확한 명세를 전달할 수 있다.\n구조화된 데이터는 곧 가치로 이어진다. 집계하고, 필터링하고, 시각화하여 의미 있는 인사이트를 도출한다. 막대 그래프로 비교하거나 추세선으로 패턴을 파악하는 것이 최종 목표다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-overview",
    "href": "10-data-intro.html#data-intro-overview",
    "title": "8  데이터, AI의 식량",
    "section": "\n8.5 이 부에서 배울 내용",
    "text": "8.5 이 부에서 배울 내용\n2부에서는 다음 자료구조를 순서대로 학습한다.\n\n\n장\n자료구조\n핵심 개념\nAI 활용 예시\n\n\n\n11\n문자열\n시퀀스, 슬라이싱, 패턴 매칭\n텍스트 전처리, 정보 추출\n\n\n12\n파일\n읽기/쓰기, 스트리밍\n대용량 파일 처리\n\n\n13\n리스트\n순회, 필터링, 변환\n컬렉션 처리\n\n\n14\n딕셔너리\n키-값, 해시\nJSON/API 데이터\n\n\n15\n튜플\n불변성, 다중 반환\n복합 데이터 그룹화\n\n\n16\n데이터프레임\n행/열, 조인, 그룹화\n표 형식 데이터 분석\n\n\n\n각 장에서는 해당 자료구조의 기본 개념을 익힌 뒤, AI에게 관련 작업을 요청하는 방법을 다룬다. 자료구조를 이해하면 AI가 생성한 코드를 검증하고 수정하는 것도 수월해진다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "10-data-intro.html#data-intro-ai-request",
    "href": "10-data-intro.html#data-intro-ai-request",
    "title": "8  데이터, AI의 식량",
    "section": "\n8.6 AI에게 데이터 작업 요청하기",
    "text": "8.6 AI에게 데이터 작업 요청하기\n자료구조를 배우면서 항상 기억할 패턴이 있다.\n명세 작성의 3요소\n\n\n입력 구조: 데이터가 현재 어떤 형태인가?\n\n변환 작업: 어떤 처리가 필요한가?\n\n출력 형태: 결과가 어떤 모습이어야 하는가?\n\n예시: 로그 파일 분석 요청\n\n서버 로그 파일(server.log)에서 ERROR가 포함된 라인만 추출해서 날짜별로 그룹화해줘.\n입력: 텍스트 파일, 각 라인 형식 [2024-01-15 10:30:45] ERROR: 메시지...\n출력: 딕셔너리 {\"2024-01-15\": [\"에러1\", \"에러2\"], \"2024-01-16\": [\"에러3\"]}\n\n이처럼 자료구조 용어(리스트, 딕셔너리, 데이터프레임)를 사용하여 입출력을 명세하면, AI가 정확한 코드를 생성할 가능성이 높아진다.\n이제 문자열부터 시작해서 각 자료구조를 하나씩 살펴보자.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>데이터, AI의 식량</span>"
    ]
  },
  {
    "objectID": "11-string.html",
    "href": "11-string.html",
    "title": "9  문자열",
    "section": "",
    "text": "9.1 문자열은 시퀀스다\n텍스트 데이터는 프로그래밍에서 가장 흔히 다루는 데이터 유형이다. 사용자 이름, 이메일 주소, 로그 파일, 웹페이지 내용, CSV 파일의 각 셀 등 모든 곳에 문자열이 존재한다. 데이터 분석에서도 텍스트 전처리, 패턴 매칭, 정보 추출 등 문자열 조작은 핵심 기술이다.\n문자열을 다루는 기본 개념을 이해하면, AI에게 텍스트 처리 작업을 명세할 때도 정확한 요구사항을 전달할 수 있다. “문자열의 3번째부터 7번째 문자를 추출해줘”라고 말하려면, 먼저 인덱싱과 슬라이싱이 무엇인지 알아야 한다.\n문자열은 여러 문자들의 시퀀스(sequence)다. 꺾쇠 연산자로 한 번에 하나씩 문자에 접근한다. substr() 함수를 사용해서 바로 특정 문자를 추출할 수도 있지만, strsplit() 함수로 문자열을 문자의 벡터로 다루는 방법도 있다.\n두 번째 문장은 변수 fruit_letter에서 1번 위치 문자를 추출하여 변수 letter에 대입한다. 꺾쇠 표현식을 인덱스(index)라고 부른다. 인덱스는 순서(sequence)에서 사용자가 어떤 문자를 원하는지 표시한다.\n하지만, 여러분이 기대한 것은 출력됨이 확인된다.\n파이썬 사용자에게 ’banana’의 첫 문자는 a가 아니라 b다. 하지만, 파이썬 인덱스는 문자열 처음부터 오프셋(offset)1이다. 첫 글자 오프셋은 0이다.\n하지만, R은 사람 친화적이기 때문에 b가 ’banana’의 첫 번째 문자가 되고 a가 두 번째, n이 세 번째 문자가 된다.\n인덱스로 문자와 연산자를 포함하는 어떤 표현식도 사용 가능지만, 인덱스 값은 정수일 필요는 없다. 정수가 아닌 경우 다음과 같은 결과를 얻게 된다. 문제는 R에서 1.5를 내려서 1로 처리한다는 점이다. 경우에 따라서는 반올림으로 판단해서 2가 될 수도 있어 오해의 소지가 있기 때문에 무조건 정수로 표현한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-sequence",
    "href": "11-string.html#r-string-sequence",
    "title": "9  문자열",
    "section": "",
    "text": "R\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n\n그림 9.1: 바나나 문자열\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-length",
    "href": "11-string.html#r-string-length",
    "title": "9  문자열",
    "section": "\n9.2 length() 함수 사용 문자열 길이 구하기",
    "text": "9.2 length() 함수 사용 문자열 길이 구하기\nlength() 함수는 문자열의 문자 갯수를 반환하는 내장함수다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n문자열의 가장 마지막 문자를 얻기 위해서, 아래와 같이 시도하고 싶을 것이다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n파이썬에서는 인덱스 오류(IndexError)가 발생하는데 이유는 ’banana’에 6번 인덱스 문자가 없기 때문이다. 0에서부터 시작했기 때문에 6개 문자는 0에서부터 5까지 번호가 매겨졌다. 마지막 문자를 얻기 위해서 length에서 1을 빼야 한다. fruit[-1]은 마지막 문자를, fruit[-2]는 끝에서 두 번째 문자를 가리킨다. 하지만, R에서는 사람이 생각하는 방식대로 마지막 문자를 얻는다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-traversal",
    "href": "11-string.html#r-string-traversal",
    "title": "9  문자열",
    "section": "\n9.3 루프를 사용한 문자열 순회",
    "text": "9.3 루프를 사용한 문자열 순회\n \n연산의 많은 경우에 문자열을 한 번에 한 문자씩 처리한다. 종종 처음에서 시작해서, 차례로 각 문자를 선택하고, 선택된 문자에 임의 연산을 수행하고, 끝까지 계속한다. 이런 처리 패턴을 순회(traversal)라고 한다. 순회를 작성하는 한 방법이 while 루프다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nwhile 루프가 문자열을 순회하여 문자열을 한 줄에 한 글자씩 화면에 출력한다. 루프 조건이 index &lt;= length(fruit_letter)이어서, index가 문자열 길이와 같을 때, 조건은 거짓이 되고, 루프의 몸통 부문은 실행되지 않는다. R이 접근한 마지막 length(fruit_letter) 인덱스 문자로, 문자열의 마지막 문자다.\n\n\n\n\n\n\n경고연습문제\n\n\n\n문자열의 마지막 문자에서 시작해서, 문자열 처음으로 역진행하면서 한 줄에 한 자씩 화면에 출력하는 while 루프를 작성하세요.\n\n\n순회를 작성하는 또 다른 방법은 for 루프다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n루프를 매번 반복할 때, 문자열 다음 문자가 변수 char에 대입된다. 루프는 더 이상 남겨진 문자가 없을 때까지 계속 실행된다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-slice",
    "href": "11-string.html#r-string-slice",
    "title": "9  문자열",
    "section": "\n9.4 문자열 슬라이스",
    "text": "9.4 문자열 슬라이스\n \n문자열의 일부분을 슬라이스(slice)라고 한다. 문자열 슬라이스를 선택하는 것은 문자를 선택하는 것과 유사하다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n[n:m] 연산자는 n번째 문자부터 m번째 문자까지의 문자열 부분을 반환한다.\n파이썬에서 fruit[:3]와 같이 콜론 앞 첫 인덱스를 생략하면, 문자열 슬라이스는 문자열 처음부터 시작한다. 파이썬에서 fruit[3:]와 같이 두 번째 인덱스를 생략하면, 문자열 슬라이스는 문자열 끝까지 간다.\n이와 동일한 역할을 수행하는 방법은 head(fruit_letter, 3), tail(fruit_letter, 3)와 같이 head(), tail() 함수를 활용한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n만약 첫 번째 인덱스가 두 번째보다 크거나 같은 경우 파이썬에서는 결과가 인용부호로 표현되는 빈 문자열(empty string)이 된다. 하지만, R에서는 해당 인덱스에 해당되는 문자가 추출된다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n빈 문자열은 어떤 문자도 포함하지 않아서 길이가 0이지만, 이것을 제외하고 다른 문자열과 동일하다. \n\n\n\n\n\n\n경고연습문제 (파이썬)\n\n\n\nfruit이 문자열로 주어졌을 때, fruit[:]의 의미는 무엇인가요?",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#문자열은-불변이다-파이썬",
    "href": "11-string.html#문자열은-불변이다-파이썬",
    "title": "9  문자열",
    "section": "\n9.5 문자열은 불변이다 (파이썬)",
    "text": "9.5 문자열은 불변이다 (파이썬)\n \n문자열 내부에 있는 문자를 변경하려고 대입문 왼쪽편에 [] 연산자를 사용하고 싶은 유혹이 있을 것이다. 예를 들어 다음과 같다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n파이썬에서 “TypeError: ‘str’ object does not support item assignment” 오류가 발생하는데 파이썬 문자열이 불변(immutable)하기 때문이다. 즉, 파이썬에서 문자열의 특정 문자를 직접 변경하려고 할 때 이 오류가 발생한다. 반면에, R에서는 문자열 자체가 불변 객체로 취급되지 않기 때문에 strsplit 함수를 사용하여 문자열을 문자의 벡터로 변환하면, 벡터의 각 요소는 별도의 문자열로 취급되어 개별적으로 변경할 수 있다. R은 파이썬과 달리 불변 문자열에 대한 제약이 없기 때문에 오류를 발생시키지않는다.\n파이썬에서 “객체(object)”는 문자열이고, 대입하고자 하는 문자는 “항목(item)”이다. 지금으로서 객체는 값과 동일하지만, 나중에 객체 정의를 좀 더 상세화할 것이다. 항목은 순서 값 중의 하나다. 최선의 방법은 원래 문자열을 변형한 새로운 문자열을 생성하는 것이다. \n새로운 첫 문자에 greeting 문자열 슬라이스를 연결한다. 원래 문자열에는 어떤 영향도 주지 않는 새로운 문자열이 생성되었다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-count",
    "href": "11-string.html#r-string-count",
    "title": "9  문자열",
    "section": "\n9.6 루프 사용 문자 계수하기",
    "text": "9.6 루프 사용 문자 계수하기\n \n다음 프로그램은 문자열에 문자 a가 나타나는 횟수를 계수(counting)한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 프로그램은 계수기(counter)라고 부르는 또 다른 연산 패턴을 보여준다. 변수 count는 0으로 초기화되고, 매번 a를 찾을 때마다 증가한다. 루프를 빠져나갔을 때, count는 결과 값 즉, a가 나타난 총 횟수를 담고 있다.\n\n\n\n\n\n\n경고연습문제\n\n\n\n문자열과 문자를 인자(argument)로 받도록 상기 코드를 count라는 함수로 캡슐화(encapsulation)하고 일반화하세요.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-in-operator",
    "href": "11-string.html#r-string-in-operator",
    "title": "9  문자열",
    "section": "\n9.7 %in% 연산자",
    "text": "9.7 %in% 연산자\n\\index{%in% 연산자} \\index{연산자!%in%} \n연산자 in은 부울 연산자로 두 개의 문자열을 받아, 첫 번째 문자열이 두 번째 문자열의 일부이면 참(TRUE)을 반환한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-comparison-operator",
    "href": "11-string.html#r-string-comparison-operator",
    "title": "9  문자열",
    "section": "\n9.8 문자열 비교",
    "text": "9.8 문자열 비교\n \n비교 연산자도 문자열에서 동작한다. 두 문자열이 같은지를 살펴보자.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n다른 비교 연산자는 단어를 알파벳 순서로 정렬하는 데 유용하다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nR과 파이썬 같은 프로그래밍 언어는 사람과 동일한 방식으로 대문자와 소문자를 다루지 않는다. 모든 대문자는 소문자 앞에 온다. 프로그래밍 언어에서 대문자와 소문자를 다루는 방식은 ASCII 코드 값을 기반으로 한다. ASCII 코드에서 대문자(A-Z)는 65부터 90까지의 값을, 소문자(a-z)는 97부터 122까지의 값을 갖기 때문에 대문자가 숫자적으로 소문자보다 먼저 나오기 때문에 문자열을 정렬하거나 비교할 때, 대문자가 소문자 앞에 위치하게 된다.\nYour word, Pineapple, comes before banana.\n이러한 문제를 다루는 일반적인 방식은 비교 연산을 수행하기 전에 문자열을 표준 포맷으로 예를 들어 모두 소문자로 변환하는 것이다. 경우에 따라서 “Pineapple”로 무장한 사람들로부터 여러분을 보호해야 하는 것도 명심한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-method",
    "href": "11-string.html#r-string-method",
    "title": "9  문자열",
    "section": "\n9.9 문자열 함수",
    "text": "9.9 문자열 함수\nR은 객체지향언어 특성을 갖고 있지만 함수형 프로그래밍 언어 특성도 갖고 있다. 문자열을 R 객체(objects)로 객체를 데이터(실제 문자열 자체)와 메서드(methods)를 담고 있는 것으로 바라볼 수도 있다. 메서드는 객체에 내장되고 어떤 객체의 인스턴스(instance)에도 사용되는 사실상 함수다. \n\n\n\n\n\n\n노트파이썬 dir 함수\n\n\n\n객체에 대해 이용 가능한 메서드를 보여주는 dir 함수가 파이썬에 있다. type 함수는 객체의 자료형(type)을 보여주고, dir은 객체에 사용될 수 있는 메서드를 보여준다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\ndir 함수가 메서드 목록을 보여주고, 메서드에 대한 간단한 문서 정보는 help를 사용할 수 있지만, 문자열 메서드에 대한 좀 더 좋은 문서 정보는 https://docs.python.org/3/library/string.html에서 찾을 수 있다.\n인자를 받고 값을 반환한다는 점에서 메서드(method)를 호출하는 것은 함수를 호출하는 것과 유사하지만, 구문은 다르다. 구분자로 점을 사용해서 변수명에 메서드명을 붙여 메서드를 호출한다.\n예를 들어, upper 메서드는 문자열을 받아 모두 대문자로 변환된 새로운 문자열을 반환한다. 함수 구문 upper(word) 대신에, word.upper() 메서드 구문을 사용한다.\n\n\n하지만, 함수형 프로그래밍 패러다임으로 문자열을 객체로 두고 함수를 적용시켜 다양한 작업을 하는 것이 일반적이다. tidyverse 패키지를 설치하게 되면 stringr 패키지가 구성요소로 포함되어 있다. str_로 시작되는 다양한 함수가 지원된다. \n예를 들어, stringr 패키지 str_to_upper() 함수는 문자열을 받아 모두 대문자로 변환된 새로운 문자열을 반환한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n동일한 작업을 함수형 패러다임으로 str_to_upper(word)와 같이 표현하는 데 반해, 객체지향으로 구현하면 파이썬 같은 경우 word.upper() 메서드 구문이 사용된다.\n예를 들어, 문자열 안에 문자열의 위치를 찾는 str_locate(), str_locate_all()이라는 문자열 함수가 있다. str_locate()는 매칭되는 첫 번째만 반환하는 반면에 str_locate_all()은 매칭되는 전부를 반환하는 차이가 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 예제에서, word 문자열에 str_locate_all() 함수를 호출하여 매개 변수로 찾고자 하는 문자를 넘긴다.\nstr_locate_all() 함수로 문자뿐만 아니라 부속 문자열(substring)도 찾을 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n한 가지 자주 있는 작업은 str_trim() 함수를 사용해서 문자열 시작과 끝의 공백(공백 여러 개, 탭, 새줄)을 제거하는 것이다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_detect() 함수와 나중에 다룰 정규표현식을 섞어 표현하게 되면 참, 거짓 같은 부울 값(boolean value)을 반환한다. '^Please'에서 ^은 문자열 시작을 지정한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n대소문자를 구별하는 것을 요구하기 때문에 str_to_lower() 함수를 사용해서 검증을 수행하기 전에, 한 줄을 입력받아 모두 소문자로 변환하는 것이 필요하다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n마지막 예제에서 문자열이 문자 “p”로 시작하는지를 검증하기 위해서, str_to_lower() 함수를 호출하고 나서 바로 str_detect() 함수를 사용한다. 주의 깊게 순서만 다룬다면, 한 줄에 다수 함수를 괄호에 넣어 호출할 수 있다.\n\n\n\n\n\n\n경고연습문제\n\n\n\n앞선 예제와 유사한 함수인 str_count()로 불리는 문자열 메서드가 stringr 패키지 내부에 있다. ? str_count() 도움말로 str_count() 함수에 대한 문서를 읽고, 문자열 ’banana’의 문자가 몇 개인지 계수하는 메서드 호출 프로그램을 작성하세요.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-parsing",
    "href": "11-string.html#r-string-parsing",
    "title": "9  문자열",
    "section": "\n9.10 문자열 파싱",
    "text": "9.10 문자열 파싱\n종종, 문자열을 들여다보고 특정 부속 문자열(substring)을 찾고 싶다. 예를 들어, 아래와 같은 형식으로 작성된 일련의 라인이 주어졌다고 가정하면,\n\nFrom stephen.marquard@uct.ac.zaSat Jan  5 09:14:16 2008\n\n각 라인마다 뒤쪽 전자우편 주소(즉, uct.ac.za)만 뽑아내고 싶을 것이다. str_locate() 함수와 문자열 슬라이싱(string sliceing)을 사용해서 작업을 수행할 수 있다.\n우선, 문자열에서 골뱅이(@, at-sign) 기호의 위치를 찾는다. 그리고, 골뱅이 기호 뒤 첫 공백 위치를 찾는다. 그리고 나서, 찾고자 하는 부속 문자열을 뽑아내기 위해서 문자열 슬라이싱을 사용한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_locate() 함수를 사용해서 찾고자 하는 문자열의 시작 위치를 명세한다. 문자열 슬라이싱(slicing)할 때, 골뱅이 기호 뒤부터 빈 공백을 포함하지 않는 위치까지 문자열을 뽑아낸다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-format",
    "href": "11-string.html#r-string-format",
    "title": "9  문자열",
    "section": "\n9.11 서식 연산자",
    "text": "9.11 서식 연산자\n \n서식 연산자(format operator) Base R의 sprintf() 함수에 C언어 스타일로 %를 사용하기도 하지만 glue: Interpreted String Literals 패키지도 최근에 많이 사용된다. glue 패키지 {}는 문자열 일부를 변수에 저장된 값으로 바꿔 문자열을 구성한다. 정수에 서식 연산자가 적용될 때, {}는 나머지 연산자가 된다. 하지만 첫 피연산자가 문자열이면, {}은 서식 연산자가 된다. 동일한 기능을 stringr 패키지 str_glue() 함수로 수행할 수 있다. \n첫 피연산자는 서식 문자열(format string)로 두 번째 피연산자가 어떤 형식으로 표현되는지를 명세하는 하나 혹은 그 이상의 서식 순서(format sequence)를 담고 있다. 결과값은 문자열이다. \n예를 들어, 형식 순서 ’%d’의 의미는 두 번째 피연산자가 정수 형식으로 표현됨을 뜻한다. (d는 “decimal”을 나타낸다.)\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n결과는 문자열 ’42’로 정수 42와 혼동하면 안 된다.\n서식 순서는 문자열 어디에도 나타날 수 있어서 문장 중간에 값을 임베드(embed)할 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n만약 문자열 서식 순서가 하나 이상이라면, 두 번째 인자는 튜플(tuple)이 된다. 서식 순서 각각은 순서대로 튜플 요소와 매칭된다.\n다음 예제는 정수 형식을 표현하기 위해서 ‘%d’, 부동 소수점 형식을 표현하기 위해서 ‘%g’, 문자열 형식을 표현하기 위해서 ‘%s’을 사용한 사례다. 여기서 왜 부동 소수점 형식이’%f’ 대신에 ’%g’인지는 질문하지 말아주세요. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n문자열 서식 순서와 갯수는 일치해야 하고, 요소의 자료형(type)도 서식 순서와 일치해야 한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 첫 예제는 충분한 요소 개수가 되지 않고, 두 번째 예제는 자료형이 맞지 않는다. 서식 연산자는 강력하지만, 사용하기가 까다로운 점이 있으니, str_glue를 사용하는 것도 권장된다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-debug",
    "href": "11-string.html#r-string-debug",
    "title": "9  문자열",
    "section": "\n9.12 디버깅",
    "text": "9.12 디버깅\n\n프로그램을 작성하면서 배양해야 하는 기술은 항상 자신에게 질문을 하는 것이다. “여기서 무엇이 잘못될 수 있을까?” 혹은 “내가 작성한 완벽한 프로그램을 망가뜨리기 위해 사용자는 무슨 엄청난 일을 할 것인가?”\n예를 들어 앞장의 반복 while 루프를 시연하기 위해 사용한 프로그램을 살펴봅시다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n사용자가 입력값으로 빈 공백 줄을 입력하게 될 때 무엇이 발생하는지 살펴봅시다.\n&gt; hello there\n[1] hello there\n&gt; # don't print this\n&gt; print this!\n[2] print this!\n&gt; \n[1] \"\"\n&gt; done\n빈 공백 줄이 입력될 때까지 코드는 잘 작동한다. 그리고 나서, 파이썬의 경우 0번째 문자가 없어서 트레이스백(traceback)이 발생한다. R의 경우 정상 실행되지만 원하는 바는 아니다. 입력 줄이 비어있을 때, 코드 3번째 줄을 “안전”하게 만드는 두 가지 방법이 있다.\n하나는 빈 문자열이면 거짓(FALSE)을 반환하도록 str_detect() 함수를 사용하는 것이다.\n\n\nR\nif(str_detect(line, '^#'))\n\n\n\n\n파이썬\nif line.startswith('#') :\n\n\n\n가디언 패턴(guardian pattern)을 사용한 if문으로 문자열에 적어도 하나의 문자가 있는 경우만 두 번째 논리 표현식이 평가되도록 코드를 작성한다. \n\n\nR\nif(str_length(line) &gt; 0 & str_detect(line, '^#'))\n\n\n\n\n파이썬\nif len(line) &gt; 0 and line[0] == '#' :",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-ai",
    "href": "11-string.html#r-string-ai",
    "title": "9  문자열",
    "section": "\n9.13 AI와 함께하는 문자열 처리",
    "text": "9.13 AI와 함께하는 문자열 처리\n문자열 처리는 AI 코딩 도구가 특히 강점을 발휘하는 영역이다. 복잡한 텍스트 변환, 패턴 추출, 데이터 정제 작업을 AI에게 요청할 때 다음과 같은 명세 패턴을 활용한다.\n\n9.13.1 명세 작성 패턴\nAI에게 문자열 처리를 요청할 때 포함해야 할 정보:\n\n\n입력 데이터 형태: 처리할 문자열의 구조와 예시\n\n원하는 출력 형태: 기대하는 결과물의 형태와 예시\n\n경계 조건: 빈 문자열, 특수문자, 다국어 등 예외 상황\n\n9.13.2 프롬프트 예시\n이메일 주소 추출\n\n다음 형식의 로그 라인에서 도메인(뒤? 부분)만 추출하는 R/Python 함수를 작성해줘.\n입력 예시: \"From user@example.com Sat Jan 5 09:14:16 2008\"\n출력 예시: \"example.com\"\n조건: 이메일이 없는 라인은 빈 문자열 반환\n\n텍스트 정규화\n\n사용자 입력 문자열을 정규화하는 함수가 필요해.\n\n앞뒤 공백 제거\n연속된 공백은 하나로\n모두 소문자로 변환\n\n입력: \"  Hello   WORLD  \"\n출력: \"hello world\"\n\n패턴 기반 분리\n\nCSV 형식이 아닌 고정 너비 텍스트 파일을 파싱해야 해.\n형식: 이름(20자) + 나이(3자) + 도시(15자)\n예시 라인: \"홍길동              025서울           \"\n결과: 리스트나 데이터프레임으로 분리\n\n이처럼 구체적인 입출력 예시와 경계 조건을 명시하면, AI가 정확한 코드를 생성할 가능성이 높아진다. 앞서 배운 슬라이싱, 문자열 함수, 정규표현식 개념을 알고 있으면 AI가 생성한 코드를 검증하고 수정하는 것도 수월해진다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-terminology",
    "href": "11-string.html#r-string-terminology",
    "title": "9  문자열",
    "section": "\n9.14 용어 정의",
    "text": "9.14 용어 정의\n\n\n계수기(counter): 무언가를 계수하기 위해서 사용되는 변수로 일반적으로 0으로 초기화하고 나서 증가한다. \n\n빈 문자열(empty string): 두 인용부호로 표현되고, 어떤 문자도 없고 길이가 0인 문자열. \n\n서식 연산자(format operator): 서식 문자열과 튜플을 받아, 서식 문자열에 지정된 서식으로 튜플 요소를 포함하는 문자열을 생성하는 연산자. \n\n서식 순서(format sequence): d처럼 어떤 값의 서식으로 표현되어야 하는지를 명세하는 “서식 문자열” 문자 순서. \n\n서식 문자열(format string): 서식 순서를 포함하는 서식 연산자와 함께 사용되는 문자열. \n\n플래그(flag): 조건이 참인지를 표기하기 위해 사용하는 불 변수(boolean variable) \n\n호출(invocation): 메서드를 호출하는 명령문. \n\n불변(immutable): 순서의 항목에 대입할 수 없는 특성. \n\n인덱스(index): 문자열의 문자처럼 순서(sequence)에 항목을 선택하기 위해 사용되는 정수 값. \n\n항목(item): 순서에 있는 값의 하나. \n\n메서드(method): 객체와 연관되어 점 표기법을 사용하여 호출되는 함수. \n\n객체(object): 변수가 참조하는 무엇. 지금은 “객체”와 “값”을 구별 없이 사용한다. \n\n검색(search): 찾고자 하는 것을 찾았을 때 멈추는 순회 패턴. \n\n순서(sequence): 정돈된 집합. 즉, 정수 인덱스로 각각의 값이 확인되는 값의 집합. \n\n슬라이스(slice): 인덱스 범위로 지정되는 문자열 부분. \n\n순회(traverse): 순서(sequence)의 항목을 반복적으로 훑기, 각각에 대해서는 동일한 연산을 수행.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#r-string-ex",
    "href": "11-string.html#r-string-ex",
    "title": "9  문자열",
    "section": "연습문제",
    "text": "연습문제\n\n다음 문자열에서 숫자를 뽑아내는 R 코드를 작성하라.\n\nstr &lt;- 'X-DSPAM-Confidence: 0.8475'\nstr_locate() 함수와 문자열 슬라이싱을 사용하여 str_sub() 문자 뒤 문자열을 뽑아내고 as.numeric() 함수를 사용하여 뽑아낸 문자열을 부동 소수점 숫자로 변환하라.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "11-string.html#footnotes",
    "href": "11-string.html#footnotes",
    "title": "9  문자열",
    "section": "",
    "text": "컴퓨터에서 어떤 주소로부터 간격을 두고 떨어진 주소와의 거리를 말한다. 기억 장치가 페이지 혹은 세그먼트 단위로 나누어져 있을 때 하나의 시작 주소로부터 오프셋만큼 떨어진 위치를 나타낸다. 네이버 지식백과(IT용어사전, 한국정보통신기술협회)↩︎",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>문자열</span>"
    ]
  },
  {
    "objectID": "12-file.html",
    "href": "12-file.html",
    "title": "10  파일",
    "section": "",
    "text": "10.1 영속성\n데이터 분석의 시작과 끝은 파일이다. CSV, JSON, 텍스트 로그, 설정 파일 등 거의 모든 데이터가 파일 형태로 저장되고 교환된다. 웹에서 데이터를 가져오든, 데이터베이스 결과를 저장하든, 결국 파일 읽기와 쓰기 작업이 필요하다.\n파일 처리의 기본 개념인 열기, 읽기, 쓰기, 닫기 패턴을 이해하면, AI에게 데이터 전처리 작업을 요청할 때도 “대용량 파일을 청크 단위로 읽어서 처리해줘”와 같은 구체적인 명세가 가능해진다.\n지금까지, 프로그램을 어떻게 작성하고 조건문, 함수, 반복을 사용하여 중앙처리장치(CPU, Central Processing Unit)에 프로그래머의 의도를 전달하는지 학습했다. 주기억장치(Main Memory)에 어떻게 자료구조를 생성하고 사용하는지도 배웠다. CPU와 주기억장치는 소프트웨어가 동작하고 실행되는 곳이고, 모든 “생각(thinking)”이 발생하는 장소다.\n하지만, 앞서 하드웨어 아키텍처를 논의했던 기억을 되살린다면, 전원이 꺼지게 되면, CPU와 주기억장치에 저장된 모든 것이 지워진다. 지금까지 작성한 프로그램은 R을 배우기 위한 일시적으로 재미로 연습한 것에 불과하다.\n이번 장에서 보조 기억장치(Secondary Memory) 혹은 파일을 가지고 작업을 시작한다. 보조 기억장치는 전원이 꺼져도 지워지지 않는다. 혹은, USB 플래시 드라이브를 사용한 경우에는 프로그램으로부터 작성한 데이터는 시스템에서 제거되어 다른 시스템으로 전송될 수 있다.\n우선 텍스트 편집기로 작성한 텍스트 파일을 읽고 쓰는 것에 초점을 맞출 것이다. 나중에 데이터베이스 소프트웨어를 통해서 읽고 쓰도록 설계된 바이너리 파일 데이터베이스를 가지고 어떻게 작업하는지를 살펴볼 것이다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-persistence",
    "href": "12-file.html#r-file-persistence",
    "title": "10  파일",
    "section": "",
    "text": "그림 10.1: 소프트웨어 아키텍처",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-open",
    "href": "12-file.html#r-file-open",
    "title": "10  파일",
    "section": "\n10.2 파일 열기",
    "text": "10.2 파일 열기\n \n하드 디스크 파일을 읽거나 쓰려고 할 때, 파일을 열어야(open) 한다. 파일을 열 때 각 파일 데이터가 어디에 저장되었는지를 알고 있는 운영체제와 커뮤니케이션한다. 파일을 열 때, 운영체제에 파일이 존재하는지 확인하고 이름으로 파일을 찾도록 요청한다.\n이번 예제에서, &lt;www.py4inf.com/code/mbox.txt&gt;에서 파일을 다운로드한 후 R을 시작한 동일한 폴더에 저장된 mbox.txt 파일을 연다.\ndownload.file(\"https://www.dr-chuck.com/py4inf/code/mbox.txt\", destfile = \"mbox.txt\") 명령어를 사용하여 코딩을 시작하는 디렉토리에 mbox.txt 이름으로 저장한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nopen이 성공하면, 운영체제는 파일 핸들(file handle)을 반환한다. 파일 핸들(file handle)은 파일에 담겨진 실제 데이터는 아니고, 대신에 데이터를 읽을 수 있도록 사용할 수 있는 “핸들(handle)”이다. 요청한 파일이 존재하고, 파일을 읽을 수 있는 적절한 권한이 있다면 이제 핸들이 여러분에게 주어졌다. \n\n\n\n\n\n그림 10.2: 파일 핸들\n\n\n파일이 존재하지 않는다면, open은 역추적(traceback) 파일 열기 오류로 실패하고, 파일 콘텐츠에 접근할 핸들도 얻지 못한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n나중에 tryCatch()를 가지고, 존재하지 않는 파일을 열려고 하는 상황을 좀 더 우아하게 처리할 것이다. 최근에 사용자 중심으로 R에 다양한 기능이 추가되어 tidyverse 패키지 일부를 구성하는 readr 패키지의 read_lines() 함수를 통해 인터넷 웹사이트에서 바로 불러오는 것도 가능하다. 하지만, readr::read_lines() 함수는 줄바꿈 문자를 가정하고 동작하기 때문에 제대로 파일을 못 읽어오는 경우도 종종 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-txt",
    "href": "12-file.html#r-file-txt",
    "title": "10  파일",
    "section": "\n10.3 텍스트 파일과 라인",
    "text": "10.3 텍스트 파일과 라인\nR 문자열이 문자 순서(sequence)로 간주되듯이 마찬가지로 텍스트 파일은 줄(라인, line) 순서(sequence)로 생각될 수 있다. 예를 들어, 다음은 오픈 소스 프로젝트 개발 팀에서 다양한 참여자들의 전자우편 활동을 기록한 텍스트 파일 샘플이다.\n\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\nReturn-Path: &lt;postmaster@collab.sakaiproject.org&gt;\nDate: Sat, 5 Jan 2008 09:12:18 -0500\nTo: source@collab.sakaiproject.org\nFrom: stephen.marquard@uct.ac.za\nSubject: [sakai] svn commit: r39772 - content/branches/\nDetails: http://source.sakaiproject.org/viewsvn/?view=revrev=39772\n...\n\n상호 의사소통한 전자우편 전체 파일은 &lt;www.py4inf.com/code/mbox.txt&gt;에서 접근 가능하고, 간략한 버전 파일은 &lt;www.py4inf.com/code/mbox-short.txt&gt;에서 얻을 수 있다. 이들 파일은 다수 전자우편 메시지를 담고 있는 파일로 표준 포맷으로 되어 있다. “From”으로 시작하는 라인은 메시지 본문과 구별되고, “From:”으로 시작하는 라인은 본문 메시지의 일부다. 더 자세한 정보는 http://en.wikipedia.org/wiki/Mbox에서 찾을 수 있다.\n파일을 라인으로 쪼개기 위해서, 줄바꿈 문자로 불리는 “줄의 끝(end of the line)”을 표시하는 특수 문자가 있다. \nR에서, 문자열 상수 역슬래시-n(\\n)으로 줄바꿈 문자를 표현한다. 두 문자처럼 보이지만, 사실은 단일 문자이다. 인터프리터에 “stuff”에 입력한 후 변수를 살펴보면, 문자열에 \\n가 있다. 하지만, cat문을 사용하여 문자열을 출력하면, 문자열이 새줄 문자에 의해서 두 줄로 쪼개지는 것을 볼 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n문자열 X\\nY의 길이는 stringr::str_length(\"X\\nY\") 명령어를 통해 확인이 가능한데 3이다. 왜냐하면 줄바꿈(newline) 문자도 한 문자이기 때문이다.\n그래서, 파일 라인을 볼 때, 라인 끝을 표시하는 줄바꿈으로 불리는 눈에 보이지 않는 특수 문자가 각 줄의 끝에 있다고 상상할 필요가 있다.\n그래서, 줄바꿈 문자는 파일에 있는 문자를 라인으로 분리한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-open-handler",
    "href": "12-file.html#r-file-open-handler",
    "title": "10  파일",
    "section": "\n10.4 파일 읽어오기",
    "text": "10.4 파일 읽어오기\n \n파일 핸들(file handle)이 파일 자료를 담고 있지 않지만, for 루프를 사용하여 파일 각 라인을 읽고 라인 수를 세는 것을 쉽게 구축할 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n파일 핸들을 for 루프 시퀀스(sequence)로 사용할 수 있다. for 루프는 단순히 파일 라인 수를 세고 전체 라인 수를 출력한다. for 루프를 대략 일반어로 풀어 말하면, “파일 핸들로 표현되는 파일 각 라인마다, count 변수에 1씩 더한다.”\nfile 함수가 전체 파일을 바로 읽지 못하는 이유는 파일이 수 기가바이트(GB) 파일 크기를 가질 수도 있기 때문이다. file 문장은 파일 크기에 관계없이 파일을 여는 데 시간이 동일하게 걸린다. 실질적으로 for 루프가 파일로부터 자료를 읽어오는 역할을 한다.\nfor 루프를 사용해서 이같은 방식으로 파일을 읽어올 때, 줄바꿈 문자를 사용해서 파일 자료를 라인 단위로 쪼갠다. 파이썬에서 줄바꿈 문자까지 각 라인 단위로 읽고, for 루프가 매번 반복할 때마다 line변수에 줄바꿈을 마지막 문자로 포함한다.\nfor 루프가 데이터를 한 번에 한 줄씩 읽어오기 때문에, 데이터를 저장할 주기억장치 저장공간을 소진하지 않고, 매우 큰 파일을 효과적으로 읽어서 라인을 셀 수 있다. 각 라인별로 읽고, 세고, 그리고 나서 폐기되기 때문에, 매우 적은 저장공간을 사용해서 어떤 크기의 파일도 상기 프로그램을 사용하여 라인을 셀 수 있다.\n만약 주기억장치 크기에 비해서 상대적으로 작은 크기의 파일이라는 것을 안다면, 전체 파일을 파일 핸들로 readLines() 함수를 사용해서 문자열로 읽어올 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 예제에서, mbox-short.txt 전체 파일 콘텐츠(94,626 문자)를 변수 inp로 바로 읽었다. 문자열 슬라이싱을 사용해서 inp에 저장된 문자열 자료 첫 20 문자를 출력한다.\n파일이 이런 방식으로 읽혀질 때, 모든 라인과 줄바꿈 문자를 포함한 모든 문자는 변수 inp에 대입된 매우 큰 문자열이다. 파일 데이터가 컴퓨터 주기억장치가 안정적으로 감당해 낼 수 있을 때만, 이런 형식의 nchar() 함수가 사용될 수 있다는 것을 기억하라.\n만약 주기억장치가 감당해 낼 수 없는 매우 파일 크기가 크다면, for나 while 루프를 사용해서 파일을 쪼개서 읽는 프로그램을 작성해야 한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-search",
    "href": "12-file.html#r-file-search",
    "title": "10  파일",
    "section": "\n10.5 파일 검색",
    "text": "10.5 파일 검색\n \n파일 데이터를 검색할 때, 흔한 패턴은 파일을 읽고, 대부분 라인은 건너뛰고, 특정 기준을 만족하는 라인만 처리하는 것이다. 간단한 검색 메커니즘을 구현하기 위해서 파일을 읽는 패턴과 문자열 메서드를 조합한다.\n예를 들어, 파일을 읽고, “From:”으로 시작하는 라인만 출력하고자 한다면, stringr 패키지에 포함된 str_detect() 문자열 탐지 함수를 사용해서 원하는 접두사(From:)로 시작하는 라인만을 선택한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n이 프로그램이 실행하면 다음 출력값을 얻는다.\n\n[1] \"From: stephen.marquard@uct.ac.za\"\n[1] \"From: louis@media.berkeley.edu\"\n[1] \"From: zqian@umich.edu\"\n[1] \"From: rjlowe@iupui.edu\"\n[1] \"From: zqian@umich.edu\"\n[1] \"From: rjlowe@iupui.edu\"\n[1] \"From: cwen@iupui.edu\"\n...\n\n“From:”으로만 시작하는 라인만 출력하기 때문에 출력값은 훌륭해 보인다.\n파일 처리 프로그램이 점점 더 복잡해짐에 따라 next를 사용해서 검색 루프(search loop)를 구조화할 필요가 있다. 검색 루프의 기본 아이디어는 “흥미로운” 라인을 집중적으로 찾고, “흥미롭지 않은” 라인은 효과적으로 건너뛰는 것이다. 그리고 나서 흥미로운 라인을 찾게 되면, 그 라인에서 특정 연산을 수행하는 것이다.\n다음과 같이 루프를 구성해서 흥미롭지 않은 라인은 건너뛰는 패턴을 따르게 한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램의 출력값은 동일하다. 흥미롭지 않는 라인은 “From:”으로 시작하지 않는 라인이라 next문을 사용해서 건너뛴다. “흥미로운” 라인(즉, “From:”으로 시작하는 라인)에 대해서는 연산 처리를 수행한다.\nstr_detect() 문자열 함수를 사용해서 검색 문자열이 라인 어디에 있는지를 찾아주는 텍스트 편집기 검색 기능을 모사(simulation)할 수 있다. str_detect() 문자열 함수는 다른 문자열 내부에 검색하는 문자열이 있는지 찾고, 존재하는 경우 참(TRUE), 만약 문자열이 없다면 거짓(FALSE)을 반환하기 때문에, “uct.ac.za?”(남아프리카 케이프 타운 대학으로부터 왔다) 문자열을 포함하는 라인을 검색하기 위해 다음과 같이 루프를 작성한다. stringr 패키지 의존성 대신 grepl() 함수를 사용할 수도 있다. if문 !str_detect(line, \"@uct.ac.za\") 대신 grepl(\"@uct.ac.za\", line) == FALSE로 대체한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n출력결과는 다음과 같다.\n\n[1] \"From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\"\n[1] \"X-Authentication-Warning: nakamura.uits.iupui.edu: apache set sender to stephen.marquard@uct.ac.za using -f\"\n[1] \"From: stephen.marquard@uct.ac.za\"\n[1] \"Author: stephen.marquard@uct.ac.za\"\n[1] \"From david.horwitz@uct.ac.za Fri Jan  4 07:02:32 2008\"\n[1] \"X-Authentication-Warning: nakamura.uits.iupui.edu: apache set sender to david.horwitz@uct.ac.za using -f\"\n[1] \"From: david.horwitz@uct.ac.za\"\n[1] \"Author: david.horwitz@uct.ac.za\"\n[1] \"r39753 | david.horwitz@uct.ac.za | 2008-01-04 13:05:51 +0200 (Fri, 04 Jan 2008) | 1 line\"\n[1] \"From david.horwitz@uct.ac.za Fri Jan  4 06:08:27 2008\"\n[1] \"X-Authentication-Warning: nakamura.uits.iupui.edu: apache set sender to david.horwitz@uct.ac.za using -f\"",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-user-input",
    "href": "12-file.html#r-file-user-input",
    "title": "10  파일",
    "section": "\n10.6 사용자가 파일명 선택",
    "text": "10.6 사용자가 파일명 선택\n매번 다른 파일을 처리할 때마다 R 코드를 편집하고 싶지는 않다. 매번 프로그램이 실행될 때마다, 파일명을 사용자가 입력하도록 만드는 것이 좀 더 유용할 것이다. 그래서 R 코드를 바꾸지 않고, 다른 파일에 대해서도 동일한 프로그램을 사용하도록 만들자.\n다음과 같이 commandArgs을 사용해서 사용자로부터 파일명을 읽어 프로그램을 실행하는 것이 단순하다. file-user-input.R 파일에 다음과 같이 R 스크립트를 작성한다. 자세한 사항은 R 병렬 프로그래밍을 참조한다. 1 그리고, 사용자의 입력을 받도록 하는 프롬프트를 생략하고 바로 쉘에서 인자를 넘기는 것으로 프로그램을 작성했다.\n\n\nR\n\ncat(\"Enter the file name: \")\nfname &lt;- readLines(file(\"stdin\"), 1) \n\nfhand &lt;- readLines(fname)\n\ncount &lt;- 0\n\nfor (line in fhand) {\n  if (startsWith(line, \"Subject:\")) {\n    count &lt;- count + 1\n  }\n}\n\nprint(paste('There were', count, 'subject lines in', fname))\n\n\n\n\n\n파이썬\n\nfname = input('Enter the file name: ')\nfhand = open(fname)\ncount = 0\nfor line in fhand:\n    if line.startswith('Subject:'):\n        count += 1\nprint('There were', count, 'subject lines in', fname)\n\n\n\n\n사용자로부터 파일명을 읽고 변수 fname에 저장하고, 그 파일을 연다. 이제 다른 파일에 대해서도 반복적으로 프로그램을 실행할 수 있다. RStudio Terminal(Console 패널 아님)을 열고 다음과 같이 인자를 넘겨 실행하면 된다.\n\n$ rscript file-user-input.R\nEnter the file name: mbox.txt\n경고메시지(들):\n사용되지 않는 커넥션 3 (stdin)를 닫습니다\n[1] \"There were 1797 subject lines in mbox.txt\"\n\n$ rscript file-user-input.R\nEnter the file name: mbox-short.txt\n경고메시지(들):\n사용되지 않는 커넥션 3 (stdin)를 닫습니다\n[1] \"There were 27 subject lines in mbox-short.txt\"\nThere were 27 subject lines in ../data/mbox-short.txt\n\n다음 절을 살펴보기 전에, 이 프로그램을 검토하면서 자신에게 다음을 질문해보자. “여기서 무엇이 잘못될 수 있을까?” 또는 “이 간결하고 멋진 프로그램이 오류를 발생시키고 바로 종료되어 사용자에게 나쁜 인상을 남길 수 있게 만드는 것은 무엇일까?”",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-trycatch",
    "href": "12-file.html#r-file-trycatch",
    "title": "10  파일",
    "section": "\n10.7 tryCatch 사용하기",
    "text": "10.7 tryCatch 사용하기\n여러분에게 엿보지 말라고 말씀드렸다. 이번이 마지막 기회다. 사용자가 파일명이 아닌 뭔가 다른 것을 입력하면 어떻게 될까?\n\n$ rscript file-user-input.R \"missing.txt\"\nfile(con, \"r\")에서 다음과 같은 에러가 발생했습니다:커넥션을 열 수 없습니다\n호출: readLines -&gt; file\n추가정보: 경고메시지(들):\nfile(con, \"r\")에서:\n  파일 'missing.txt'를 여는데 실패했습니다: No such file or directory\n실행이 정지되었습니다\n\n$ rscript file-user-input.R \"na na boo boo\"\nfile(con, \"r\")에서 다음과 같은 에러가 발생했습니다:커넥션을 열 수 없습니다\n호출: readLines -&gt; file\n추가정보: 경고메시지(들):\nfile(con, \"r\")에서:\n  파일 'na na boo boo'를 여는데 실패했습니다: No such file or directory\n실행이 정지되었습니다\n\n웃을 일은 절대 아니다. 사용자는 결국 여러분이 작성한 프로그램을 망가뜨리기 위해 고의든 악의를 가지든 가능한 모든 수단을 강구할 것이다. 사실, 소프트웨어 개발팀의 중요한 부분은 품질 보증(Quality Assurance, QA)이라는 조직이다. 품질보증 조직은 프로그래머가 만든 소프트웨어를 망가뜨리기 위해 가능한 말도 안 되는 것을 수행한다. \n사용자가 소프트웨어를 제품으로 구매하거나, 주문형으로 개발하는 프로그램에 대해 월급을 지급하던지 관계없이 품질보증 조직은 프로그램이 사용자에게 전달되기 전까지 프로그램 오류를 발견할 책임이 있다. 그래서 품질보증 조직은 프로그래머의 최고의 친구다.\n프로그램 오류를 찾았기 때문에, tryCatch 구조를 사용해서 오류를 우아하게 고쳐본다. 파일 열기 file() 호출이 잘못될 수 있다고 가정하고, file() 호출이 실패할 때를 대비해서 다음과 같이 복구 코드를 추가한다. \n\n\n\n10.7.1 R 파일 file-user-input-try.R\n\n\ncat(\"Enter the file name: \")\nfname &lt;- readLines(file(\"stdin\"), 1) \n\nfileOpened &lt;- FALSE\n\nresult &lt;- try({\n  fhand &lt;- readLines(fname)\n  fileOpened &lt;- TRUE\n}, silent = TRUE)\n\nif (!fileOpened) {\n  cat(\"File cannot be opened:\", fname, \"\\n\")\n  q(\"no\")\n}\n\ncount &lt;- 0\n\nfor (line in fhand) {\n  if (startsWith(line, \"Subject:\")) {\n    count &lt;- count + 1\n  }\n}\n\ncat(\"There were\", count, \"subject lines in\", fname, \"\\n\")\n\n\n\n\n\n\n10.7.2 파이썬 file-user-input-try.py\n\n\nfname = input('Enter the file name: ')\ntry:\n    fhand = open(fname)\nexcept:\n    print('File cannot be opened:', fname)\n    exit()\n\ncount = 0\nfor line in fhand:\n    if line.startswith('Subject:'):\n        count += 1\n\nprint('There were', count, 'subject lines in', fname)\n\n\n\n\n이제 사용자 혹은 품질 보증 조직에서 올바르지 않거나 어처구니없는 파일명을 입력했을 때, 버그를 try() 함수로 잡아서 우아하게 복구한다.\n\n$ rscript file-user-input-try.R\nEnter the file name: mbox.txt\n경고메시지(들):\n사용되지 않는 커넥션 3 (stdin)를 닫습니다\nThere were 1797 subject lines in mbox.txt\n\n$ rscript file-user-input-try.R\nEnter the file name: no no no\n경고메시지(들):\nfile(con, \"r\")에서:\n  파일 'no no no'를 여는데 실패했습니다: No such file or directory\nFile cannot be opened: no no no\n\nR 프로그램을 작성할 때 readLines() 파일 열기 호출을 보호하는 것은 try()의 적절한 사용 예제가 된다. “R 방식(R way)”으로 무언가를 작성할 때, “알스러운”이라는 용어를 사용한다. 상기 파일을 여는 예제는 알스러운 방식의 좋은 예가 된다고 말한다.\nR에 좀 더 자신감이 생기게 되면, 다른 R 프로그래머와 동일한 문제에 대해 두 가지 동치하는 해답을 가지고 어떤 접근법이 좀 더 “알스러운지”에 대한 현답을 찾는 데도 관여하게 된다.\n“좀 더 알스럽게” 되는 이유는 프로그래밍이 엔지니어링적인 면과 예술적인 면을 동시에 가지고 있기 때문이다. 항상 무언가를 단지 작동하는 것에만 관심이 있지 않고, 프로그램으로 작성한 해결책이 좀 더 우아하고, 다른 동료에 의해서 우아한 것으로 인정되기를 또한 원한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-write",
    "href": "12-file.html#r-file-write",
    "title": "10  파일",
    "section": "\n10.8 파일에 쓰기",
    "text": "10.8 파일에 쓰기\n\n파일에 쓰기 위해서는 두 번째 매개 변수로 ‘w’ 모드로 파일을 열어야 한다.\n\n\nR\n\nfout &lt;- file(\"output.txt\", \"w\")\nprint(fout)\nclose(fout)\n\n\n\n\n\n파이썬\n\nfout = open('output.txt', 'w')\nprint(fout)\n\n\n\n\n파일이 이미 존재하는데 쓰기 모드에서 파일을 여는 것은 이전 데이터를 모두 지워버리고, 깨끗한 파일 상태에서 다시 시작되니 주의가 필요하다. 만약 파일이 존재하지 않는다면, 새로운 파일이 생성된다.\n파일 핸들 객체의 writeLines() 함수는 데이터를 파일에 저장한다. 라인을 끝내고 싶을 때, 명시적으로 줄바꿈 문자를 삽입해서 파일에 쓰도록 라인 끝을 필히 관리해야 한다. print문이 자동적으로 줄바꿈을 추가하듯이 writeLines() 함수도 자동적으로 줄바꿈을 추가한다. \n\n\nR\n\nfout &lt;- file(\"output.txt\", \"w\")\nline1 &lt;- \"This here's the wattle,\\n\"\nwriteLines(line1, fout)\nline2 &lt;- 'the emblem of our land.\\n'\nwriteLines(line2, fout)\nclose(fout)\n\n\n\n\n\n파이썬\n\nfout = open(\"output.txt\", \"w\")\nline1 = \"This here's the wattle,\\n\"\nfout.write(line1)\nline2 = 'the emblem of our land.\\n'\nfout.write(line2)\nfout.close()\n\n\n\n\n파일 쓰기가 끝났을 때, 파일을 필히 닫아야 한다. 파일을 닫는 것은 데이터 마지막 비트까지 디스크에 물리적으로 쓰여져서, 전원이 나가더라도 자료가 유실되지 않는 역할을 한다.\n파일 읽기로 연 파일을 닫을 수 있지만, 몇 개 파일을 열어놓았다면 약간 단정치 못하게 끝날 수 있다. 왜냐하면 프로그램이 종료될 때 열린 모든 파일이 닫혀졌는지 파이썬이 확인하기 때문이다. 파일에 쓰기를 할 때는, 파일을 명시적으로 닫아서 예기치 못한 일이 발생할 여지를 없애야 한다.\n파일에 두 문장을 써넣은 결과는 다음과 같다.\n\n$ cat output.txt\nThis here's the wattle,\n\nthe emblem of our land.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-debug",
    "href": "12-file.html#r-file-debug",
    "title": "10  파일",
    "section": "\n10.9 디버깅",
    "text": "10.9 디버깅\n \n파일을 읽고 쓸 때, 공백 때문에 종종 문제에 봉착한다. 이런 종류의 오류는 공백, 탭, 줄바꿈이 눈에 보이지 않기 때문에 디버그하기도 쉽지 않다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n우선 RStudio IDE의 상단 메뉴에서 Tools -&gt; Global Options -&gt; Code -&gt; Display -&gt; “Show whitespace characters”를 통해 공백문자(whitespace)에 대해 확인할 수 있다.\n내장함수 dput이 도움이 될 수 있다. 인자로 임의 객체를 잡아 객체 문자열 표현식으로 반환한다. 문자열 공백문자는 역슬래시 시퀀스로 표현된다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n여러분이 봉착하는 또 다른 문제는 다른 시스템에서는 라인 끝을 표기하기 위해서 다른 문자를 사용한다는 점이다. 어떤 시스템은 \\n으로 줄바꿈을 표기하고, 다른 시스템은 \\r으로 반환 문자(return character)를 사용한다. 둘 다 모두 사용하는 시스템도 있다. 파일을 다른 시스템으로 이식한다면, 이러한 불일치가 문제를 야기한다. \n대부분의 시스템에는 A 포맷에서 B 포맷으로 변환하는 응용프로그램이 있다. https://en.wikipedia.org/wiki/Newline에서 응용프로그램을 찾을 수 있고, 좀 더 많은 것을 읽을 수 있다. 물론, 여러분이 직접 프로그램을 작성할 수도 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-ai",
    "href": "12-file.html#r-file-ai",
    "title": "10  파일",
    "section": "\n10.10 AI와 함께하는 파일 처리",
    "text": "10.10 AI와 함께하는 파일 처리\n파일 처리는 반복적이고 패턴이 명확한 작업이 많아 AI 코딩 도구를 활용하기 좋은 영역이다. 특히 대용량 파일 처리, 복잡한 형식 파싱, 다중 파일 일괄 처리 등에서 AI의 도움이 유용하다.\n\n10.10.1 명세 작성 패턴\nAI에게 파일 처리를 요청할 때 포함해야 할 정보:\n\n\n파일 형식: 텍스트/바이너리, 인코딩, 구분자\n\n처리 방식: 전체 읽기 vs 스트리밍, 청크 크기\n\n예외 처리: 파일 없음, 권한 오류, 인코딩 오류\n\n10.10.2 프롬프트 예시\n로그 파일 분석\n\n수백 MB 크기의 서버 로그 파일에서 ERROR 패턴이 포함된 라인만 추출하는 R/Python 함수를 작성해줘.\n조건: - 파일이 너무 커서 한 번에 메모리에 올릴 수 없음 - 한 줄씩 읽으면서 처리 - 결과는 별도 파일로 저장\n입력: server.log\n출력: errors.log\n\n다중 파일 병합\n\n특정 폴더에 있는 모든 CSV 파일을 하나로 합치는 스크립트가 필요해.\n\n헤더는 첫 번째 파일에서만 가져오기\n파일명을 새 컬럼으로 추가\n빈 파일은 건너뛰기\n\n폴더: data/monthly/\n출력: data/combined.csv\n\n형식 변환\n\nJSON 파일을 읽어서 CSV로 변환하는 함수를 작성해줘.\nJSON 구조:\n[{\"name\": \"홍길동\", \"age\": 30, \"city\": \"서울\"}, ...]\n조건: 중첩된 객체가 있으면 문자열로 평탄화\n\n이처럼 파일 형식, 크기 제약, 예외 상황을 명확히 전달하면 AI가 적절한 처리 전략(스트리밍, 청크 처리, 예외 처리)을 적용한 코드를 생성한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-terminology",
    "href": "12-file.html#r-file-terminology",
    "title": "10  파일",
    "section": "\n10.11 용어 정의",
    "text": "10.11 용어 정의\n\n\n잡기(catch): tryCatch 함수를 사용하여 프로그램이 예외 상황으로 인해 종료되는 것을 방지하는 과정으로 예외가 발생할 때 실행할 코드를 지정하고,정상적으로 코드를 계속 실행할 수 있게 한다. \n\n줄바꿈: 라인 끝을 표기하기 위해 파일이나 문자열에 사용되는 특수 문자. \n\n파이썬다움(Pythonic): 파이썬에서 우아하게 작동하는 기술. “try와 catch를 사용하는 것은 파일이 없는 경우를 복구하는 파이썬스러운 방식이다.” \n\n품질 보증(Quality Assurance, QA): 소프트웨어 제품의 전반적인 품질을 보증하는 데 집중하는 사람이나 조직. 품질 보증은 소프트웨어 제품을 시험하고, 제품이 시장에 출시되기 전에 문제를 확인하는 데 관여한다. \n\n텍스트 파일: 하드디스크 같은 영구 저장소에 저장된 일련의 문자 집합.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#r-file-ex",
    "href": "12-file.html#r-file-ex",
    "title": "10  파일",
    "section": "연습문제",
    "text": "연습문제\n\n파일을 읽고 한 줄씩 파일의 내용을 모두 대문자로 출력하는 프로그램을 작성하세요. 프로그램을 실행하면 다음과 같이 보일 것입니다.\n\n\n$ Rscript shout.R \"mbox-short.txt\"\n\nFROM STEPHEN.MARQUARD@UCT.AC.ZA SAT JAN 5 09:14:16 2008\nRETURN-PATH: &lt;POSTMASTER@COLLAB.SAKAIPROJECT.ORG&gt;\nRECEIVED: FROM MURDER (MAIL.UMICH.EDU [141.211.14.90])\nBY FRANKENSTEIN.MAIL.UMICH.EDU (CYRUS V2.3.8) WITH LMTPA;\nSAT, 05 JAN 2008 09:14:16 -0500\n\nhttp://www.py4inf.com/code/mbox-short.txt에서 파일을 다운로드 받으세요.\n\n파일명을 입력받아, 파일을 읽고, 다음 형식의 라인을 찾는 프로그램을 작성하세요.\n\n\nX-DSPAM-Confidence: 0.8475\n\n“X-DSPAM-Confidence:”로 시작하는 라인을 만나게 되면, 부동 소수점 숫자를 뽑아내기 위해 해당 라인을 별도로 보관하세요. 라인 수를 세고, 라인으로부터 스팸 신뢰값의 총계를 계산하세요. 파일의 끝에 도달했을 때, 평균 스팸 신뢰도를 출력하세요.\n\n$ Rscript calc.R \"mbox-short.txt\"\nAverage spam confidence: 0.750718518519\n\n$ Rscript calc.R \"mbox.txt\"\nAverage spam confidence: 0.894128046745\n\nmbox.txt와 mbox-short.txt 파일에 작성한 프로그램을 시험하세요.\n\n때때로, 프로그래머가 지루해지거나, 약간 재미를 목적으로, 프로그램에 무해한 부활절 달걀(Easter Egg, https://en.wikipedia.org/wiki/Easter_egg_(media))을 넣습니다. 사용자가 파일명을 입력하는 프로그램을 변형시켜, ’na na boo boo’로 파일명을 정확하게 입력했을 때, 재미있는 메시지를 출력하는 프로그램을 작성하세요. 파일이 존재하거나, 존재하지 않는 다른 모든 파일에 대해서도 정상적으로 작동해야 합니다. 여기 프로그램을 실행한 견본이 있습니다.\n\n\n$ Rscript egg.R \"mbox.txt\"\nThere were 1797 subject lines in mbox.txt\n\n$ Rscript egg.R \"missing.tyxt\"\nFile cannot be opened: missing.tyxt\n\n$ Rscript egg.R \"na na boo boo\"\nNA NA BOO BOO TO YOU - You have been punk'd!\n\n프로그램에 부활절 달걀을 넣도록 격려하지는 않습니다. 단지 연습입니다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "12-file.html#footnotes",
    "href": "12-file.html#footnotes",
    "title": "10  파일",
    "section": "",
    "text": ".R 스크립트를 인자와 함께 실행↩︎",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>파일</span>"
    ]
  },
  {
    "objectID": "13-list.html",
    "href": "13-list.html",
    "title": "11  리스트",
    "section": "",
    "text": "11.1 리스트는 시퀀스다\n프로그래밍에서 여러 값을 하나로 묶어 관리해야 하는 상황은 매우 흔하다. 파일에서 읽어온 데이터 라인들, 사용자로부터 입력받은 숫자들, 웹에서 가져온 항목들 모두 리스트로 저장하고 처리한다. 리스트는 데이터를 순서대로 저장하고, 반복 처리하고, 필터링하는 가장 기본적인 도구다.\n리스트의 개념과 조작 방법을 이해하면, AI에게 데이터 처리 작업을 요청할 때 “리스트에서 조건에 맞는 요소만 필터링해줘”, “각 요소에 함수를 적용해줘”와 같은 명확한 요구사항을 전달할 수 있다.\n문자열처럼, 리스트(list)는 값의 시퀀스다. 문자열에서, 값은 문자지만, 리스트에서는 임의 자료형(type)도 될 수 있다. 리스트 값은 요소(elements)나 때때로 항목(items)으로 불린다.\n신규 리스트를 생성하는 방법은 여러 가지가 있다. 가장 간단한 방법은 list() 함수로 요소를 감싸는 것이다.\n첫 번째 예제는 4개 정수 리스트다. 두번째 예제는 3개 문자열 리스트다. 세 번째 예제는 한글 문자열 리스트다. 리스트 문자열 요소가 동일한 자료형(type)일 필요는 없다. 다음 리스트는 문자열, 부동 소수점 숫자, 정수, (아!) 또 다른 리스트를 담고 있다.\n또 다른 리스트 내부에 리스트가 중첩(nested)되어 있다.\n어떤 요소도 담고 있지 않는 리스트를 빈 리스트(empty list)라고 부르고, list()로 생성한다.\n예상했듯이, 리스트 값을 변수에 대입할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-sequence",
    "href": "13-list.html#r-list-sequence",
    "title": "11  리스트",
    "section": "",
    "text": "R\n\nlist(10, 20, 30, 40)\nlist('crunchy frog', 'ram bladder', 'lark vomit')\nlist('고양이', '호랑이', '사자')\n\n\n\n\n\n파이썬\n\n[10, 20, 30, 40]\n['crunchy frog', 'ram bladder', 'lark vomit']\n['고양이', '호랑이', '사자']\n\n\n\n\n\n\n\nR\n\nlist('spam', 2.0, 5, list(10, 20))\n\n\n\n\n\n파이썬\n\n['spam', 2.0, 5, [10, 20]]\n\n\n\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-mutable",
    "href": "13-list.html#r-list-mutable",
    "title": "11  리스트",
    "section": "\n11.2 리스트는 변경 가능하다",
    "text": "11.2 리스트는 변경 가능하다\n \n리스트 요소에 접근하는 구문은 문자열 문자에 접근하는 것과 동일한 꺾쇠 괄호 연산자다. 꺾쇠 괄호 내부 표현식은 인덱스를 명세한다. 기억할 것은 인덱스는 1에서부터 시작한다는 것이다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n문자열과 마찬가지로, 리스트 항목 순서를 바꾸거나, 리스트에 새로운 항목을 다시 대입할 수 있기 때문에 리스트는 변경 가능하다. 꺾쇠 괄호 연산자가 대입문 왼쪽편에 나타날 때, 새로 대입될 리스트 요소를 나타낸다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n리스트 numbers의 첫 번째 요소는 123 값을 가지고 있었으나, 이제 5 값을 가진다. \n리스트를 인덱스와 요소의 관계로 생각할 수 있다. 이 관계를 매핑(mapping)이라고 부른다. 각각의 인덱스는 요소 중 하나에 대응(“maps to”)된다. \n리스트 인덱스는 문자열 인덱스와 동일한 방식으로 동작한다.\n\n어떠한 정수 표현식도 인덱스로 사용할 수 있다.\n존재하지 않는 요소를 읽거나 쓰려고 하면, 일종의 인덱스 오류(IndexError)로 NULL이 반환된다.\n인덱스가 음의 값이면, 해당 리스트 원소가 누락된다. \n\n%in% 연산자도 또한 리스트에서 동작하니 리스트 원소로 존재하는지 여부를 판별하는 데 사용할 수 있다.\n \\index{%in% 연산자} \\index{연산자!%in%}\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-traversal",
    "href": "13-list.html#r-list-traversal",
    "title": "11  리스트",
    "section": "\n11.3 리스트 순회법",
    "text": "11.3 리스트 순회법\n \n리스트 요소를 순회하는 가장 흔한 방법은 for 문을 사용하는 것이다. 문자열에서 사용한 것과 구문은 동일하다.\n\n\nR\n\nfor(cheese in cheeses) {\n  print(cheese)\n}\n\n\n\n\n\n파이썬\n\nfor cheese in cheeses:\n    print cheese\n\n\n\n\n리스트 요소를 읽기만 한다면 이것만으로도 잘 동작한다. 하지만, 리스트 요소를 쓰거나 갱신하는 경우, 인덱스가 필요하다. 리스트 요소를 쓰거나 갱신하는 일반적인 방법은 seq_along() 함수를 조합하는 것이다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 루프는 리스트를 순회하고 각 요소를 갱신한다. seq_along() 함수는 1에서 \\(n\\)까지 리스트 인덱스를 반환한다. 여기서, \\(n\\)은 리스트 길이가 된다. 매번 루프가 반복될 때마다, i는 다음 요소 인덱스를 얻는다. 몸통 부문 대입문은 i를 사용해서 요소의 이전 값을 읽고 새 값을 대입한다. \n빈 리스트(list())에 대해서 for 문은 결코 몸통 부문을 실행하지 않는다.\n\n\nR\n\nfor(x in list()) {\n  print('이런 일은 절대 발생하지 않는다.')\n}\n\n\n\n\n\n파이썬\n\nfor x in empty:\n    print('이런 일은 절대 발생하지 않는다.')\n\n\n\n\n리스트가 또 다른 리스트를 담을 수 있지만, 중첩된 리스트는 여전히 요소 하나로 간주된다. 다음 리스트 길이는 4다. \n\n\nR\n\nlist('spam', 1, list('브리', '체다', '까멩베르'), list(1, 2, 3))\n\n\n\n\n\n파이썬\n\n['spam', 1, ['Brie', 'Roquefort', 'Pol le Veq'], [1, 2, 3]]",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-operator",
    "href": "13-list.html#r-list-operator",
    "title": "11  리스트",
    "section": "\n11.4 리스트 연산자",
    "text": "11.4 리스트 연산자\n\nc() 함수 연산자는 리스트를 추가하여 결합시킨다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n유사하게 rep() 함수를 활용하면 주어진 횟수만큼 리스트를 반복한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n첫 예제는 list(0)을 4회 반복한다. 두 번째 예제는 list(1, 2, 3) 리스트를 3회 반복한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-slice",
    "href": "13-list.html#r-list-slice",
    "title": "11  리스트",
    "section": "\n11.5 리스트 슬라이스",
    "text": "11.5 리스트 슬라이스\n \n슬라이스(slice) 연산자는 리스트에도 또한 동작한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n첫 번째 인덱스를 1로 지정하면, 슬라이스는 처음부터 시작한다. 두 번째 인덱스를 length() 함수로 리스트 길이를 지정하면, 슬라이스는 끝까지 간다. 그래서 양쪽의 인덱스를 생략하면, t같이 지정하면 슬라이스 결과는 전체 리스트를 복사한 것이 된다. \n리스트는 변경이 가능하기 때문에 리스트를 접고, 돌리고, 훼손하는 연산을 수행하기 전에 복사본을 만들어두는 것이 유용하다. \n대입문 왼편의 슬라이스 연산자로 복수의 요소를 갱신할 수 있다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-function",
    "href": "13-list.html#r-list-function",
    "title": "11  리스트",
    "section": "\n11.6 리스트 함수",
    "text": "11.6 리스트 함수\n \nR은 리스트 자료형에 연산할 수 있는 함수를 제공한다. 예를 들어, 덧붙이기(append) 함수는 리스트 끝에 신규 요소를 추가한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n정렬(order) 함수는 낮음에서 높음으로 리스트 요소를 정렬한다. 리스트에서 sapply() 혹은 unlist() 함수로 값으로 변환시키고 order() 함수를 통해 내림차순 혹은 오름차순으로 정렬 인덱스를 뽑아 리스트 내 원소를 정렬시킨다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-delete",
    "href": "13-list.html#r-list-delete",
    "title": "11  리스트",
    "section": "\n11.7 리스트 요소 삭제",
    "text": "11.7 리스트 요소 삭제\n \n리스트 요소를 삭제하는 방법이 몇 가지 있다. 리스트 요소 인덱스를 알고 있다면, 숫자 인덱스 앞에 - 기호를 붙여 사용한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n리스트 요소 명칭을 알고 있다면, 리스트 요소에 NULL을 대입하여 삭제시킨다.\n\nt &lt;- list(a='a', b='b', c = 'c')\nt[[\"c\"]] &lt;- NULL\nt$c &lt;- NULL\nt\n#&gt; $a\n#&gt; [1] \"a\"\n#&gt; \n#&gt; $b\n#&gt; [1] \"b\"\n\nNULL을 대입하여 삭제시킨 리스트는 제거된 요소를 반환한다. t[[1]] 리스트 인덱스를 통해 요소에 접근하고 NULL을 대입하여 삭제한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n(인덱스 혹은 리스트 요소 이름이 아닌) 제거할 요소값을 알고 있다면, 리스트 요소 값을 활용해서 제거하는 것도 가능하다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n하나 이상의 요소를 제거하기 위해서, 슬라이스 인덱스(slice index)를 사용하는 것도 가능하다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n위의 예제에서 2에서 5까지 모든 요소를 선택하고 선택된 모든 요소를 제거한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#리스트와-함수",
    "href": "13-list.html#리스트와-함수",
    "title": "11  리스트",
    "section": "\n11.8 리스트와 함수",
    "text": "11.8 리스트와 함수\n루프를 작성하지 않고도 리스트를 빠르게 살펴볼 수 있는 리스트에 적용할 수 있는 내장 함수를 활용하는 것도 방법이지만, 깔끔한 세상(tidyverse) 생태계의 일원인 purrr 함수형 프로그래밍 패키지에 내장된 함수를 활용하는 것도 권장된다.\n하지만, 다음과 같이 1차원 리스트는 unlist() 함수를 활용하여 벡터로 변환해서 사용하는 것이 편리한 경우가 많다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nsum(), max(), length() 등 함수는 입력 자료형이 무엇이냐에 따라 다르게 동작할 수 있고, 입력 자료형에 결측값 등 특이값이 들어있는 경우 기대했던 결과가 나올 수 없으니 반드시 자료형을 사전에 점검하고 활용하도록 한다.\n리스트를 사용해서, 앞서 작성한 프로그램을 다시 작성해서 사용자가 입력한 숫자 목록 평균을 계산한다.\n우선 리스트 없이 평균을 계산하는 프로그램:\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 프로그램에서, count 와 sum 변수를 사용해서 반복적으로 사용자가 숫자를 입력하면 값을 저장하고, 지금까지 사용자가 입력한 누적 합계를 계산한다. R 콘솔에서 source() 함수를 사용해서 실행한 결과는 다음과 같다.\n\n&gt; source(\"code/list_average.R\")\n숫자를 입력하세요: 10\n숫자를 입력하세요: 20\n숫자를 입력하세요: 30\n숫자를 입력하세요: done\n평균: 20\n\n단순하게, 사용자가 입력한 각 숫자를 리스트로 기억하고 내장 함수를 사용해서 프로그램 마지막에 합계와 갯수를 통해 평균을 계산한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n루프가 시작되기 전 빈 리스트를 생성하고, 매번 숫자를 입력할 때마다 숫자를 리스트에 추가한다. 프로그램 마지막에 간단하게 리스트 총합을 계산하고, 평균을 산출하기 위해서 입력한 숫자 개수로 나눈다. R 콘솔에서 source() 함수를 사용해서 실행한 결과는 다음과 같다.\n\n&gt; source(\"code/list_average2.R\")\n숫자를 입력하세요: 10\n숫자를 입력하세요: 20\n숫자를 입력하세요: 30\n숫자를 입력하세요: done\n평균: 20",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-string",
    "href": "13-list.html#r-list-string",
    "title": "11  리스트",
    "section": "\n11.9 리스트와 문자열",
    "text": "11.9 리스트와 문자열\n \n문자열(string)은 문자 시퀀스이고, 리스트는 값 시퀀스이다. 하지만 리스트 문자는 문자열과 같지는 않다. 문자열을 리스트 문자로 변환하기 위해서, strsplit() 함수를 사용한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nlist는 내장 함수 이름이기 때문에, 변수명으로 사용하는 것을 피해야 한다. l을 사용하면 1처럼 보이기 때문에 가능하면 피한다. 그래서, t를 사용했다.\nstrsplit() 함수는 문자열을 구분자(이번 경우에는 NULL)를 사용해서 문자 각각으로 쪼갠다. 문자열 단어로 쪼개려면, 구분자를 바꿔 예를 들어 공백을 기준으로 쪼갠다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n분할 함수를 사용해서 문자열을 리스트 토큰으로 쪼개면, 인덱스 연산자(‘[]’)를 사용하여 리스트의 특정 단어를 볼 수 있다.\n옵션 인자로 단어 경계로 어떤 문자를 사용할 것인지 지정하는 데 사용되는 구분자(delimiter)를 활용하여 분할 strsplit() 함수를 호출한다. 다음 예제는 구분자로 하이픈(‘-’)을 사용한 사례이다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n합병(paste) 함수는 분할(strsplit) 함수의 역이다. 문자열 리스트를 받아 리스트 요소를 연결한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기의 경우, 구분자가 공백 문자여서 결합(paste) 함수가 단어 사이에 공백을 넣는다. 공백 없이 문자열을 결합하기 위해서, 구분자로 빈 문자열 ’’을 사용한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-parsing",
    "href": "13-list.html#r-list-parsing",
    "title": "11  리스트",
    "section": "\n11.10 라인 파싱하기",
    "text": "11.10 라인 파싱하기\n파일을 읽을 때 통상, 단지 전체 라인을 출력하는 것 말고 뭔가 다른 것을 하고자 한다. 종종 “흥미로운 라인을” 찾아서 라인을 파싱(parse)하여 흥미로운 부분을 찾고자 한다. “From”으로 시작하는 라인에서 요일을 찾고자 하면 어떨까?\n\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n\n이런 종류의 문제에 직면했을 때, stringr 패키지 분할 str_split() 함수가 매우 효과적이다. 작은 프로그램을 작성하여 “From”으로 시작하는 라인을 찾고 str_split() 함수로 파싱하고 라인의 흥미로운 부분을 출력한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nif 문의 축약 형태를 사용하여 next 문을 if 문과 동일한 라인에 놓았다. if 문 축약 형태는 next 문을 들여쓰기를 다음 라인에 한 것과 동일하다.\n프로그램은 다음을 출력한다.\n\nSat\nFri\nFri\nFri\n...\n\n나중에, 매우 정교한 기술에 대해서 학습해서 정확하게 검색하는 비트(bit) 수준 정보를 찾아내기 위해서 작업할 라인을 선택하고, 어떻게 해당 라인을 뽑아낼 것이다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-object-value",
    "href": "13-list.html#r-list-object-value",
    "title": "11  리스트",
    "section": "\n11.11 객체와 값",
    "text": "11.11 객체와 값\n \n다음 대입문을 실행하면,\n\na &lt;- 'banana'\nb &lt;- 'banana'\n\na와 b 모두 문자열을 참조하지만, 두 변수가 동일한 문자열을 참조하는지 알 수 없다. 두 가지 가능한 상태가 있다.\n\n\n\n\n\n그림 11.1: 문자열 참조\n\n\n한 가지 경우는 a와 b가 같은 값을 가지는 다른 두 객체를 참조하는 것이다. 두 번째 경우는 같은 객체를 참조하는 것이다. \n두 변수가 동일한 객체를 참조하는지를 확인하기 위해서, 파이썬에서는 is 연산자가 사용된다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n이 경우, 파이썬은 하나의 문자열 객체를 생성하고 a와 b 모두 동일한 객체를 참조한다. \n하지만, 리스트 두 개를 생성할 때, 객체가 두 개다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기의 경우, 두 개의 리스트는 동등하다고 말할 수 있다. 왜냐하면 동일한 요소를 가지고 있기 때문이다. 하지만, 같은 객체는 아니기 때문에 동일하지는 않다. 두 개의 객체가 동일하다면, 두 객체는 또한 동등하다. 하지만, 동등하다고 해서 반드시 동일하지는 않다. \nR과 파이썬이 다른 결과를 출력하는 이유는 무엇일까? R identical() 함수는 객체의 값과 구조가 완전히 동일한지를 확인한다. a &lt;- list(1, 2, 3)와 b &lt;- list(1, 2, 3)의 경우, a와 b는 별도의 객체이지만, 그 내용(값과 구조)이 완전히 동일하기 때문에 identical(a, b)는 TRUE를 반환한다. 파이썬 is 연산자는 객체가 메모리 상에서 동일한 위치를 가리키는지(즉, 같은 객체인지)를 확인한다. a = [1, 2, 3]와 b = [1, 2, 3]의 경우, a와 b는 값은 동일하지만 서로 다른 메모리 위치에 할당된 별개의 리스트 객체라서 a is b는 False를 반환한다.\n지금까지 “객체(object)”와 “값(value)”을 구분 없이 사용했지만, “객체가 값을 가진다.”라고 말하는 것이 좀 더 정확하다. a = [1,2,3]을 실행하면, a는 특별한 순서 요소 값을 갖는 리스트 객체로 참조한다. 만약 다른 리스트가 같은 요소를 가지고 있다면, 그 리스트는 같은 값을 가진다고 말할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-aliasing",
    "href": "13-list.html#r-list-aliasing",
    "title": "11  리스트",
    "section": "\n11.12 에일리어싱",
    "text": "11.12 에일리어싱\n에일리어싱(별칭 부여, Aliasing) 용어는 두 개 이상의 변수가 동일한 객체를 참조할 때 사용된다. a가 객체를 참조하고, b &lt;- a 대입한다면, 두 변수는 동일한 객체를 참조한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n객체와 변수의 연관 짓는 것을 참조(reference)라고 한다. 상기의 경우 동일한 객체에 두 개의 참조가 있다. \n하나 이상의 참조를 가진 객체는 한 개 이상의 이름을 갖게 되어서, 객체가 에일리어스(aliased) 되었다고 한다. 만약 에일리어스된 객체가 변경 가능하면, 변화의 여파는 다른 객체에도 파급된다. \nR에는 파이썬 문자열(string), 튜플(tuple)과 같은 변경 불가능한 자료구조가 없다. 대신 객체 복사본을 생성하여 불변성을 유사하게 구현할 수 있다. dplyr과 같은 패키지에서 데이터 조작을 위해 내부적으로 데이터 복사본을 만들어 작업하는 경우가 많다. 다음 예제를 통해 R과 파이썬 차이를 확인할 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n이와 같은 행동이 유용하기도 하지만, 오류를 발생시키기도 쉽다. 일반적으로, 변경 가능한 객체(mutable object)로 작업할 때 에일리어싱을 피하는 것이 안전하다. \n\na = 'banana'\nb = 'banana'\n\n파이썬 문자열 같이 변경 불가능한 객체에 에일리어싱은 그렇게 문제가되지 않는다. 상기 파이썬 예제에서, a와 b가 동일한 문자열을 참조하든 참조하지 않든 거의 차이가 없다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-debug",
    "href": "13-list.html#r-list-debug",
    "title": "11  리스트",
    "section": "\n11.13 디버깅",
    "text": "11.13 디버깅\n\n부주의한 리스트 사용이나 변경 가능한 객체를 사용하는 경우 디버깅에 시간이 오래 걸릴 수 있다. 다음에 일반적인 함정 유형과 회피하는 방법을 소개한다.\n\nR에서 리스트 함수가 파이썬과는 다르게 동작한다. R 리스트는 기본적으로 변경 가능(mutable)하지만, 리스트를 변형하는 함수 대부분은 새로운 리스트를 반환하고 원본 리스트는 변경하지 않는다. 파이썬에서 문자열이 작동하는 방식과 유사하지만 차이가 있다. 예를 들어, R에서 sort 함수는 t 리스트의 원본 내용을 변경하지 않고, 정렬된 결과를 새로운 벡터 t_sorted에 저장한다. R에서 리스트나 벡터를 다룰 때는 이러한 특성을 기억하는 것이 중요하다. 또한 R에서는 인터랙티브 환경에서 함수의 동작을 테스트하고, 관련 문서나 도움말(?function_name)을 참조하여 함수가 어떻게 작동하는지 먼저 이해할 것을 권장한다. 하지만, 파이썬에서 word = word.strip()과 같은 코드를 사용하여 문자열에서 공백을 제거하고, t = t.sort()처럼 리스트를 정렬할 수 있다. 하지만 정렬(sort) 메서드는 None을 반환하기 때문에 주의가 필요하다. 따라서, 리스트 관련 함수, 메서드, 연산자를 사용하기 전에, 문서를 주의 깊게 읽고, 인터랙티브 모드에서 시험하는 것을 권장한다.\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n \n\n\n관용구를 선택하고 고수하라. \n\n리스트와 관련된 문제 일부는 리스트를 가지고 할 수 있는 것이 너무 많다는 것이다. 예를 들어, 리스트에서 요소를 제거하기 위해서는 list 객체에서 직접 요소를 제거하는 대신, 새로운 리스트를 생성하거나 벡터로 작업을 대신한다. R에는 파이썬 pop, remove, del에 해당하는 직접적인 함수가 없으며, 대신 리스트의 특정 요소를 제외한 새로운 리스트를 생성한다. 요소를 추가하기 위해서 append 함수를 사용하거나, c() 함수로 리스트 또는 벡터에 요소를 추가한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n에일리어싱을 회피하기 위해 사본 만들기. \n\nR에서 리스트나 벡터를 정렬하면서 원본 데이터를 보존하고 싶은 경우, 정렬 함수가 원본 객체를 변경하지 않고 새로운 객체를 반환하기 때문에 별도의 사본을 만들 필요가 없다. 하지만, 데이터 분석에서처럼 원본 데이터를 보존하여 만일의 사태에 대비하는 것이 좋다. 파이썬에서는 원본 리스트를 유지하면서, 변경을 가하는 sort와 같은 메서드를 사용하고자 한다면, 사본을 만들어야 한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 예제에서 원 리스트는 그대로 둔 상태로 새로 정렬된 리스트를 반환된 결과는 t에 저장한다. 하지만 이 경우에는, 변수명으로 sorted를 사용하는 것을 피해야 한다!\n\n리스트, 분할(split), 파일\n\n파일을 읽고 파싱할 때, 프로그램이 중단될 수 있는 입력값을 마주할 수많은 기회가 있다. 그래서 파일을 훑어 “건초더미에서 바늘”을 찾는 프로그램을 작성할 때 사용한 가디언 패턴(guardian pattern)을 다시 살펴보는 것은 좋은 생각이다.\n파일 라인에서 요일을 찾는 프로그램을 다시 살펴보자.\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n각 라인을 단어로 나누었기 때문에, startswith를 사용하지 않고, 라인에 관심 있는 단어가 있는지 살펴보기 위해서 단순하게 각 라인의 첫 단어를 살펴본다. 다음과 같이 continue 문을 사용해서 “From”이 없는 라인을 건너뛴다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램이 훨씬 간단하고, 파일 끝에 있는 새줄(newline)을 제거하기 위해 str_trim() 함수를 사용할 필요도 없다. 하지만, 더 좋아졌는가?\n작동하는 것 같지만, 경우에 따라서 첫 줄에 Sat를 출력하고 나서 오류로 프로그램이 정상 동작에 실패하는 경우도 있다. 무엇이 잘못되었을까? 어딘가 엉망이 된 데이터가 있어 우아하고, 총명하며, 매우 R스러운 프로그램을 망가뜨린 건가?\n오랜 동안 프로그램을 응시하고 머리를 짜내거나, 다른 사람에게 도움을 요청할 수 있지만, 빠르고 현명한 접근법은 print() 문을 추가하는 것이다. print() 문을 넣는 가장 좋은 장소는 프로그램이 동작하지 않는 라인 앞이 적절하고, 프로그램 실패를 야기할 것 같은 데이터를 출력한다.\n이 접근법이 많은 라인을 출력하지만, 즉석에서 문제에 대해서 손에 잡히는 단서는 최소한 준다. 그래서 words를 출력하는 출력문을 5번째 라인 앞에 추가한다. “Debug:”를 접두어로 라인에 추가하여, 정상적인 출력과 디버그 출력을 구분한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램을 실행할 때, 많은 출력결과가 스크롤되어 화면 위로 지나간다. 마지막에 디버그 결과물과 역추적(traceback)을 보고 역추적(traceback) 바로 앞에서 무슨 일이 생겼는지 알 수 있다.\n\n\nR\n\nDebug: 'X-DSPAM-Confidence:', '0.8475'\nDebug: 'X-DSPAM-Probability:', '0.0000'\nDebug: \n\n\n\n\n\n파이썬\n\nDebug: ['X-DSPAM-Confidence:', '0.8475']\nDebug: ['X-DSPAM-Probability:', '0.0000']\nDebug: []\nTraceback (most recent call last):\n  File \"D:/tcs/gpt-coding/data/mbox_debug.py\", line 5, in &lt;module&gt;\n    if words[0] != 'From':\nIndexError: list index out of range\n\n\n\n\n각 디버그 라인은 리스트 단어를 출력하는데, 라인을 분할 str_split() 함수를 활용하여 단어로 만들 때 얻어진다. 프로그램이 실패할 때 리스트 단어는 비었다 ’’. 텍스트 편집기로 파일을 열어 살펴보면 그 지점은 다음과 같다.\n\nX-DSPAM-Result: Innocent\nX-DSPAM-Processed: Sat Jan 5 09:14:16 2008\nX-DSPAM-Confidence: 0.8475\nX-DSPAM-Probability: 0.0000\n\nDetails: http://source.sakaiproject.org/viewsvn/?view=rev&rev=39772\n\n프로그램이 빈 라인을 만났을 때, 오류가 발생한다. 물론, 빈 라인은 ‘0’ 단어 (“zero words”)다. 프로그램을 작성할 때, 왜 이것을 생각하지 못했을까? 첫 단어(word[1])가 “From”과 일치하는지 코드가 점검할 때, “인덱스 범위 오류(index out of range)”가 발생한다.\n물론, 첫 단어가 없다면 첫 단어 점검을 회피하는 가디언 코드(guardian code)를 삽입하기 최적 장소이다. 코드를 보호하는 방법은 많다. 첫 단어를 살펴보기 전에 단어의 개수를 확인하는 방법을 택한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n{r\n변경한 코드가 실패해서 다시 디버그할 경우를 대비해서, print문을 제거하는 대신에 print문을 주석 처리한다. 그리고 나서, 단어가 ‘0’ 인지를 살펴보고 만약 ‘0’ 이면, 파일 다음 라인으로 건너뛰도록 next문을 사용하는 가디언 문장(guardian statement)을 추가한다.\n두 개의 next문이 “흥미롭고” 좀 더 처리가 필요한 라인 집합을 정제하도록 돕는 것으로 생각할 수 있다. 단어가 없는 라인은 “흥미 없어서” 다음 라인으로 건너뛴다. 첫 단어에 “From”이 없는 라인도 “흥미 없어서” 건너뛴다.\n변경된 프로그램이 성공적으로 실행되어서, 아마도 올바르게 작성된 것으로 보인다. 가디언 문장(guardian statement)이 words[1]가 정상 작동할 것이라는 것을 확인해 주지만, 충분하지 않을 수도 있다. 프로그램을 작성할 때, “무엇이 잘못될 수 있을까?”를 항상 생각해야 한다.\n연습문제: 상기 프로그램의 어느 라인이 여전히 적절하게 보호되지 않은지를 생각해 보세요. 텍스트 파일을 구성해서 프로그램이 실패하도록 만들 수 있는지 살펴보세요. 그리고 나서, 프로그램을 변경해서 라인이 적절하게 보호되게 하고, 새로운 텍스트 파일을 잘 다룰 수 있도록 시험하세요.\n연습문제: 두 if 문 없이, 상기 예제의 가디언 코드(guardian code)를 다시 작성하세요. 대신에 단일 if문과 & 논리 연산자를 사용하는 복합 논리 표현식을 사용하세요.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-ai",
    "href": "13-list.html#r-list-ai",
    "title": "11  리스트",
    "section": "\n11.14 AI와 함께하는 리스트 처리",
    "text": "11.14 AI와 함께하는 리스트 처리\n리스트 처리는 데이터 분석과 프로그래밍의 핵심이다. AI에게 리스트 관련 작업을 요청할 때는 입력 데이터의 구조, 처리 방식, 기대 출력을 명확히 전달해야 한다.\n\n11.14.1 명세 작성 패턴\nAI에게 리스트 처리를 요청할 때 포함해야 할 정보:\n\n\n입력 데이터: 리스트의 요소 타입과 예시\n\n처리 방식: 필터링, 변환, 집계 등\n\n출력 형태: 결과 리스트, 단일 값, 또는 다른 자료구조\n\n11.14.2 프롬프트 예시\n조건부 필터링\n\n정수 리스트에서 짝수만 추출하는 R/Python 함수를 작성해줘.\n입력: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n출력: [2, 4, 6, 8, 10]\n조건: 빈 리스트 입력 시 빈 리스트 반환\n\n리스트 변환\n\n문자열 리스트의 각 요소를 대문자로 변환하고 길이순으로 정렬하는 함수가 필요해.\n입력: [\"apple\", \"banana\", \"kiwi\", \"strawberry\"]\n출력: [\"KIWI\", \"APPLE\", \"BANANA\", \"STRAWBERRY\"]\n\n중첩 리스트 처리\n\n2차원 리스트(행렬)에서 각 행의 합계를 구하는 함수를 작성해줘.\n입력: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n출력: [6, 15, 24]\n조건: 행 길이가 다를 수 있음\n\n리스트 집계\n\n단어 리스트에서 가장 자주 등장하는 단어 상위 3개를 찾아줘.\n입력: 텍스트 파일에서 읽어온 단어 리스트\n출력: 튜플 리스트 [(\"the\", 45), (\"and\", 32), (\"is\", 28)]\n\n이처럼 구체적인 입출력 예시를 제공하면, AI가 정확한 로직을 구현한다. 앞서 배운 순회, 슬라이싱, 리스트 함수 개념을 알고 있으면 AI가 생성한 코드가 올바른지 검증하기 수월하다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-terminology",
    "href": "13-list.html#r-list-terminology",
    "title": "11  리스트",
    "section": "\n11.15 용어 정의",
    "text": "11.15 용어 정의\n\n\n에일리어싱(aliasing): 하나 혹은 그 이상의 변수가 동일한 객체를 참조하는 상황. \n\n구분자(delimiter): 문자열이 어디서 분할되어야 할지를 표기하기 위해서 사용되는 문자나 문자열. \n\n요소(element): 리스트 혹은 다른 시퀀스 값의 하나로 항목(item)이라고도 한다. \n\n동등한(equivalent): 같은 값을 가짐. \n\n인덱스(index): 리스트의 요소를 지칭하는 정수 값. \n\n\n동일한(identical): 동등을 함축하는 같은 객체임. \n\n리스트(list): 시퀀스 값. \n\n리스트 순회(list traversal): 리스트의 각 요소를 순차적으로 접근함. \n\n중첩 리스트(nested list): 또 다른 리스트의 요소인 리스트. \n\n객체(object): 변수가 참조할 수 있는 무엇. 객체는 자료형(type)과 값(value)을 가진다. \n\n참조(reference): 변수와 값의 연관.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "13-list.html#r-list-ex",
    "href": "13-list.html#r-list-ex",
    "title": "11  리스트",
    "section": "연습문제",
    "text": "연습문제\n\n\nhttp://www.py4inf.com/code/romeo.txt에서 파일 사본을 다운로드 받는다. romeo.txt 파일을 열어, 한 줄씩 읽어들이는 프로그램을 작성하세요. 각 라인마다 stringr 팩키지에서 분할 str_split() 함수를 사용하여 라인을 단어 리스트로 쪼갠다. \n\n각 단어마다, 단어가 이미 리스트에 존재하는지를 확인하세요. 만약 단어가 리스트에 없다면, 리스트에 새 단어로 추가한다.\n프로그램이 완료되면, 알파벳 순으로 결과 단어를 정렬하고 출력하세요.\n\nEnter file: romeo.txt\n[1] 'Arise', 'But', 'It', 'Juliet', 'Who', 'already',\n'and', 'breaks', 'east', 'envious', 'fair', 'grief',\n'is', 'kill', 'light', 'moon', 'pale', 'sick', 'soft',\n'sun', 'the', 'through', 'what', 'window',\n'with', 'yonder'\n\n\n전자우편 데이터를 읽어 들이는 프로그램을 작성한다. “From”으로 시작하는 라인을 발견했을 때, stringr 팩키지에서 분할 str_split() 함수를 사용하여 라인을 단어로 쪼갠다. “From” 라인의 두번째 단어, 누가 메시지를 보냈는지에 관심이 있다.\n\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n“From” 라인을 파싱하여 각 “From”라인의 두 번째 단어를 출력한다. 그리고 나서, “From:”이 아닌 “From”라인 갯수를 세고, 끝에 갯수를 출력한다.\n여기 몇 줄을 삭제한 출력 예시가 있다.\n\nRscript fromcount.R\nEnter a file name: mbox-short.txt\n\nstephen.marquard@uct.ac.za\nlouis@media.berkeley.edu\nzqian@umich.edu\n\n[...some output removed...]\n\nray@media.berkeley.edu\ncwen@iupui.edu\ncwen@iupui.edu\ncwen@iupui.edu\n\nThere were 27 lines in the file with From as the first word\n\n\n사용자가 숫자 리스트를 입력하고, 입력한 숫자 중에 최대값과 최소값을 출력하고 사용자가 “done”을 입력할 때 종료하는 프로그램을 다시 작성한다. 사용자가 입력한 숫자를 리스트에 저장하고, max() 과 min() 함수를 사용하여 루프가 끝나면, 최대값과 최소값을 출력하는 프로그램을 작성한다.\n\n\nEnter a number: 6\nEnter a number: 2\nEnter a number: 9\nEnter a number: 3\nEnter a number: 5\nEnter a number: done\nMaximum: 9.0\nMinimum: 2.0",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>리스트</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html",
    "href": "14-dictionaries.html",
    "title": "12  딕셔너리",
    "section": "",
    "text": "12.1 명칭을 갖는 리스트\n현대 프로그래밍에서 딕셔너리(키-값 쌍)는 가장 중요한 자료구조 중 하나다. 웹 API에서 데이터를 가져오면 대부분 JSON 형식인데, JSON의 기본 구조가 바로 딕셔너리다. 설정 파일, 사용자 정보, 데이터베이스 조회 결과 등 거의 모든 곳에서 키-값 구조를 만난다.\n딕셔너리의 개념을 이해하면, AI에게 “JSON 데이터에서 특정 필드를 추출해줘”, “사용자 정보를 딕셔너리로 구성해줘”와 같은 요청을 명확하게 전달할 수 있다.\n명칭을 갖는 리스트(named list)는 딕셔너리로 더 잘 알려져 있고, 딕셔너리(dictionary)는 리스트와 유사하지만 좀 더 일반적이다. 리스트에서 위치(인덱스)가 정수이지만, 딕셔너리에서 인덱스는 임의 자료형(type)이 될 수 있다.\n딕셔너리를 인덱스 집합(키(keys)라고 부름)에서 값(value) 집합으로 사상(mapping)하는 것으로 생각할 수 있다. 각각의 키는 값에 대응한다. 키와 값을 연관시키는 것을 키-값 페어(key-value pair)라고 부르고, 종종 항목(item)으로도 부른다.\n한 예제로, 영어 단어에서 한국어 단어로 매핑되는 사전을 만들 것이다. 키와 값은 모두 문자열이다.\nlist 함수는 항목이 전혀 없는 리스트를 신규로 생성한다. list는 내장함수명이기 때문에 변수명으로 사용하는 것을 피해야 한다.\nlist()는 빈 리스트임을 나타낸다. 리스트에 신규 요소를 추가하기 위해서 list() 함수 내부에 '명칭'='값'과 같이 명칭과 값을 지정한다. 상기 코드는 키(명칭) 'one'에서 값 '하나'를 매핑하는 항목을 생성한다. 명칭을 갖는 리스트를 다시 출력하면, 키-값 페어(key-value pair)를 볼 수 있다.\n다수 키-값을 갖는 명칭을 갖는 리스트를 제작할 경우 순차적으로 작성하고 list()로 감싼다.예를 들어, 세개 항목을 가진 명칭을 갖는 리스트를 생성할 수 있다. eng2kr을 출력하면 다음과 같다.\n명칭을 갖는 리스트에서 키를 사용해서 상응하는 값을 찾을 수 있다.\n'two' 키는 항상 값 '둘'에 상응되어서 명칭을 갖는 리스트 항목 순서는 문제가 되지 않는다. 만약 키가 리스트에 존재하지 않으면, NULL 값을 반환한다. length() 함수를 리스트에 사용하여 키-값 페어(key-value pair) 항목 개수를 파악할 수 있다.\n%in% 연산자는 명칭을 갖는 리스트에 키(Key, 명칭)가 있는지 알려준다. %in% 연산자는 각 항목마다 키(명칭)가 있는지 참/거짓으로 알려주기 때문에 any()와 결합해서 사용하게 되면 리스트에 키가 있는지 없는지만 확인할 때 요긴하다. \\index{%in% 연산자} \\index{연산자!%in%}\n이번에는 리스트에 값이 있는지를 확인해보자. unlist() 함수를 사용해서 값을 얻은 후에 %in% 연산자를 사용해서 값이 있는지를 확인할 수 있다.\n“둘” 값을 갖는 항목이 있는지를 %in% 연산자를 사용해서 확인했다. 조금 확장해서 “둘”, “셋”이 있는지도 없는지도 쉽게 확인할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#r-named-list",
    "href": "14-dictionaries.html#r-named-list",
    "title": "12  딕셔너리",
    "section": "",
    "text": "R\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n\n경고파이썬 딕셔너리\n\n\n\n파이썬 3.7 버전 이전에는 키-값 페어(key-value pair)의 순서가 같지 않다. 사실 동일한 사례를 여러분의 컴퓨터에서 입력하면, 다른 결과를 얻게 된다. 일반적으로, 딕셔너리 항목 순서는 예측 가능하지 않았다. 파이썬 3.7 버전 이후부터는 딕셔너리 항목 순서가 입력한 순서대로 유지된다. 딕셔너리 요소가 정수 인덱스로 색인되지 않아서 문제되지는 않는다. 대신에, 키를 사용해서 항상 상응하는 값을 찾을 수 있다. R 네임드 리스트(named list)는 항상 정의한 순서대로 요소를 유지한다. 리스트에 요소를 추가하면 추가된 순서대로 요소가 유지되며, 이 순서는 변경되지 않는다.\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n12.1.1 연습문제\nwords.txt 단어를 읽어서 명칭을 갖는 리스트에 키로 저장하는 프로그램을 작성한다. 값이 무엇이든지 상관없다. 리스트에 문자열을 확인하는 가장 빠른 방법으로 명칭을 확인할 경우 names() 함수와 값을 확인할 경우 그냥 %in% 연산자와 조합하여 사용할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#named-list-wordlist",
    "href": "14-dictionaries.html#named-list-wordlist",
    "title": "12  딕셔너리",
    "section": "\n12.2 계수기로 리스트 사용하기",
    "text": "12.2 계수기로 리스트 사용하기\n\n문자열이 주어진 상태에서, 각 문자가 얼마나 나타나는지를 센다고 가정한다. 몇 가지 방법이 아래에 있다.\n\n26개 변수를 알파벳 문자 각각에 대해 생성한다. 그리고 나서 아마도 연쇄 조건문을 사용하여 문자열을 훑고 해당 계수기(counter)를 하나씩 증가한다.\n26개 요소를 가진 리스트를 생성한다. 리스트 안에 인덱스로 숫자를 사용해서 적당한 계수기(counter)를 증가한다.\n키(key)로 문자, 계수기(counter)로 해당 값(value)을 갖는 리스트를 생성한다. 처음 문자를 만나면, 딕셔너리에 항목으로 추가한다. 추가한 후에는 기존 항목 값을 증가한다.\n\n상기 3개 옵션은 동일한 연산을 수행하지만, 각각은 다른 방식으로 연산을 구현한다.\n구현(implementation)은 연산(computation)을 수행하는 방법이다. 어떤 구현 방법이 다른 것보다 낫다. 다음에 명칭을 갖는 리스트로 구현한 코드가 있다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n계수기(counter) 혹은 빈도에 대한 통계 용어인 히스토그램(histogram)을 효과적으로 산출할 수 있다. \nfor 루프는 문자열을 훑는다. 매번 루프를 반복할 때마다 리스트에 문자 c가 없다면, 키 c와 초기값 1을 가진 새로운 항목을 생성한다. 문자 c가 이미 리스트에 존재한다면, d[[c]]를 증가한다.\n파이썬 딕셔너리에는 키와 디폴트(default) 값을 갖는 get 메서드가 있다. 딕셔너리에 키가 나타나면, get 메서드는 해당 값을 반환하고, 해당 값이 없으면 지정한 디폴트 값 0 을 반환한다. 예를 들어, counts.get('jan', 0)은 100을 반환하고, counts.get('tim', 0)은 0을 반환한다. 하지만, R에는 이와 같은 기능이 없기 때문에 get_value() 함수를 제작하여 구현한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n히스토그램은 문자 'a', 'b'는 1회, 'o'는 2회 등등 나타남을 보여준다. R은 태생이 통계를 근간으로 하기 때문에 빈도수를 구하거나 하는 문제를 아주 쉽고 간결하게 작성할 수 있다. 앞선 for, if 문을 명칭이 있는 리스트 자료구조를 이용해서 길게 작성했지만, table() 함수를 사용하면 훨씬 간결하게 동일한 효과를 낼 수 있다. 파이썬에 get 메서드를 사용해서 상기 히스토그램 루프를 좀 더 간결하게 작성할 수 있다. get 메서드는 딕셔너리에 키가 존재하지 않는 경우를 자동적으로 다루기 때문에, if문을 없애 4줄을 1줄로 줄일 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n시간을 가지고서 잠시 if 문과 in 연산자를 사용한 루프와 적절한 전처리 과정을 거쳐 자료형을 맞추고 나서 table() 함수를 사용한 방식을 비교해 보세요. 동일한 연산을 수행하지만, 루프를 사용한 방식은 더 많은 코드를 필요로 한다. 파이썬에서도 계수기(counter) 루프를 단순화하려고 get 메서드를 사용하는 것은 파이썬에서 흔히 사용되는 일종의 ’숙어(idiom)’다. if 문과 in 연산자를 사용한 루프와 비교하여 get메서드를 사용한 루프를 비교해 보면 동일한 연산을 수행하지만, 뒷쪽 구현이 코드도 작고 더 간결하다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#named-list-file",
    "href": "14-dictionaries.html#named-list-file",
    "title": "12  딕셔너리",
    "section": "\n12.3 리스트와 파일",
    "text": "12.3 리스트와 파일\n딕셔너리의 흔한 사용법 중의 하나는 텍스트로 작성된 파일에 단어 빈도를 세는 것이다. http://shakespeare.mit.edu/Tragedy/romeoandjuliet/romeo_juliet.2.2.html 사이트 덕분에 로미오와 쥴리엣(Romeo and Juliet) 텍스트 파일에서 시작한다. 처음 연습으로 구두점이 없는 짧고 간략한 텍스트 버전을 사용한다. 나중에 구두점이 포함된 전체 텍스트로 작업할 것이다.\nBut soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n파일 라인을 읽고, 각 라인을 단어 리스트로 쪼개고, 루프를 돌려 사전을 이용하여 각 단어의 빈도수를 세는 R 프로그램을 작성한다.\n두 개의 for 루프를 사용한다. 외곽 루프는 파일 라인을 읽고, 내부 루프는 특정 라인의 단어 각각에 대해 반복한다. 하나의 루프는 외곽 루프가 되고, 또 다른 루프는 내부 루프가 되어서 중첩 루프(nested loops)라고 불리는 패턴 사례다.\n외곽 루프가 한번 반복을 할 때마다 내부 루프는 모든 반복을 수행하기 때문에 내부 루프는 “좀 더 빨리” 반복을 수행하고 외곽 루프는 좀 더 천천히 반복을 수행하는 것으로 생각할 수 있다.\n두 중첩 루프의 조합이 입력 파일의 모든 라인에 있는 모든 단어의 빈도를 계수(count)하는 것을 보증한다.\n중첩루프를 돌려 단어 빈도수를 계산하는 것도 가능하지만 R의 강력한 내장함수를 활용하여 간결하게 다음과 같이 작성할 수도 있다.\n\nromeo_text &lt;- \"But soft what light through yonder window breaks It is the east and Juliet is the sun Arise fair sun and kill the envious moon Who is already sick and pale with grief\"\n\nromeo_split &lt;- stringr::str_split(romeo_text, \" \")[[1]]\n\nromeo_freq &lt;- romeo_split %&gt;% \n  table() %&gt;% \n  unlist()\n\n프로그램을 실행하면, 정렬되지 않은 해시 순서로 모든 단어의 빈도수를 출력한다. romeo.txt 파일은 www.py4inf.com/code/romeo.txt에서 다운로드 가능하다. 다운로드 받은 romeo.txt 파일을 로컬 파일에 저장한 후에 파일명을 읽어 실행하는 코드를 작성하여 실행하면 다음과 같은 결과를 확인할 수 있다.\n이를 위해서 앞서 작성한 코드를 다음과 같이 사용자 입력을 받아 처리할 수 있도록 count1.R 파일에 저장한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 코드를 쉘에서 Rscript 명령어로 실행하게 되면 romeo.txt 파일에 담긴 단어 빈도수를 계산할 수 있게 된다.\n\n$ Rscript --vanilla code/romeo_count.R\n\n파일명을 입력하세요? data/romeo.txt\n#&gt; already     and   Arise  breaks     But    east envious    fair   grief      is\n#&gt;       1       3       1       1       1       1       1       1       1       3\n#&gt;      It  Juliet    kill   light    moon    pale    sick    soft     sun     the\n#&gt;       1       1       1       1       1       1       1       1       2       3\n#&gt; through    what     Who  window    with  yonder\n#&gt;       1       1       1       1       1       1\n\n가장 높은 빈도 단어와 빈도수를 찾기 위해서 리스트를 훑는 것이 불편하다. 좀 더 도움이 되는 출력결과를 만들려고 코드를 바꿔보자.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#named-list-loop",
    "href": "14-dictionaries.html#named-list-loop",
    "title": "12  딕셔너리",
    "section": "\n12.4 반복과 리스트",
    "text": "12.4 반복과 리스트\nfor문에 순서(sequence)로서 리스트를 사용한다면, 리스트 키를 훑는다. 루프는 각 키와 해당 값을 출력한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n이 패턴을 사용해서 앞서 기술한 다양한 루프 숙어를 구현한다. 예를 들어, 리스트에서 10보다 큰 값을 가진 항목을 모두 찾고자 한다면, 다음과 같이 코드를 작성한다. for 루프는 딕셔너리 키(keys)를 반복한다.\n그래서, 인덱스 연산자를 사용해서 각 키에 상응하는 값(value)을 가져와야 한다. 출력값에서 10 이상 값만 가진 항목만 볼 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n알파벳 순으로 키를 출력하고자 한다면, 리스트 객체에서 이름을 따로 추출해서 알파벳순서로 정렬한다. 그리고 이를 리스트 객체에 반영하여 정렬된 명칭이 있는 리스트를 준비한다. 아래와 같이 정렬된 순서로 키/값 페어(key/value pair)를 출력한다. 파이썬 dict_keys 객체는 sort() 메서드가 지원되지 않아서 list() 함수를 사용해서 리스트로 변환한 후 정렬한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n첫 명칭이 있는 리스트는 정렬되지 않은 키 리스트였다면, for 루프로 정렬된 키/값 페어(key/value pair)를 확인할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#named-list-advanced",
    "href": "14-dictionaries.html#named-list-advanced",
    "title": "12  딕셔너리",
    "section": "\n12.5 고급 텍스트 파싱",
    "text": "12.5 고급 텍스트 파싱\n\nromeo.txt 파일을 사용한 상기 예제에서, 수작업으로 모든 구두점을 제거해서 가능한 단순하게 만들었다. 실제 텍스트는 아래 보여지는 것처럼 많은 구두점이 있다.\nBut, soft! what light through yonder window breaks?\nIt is the east, and Juliet is the sun.\nArise, fair sun, and kill the envious moon,\nWho is already sick and pale with grief,\nR stringr 패키지 str_split() 함수는 공백을 찾고 공백으로 구분되는 토큰으로 단어를 처리하기 때문에, “soft!” 와 “soft”는 다른 단어로 처리되고 각 단어에 대해서 별도 딕셔너리 항목을 생성한다.\n파일에 대문자가 있어서, “who”와 “Who”를 다른 단어, 다른 빈도수를 가진 것으로 처리한다.\nstringr 패키지 str_to_lower, str_squish, str_replace_all, 문자열 함수를 사용해서 상기 문제를 해결할 수 있다. str_replace_all 함수가 가장 적합하다. str_replace_all 함수에 대한 문서는 다음과 같다.\n\nstr_replace_all(string, pattern, replacement)\n\npattern 매개변수를 사용해서 모든 구두점을 삭제할 수 있다. “구두점”으로 간주되는 문자 리스트는 [[:punct:]]에 정의되어 있어 별도 ~!@#$%^&*(){}_+:\\\"&lt;&gt;?,./;'[]-=와 같이 지정하지 않아도 된다. replacement에는 삭제 혹은 교체 문자를 지정하면 된다.\n프로그램을 다음과 같이 수정한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_replace_all 함수를 사용해서 모든 구두점을 제거했고, str_to_lower 함수를 사용해서 라인을 소문자로 수정했다. 나머지 프로그램은 변경된 것이 없다.\n상기 프로그램을 실행한 출력결과는 다음과 같다.\n\n$ Rscript.exe code/romeo_parsing.R\n\n파일명을 입력하세요? romeo.txt\n#&gt; already     and   Arise  breaks     But    east envious    fair   grief      is\n#&gt;       1       3       1       1       1       1       1       1       1       3\n#&gt;      It  Juliet    kill   light    moon    pale    sick    soft     sun     the\n#&gt;       1       1       1       1       1       1       1       1       2       3\n#&gt; through    what     Who  window    with  yonder\n#&gt;       1       1       1       1       1       1\n\n출력결과는 여전히 다루기 힘들어 보인다. R 프로그래밍을 통해 정확히 찾고자 하는 것을 찾았으나 R 튜플(tuples)(다양한 자료형을 갖는 리스트)에 대해서 학습할 필요성을 느끼게 한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#r-dicionaries-debugging",
    "href": "14-dictionaries.html#r-dicionaries-debugging",
    "title": "12  딕셔너리",
    "section": "\n12.6 디버깅",
    "text": "12.6 디버깅\n\n점점 더 큰 데이터로 작업함에 따라, 수작업으로 데이터를 확인하거나 출력을 통해서 디버깅을 하는 것이 어려울 수 있다. 큰 데이터를 디버깅하는 몇 가지 방법은 다음과 같다.\n\n\n입력값을 줄여라: Scale down the input\n가능하면, 데이터 크기를 줄여라. 예를 들어, 프로그램이 텍스트 파일을 읽는다면, 첫 10줄로 시작하거나, 찾을 수 있는 작은 예제로 시작하라. 데이터 파일을 편집하거나, 프로그램을 수정해서 첫 n 라인만 읽도록 프로그램을 변경하라.\n오류가 있다면, n을 줄여서 오류를 재현하는 가장 작은 값으로 만들어라. 그리고 나서, 오류를 찾고 수정해 나감에 따라 점진적으로 늘려나가라.\n\n\n요약값과 자료형을 확인하라: Check summaries and types\n전체 데이터를 출력하고 검증하는 대신에 데이터를 요약하여 출력하는 것을 생각하라. 예를 들어, 딕셔너리 항목의 숫자 혹은 리스트 숫자의 총계\n실행 오류(runtime errors)의 일반적인 원인은 올바른 자료형(right type)이 아니기 때문이다. 이런 종류의 오류를 디버깅하기 위해서, 종종 값의 자료형을 출력하는 것으로 충분하다.\n\n\n자가 진단 작성: Write self-checks\n종종 오류를 자동적으로 검출하는 코드를 작성한다. 예를 들어, 리스트 숫자의 평균을 계산한다면, 결과값은 리스트의 가장 큰 값보다 클 수 없고, 가장 작은 값보다 작을 수 없다는 것을 확인할 수 있다. “완전히 비상식적인” 결과를 탐지하기 때문에 “건전성 검사(sanity check)”라고 부른다.\n또 다른 검사법은 두 가지 다른 연산의 결과를 비교해서 일치하는지 살펴보는 것이다. “일치성 검사(consistency check)”라고 부른다. \n\n\n고급 출력: Pretty print the output\n디버깅 출력결과를 서식화하는 것은 오류 발견을 용이하게 한다.\n\n\n다시 한번 강조하면, 발판(scaffolding)을 만드는데 들인 시간이 디버깅에 소비되는 시간을 줄일 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#r-dictionaries-ai",
    "href": "14-dictionaries.html#r-dictionaries-ai",
    "title": "12  딕셔너리",
    "section": "\n12.7 AI와 함께하는 딕셔너리 처리",
    "text": "12.7 AI와 함께하는 딕셔너리 처리\n딕셔너리는 JSON 데이터 처리, API 응답 파싱, 설정 관리 등 실무에서 핵심적인 역할을 한다. AI에게 딕셔너리 관련 작업을 요청할 때는 데이터 구조와 기대 결과를 명확히 전달해야 한다.\n\n12.7.1 명세 작성 패턴\nAI에게 딕셔너리 처리를 요청할 때 포함해야 할 정보:\n\n\n데이터 구조: 키와 값의 타입, 중첩 여부\n\n처리 방식: 조회, 변환, 필터링, 집계\n\nJSON 연계: API 응답 형식, 필요한 필드\n\n12.7.2 프롬프트 예시\nJSON 데이터 파싱\n\n다음 JSON API 응답에서 사용자 이름과 이메일만 추출하는 R/Python 함수를 작성해줘.\n{\"users\": [{\"id\": 1, \"name\": \"홍길동\", \"email\": \"hong@test.com\", \"age\": 30}, ...]}\n출력: [{\"name\": \"홍길동\", \"email\": \"hong@test.com\"}, ...]\n조건: users 배열이 비어있으면 빈 리스트 반환\n\n단어 빈도 계산\n\n텍스트 파일에서 단어 빈도를 계산하고 상위 10개를 반환하는 함수가 필요해.\n조건: - 대소문자 구분 없음 - 구두점 제거 - 결과: [(\"the\", 45), (\"and\", 32), ...] 형식\n입력: 텍스트 파일 경로\n출력: 튜플 리스트 (단어, 빈도)\n\n설정 파일 처리\n\nYAML 설정 파일을 읽어서 특정 섹션의 값을 업데이트하는 함수를 작성해줘.\n입력: - 파일 경로 - 섹션 이름 (예: “database”) - 업데이트할 키-값 쌍\n조건: 섹션이 없으면 새로 생성\n\n중첩 딕셔너리 평탄화\n\n중첩된 딕셔너리를 평탄한 딕셔너리로 변환해줘.\n입력: {\"user\": {\"name\": \"홍길동\", \"address\": {\"city\": \"서울\"}}}\n출력: {\"user.name\": \"홍길동\", \"user.address.city\": \"서울\"}\n\n이처럼 실제 데이터 구조 예시와 기대 출력 형식을 제공하면, AI가 정확한 딕셔너리 조작 코드를 생성한다. 앞서 배운 키-값 접근, 루프 순회, 중첩 구조 개념을 알고 있으면 생성된 코드를 쉽게 검증할 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#r-dictionaries-terminology",
    "href": "14-dictionaries.html#r-dictionaries-terminology",
    "title": "12  딕셔너리",
    "section": "\n12.8 용어 정의",
    "text": "12.8 용어 정의\n\n\n명칭있는 리스트/딕셔너리(dictionary): 키(key)에서 해당 값으로 매핑(mapping) \n\n해시테이블(hashtable): 파이썬 딕셔너리를 구현하기 위해 사용된 알고리즘 \n\n해시 함수(hash function): 키에 대한 위치를 계산하기 위해서 해시테이블에서 사용되는 함수 \n\n히스토그램(histogram): 계수기(counter) 집합. \n\n\n구현(implementation): 연산(computation)을 수행하는 방법 \n\n항목(item): 키-값 페어(key-value pair)에 대한 또 다른 이름. \n\n키(key): 키-값 페어(key-value pair)의 첫 번째 부분으로 딕셔너리에 나타나는 객체. \n\n키-값 페어(key-value pair): 키에서 값으로 매핑 표현. \n\n룩업(lookup): 키를 가지고 해당 값을 찾는 딕셔너리 연산. \n\n중첩 루프(nested loops): 루프 “내부”에 하나 혹은 그 이상의 루프가 있음. 외곽 루프가 1회 실행될 때, 내부 루프는 전체 반복을 완료함. \n\n값(value):키-값 페어(key-value pair)의 두 번째 부분으로 딕셔너리에 나타나는 객체. 앞에서 사용한 단어 “값(value)”보다 더 구체적이다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "14-dictionaries.html#r-dictionaries-ex",
    "href": "14-dictionaries.html#r-dictionaries-ex",
    "title": "12  딕셔너리",
    "section": "연습문제",
    "text": "연습문제\n\n커밋(commit)이 무슨 요일에 수행되었는지에 따라 전자우편 메시지를 구분하는 프로그램을 작성하세요. “From”으로 시작하는 라인을 찾고, 3번째 단어를 찾아서 요일별 횟수를 계수(count)하여 저장하세요. 프로그램 끝에 딕셔너리 내용을 출력하세요. (순서는 문제가 되지 않습니다.)\n\n라인 예시:\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n\n실행 예시:\nRscript --vanilla dow.R\n파일명을 입력하세요: mbox-short.txt\n{'Fri': 20, 'Thu': 6, 'Sat': 1}\n\n전자우편 로그(log)를 읽고, 히스토그램을 생성하는 프로그램을 작성하세요. 딕셔너리를 사용해서 전자우편 주소별로 얼마나 많은 전자우편이 왔는지를 계수(count)하고 딕셔너리를 출력합니다.\n\n파일명을 입력하세요: mbox-short.txt\n{'gopal.ramasammycook@gmail.com': 1, 'louis@media.berkeley.edu': 3, \n'cwen@iupui.edu': 5, 'antranig@caret.cam.ac.uk': 1, \n'rjlowe@iupui.edu': 2, 'gsilver@umich.edu': 3, \n'david.horwitz@uct.ac.za': 4, 'wagnermr@iupui.edu': 1, \n'zqian@umich.edu': 4, 'stephen.marquard@uct.ac.za': 2, \n'ray@media.berkeley.edu': 1}\n\n상기 프로그램에 누가 가장 많은 전자우편 메시지를 가졌는지 알아내는 코드를 추가한다.\n\n결국, 모든 데이터를 읽고, 딕셔너리를 생성한다. 최대 루프를 사용해서 딕셔너리를 훑어서 누가 가장 많은 전자우편 메시지를 갖는지, 그리고 그 사람이 얼마나 많은 메시지를 갖는지 출력한다.\n파일명을 입력하세요: mbox-short.txt\ncwen@iupui.edu 5\n\n파일명을 입력하세요: mbox.txt\nzqian@umich.edu 195\n\n다음 프로그램은 주소 대신에 도메인 이름을 기록한다. 누가 메일을 보냈는지 대신(즉, 전체 전자우편 주소) 메시지가 어디에서부터 왔는지 출처를 기록한다. 프로그램 마지막에 딕셔너리 내용을 출력한다.\n\nRscript --vanilla schoolcount.R\n파일명을 입력하세요: mbox-short.txt\n{'media.berkeley.edu': 4, 'uct.ac.za': 6, 'umich.edu': 7, \n'gmail.com': 1, 'caret.cam.ac.uk': 1, 'iupui.edu': 8}",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>딕셔너리</span>"
    ]
  },
  {
    "objectID": "15-tuples.html",
    "href": "15-tuples.html",
    "title": "13  튜플(Tuples)",
    "section": "",
    "text": "13.1 튜플은 불변이다\n여러 값을 묶어서 하나의 단위로 다루는 것은 프로그래밍의 기본이다. 파이썬에서는 불변성을 가진 튜플이 이 역할을 하고, R에서는 다양한 자료형을 담을 수 있는 리스트가 유사한 역할을 한다. 함수에서 여러 값을 반환하거나, 정렬을 위해 키-값 쌍을 만들거나, 데이터를 그룹화할 때 이런 복합 자료구조가 필요하다.\n이 장에서 다루는 패턴을 이해하면, AI에게 “빈도순으로 정렬해줘”, “여러 값을 묶어서 반환해줘”와 같은 요청을 할 때 기대하는 결과를 정확히 전달할 수 있다.\n다양한 자료형을 갖는 리스트가 튜플(tuple)이다. 튜플(tuple)[^about-tuple]은 리스트와 마찬가지로 순서(sequence) 값이다. 튜플에 저장된 값은 임의 자료형(type)이 될 수 있고, 정수로 색인 된다. 일반적으로 알려진 튜플은 불변(immutable하다는 것이다. 튜플은 비교 가능(comparable)하고 해쉬형(hashable)이다. 따라서, 리스트 값을 정렬할 수 있고, 키 값으로 튜플을 사용할 수 있다.\n[^about-tuple] : 재미난 사실: 단어 ‘’튜플(tuple)’’은 가변 길이 (한배, 두배, 세배, 네배, 다섯배, 여섯배, 일곱배 등) 숫자열에 붙여진 이름에서 유래한다\n구문론적으로, 튜플은 콤마로 구분되는 서로 다른 자료형을 갖는 리스트 값이다.\nt &lt;- list('a', 'b', 'c', 'd', 'e')\n튜플(tuple)이 생성자 이름이기 list이기 때문에 변수명으로 리스트(list) 사용을 피해야 한다.\n대부분의 리스트 연산자는 튜플에서도 사용 가능하다. 꺾쇠 연산자가 요소를 색인한다.\nt[1]\n#&gt; [[1]]\n#&gt; [1] \"a\"\n그리고, 슬라이스 연산자(slice operator)는 요소 범위를 선택한다.\nt[2:3]\n#&gt; [[1]]\n#&gt; [1] \"b\"\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"c\"\n하지만, 파이썬 튜플 요소 중 하나를 변경하고 하면 오류가 발생하지만, R에서 리스트는 다양한 자료형을 담을 수 있고 변경도 가능하다.\nt[1] &lt;- 'A'\nt\n#&gt; [[1]]\n#&gt; [1] \"A\"\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"b\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] \"c\"\n#&gt; \n#&gt; [[4]]\n#&gt; [1] \"d\"\n#&gt; \n#&gt; [[5]]\n#&gt; [1] \"e\"",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#tuple-frequency",
    "href": "15-tuples.html#tuple-frequency",
    "title": "13  튜플(Tuples)",
    "section": "\n13.2 가장 빈도수 높은 단어",
    "text": "13.2 가장 빈도수 높은 단어\n로미오와 쥴리엣 2장 2막 텍스트 파일(romeo-full.txt)로 다시 돌아와서, 텍스트에서 가장 빈도수가 높은 단어를 10개를 출력하는 프로그램을 작성한다.\n\nlibrary(tidyverse)\n\nromeo_text &lt;- readr::read_lines(\"data/romeo-full.txt\")\n\nromeo_split &lt;- stringr::str_split(romeo_text, \" \") %&gt;%\n  unlist() %&gt;%\n  stringr::str_to_lower() %&gt;%\n  stringr::str_replace_all(., pattern = \"[[:punct:]]\",\n                           replacement = \"\")\n\nromeo_split &lt;- romeo_split[romeo_split != \"\"]\n\nromeo_full_freq &lt;- romeo_split %&gt;% unlist() %&gt;%\n  table() %&gt;%\n  as_tibble() %&gt;% \n  set_names(c(\"key\", \"value\")) %&gt;% \n  arrange(desc(value)) %&gt;% \n  slice_head(n=10)\n\n# romeo_full_freq\n\n파일을 읽고 각 단어를 문서의 단어 빈도수는 전처리 로직으로 구두점을 제거하고 모두 소문자로 변환한 후에 table() 함수로 단어별 빈도수를 계산하고 데이터프레임으로 변환 후 고빈도 단어 10개를 추출한다.\n이제 단어 빈도 분석을 위해서 작성한 프로그램의 마지막 출력결과는 원하는 바를 완수한 것처럼 보인다.\n\n#&gt; # A tibble: 10 × 2\n#&gt;   key   value\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 that     14\n#&gt; 2 is       13\n#&gt; 3 her      11\n#&gt; 4 the      11\n#&gt; 5 and      10\n#&gt; 6 she       9\n#&gt; # ℹ 4 more rows",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#tuple-sequences",
    "href": "15-tuples.html#tuple-sequences",
    "title": "13  튜플(Tuples)",
    "section": "\n13.3 순열: 문자열, 리스트, 튜플",
    "text": "13.3 순열: 문자열, 리스트, 튜플\n여기서 리스트 튜플에 초점을 맞추었지만, 이장의 거의 모든 예제가 또한 리스트의 리스트, 튜플의 튜플, 리스트 튜플에도 동작한다. 가능한 모든 조합을 열거하는 것을 피하기 위해서, 순열의 순열(sequences of sequences)에 대해서 논의하는 것이 때로는 쉽다.\n대부분의 문맥에서 다른 종류의 순열(문자열, 리스트, 튜플)은 상호 호환해서 사용될 수 있다. 그런데 왜 그리고 어떻게 다른 것보다 이것을 선택해야 될까?\n서로 다른 자료형이 갖는 특징을 잘 파악하고 주어진 문제를 가장 쉽게 풀수 있는 방향의 자료형을 선택한다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#tuple-debugging",
    "href": "15-tuples.html#tuple-debugging",
    "title": "13  튜플(Tuples)",
    "section": "\n13.4 디버깅",
    "text": "13.4 디버깅\n리스트, 딕셔너리, 튜플은 자료 구조(data structures)로 일반적으로 알려져 있다. 이번장에서 리스트 튜플, 키로 튜플, 값으로 리스트를 담고 있는 딕셔너리 같은 복합 자료 구조를 보기 시작했다. 복합 자료 구조는 유용하지만, 저자가 작명한 형태 오류(shape errors)라고 불리는 오류에 노출되어 있다. 즉, 자료 구조가 잘못된 자료형(type), 크기, 구성일 경우 오류가 발생한다. 혹은 코드를 작성하고, 자료의 모양이 생각나지 않는 경우도 오류의 원인이 된다.\n예를 들어, 정수 하나를 가진 리스트를 기대하고, (리스트가 아닌) 일반 정수를 넘긴다면, 작동하지 않는다.\n프로그램을 디버깅할 때, 정말 어려운 버그를 잡으려고 작업을 한다면, 다음 네가지를 시도할 수 있다.\n\n코드 읽기(reading): 코드를 면밀히 조사하고, 스스로에게 다시 읽어 주고, 코드가 자신이 작성한 의도를 담고 있는지 점검하라.\n실행(running): 변경해서 다른 버젼을 실행해서 실험하라. 종종, 프로그램이 적절한 곳에 적절한 것을 보여준다면, 문제가 명확하다. 발판(scaffolding)을 만들기 위해서 때때로 시간을 들일 필요도 있다.\n반추(ruminating):생각의 시간을 갖자. 어떤 종류의 오류인가: 구문, 실행, 의미론(semantic). 오류 메시지로부터 혹은 프로그램 출력결과로부터 무슨 정보를 얻을 수 있는가? 어떤 종류 오류가 지금 보고 있는 문제를 만들었을까? 문제가 나타나기 전에, 마지막으로 변경한 것은 무엇인가?\n퇴각(retreating): 어느 시점에선가, 최선은 물러서서, 최근의 변경을 다시 원복하는 것이다. 잘 동작하고 이해하는 프로그램으로 다시 돌아가서, 다시 프로그램을 작성한다.\n\n초보 프로그래머는 종종 이들 활동 중 하나에 사로잡혀 다른 것을 잊곤 한다. 활동 각각은 고유한 실패 방식과 함께 온다.\n예를 들어, 프로그램을 정독하는 것은 문제가 인쇄상의 오류에 있다면 도움이 되지만, 문제가 개념상 오해에 뿌리를 두고 있다면 그다지 도움이 되지 못한다. 만약 작성한 프로그램을 이해하지 못한다면, 100번 읽을 수는 있지만, 오류를 발견할 수는 없다. 왜냐하면, 오류는 여러분 머리에 있기 때문입니다.\n만약 작고 간단한 테스트를 진행한다면, 실험을 수행하는 것이 도움이 될 수 있다. 하지만, 코드를 읽지 않거나, 생각없이 실험을 수행한다면, 프로그램이 작동될 때까지 무작위 변경하여 개발하는 “랜덤 워크 프로그램(random walk programming)” 패턴에 빠질 수 있다. 말할 필요없이 랜덤 워크 프로그래밍은 시간이 오래 걸린다.\n생각할 시간을 가져야 한다. 디버깅은 실험 과학 같은 것이다. 문제가 무엇인지에 대한 최소한 한 가지 가설을 가져야 한다. 만약 두개 혹은 그 이상의 가능성이 있다면, 이러한 가능성 중에서 하나라도 줄일 수 있는 테스트를 생각해야 한다.\n휴식 시간을 가지는 것은 생각하는데 도움이 된다. 대화를 하는 것도 도움이 된다. 문제를 다른 사람 혹은 자신에게도 설명할 수 있다면, 질문을 마치기도 전에 답을 종종 발견할 수 있다.\n하지만, 오류가 너무 많고 수정하려는 코드가 매우 크고, 복잡하다면 최고의 디버깅 기술도 무용지물이다. 가끔, 최선의 선택은 퇴각하는 것이다. 작동하고 이해하는 곳까지 후퇴해서 프로그램을 간략화하라.\n초보 프로그래머는 종종 퇴각하기를 꺼려한다. 왜냐하면, 설사 잘못되었지만, 한줄 코드를 지울 수 없기 때문이다. 삭제하지 않는 것이 기분을 좋게 한다면, 다시 작성하기 전에 프로그램을 다른 파일에 복사하라. 그리고 나서, 한번에 조금씩 붙여넣어라.\n정말 어려운 버그(hard bug)를 발견하고 고치는 것은 코드 읽기, 실행, 반추, 때때로 퇴각을 요구한다. 만약 이들 활동 중 하나도 먹히지 않는다면, 다른 것들을 시도해 보세요.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#r-tuple-ai",
    "href": "15-tuples.html#r-tuple-ai",
    "title": "13  튜플(Tuples)",
    "section": "\n13.5 AI와 함께하는 복합 자료구조 처리",
    "text": "13.5 AI와 함께하는 복합 자료구조 처리\n복합 자료구조(튜플, 리스트의 리스트 등)는 빈도 분석, 정렬, 그룹화 등 다양한 작업에 활용된다. AI에게 이런 작업을 요청할 때는 데이터의 구조와 기대하는 출력 형태를 명확히 전달한다.\n\n13.5.1 명세 작성 패턴\nAI에게 복합 자료구조 처리를 요청할 때 포함해야 할 정보:\n\n\n입력 구조: 데이터의 형태 (리스트, 딕셔너리, 중첩 구조)\n\n처리 방식: 정렬 기준, 그룹화 방법, 집계 함수\n\n출력 형태: 튜플 리스트, 딕셔너리, 데이터프레임 등\n\n13.5.2 프롬프트 예시\n빈도 기반 정렬\n\n텍스트에서 단어 빈도를 계산하고 빈도순으로 내림차순 정렬해줘.\n입력: 텍스트 문자열 또는 파일\n출력: [(\"the\", 45), (\"and\", 32), (\"is\", 28), ...]\n조건: - 대소문자 무시 - 구두점 제거 - 상위 N개만 반환\n\n다중 값 반환\n\n리스트의 통계값(최소, 최대, 평균, 중앙값)을 한 번에 계산해서 반환하는 함수를 작성해줘.\n입력: 숫자 리스트 [1, 2, 3, 4, 5]\n출력: 명명된 리스트 list(min=1, max=5, mean=3, median=3)\n\n복합 키 정렬\n\n학생 정보 리스트를 학년순, 같은 학년 내에서는 점수 내림차순으로 정렬해줘.\n입력: [{\"name\": \"홍길동\", \"grade\": 3, \"score\": 85}, ...]\n출력: 정렬된 리스트\n\n이처럼 복합 자료구조 작업을 명세할 때는 정렬 기준이나 그룹화 방법을 구체적으로 제시하면 AI가 정확한 코드를 생성한다. DSU(Decorate-Sort-Undecorate) 패턴이나 다중 키 정렬 같은 개념을 알고 있으면 결과 검증도 수월하다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#r-tuple-terminology",
    "href": "15-tuples.html#r-tuple-terminology",
    "title": "13  튜플(Tuples)",
    "section": "\n13.6 용어정의",
    "text": "13.6 용어정의\n\n\n비교가능한(comparable):동일한 자료형의 다른 값과 비교하여 큰지, 작은지, 혹은 같은지를 확인하기 위해서 확인할 수 있는 자료형(type). 비교가능한(comparable) 자료형은 리스트에 넣어서 정렬할 수 있다.\n\n자료 구조(data structure):연관된 값의 집합, 종종 리스트, 딕셔너리, 튜플 등으로 조직화된다.\n\nDSU: “decorate-sort-undecorate,”의 약어로 리스트 튜플을 생성, 정렬, 결과 일부 추출을 포함하는 패턴.\n\n모음(gather): 가변-길이 인자 튜플을 조합하는 연산.\n\n해쉬형(hashable): 해쉬 함수를 가진 자료형(type). 정수, 소수점, 문자열 같은 불변형은 해쉬형이다. 리스트나 딕셔너리 처럼 변경가능한 형은 해쉬형이 아니다.\n\n스캐터(scatter): 순서(sequence)를 리스트 인자로 다루는 연산.\n\n(자료 구조의) 형태: 자료 구조의 자료형(type), 크기, 구성을 요약.\n\n싱글톤(singleton): 단일 요소를 가진 리스트 (혹은 다른 순서(sequence)).\n\n튜플(tuple): 불변 요소들의 순서 (sequence).\n\n튜플 대입(tuple assignment): 오른편 순서(sequence)와 왼편 튜플 변수를 대입. 오른편이 평가되고나서 각 요소들은 왼편의 변수에 대입된다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "15-tuples.html#tuple-ex",
    "href": "15-tuples.html#tuple-ex",
    "title": "13  튜플(Tuples)",
    "section": "\n13.7 연습문제",
    "text": "13.7 연습문제\n\n앞서 작성한 프로그램을 다음과 같이 수정하세요. “From”라인을 읽고 파싱하여 라인에서 주소를 뽑아내세요. 딕셔너리를 사용하여 각 사람으로부터 메시지 숫자를 계수(count)한다.\n모든 데이터를 읽은 후에 가장 많은 커밋(commit)을 한 사람을 출력하세요. 딕셔너리로부터 리스트 (count, email) 튜플을 생성하고 역순으로 리스트를 정렬한 후에 가장 많은 커밋을 한 사람을 출력하세요.\n\n    Sample Line:\n    From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n\n    Enter a file name: mbox-short.txt\n    cwen@iupui.edu 5\n\n    Enter a file name: mbox.txt\n    zqian@umich.edu 195\n\n이번 프로그램은 각 메시지에 대한 하루 중 시간의 분포를 계수(count)한다. “From” 라인으로부터 시간 문자열을 찾고 콜론(:) 문자를 사용하여 문자열을 쪼개서 시간을 추출합니다. 각 시간별로 계수(count)를 누적하고 아래에 보여지듯이 시간 단위로 정렬하여 한 라인에 한시간씩 계수(count)를 출력합니다.\n\n    Sample Execution:\n    Rscript timeofday.R\n    Enter a file name: mbox-short.txt\n    04 3\n    06 1\n    07 1\n    09 2\n    10 3\n    11 6\n    14 1\n    15 2\n    16 4\n    17 2\n    18 1\n    19 1\n\n파일을 읽고, 빈도(frequencey)에 따라 내림차순으로 문자(letters)를 출력하는 프로그램을 작성하세요. 작성한 프로그램은 모든 입력을 소문자로 변환하고 a-z 문자만 계수(count)한다. 공백, 숫자, 문장기호 a-z를 제외한 다른 어떤 것도 계수하지 않습니다. 다른 언어로 구성된 텍스트 샘플을 구해서 언어마다 문자 빈도가 어떻게 변하는지 살펴보세요. 결과를 wikipedia.org/wiki/Letter_frequencies 표와 비교하세요.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>튜플(Tuples)</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html",
    "href": "16-dataframe.html",
    "title": "14  데이터프레임",
    "section": "",
    "text": "14.1 측정 변수의 구분\n데이터 분석에서 가장 중요한 자료구조가 데이터프레임이다. CSV 파일, 데이터베이스 쿼리 결과, 엑셀 시트 등 거의 모든 표 형식 데이터가 데이터프레임으로 표현된다. R에서는 data.frame과 tibble, Python에서는 pandas.DataFrame이 이 역할을 한다.\n데이터프레임의 구조와 조작 방법을 이해하면, AI에게 “특정 조건을 만족하는 행을 필터링해줘”, “그룹별 평균을 계산해줘”, “두 데이터프레임을 조인해줘”와 같은 데이터 처리 요청을 명확하게 전달할 수 있다.\n다른 프로그래밍 언어에서 다루지 않는 독특한 자료구조가 데이터프레임(Dataframe)이다. R도 프로그래밍 언어이기 때문에 다른 언어에서 갖고 있는 자료구조를 대부분 갖추고 있지만, 데이터 분석, 시각화, 모형 개발 등에 꼭 필요한 기본 자료구조가 데이터프레임이다. 데이터프레임을 본격적으로 살펴보기 전에 통계학에서 다루는 측정에 대해 살펴보고, 측정 척도(scale)에 대한 이론적 배경을 이해한다. 척도의 개념에 대응되는 R 자료구조를 통해 데이터프레임과 추후 프로그래밍 과정에서 많이 다뤄지는 리스트에 대한 차별점도 살펴본다.\n분석 과정에서 현실 세계의 다양한 사건과 현상들을 관찰하고, 이후 측정 단계를 거쳐 수치나 범주 형태로 자료, 즉 데이터로 생산된다. 이는 복잡한 실제 현상들을 체계적이고 구조화된 데이터로 전환하는 과정으로, 이러한 데이터 분석 과정에서 컴퓨터 활용이 중요하다. 프로그래밍 언어들마다 데이터를 처리하고 관리하기 위한 고유한 자료구조를 가지고 있다. 측정 단계에서 생산된 다양한 데이터를 담아낼 수 있는 자료구조가 데이터프레임이다.\n자료의 고유 특성을 수치화하는 측정 척도로 명목형, 순서형, 구간형, 비율형 4가지 주요 유형으로 분류된다. 측정 척도는 데이터 유형별로 적합한 유의미한 통계량을 결정하는 데 중요한 역할을 한다. [1] [2] [3]",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#data-type-for-data-science",
    "href": "16-dataframe.html#data-type-for-data-science",
    "title": "14  데이터프레임",
    "section": "",
    "text": "명목척도(Nominal): 단순히 개체 특성 분류를 위해 숫자나 부호를 부여한 척도로 숫자는 의미가 없음.\n\n남자: M, 여자: F 혹은 월: 1, 화: 2, … 일:7 혹은 갑:1, 을:2, 병:3, …\n\n\n서열척도(Ordinal): 명목척도에 부가적으로 “순서(서열)” 정보가 추가된 척도로 측정대상 간 차이는 정보가 없음.\n\n군대계급: 사병, 장교, 장군 등\n소득계층: 1분위, 2분위, 3분위 등\n\n\n등간척도(Interval): 서열척도에 부가적으로 “등간격” 정보가 추가된 척도\n\n온도에서 0도는 상대적인 위치로 수학에서 다루는 개념과 차이가 있음.\n온도가 서울 10도, 제주 20도는 제주가 서울보다 온도가 2배 높지 않음.\n온도, 시력, IQ 지수, 물가지수 등\n\n\n비율척도(Ratio): 구간척도에 “비율” 비교특성이 추가된 척도로 “비율 등간격” 특성이 포함됨.\n\n키나 몸무게에서 0은 수학적 의미 0을 의미함.\n100m는 200m의 절반 의미.\n절대 ’0’을 가지고 사칙연산이 가능함.\n연령, 월소득, TV 시청률 등.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#data-type-basics",
    "href": "16-dataframe.html#data-type-basics",
    "title": "14  데이터프레임",
    "section": "\n14.2 기본 자료구조",
    "text": "14.2 기본 자료구조\n\n측정은 한 번만 이뤄지는 것이 아닌 여러 관측점을 통해 데이터로 표현되기 때문에 이를 담을 수 있는 벡터 자료구조가 필요하다. R 언어에서 벡터 자료형을 주로 원자 벡터와 리스트로 분류한다. 원자 벡터는 논리형(logical), 정수형(integer), 부동 소수점형(double), 문자형(character), 복소수형(complex), raw 등 여섯 가지 자료형을 포함하며, 이중 논리형, 정수형, 부동 소수점형, 문자형이 주로 사용된다. 리스트는 다양한 자료형을 포함할 수 있는 재귀 벡터(recursive vector)로, 복잡한 데이터 구조를 효과적으로 다루는 데 적합하다.[4]\nR에서 자료형을 type, mode, storage mode로 다르게 표현하는데 데이터 객체의 다양한 측면을 표현하기 위함이다. 자료형(type)은 객체의 내부적인 구현 유형을 표현한다. 예를 들어, 정수형, 부동 소수점형, 문자형을 들 수 있다. 모드(mode)는 객체가 프로그래밍적으로 어떻게 다뤄지는지를 나타내며, type보다 더 일반적인 개념으로 사용자 관점에서 데이터를 어떻게 사용할 수 있는지를 나타낸다. 예를 들어, 자료형이 정수형 혹은 부동 소수점형은 사용자 모드에서 숫자형(numeric)이 훨씬 수월하다. 저장 모드(storage mode)는 객체가 저장되는 방식을 나타내며, 특히 벡터의 경우에는 벡터의 원소 유형을 의미한다. 예를 들어, 정수 벡터 storage mode는 integer가 된다. \n\n자료형, 사용자 모드, 저장 모드 비교표\n\n자료형(Type)\n사용자 모드(Mode)\n저장모드(Storage Mode)\n\n\n\nlogical\nlogical\nlogical\n\n\ninteger\nnumeric\ninteger\n\n\ndouble\nnumeric\ndouble\n\n\ncomplex\ncomplex\ncomplex\n\n\ncharacter\ncharacter\ncharacter\n\n\nraw\nraw\nraw\n\n\n\n따라서, 원자벡터는 동질적(homogeneous)이고, 리스트는 상대적으로 이질적(heterogeneous)이다. 모든 벡터는 두 가지 성질(Property)을 갖는데, 자료형과 길이로 이를 확인하는 데 typeof()와 length() 함수를 사용해서 확인한다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n모드 함수는 객체의 모드를 반환하고, 클래스 함수는 클래스를 반환한다. 가장 흔하게 만나는 객체 모드는 숫자, 문자, 논리 모드다. 리스트나 데이터프레임과 같이 다양한 모드를 한 객체 안에 포함하는 경우도 있다.\n리스트(List)는 데이터를 저장하는 유연하며 강력한 방법으로 과거 리스트 자료구조를 처리하는 *apply 함수와 함께 가장 빈번하게 사용되는 자료형이다. 현재는 purrr 팩키지 map_*()함수를 사용한다. 리스트형 자료 a를 세 가지 숫자형, 문자형, 숫자형과 리스트 총 네 가지 자료형을 포함하게 작성한다. map_chr() 함수를 이용하여 mode와 class 인자를 넣어줌으로써, 각각 자료형의 모드와 자료형을 확인한다. \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n리스트에서 원소를 뽑아내는 의미를 살펴보자. 시각적으로 표현하면 다음과 같다. 리스트는 이질적인 객체를 담을 수 있다는 점에서 동질적인 것만 담을 수 있어 한계가 있는 원자벡터보다 쓰임새가 다르다. 회귀분석 결과 산출되는 lm 결과값은 다양한 정보를 담을 수 있는 리스트로 표현된다.\n\n리스트 생성 : list()\n\n하위 리스트 추출 : [\n\n리스트에 담긴 원소값 추출 : [[, $ → 연산작업을 통해 위계를 갖는 구조를 제거한다.\n\n\n\n리스트 원소 1개\n리스트 원소 2개\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\n그림 14.1: 리스트에서 하위 리스트 뽑아내기 - 출처: 해들리 위컴\n\n\n범주형 자료를 R에 저장하기 위해서 요인(Factor) 클래스를 사용하며 요인 클래스를 사용하여 자료를 저장할 경우 저장 공간을 절약할 수 있다. 요인은 내부적으로 숫자(value)로 저장을 하고 레이블(value label)을 사용하여 표시하여 저장 공간을 절약한다. \n\n\n\n\n\n\n노트자료형 확인\n\n\n\n각각의 데이터 형식에 맞는지를 다양한 테스트 함수(is.)를 이용하여 데이터 형식을 확인할 수 있다.\n\n\nis.list : 리스트 형식인 확인\n\nis.factor : 팩터 형식인지 확인\n\nis.numeric : 숫자형인지 확인\n\nis.data.frame : 데이터 프레임형인지 확인\n\nis.character : 문자형인지 확인",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#extended-data-type",
    "href": "16-dataframe.html#extended-data-type",
    "title": "14  데이터프레임",
    "section": "\n14.3 자료형 확장",
    "text": "14.3 자료형 확장\n요인, 텍스트, 날짜와 시간도 R에서 자주 사용되는 중요한 데이터 자료형으로 별도로 다뤄진다. 이를 위해서 stringr, lubridate, forcats 팩키지를 사용해서 데이터 정제 작업은 물론 기계학습 예측모형 개발에 활용한다.\n\n\n데이터 과학 중요 자료구조\n\n\n\nR 자료형\n자료형\n예제\n\n\n\nlogical\n부울\n부도여부(Y/N), 남여\n\n\ninteger\n정수\n코로나19 감염자수\n\n\nfactor\n범주\n정당, 색상\n\n\nnumeric\n실수\n키, 몸무게, 주가, 환율\n\n\ncharacter\n텍스트\n주소, 이름, 책제목\n\n\nDate\n날짜\n생일, 투표일",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#data-type-factor",
    "href": "16-dataframe.html#data-type-factor",
    "title": "14  데이터프레임",
    "section": "\n14.4 범주 자료형",
    "text": "14.4 범주 자료형\n명목척도 범주형, 서열척도 범주 자료형을 생성하는 경우 주의를 기울여야 한다. factor 함수를 사용해서 요인형 자료형을 생성하는데, 내부적으로 저장 공간을 효율적으로 사용하고 속도를 빠르게 하는 데 유용하다. 순서를 갖는 범주형의 경우 factor 함수 내부에 levels 인자를 넣어 정의하면 순서 정보가 유지된다. \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n범주형 자료의 경우 범주가 갖는 척도 가독성을 높이기 위해 levels() 함수를 사용하기도 한다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n통계 처리와 자료분석에 문자형 벡터와 요인 범주형 벡터를 다른 의미를 갖는 점에 유의한다. 동일한 summary() 함수지만 입력 자료형에 따라 R은 적절한 후속 작업을 자동으로 수행한다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#data-type-dataframe-in-r",
    "href": "16-dataframe.html#data-type-dataframe-in-r",
    "title": "14  데이터프레임",
    "section": "\n14.5 데이터프레임",
    "text": "14.5 데이터프레임\nR은 6가지 기본 벡터로 자료를 저장하지만, 이외에 행렬(matrix), 데이터프레임(data.frame), 리스트(list) 자료구조가 있다. 하지만, 자료분석을 위해서 데이터를 데이터셋의 형태로 구성해야 한다. 데이터셋이 중요한 이유는 자료를 분석하기 위해서 다양한 형태의 개별 자료를 통합적으로 분석하기 위해서다. 이를 위해서 리스트 자료구조로 일단 모으게 된다. 예를 들어 개인 신용분석을 위해서는 개인의 소득, 부채, 성별, 학력 등등의 숫자형, 문자형, 요인(Factor)형 등의 자료를 데이터셋에 담아야 한다. 특히 변수와-관측값(Variable-Observation) 형식의 자료를 분석하기 위해서는 데이터프레임(data.frame)을 사용한다. 데이터프레임은 모든 변수에 대해서 관측값이 같은 길이를 갖도록 만들어 놓은 것이다. \n\n\n리스트와 데이터프레임\n\n데이터프레임은 data.frame() 함수를 사용해서 생성한다. R 객체 구조 파악을 위해서는 간단한 자료의 경우 데이터 형식을 확인할 수 있는 1–2줄 정도의 간단한 스크립트와 명령어를 통해서 확인이 가능하지만, 복잡한 데이터의 구조를 파악하기 위해서는 summary 함수와 str 함수를 통해서 확인해야 한다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#data-type-vector",
    "href": "16-dataframe.html#data-type-vector",
    "title": "14  데이터프레임",
    "section": "\n14.6 벡터, 행렬, 배열, 데이터프레임",
    "text": "14.6 벡터, 행렬, 배열, 데이터프레임\n가장 많이 사용되는 논리형, 문자형, 숫자형을 통해 자료분석 및 모형개발을 진행하게 되고, 경우에 따라서 동일한 자료형을 모은 경우 이를 행렬로 표현할 수 있고, 행렬을 모아 RGB 시각 데이터를 위한 배열(Array)로 표현한다. 데이터프레임은 서로 다른 자료형을 모아 넣은 것이다. \n\n\nR 자료구조 - 벡터, 행렬, 배열, 데이터프레임",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#is-na-null",
    "href": "16-dataframe.html#is-na-null",
    "title": "14  데이터프레임",
    "section": "\n14.7 NULL과 NA\n",
    "text": "14.7 NULL과 NA\n\n결측되었다는 없다는 것을 표시하는 방법이 두 가지 필요하다. 하나는 벡터가 없다는 NULL이고, 벡터 내부에 값이 결측되었다는 NA다. dataframe$variable &lt;- NULL 명령문을 사용하면 데이터프레임(dataframe)에 변수(variable)를 날려보내는 효과가 있다. 예를 들어 책장이 아예 없다는 의미(NULL)와 책장에 책이 없다(NA)는 다른 개념을 지칭하고 쓰임새가 다르다. \n\n\nNULL\n\n# NULL 자료형과 길이\ntypeof(NULL)\n#&gt; [1] \"NULL\"\nlength(NULL)\n#&gt; [1] 0\n\n\n\nNA\n\n# NA 자료형과 길이\ntypeof(NA)\n#&gt; [1] \"logical\"\nlength(NA)\n#&gt; [1] 1\n\n\n\nNA의 중요한 특징은 전염된다는 것이다. 즉, NA에 연산을 가하면 연산 결과는 무조건 NA가 된다. NA가 7보다 큰지, 7을 더하고 빼고, 부울 연산을 하든 NA와 연산 결과는 무조건 NA가 된다.\n\nNA + 7\n#&gt; [1] NA\nNA / 7\n#&gt; [1] NA\nNA &gt; 7\n#&gt; [1] NA\n7 == NA\n#&gt; [1] NA\nNA == NA\n#&gt; [1] NA",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#fp-list-columns",
    "href": "16-dataframe.html#fp-list-columns",
    "title": "14  데이터프레임",
    "section": "\n14.8 리스트 칼럼",
    "text": "14.8 리스트 칼럼\n레고를 통해 살펴본 R 자료구조는 계산 가능한 원자 자료형(논리형, 숫자형, 요인형)으로 크게 볼 수 있다. R에서 정수형과 부동소수점은 그다지 크게 구분을 하지 않는다. 동일 길이를 갖는 벡터를 쭉 붙여넣으면 자료구조형이 데이터프레임으로 되고, 길이가 같지 않는 벡터를 한 곳에 모아넣은 자료구조가 리스트다. 1 2 \n데이터프레임이 굳이 모두 원자벡터만을 갖출 필요는 없다. 리스트를 데이터프레임 내부에 갖는 것도 데이터프레임인데 굳이 구별하자면 티블(tibble)이고, 이런 자료구조를 리스트-칼럼(list-column)이라고 부른다.\n\n\n\n\n\n그림 14.2: 리스트 칼럼\n\n\n의외로 리스트-칼럼 자료구조를 실무에서 빈번히 마주하게 된다. 정규표현식을 사용하여 텍스트 데이터에서 원하는 패턴을 추출하거나 변환할 수 있다. 추출된 결과는 주로 리스트 형태로 저장되며, 리스트-칼럼을 활용하면 텍스트 처리 결과를 데이터프레임에 직접 저장할 수 있어 편리하다. 웹 API를 통해 수집한 JSON이나 XML 형식의 데이터는 계층적 구조를 가지고 있어 리스트-칼럼을 사용하여 데이터프레임에 저장하면 복잡한 구조의 데이터를 분석에 용이한 형태로 환하기 수월하다.\n분할-적용-병합(Split-Apply-Combine) 전략은 데이터를 그룹별로 나누어 각 그룹에 동일한 연산을 적용하고, 결과를 다시 병합하는 방법으로 그룹별 연산 결과는 리스트 형태로 저장되며, 리스트-칼럼을 사용하여 데이터프레임에 통합시킨 후 후속 작업을 이어나가는 패턴을 흔히 볼 수 있다.\n이렇게 리스트-칼럼을 활용하여 데이터를 처리하고 분석하는 과정에서, 티블(tibble) 형태의 데이터프레임을 사용하면 데이터 탐색과 조작이 한결 수월해진다. 데이터프레임이 티블(tibble) 형태로 되어 있을 때, 데이터프레임 파악, 인덱싱, 연산, 간략화 등 다양한 작업을 수월하게 할 수 있다.\n먼저, 들여다보기(Inspect) 측면에서 티블 형태 데이터프레임은 콘솔에 출력했을 때 깔끔하게 보여주므로, 데이터의 구조와 내용을 쉽게 파악할 수 있다. 또한, glimpse() 함수를 사용하면 데이터프레임 개요를 자료형과 함께 한 눈에 확인할 수 있다.\n인덱싱(Indexing) 측면에서는 티블이 데이터프레임과 동일하게 [], [[]], $ 연산자를 사용하여 원소에 접근할 수 있어, 열 이름이나 위치를 사용하여 원하는 변수나 관측값을 추출할 수 있다.\n연산(Compute) 측면에서도 리스트-칼럼을 포함한 티블에서 mutate(), summarise() 등의 함수를 사용하여 새로운 변수를 생성하거나 요약 통계량을 계산할 수 있으며, 이 과정에서 리스트-칼럼에 대한 연산도 자연스럽게 수행할 수 있다.\n마지막으로 간략화(Simplify) 측면에서는 리스트-칼럼을 포함한 티블을 일반적인 데이터프레임으로 변환할 때, unnest() 함수를 사용할 수 있다. 이를 통해 리스트-칼럼의 각 요소를 개별 행으로 풀어내어, 분석에 더 용이한 형태로 만들 수 있다.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#sec-dataframe-ai",
    "href": "16-dataframe.html#sec-dataframe-ai",
    "title": "14  데이터프레임",
    "section": "\n14.9 AI와 함께하는 데이터프레임 처리",
    "text": "14.9 AI와 함께하는 데이터프레임 처리\n데이터프레임은 행과 열로 구성된 표 형식 데이터의 표준이다. AI에게 데이터프레임 작업을 요청할 때는 입력 데이터의 구조, 원하는 변환 작업, 출력 형태를 명확히 전달해야 한다.\n명세 작성 패턴\n\n데이터프레임의 구조(열 이름, 자료형, 샘플 데이터) 제시\n필터링, 그룹화, 조인 등 원하는 변환 작업 기술\n결과 데이터프레임의 예상 형태 설명\n\n프롬프트 예시\n\n“sales 데이터프레임에서 region이 ’Seoul’이고 amount가 10000 이상인 행만 추출하는 R/Python 코드를 작성해줘”\n“customers와 orders 두 데이터프레임을 customer_id로 조인해서 고객별 총 주문금액을 계산하는 코드를 작성해줘”\n“월별 매출 데이터가 wide format인데, long format으로 변환하고 싶어. tidyr/pandas를 사용해줘”\n“NA 값이 포함된 데이터프레임에서 결측치를 그룹별 평균으로 대체하는 방법을 알려줘”",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#연습문제",
    "href": "16-dataframe.html#연습문제",
    "title": "14  데이터프레임",
    "section": "연습문제",
    "text": "연습문제\n객관식\n\nR에서 벡터 자료형을 주로 어떻게 분류하는가?\n\n\n원자 벡터와 리스트\n숫자형과 문자형\n정수형과 실수형\n행렬과 배열\n\n\n데이터프레임에서 특정 변수를 제거하기 위해 사용하는 코드는?\n\n\ndataframe$variable == NULL\ndataframe$variable = NULL\n\ndataframe$variable &lt;- NULL\ndataframe &lt;- NULL\n\n\n다음 중 리스트-칼럼 자료구조를 활용하기에 적합하지 않은 경우는?\n\n\n정규표현식을 통한 텍스트 문자열 처리\n웹 API로 추출된 JSON, XML 데이터\n분할-적용-병합(Split-Apply-Combine) 전략\n단순한 숫자형 벡터 저장\n서술형\n\n데이터프레임을 생성하는 함수의 이름과 사용 예시를 간단히 작성하시오.\n\n\n리스트-칼럼 자료구조의 장점을 설명하고, 이를 분석에 활용하는 방법에 대해 서술하시오.\n\n\n\n\n\n[1] \nS. S. Stevens, “On the theory of scales of measurement”, Science, vol 103, 호 2684, pp 677–680, 1946.\n\n\n[2] \nN. Wiener, “A new theory of measurement: a study in the logic of mathematics”, Proceedings of the London Mathematical Society, vol 2, 호 1, pp 181–205, 1921.\n\n\n[3] \n이경화, 고등학교 실용통계. 통계청 통계교육원, 2020.\n\n\n[4] \nH. Wickham, M. Çetinkaya-Rundel, 와/과 G. Grolemund, R for data science. \" O’Reilly Media, Inc.\", 2023.",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "16-dataframe.html#footnotes",
    "href": "16-dataframe.html#footnotes",
    "title": "14  데이터프레임",
    "section": "",
    "text": "List columns↩︎\nPhotos that depict R data structures and operations via Lego↩︎",
    "crumbs": [
      "**2부** 자료구조",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>데이터프레임</span>"
    ]
  },
  {
    "objectID": "git-basics.html",
    "href": "git-basics.html",
    "title": "15  자동화된 버전 관리",
    "section": "",
    "text": "누군가 무엇을 했는지, 언제 했는지를 추적하기 위해서 버전 관리를 어떻게 사용할 수 있는지 탐색해보자. 다른 사람과 협업을 하지 않더라도, 자동화된 버전 관리가 다음 상황보다 훨씬 더 낫다:\n\n\n\n\n\n\n\nPiled Higher and Deeper by Jorge Cham, http://www.phdcomics.com/comics/archive_print.php?comicid=1531\n\n\n이전에 위와 같은 상황에 처했었다. 같은 문서에 대해서 거의 동일한 다수 버전을 관리하는 것은 우스꽝스러워 보인다. 일부 워드프로세서에는 이런 상황을 좀 더 잘 처리하도록 하는 기능이 있다. 예를 들어, 마이크로소프트 워드 “변경 내용 추적(Track Changes)”이나 구글 문서(Google Docs)의 버전 기록 기능이 그것이다.\n버전 관리 시스템은 문서의 기본 버전으로 시작한 후, 각 단계마다 변경한 이력을 저장한다. 테이프로 생각하면 이해하기 쉽다. 테이프를 되감으면 문서를 시작한 지점으로 돌아가고, 각 변경 사항을 다시 적용하면 가장 최신 버전이 된다.\n\n\n\n\n\n\n그림 15.1: 변경 사항이 순차적으로 저장된다.\n\n\n\n변경 사항을 문서 그 자체와 별개로 생각하면, 동일한 기반 문서에 서로 다른 변경 사항을 적용해보는 식으로 “재생(playback)”할 수 있고, 이를 별도의 문서 버전을 관리하는 것으로 간주할 수 있다. 예를 들어, 두 사용자가 같은 문서에 독립적으로 변경 작업을 수행할 수 있다.\n\n\n\n\n\n\n그림 15.2: 다른 버전이 저장될 수도 있다.\n\n\n\n만약 충돌이 발생하지 않는다면, 심지어 동일한 문서에 두 가지 변경 사항을 모두 적용할 수도 있다.\n\n\n\n\n\n\n\n그림 15.3: 여러 버전이 병합될 수도 있다.\n\n\n\n버전 관리 시스템은 사용자를 대신해서 변경 사항을 기록하고, 파일 버전을 생성하며 파일을 병합하는 데 유용한 도구이다. 버전 관리 시스템을 사용하면 어떤 변경 사항을 다음 버전에 반영할지 결정할 수 있는데, 이를 커밋(commit)이라고 부른다. 또한 커밋에 관한 유용한 메타 정보도 보관한다. 특정 프로젝트와 프로젝트 메타 정보에 대한 완전한 커밋 이력은 저장소(repository)에 보관된다. 저장소는 협업하는 여러 동료의 컴퓨터 간에 동기화될 수 있다. \n\n\n\n\n\n\n힌트버전 관리 시스템의 오랜 역사\n\n\n\n\n자동화된 버전 관리 시스템은 전혀 새로운 것이 아니다. 1980년대부터 RCS, CVS, Subversion 같은 도구가 존재했고, 많은 대기업에서 사용되어 왔다. 하지만 다양한 기능의 한계로 인해 이들 중 다수는 이제 레거시 시스템(legacy system)으로 간주된다. 최근에 등장한 Git과 Mercurial 같은 도구는 분산(distributed) 기능을 제공한다. 이는 저장소를 반드시 중앙 서버에 둘 필요가 없다는 의미이다. 이러한 최신 시스템에는 동시에 여러 저자가 동일한 파일을 편집하는 것을 가능하게 하는 강력한 병합(merge) 도구도 내장되어 있다.\n\n\n\n\n\n\n\n\n힌트논문 작성 시 버전 관리\n\n\n\n\n\n논문을 작성하면서 정말 멋진 문단을 초안으로 작성했지만, 나중에 망쳐버렸다고 상상해 보자. 어떻게 해야 정말 멋진 결론 부분이 포함된 문서 버전을 되살릴 수 있을까? 과연 가능할까?\n공동 저자가 5명 있다고 가정해 보자. 이들이 논문에 반영한 변경 사항과 의견(comment)을 어떻게 관리할 수 있을까? 마이크로소프트 워드나 리브레오피스 Writer를 사용한다면 변경 내용 추적 기능으로 변경 사항을 반영하면 어떻게 될까? 이러한 변경 내역을 계속 보관하고 있을 수 있을까?",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>자동화된 버전 관리</span>"
    ]
  },
  {
    "objectID": "git-setup-create.html",
    "href": "git-setup-create.html",
    "title": "16  Git 설정과 저장소",
    "section": "",
    "text": "16.1 Git 추가 설정\n처음 Git을 새로운 컴퓨터에서 사용할 때는 몇 가지 설정이 필요하다. 다음은 Git을 시작할 때 필수적으로 설정해야 하는 몇 가지 사례다.\n명령 줄에서 Git 명령어는 다음과 같이 작성된다. git verb options. 여기서 verb는 실제로 수행하고자 하는 명령어이고, options는 verb에 필요할 수 있는 추가 선택 사항 정보가 된다. 다음은 드라큘라(Dracula)가 새로 구입한 노트북에서 환경을 설정하는 방법이다.\n드라큘라(Dracula) 대신에 본인의 이름과 이메일 주소를 사용한다. 사용자명과 이메일 주소는 후속 Git 활동과 연관된다. 이것이 의미하는 바는 GitHub, BitBucket, GitLab 등 Git 호스팅 서버에 푸시하는 모든 변경 사항에 사용자명과 이메일 주소가 포함됨을 의미한다.\n이번 학습에서는 GitHub을 사용하는데, 여기에 사용되는 이메일 주소는 GitHub 계정 설정 시 사용한 것과 동일해야 한다. 만약 개인정보가 걱정된다면 GitHub의 이메일 주소 비공개 지침을 참조하자. GitHub에서 비공개 이메일 주소를 선택했다면 user.email에도 동일한 주소를 사용해야 한다. 즉, GitHub 설정의 username을 username@users.noreply.github.com으로 바꾼다. 나중에 git config 명령어로 이메일 주소를 변경할 수 있다.\n드라큘라도 선호하는 텍스트 편집기를 설정해야 하는데, 다음 표를 참조하면 된다.\n필요할 때마다 Git에서 사용할 텍스트 편집기 설정을 변경할 수 있다.\n앞서 실행한 상기 명령어는 한번만 실행하면 된다. --global 플래그는 Git으로 하여금 해당 컴퓨터에 본인 계정의 모든 프로젝트에 환경설정한 것을 사용하도록 한다.\n본인이 설정한 환경설정 내용은 언제라도 다음 명령어를 입력하여 확인할 수 있다.\n원하는 대로 설정을 변경할 수 있다. 편집기를 바꾸거나 이메일 주소를 업데이트할 때도 동일한 명령어를 사용하면 된다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Git 설정과 저장소</span>"
    ]
  },
  {
    "objectID": "git-setup-create.html#git-korean",
    "href": "git-setup-create.html#git-korean",
    "title": "16  Git 설정과 저장소",
    "section": "",
    "text": "16.1.1 로컬 PC와 SSH 키 연결\n\nGitHub에 저장소(repository)를 만들고 여러 PC에서 작업할 경우, GitHub 인증 작업을 거치는 것이 여러모로 편리하다. 그 중 하나는 공개 키(public key)를 GitHub에 등록하여 작업하는 방식이다.\n\n윈도우 사용자는 먼저 Git for Windows를 다운로드하여 설치한다.\nssh-keygen 명령어로 공개 키와 비밀 키를 생성한다.\n생성된 공개 키를 GitHub 계정에 등록한다.\n\n\n\n16.1.2 SSH 공개 키/비밀 키 생성\nSSH 공개 키와 비밀 키를 생성하고 GitHub에 등록하는 과정은 다음과 같다. 먼저 ssh-keygen 명령어에 매개변수와 GitHub 이메일 주소를 지정한다. 1\n$ ssh-keygen -t rsa -C \"your_email@example.com\" \nssh-keygen으로 생성된 키를 GitHub에 등록한다.\n\n우측 상단 [Settings] → [SSH and GPG keys] → [New SSH key]\n\n[New SSH key]를 클릭하면 Title과 Key 입력란이 나타난다. Title에는 식별 가능한 이름을 지정하고, 앞서 생성한 id_rsa.pub 내용을 Key에 복사하여 붙여넣는다.\n$ cat ~/.ssh/id_rsa.pub\n\nssh-rsa AAAxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxYxY9 email_address@mail.com\n\n\n16.1.3 첫 커밋(commit)\n인증을 완료하고 저장소에서 처음 파일을 커밋할 때 git add, git commit -m 명령어를 연속해서 실행하면 커밋 작성자 정보를 등록하라는 메시지가 나타난다. git config로 이메일과 사용자명을 설정하면 정상적으로 커밋할 수 있다.\n$ git config --global user.email \"you@example.com\"\n$ git config --global user.name \"Your Name\"\n\n\n16.1.4 비밀번호 없이 푸시하기\n다음 단계로 비밀번호 없이 커밋된 내용을 GitHub에 전달하는 방법은 자격인증(credential) 캐싱을 통한 간단한 방법이 있다. 물론 처음에는 사용자명과 비번을 입력하는 과정을 필수적으로 거치게 된다.2\n$ git config credential.helper store\n$ git push https://github.com/repo.git\n\nUsername for 'https://github.com': &lt;USERNAME&gt;\nPassword for 'https://USERNAME@github.com': &lt;PASSWORD&gt; \n보안을 강화하기 위해 캐시 시간 제한을 7200초(2시간)로 설정할 수 있다.\n$ git config --global credential.helper 'cache --timeout 7200'",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Git 설정과 저장소</span>"
    ]
  },
  {
    "objectID": "git-setup-create.html#git-create",
    "href": "git-setup-create.html#git-create",
    "title": "16  Git 설정과 저장소",
    "section": "16.2 저장소 생성",
    "text": "16.2 저장소 생성\n\nGit 환경설정이 완료되면, Git를 사용할 수 있다. 행성 착륙선을 화성에 보낼 수 있는지 조사를 하고 있는 늑대인간과 드라큘라 이야기를 계속해서 진행해 보자.\n\n\n\n\n\n\n그림 16.1: Git 동기 부여 사례\n\n\n\n먼저 바탕화면(Desktop)에 작업할 디렉토리를 생성하고, 생성한 디렉토리로 이동하자:\n$ cd ~/Desktop\n$ mkdir planets\n$ cd planets\n그리고 나서, planets을 저장소(repository)로 만든다. 저장소는 Git이 파일에 대한 버전 정보를 저장하는 장소다.\n$ git init\ngit init 명령어가 서브디렉토리(subdirectory)와 파일을 담고 있는 저장소를 생성하는데 주목한다. planets 저장소 내부에 중첩된 별도 저장소를 생성할 필요는 없다. 또한, planets 디렉토리를 생성하고 저장소로 초기화하는 것은 완전히 서로 다른 과정이다.\nls를 사용해서 디렉토리 내용을 살펴보면, 변한 것이 아무것도 없는 것처럼 보인다:\n$ ls\n하지만, 모든 것을 보여주는 -a 플래그를 추가하면, Git은 planets 디렉토리 내부에 .git 로 불리는 숨겨진 디렉토리를 생성한 것을 볼 수 있다:\n$ ls -a\n\n.   ..  .git\nGit은 .git이라는 특별한 하위 디렉토리에 프로젝트에 대한 정보를 저장한다. 여기에는 프로젝트 디렉토리 내부에 위치한 모든 파일과 서브 디렉토리가 포함된다. 만약 .git를 삭제하면, 프로젝트 이력을 모두 잃어버리게 된다.\n모든 것이 제대로 설정되었는지를 확인하려면, Git에게 다음과 같이 프로젝트 상태를 확인 명령어를 던진다:\n$ git status\n\n# On branch master\n#\n# Initial commit\n#\nnothing to commit (create/copy files and use \"git add\" to track)\n다른 git 버전을 사용할 경우, 출력 결과물이 다소 다를 수 있다.\n\n\n\n\n\n\n경고Git 저장소를 생성할 장소\n\n\n\n(이미 생성한 프로젝트) 행성에 대한 정보를 추적하면서, 드라큘라는 달에 관한 정보도 추적하고자 한다. planets 프로젝트와 관련된 새로운 프로젝트 moons를 시작한다. 늑대인간의 걱정에도 불구하고, Git 저장소 내부에 또 다른 Git 저장소를 생성하려고 다음 순서로 명령어를 입력해 나간다.\n$ cd ~/Desktop   # 바탕화면 디렉토리로 되돌아 간다.\n$ cd planets     # planets 디렉토리로 들어간다.\n$ ls -a          # planets 디렉토리에 .git 서브 디렉토리가 있는지 확인한다.\n$ mkdir moons    # planets/moons 서브 디렉토릴르 생성한다.\n$ cd moons       # moons 서브 디렉토리로 이동한다.\n$ git init       # Git 저장소를 moons 하위디렉토리에 생성한다.\n$ ls -a          # 새로운 Git 저장소가 .git 하위 디렉토리에 있는지 확인한다.\nmoons 서브 디렉토리에 저장된 파일을 추적하기 위해 moons 디렉토리 안에서 git init 명령을 실행해야 할까?\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n아니다. moons 서브 디렉토리에 Git 저장소를 만들 필요는 없다. 왜냐하면, planets 저장소가 이미 모든 파일, 서브 디렉토리, planets 디렉토리 아래 서브 디렉토리 파일 모두를 추적하기 때문이다. 따라서, 달에 관한 모든 정보를 추정하는데, 드랴큘라는 planets 디렉토리 아래 moons 서브 디렉토리를 추가하는 것으로 충분하다.\n추가적으로, 만약 Git 저장소가 중첩(nested)되면, Git 저장소는 서로 방해할 수 있다. 바깥 저장소가 내부 저장소 버전관리를 하게 된다. 따라서, 별도 디렉토리에 서로 다른 신규 Git 저장소를 생성하는게 최선이다.\n디렉토리에 저장소가 서로 충돌하지 않도록 하려면, git status 출력물을 점검하면 된다. 만약, 다음과 같은 출력물이 생성되게 되면 신규 저장소를 생성하는 것이 권장된다:\n$ git status\n\nfatal: Not a git repository (or any of the parent directories): .git\n\n\n\n\n\n\n\n\n\n\n\n주의git init 실수 올바르게 고치기\n\n\n\n늑대인간은 드라큘라에게 중첩된 저장소가 중복되어 불필요할 뿐만 아니라 향후 혼란을 야기할 수 있다고 설명했다. 드라큘라는 중첩된 저장소를 제거하고자 한다.\nmoons 서브 디렉터리에서 마지막으로 실행한 git init 명령어를 어떻게 취소할 수 있을까?\n\n\n\n\n\n\n노트해답 – 주의해서 사용할 것!\n\n\n\n\n\n이러한 사소한 실수를 되돌리려면, 드라큘라는 planets 디렉토리에서 다음 명령어를 실행하여 .git 디렉토리를 제거하기만 하면 된다:\n$ rm -rf moons/.git\n하지만, 주의할 것! 디렉토리를 잘못 입력하게 되면, 보관해야 하는 프로젝트 정보를 담고 있는 Git 이력 전체가 삭제될 수 있다. 따라서, pwd 명령어를 사용해서 현재 작업 디렉토리를 항상 확인한다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Git 설정과 저장소</span>"
    ]
  },
  {
    "objectID": "git-setup-create.html#footnotes",
    "href": "git-setup-create.html#footnotes",
    "title": "16  Git 설정과 저장소",
    "section": "",
    "text": "nickjoIT (2017), “GitHub SSH 키 생성 및 등록하여 사용하기”↩︎\nStackoverflow, “How do I avoid the specification of the username and password at every git push?”↩︎",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Git 설정과 저장소</span>"
    ]
  },
  {
    "objectID": "git-change.html",
    "href": "git-change.html",
    "title": "17  변경사항 추적",
    "section": "",
    "text": "먼저 디렉토리 위치가 맞는지 확인하자. planets 디렉토리에 위치해야 한다.\n$ pwd\n\n/home/vlad/Desktop/planets\nmoons 디렉토리에 여전히 있다면, planets 디렉토리로 되돌아간다.\n$ pwd\n\n/home/vlad/Desktop/planets/moons\n$ cd ..\n전진기지로서 화성의 적합성에 관한 기록을 담고 있는 mars.txt 파일을 생성한다. (파일 편집을 위해서 nano 편집기를 사용한다; 원하는 어떤 편집기를 사용해도 된다. 특히, 앞에서 전역으로 설정한 core.editor일 필요는 없다. 하지만, 파일을 새로 생성하거나 편집할 때 배쉬 명령어는 사용자가 선택한 편집기에 의존하게 된다. (nano일 필요는 없다.) 텍스트 편집기에 대한 환기로, 챗GPT 유닉스 쉘의 “어떤 편집기가 좋을까요?” 부분을 참고한다.\n$ nano mars.txt\nmars.txt 파일에 다음 텍스트를 타이핑한다:\nCold and dry, but everything is my favorite color\nmars.txt 파일은 이제 한 줄을 포함하게 되어서, 다음 명령어로 내용을 확인할 수 있다:\n$ ls\n\nmars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\n다시 한번 프로젝트의 상태를 확인하고자 하면, Git이 새로운 파일이 인지되었다고 알려준다: \n$ git status\n\nOn branch master\n\nInitial commit\n\nUntracked files:\n   (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    mars.txt\nnothing added to commit but untracked files present (use \"git add\" to track)\n“untracked files” 메시지가 의미하는 것은 Git이 추적하고 있지 않는 파일 하나가 디렉토리에 있다는 것이다. git add를 사용해서 Git에게 추적관리하라고 알려준다: \n$ git add mars.txt\n그리고 나서, 올바르게 처리되었는지 확인한다:\n$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n    new file:   mars.txt\n이제 Git은 mars.txt 파일을 추적할 것이라는 것을 알고 있지만, 커밋으로 아직 저장소에는 어떤 변경사항도 기록되지 않았다. 이를 위해서 명령어 하나 더 실행할 필요가 있다: \n$ git commit -m \"Start notes on Mars as a base\"\n\n[master (root-commit) f22b25e] Start notes on Mars as a base\n 1 file changed, 1 insertion(+)\n create mode 100644 mars.txt\ngit commit을 실행할 때, Git은 git add를 사용해서 저장하려고 하는 모든 대상을 받아서 .git 디렉토리 내부에 영구적으로 사본을 저장한다. 이 영구 사본을 커밋(commit) (혹은 수정(revision))이라고 하고, 짧은 식별자는 f22b25e이다. (여러분의 커밋번호의 짧은 식별자는 다를 수 있다.)\n-m (“message”를 의미) 플래그를 사용해서 나중에 무엇을 왜 했는지 기억에 도움이 될 수 있는 주석을 기록한다. -m 옵션 없이 git commit을 실행하면, Git은 nano (혹은 처음에 core.editor에서 설정한 다른 편집기)를 실행해서 좀 더 긴 메시지를 작성할 수 있다.\n좋은 커밋 메시지(Good commit messages) 작성은 커밋으로 만들어진 간략한 (영문자 기준 50문자 이하) 변경사항 요약으로 시작된다. 일반적으로 메시지는 완전한 문장이 되어야 한다. 예를 들어, “If applied, this commit will” . 만약 좀 더 상세한 사항을 남기려면, 요약줄 사이에 빈줄을 추가하고 추가적인 내역을 적는다. 추가되는 공간에 왜 변경을 하는지 사유를 남기고, 어떤 영향을 미치는지도 기록한다.\n이제 git status를 실행하면:\n$ git status\n\nOn branch master\nnothing to commit, working directory clean\n모든 것이 최신 상태라고 보여준다. 최근에 작업한 것을 알고자 한다면, git log를 사용해서 프로젝트 이력을 보여주도록 Git에게 명령어를 보낸다:\n$ git log\n\ncommit f22b25e3233b4645dabd0d81e651fe074bd8e73b\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 09:51:46 2013 -0400\n\n    Start notes on Mars as a base\ngit log는 시간 역순으로 저장소의 모든 변경사항을 나열한다. 각 수정사항 목록은 전체 커밋 식별자(앞서 git commit 명령어로 출력한 짧은 문자와 동일하게 시작), \n수정한 사람, 언제 생성되었는지, 커밋을 생성할 때 Git에 남긴 로그 메시지가 포함된다.\n\n\n\n\n\n\n주의내가 작성한 변경사항은 어디에 있나?\n\n\n\n이 시점에서 ls 명령어를 다시 실행하면, mars.txt 파일만 덩그러니 보게 된다. 왜냐하면, Git이 앞에서 언급한 .git 특수 디렉토리에 파일 변경 이력 정보를 저장했기 때문이다. 그래서 파일 시스템이 뒤죽박죽되지 않게 된다. (따라서, 옛 버전을 실수로 편집하거나 삭제할 수 없다.)\n\n\n이제 드라큘라가 이 파일에 정보를 더 추가했다고 가정하자. (다시 한번 nano 편집기로 편집하고 나서 cat으로 파일 내용을 살펴본다. 다른 편집기를 사용할 수도 있고, cat으로 파일 내용을 꼭 볼 필요도 없다.)\n$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\ngit status를 실행하면, Git이 이미 알고 있는 파일이 변경되었다고 알려준다:\n$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n마지막 줄이 중요한 문구다: “no changes added to commit”. mars.txt 파일을 변경했지만, 아직 Git에게는 변경사항을 저장하려고 하거나 (git add로 수행), 저장소에 저장하라고 (git commit로 수행) 알려주지 않았다. 이제 행동에 나서보자. 저장하기 전에 변경사항을 항상 검토하는 것은 좋은 습관이다. git diff를 사용해서 작업 내용을 두 번 검증한다. git diff는 현재 파일의 상태와 가장 최근에 저장된 버전의 차이를 보여준다:\n$ git diff\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..315bf3a 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,2 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n출력 결과가 암호 같은데 이유는 한 파일이 주어졌을 때 다른 파일 하나를 어떻게 재구성하는지를 알려주는 patch와 편집기 같은 도구를 위한 일련의 명령어라서 그렇다. 만약 해당 내역을 조각내서 쪼개다면:\n\n첫 번째 행은 Git이 신규 파일과 옛 버전 파일을 비교하는 유닉스 diff 명령어와 유사한 출력 결과를 생성하고 있다.\n두 번째 행은 정확하게 Git이 파일 어느 버전을 비교하는지 알려준다; df0654a와 315bf3a은 해당 버전에 대해서 중복되지 않게 컴퓨터가 생성한 표식이다.\n세 번째와 네 번째 행은 변경되는 파일 명칭을 다시 한번 보여주고 있다.\n\n나머지 행이 가장 흥미롭다. 실제 차이가 나는 것과 어느 행에서 발생했는지 보여준다. 특히 첫 번째 열의 + 기호는 어디서 행이 추가되었는지 보여준다.\n\n변경사항 검토 후에, 변경사항을 커밋(commit)하자.\n$ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\n$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n이럴 수가, git add를 먼저 하지 않아서 Git이 커밋을 할 수 없다. 고쳐보자.\n$ git add mars.txt\n$ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\n\n[master 34961b1] Add concerns about effects of Mars' moons on Wolfman\n 1 file changed, 1 insertion(+)\n실제로 무엇을 커밋하기 전에 커밋하고자 하는 파일을 먼저 추가하라고 Git이 주문하는데, 이유는 한번에 모든 것을 커밋하고 싶지 않을 수도 있기 때문이다. 예를 들어, 작성하고 있는 논문에 지도교수 논문을 일부 인용하여 추가한다고 가정하자. 논문 중간에 인용되는 추가부분과 상응되는 참고문헌을 커밋하고는 싶지만, 결론 부분을 커밋하고는 싶지 않다. (아직 결론이 완성되지 않았다.)\n이런 점을 고려해서, Git은 특별한 준비 영역(staging)이 있어서 현재 변경부분(change set)을 추가는 했으나 아직 커밋하지 않는 것을 준비 영역에서 추적하고 있다.\n\n\n\n\n\n\n주의준비 영역(Staging area)\n\n\n\n프로젝트 기간 동안에 걸쳐 발생된 변경사항에 대해 스냅사진을 찍는 것으로 Git을 바라보면, git add 명령어는 무엇이 스냅사진(준비영역에 놓는 것)에 들어갈지 명세하고, git commit 명령어는 실제로 스냅사진을 찍는 것이다. 만약 git commit을 타이핑할 때 준비된 어떤 것도 없다면, Git이 git commit -a 혹은 git commit --all 명령어 사용을 재촉한다. 사진을 찍으려고 모두 모이세요 하는 것과 같다. 하지만, 준비영역에 추가할 것을 명시적으로 하는 것이 항상 좋다. 왜냐하면 커밋을 했는데 잊은 것이 있을 수도 있기 때문이다. (스냅사진으로 돌아가서, -a 옵션을 사용했기 때문에 스냅사진에 들어갈 항목을 불완전하게 작성했을 수도 있다!) 수작업으로 준비영역에 올리거나, 원하는 것보다 많은 것을 올렸다면 “git undo commit”을 찾아보라.\n\n\n\n\n\n\n\n\n그림 17.1: Git 준비(Staging) 영역\n\n\n\n파일 변경사항을 편집기에서 준비 영역으로, 그리고 장기 저장소로 옮기는 것을 살펴보자. 먼저, 파일에 행 하나를 더 추가한다. \n$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\n$ git diff\n\ndiff --git a/mars.txt b/mars.txt\nindex 315bf3a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n지금까지 좋다. 파일의 끝에 행을 하나 추가했다(첫 열에 +이 보인다). 이제, 준비영역에 변경사항을 놓고, git diff 명령어가 보고하는 것을 살펴보자.\n$ git add mars.txt\n$ git diff\n출력결과가 없다. Git이 알려줄 수 있는 것은 영구히 저장되는 것과 현재 디렉토리에 작업하고 있는 것에 차이가 없다는 것이다. 하지만, 다음과 같이 명령어를 친다면:\n$ git diff --staged\n\ndiff --git a/mars.txt b/mars.txt\nindex 315bf3a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n마지막으로 커밋된 변경사항과 준비 영역(Staging)에 있는 것과 차이를 보여준다. 변경사항을 저장하자:\n$ git commit -m \"Discuss concerns about Mars' climate for Mummy\"\n\n[master 005937f] Discuss concerns about Mars' climate for Mummy\n 1 file changed, 1 insertion(+)\n현재 상태를 확인하자:\n$ git status\n\nOn branch master\nnothing to commit, working directory clean\n그리고 지금까지 작업한 이력을 살펴보자:\n$ git log\n\ncommit 005937fbe2a98fb83f0ade869025dc2636b4dad5\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 10:14:07 2013 -0400\n\n    Discuss concerns about Mars' climate for Mummy\n\ncommit 34961b159c27df3b475cfe4415d94a6d1fcd064d\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 10:07:21 2013 -0400\n\n    Add concerns about effects of Mars' moons on Wolfman\n\ncommit f22b25e3233b4645dabd0d81e651fe074bd8e73b\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 09:51:46 2013 -0400\n\n    Start notes on Mars as a base\n\n\n\n\n\n\n힌트단어 단위 차이분석(Word-based diffing)\n\n\n\n경우에 따라서는 줄 단위로 텍스트 차이 분석이 너무 자세하지 않을 수도 있다. git diff 명령어에 --color-words 선택옵션이 유용할 수 있는데 이유는 색상을 사용해서 변경된 단어를 강조해서 표시해 주기 때문이다.\n\n\n\n\n\n\n\n\n힌트로그 페이지별 보기\n\n\n\n화면에 git log 출력결과가 너무 긴 경우, git에 화면 크기에 맞춰 페이지 단위로 쪼개주는 프로그램이 제공된다. 페이지별 쪼개보기(“pager”)가 호출되면, 화면 마지막 줄에 프롬프트 대신에 :이 나타난다.\n\n페이저(pager)에서 나오려면, Q를 타이핑한다.\n다음 페이지로 이동하려면, Spacebar를 타이핑한다.\n전체 페이지에서 특정 단어를 검색하려면,\n/를 타이핑하고, 특정 단어를 검색하는 검색어를 타이핑한다. 검색에 매칭되는 단어를 따라가려면 N을 타이핑한다.\n\n\n\n\n\n\n\n\n\n힌트로그 크기 제한걸기\n\n\n\ngit log가 전체 터미널 화면을 뒤덮는 것을 피하려면, -N 선택옵션을 적용해서 Git이 화면에 출력하는 커밋 숫자에 제한을 건다. 여기서 -N은 보고자 하는 커밋 개수가 된다. 예를 들어 가장 마지막 커밋만 보려고 한다면 다음과 같이 타이핑한다:\n$ git log -1\n\ncommit 005937fbe2a98fb83f0ade869025dc2636b4dad5\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 10:14:07 2013 -0400\n   Discuss concerns about Mars' climate for Mummy\n--oneline 선택옵션을 사용해서 출력되는 로그 메시지 크기를 줄일 수도 있다:\n$ git log --oneline\n\n* 005937f Discuss concerns about Mars' climate for Mummy\n* 34961b1 Add concerns about effects of Mars' moons on Wolfman\n* f22b25e Start notes on Mars as a base\n--oneline 선택옵션과 다른 선택옵션을 조합할 수도 있다. 유용한 조합 사례로 다음이 있다:\n$ git log --oneline --graph --all --decorate\n\n* 005937f Discuss concerns about Mars' climate for Mummy (HEAD, master)\n* 34961b1 Add concerns about effects of Mars' moons on Wolfman\n* f22b25e Start notes on Mars as a base\n\n\n\n\n\n\n\n\n힌트디렉토리\n\n\n\nGit에서 디렉토리에 관해서 알아두면 좋을 두 가지 사실. \n\nGit은 그 자체로 디렉토리를 추적하지 않고, 디렉토리에 담긴 파일만 추적한다. 믿지 못하겠다면, 직접 다음과 같이 시도해 본다:\n\n$ mkdir directory\n$ git status\n$ git add directory\n$ git status\n새로 생성된 directory 이름을 갖는 디렉토리가 git add 명령어로 명시적으로 추가했음에도 불구하고 untracked files 목록에 나오지 않고 있다. 이런 이유로 인해서 가끔 .gitkeep 파일을 보게 된다. .gitignore와 달리, 특별하지는 않고 유일한 목적은 디렉토리를 만들어 내어 Git이 저장소에 추가하도록 하는 역할만 수행한다. 사실 원하는 이름으로 파일명을 붙일 수 있다.\n\nGit 저장소에 디렉토리를 생성하고 파일로 채워넣으면, 다음과 같이 디렉토리의 모든 파일을 추가할 수 있다:\n\ngit add &lt;directory-with-files&gt;\n직접 실습해보자.\n$ touch spaceships/apollo-11 spaceships/sputnik-1\n$ git status\n$ git add spaceships\n$ git status\n다음으로 넘어가기 전에, 이러한 변경사항을 커밋한다.\n$ git commit -m \"Add some initial thoughts on spaceships\"\n\n\n요약하면, 변경사항을 저장소에 추가하고자 할 때, 먼저 변경된 파일을 준비 영역(Staging)에 git add 명령어로 추가하고 나서, 준비 영역의 변경사항을 저장소에 git commit 명령어로 최종 커밋한다.\n\n\n\n\n\n\n그림 17.2: Git 커밋(Commit) 작업흐름\n\n\n\n\n\n\n\n\n\n힌트커밋 메시지 고르기\n\n\n\n\n다음 중 어떤 커밋 메시지가 mars.txt 파일의 마지막 커밋으로 가장 적절할까요?\n\n“Changes”\n“Added line ‘But the Mummy will appreciate the lack of humidity’ to mars.txt”\n“Discuss effects of Mars’ climate on the Mummy”\n\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n1번은 충분히 기술되어 있지 못하고 커밋 목적이 불확실하다;\n2번은 “git diff” 명령어를 사용한 것과 불필요하게 중복된다;\n3번이 좋다: 짧고, 기술이 잘되어 있고, 피할 수 없게 명백하다(imperative).\n\n\n\n\n\n\n\n\n\n\n\n힌트Git에 변경사항 커밋하기\n\n\n\n다음 중 어떤 명령어가 로컬 Git 저장소에 myfile.txt 파일 변경사항을 저장시키는걸까?\n\n   $ git commit -m \"my recent changes\"\n   $ git init myfile.txt\n   $ git commit -m \"my recent changes\"\n   $ git add myfile.txt\n   $ git commit -m \"my recent changes\"\n   $ git commit -m myfile.txt \"my recent changes\"\n\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n\n파일이 이미 준비영역(staging)에 올라온 경우만 커밋이 생성된다.\n신규 저장소를 생성하게 된다.\n정답: 파일을 준비영역에 추가하고 나서, 커밋하게 된다.\nmyfile.txt 파일에 “my recent changes” 메시지를 갖는 커밋을 생성한다.\n\n\n\n\n\n\n\n\n\n\n\n\n힌트파일 다수를 커밋\n\n\n\n준비영역(staging area)은 스냅샷 한 번에 원하는 만큼 파일의 변경사항을 담아낼 수 있다. 1. mars.txt 파일에 전진기지로 생각하는 금성(Venus)를 고려하고 있다는 결정을 담은 텍스트를 추가한다. 2. venus.txt 파일을 새로 생성해서 본인과 친구들에게 금성에 관한 첫생각을 담아낸다. 3. 파일 두 개에 변경사항을 준비영역에 추가하고 커밋한다.\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n먼저, mars.txt, venus.txt 파일에 변경사항을 기록한다:\n$ nano mars.txt\n$ cat mars.txt\n\nMaybe I should start with a base on Venus.\n$ nano venus.txt\n$ cat venus.txt\n\nVenus is a nice planet and I definitely should consider it as a base.\n준비영역에 파일 두 개를 추가한다. 한 줄로 추가 작업을 수행할 수 있다:\n$ git add mars.txt venus.txt\n혹은 명령어를 여러 번 타이핑하면 된다:\n$ git add mars.txt\n$ git add venus.txt\n이제 파일을 커밋할 준비가 되었다. git status를 사용해서 확인하면, 커밋을 할 준비가 되었다:\n$ git commit -m \"Write plans to start a base on Venus\"\n[master cc127c2]\nWrite plans to start a base on Venus\n2 files changed, 2 insertions(+)\ncreate mode 100644 venus.txt\n\n\n\n\n\n\n\n\n\n\n\n힌트bio 저장소\n\n\n\n\nbio라는 새로운 Git 저장소를 본인 로컬 컴퓨터에 생성한다.\nme.txt라는 파일로 본인에 대한 3줄 이력서를 작성한다. 변경사항을 커밋한다.\n\n그리고 나서 한 줄을 바꾸고, 네 번째 줄을 추가하고 나서,\n원래 상태와 갱신된 상태의 차이를 화면에 출력한다.\n\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n필요하다면, planets 폴더에서 빠져나온다:\n$ cd ..\nbio 폴더를 새로 생성하고 bio 폴더로 이동한다:\n$ mkdir bio\n$ cd bio\ngit 명령어로 초기화한다:\n$ git init\nnano 혹은 선호하는 편집기를 사용해서 me.txt 파일에 본인 일대기를 작성한다. 파일을 추가하고 나서, 저장소에 커밋한다:\n$ git add me.txt\n$ git commit -m'Adding biography file'\n기술된 것(한 줄 변경하고, 4번째 줄을 추가한다)처럼 파일을 변경한다. 원본 상태와 수정된 상태를 git diff 명령어를 사용해서 화면에 출력한다:\n$ git diff me.txt\n\n\n\n\n\n\n\n\n\n\n\n힌트저자(Author)와 커미터(Committer)\n\n\n\n매번 커밋을 할 때마다, Git은 이름을 두 번 저장한다. 본인 이름이 저자(Author)와 커미터(Committer)로 기록된다. 마지막 커밋에 추가 정보를 Git에게 요구하면 확인이 가능하다:\n$ git log --format=full\n커밋할 때, 저자를 다른 누군가로 바꿀 수 있다:\n$ git commit --author=\"Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\"\n커밋을 두 개 생성한다. 하나는 --author 옵션을 갖는 것으로 저자로 동료 이름을 반영한다. git log와 git log --format=full 명령어를 실행한다. 이를 통해 동료들과 어떻게 협업할 수 있을지 생각해 보자.\n\n\n\n\n\n\n노트해답\n\n\n\n\n\n$ git add me.txt\n$ git commit -m \"Update Vlad's bio.\" --author=\"Frank N. Stein &lt;franky@monster.com&gt;\"\n\n[master 4162a51] Update Vlad's bio.\nAuthor: Frank N. Stein &lt;franky@monster.com&gt;\n1 file changed, 2 insertions(+), 2 deletions(-)\n\n$ git log --format=full\ncommit 4162a51b273ba799a9d395dd70c45d96dba4e2ff\nAuthor: Frank N. Stein &lt;franky@monster.com&gt;\nCommit: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\n\nUpdate Vlad's bio.\n\ncommit aaa3271e5e26f75f11892718e83a3e2743fab8ea\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nCommit: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nVlad's initial bio.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>변경사항 추적</span>"
    ]
  },
  {
    "objectID": "git-history.html",
    "href": "git-history.html",
    "title": "18  이력 탐색",
    "section": "",
    "text": "앞선 학습에서 살펴봤듯이, 식별자로 커밋을 조회할 수 있다. HEAD 식별자를 사용해서 작업 디렉터리의 가장 최근 커밋을 조회할 수 있다.\nmars.txt 파일에 한 번에 한 줄씩 추가했다. 따라서 눈으로 봐도 진행 사항을 쉽게 추적할 수 있다. HEAD를 사용해서 추적 작업을 수행해 보자. 시작 전에 mars.txt 파일에 변경을 가해보자.\n$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nAn ill-considered change\n이제, 변경된 사항을 살펴보자.\n$ git diff HEAD mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex b36abfd..0848c8d 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,3 +1,4 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n But the Mummy will appreciate the lack of humidity\n+An ill-considered change.\nHEAD만 빼면, 앞서 살펴본 것과 동일하다. 이러한 접근법의 정말 좋은 점은 이전 커밋을 조회할 수 있다는 점이다.\n~1(“~”은 “틸드(tilde)”, 발음기호 [til-duh])을 추가해서 HEAD 이전 첫 번째 커밋을 조회할 수 있다. \n$ git diff HEAD~1 mars.txt\ngit diff 명령어를 사용해서 이전 커밋과 차이난 점을 보고자 한다면,\nHEAD~1, HEAD~2 표기법을 사용해서 조회를 쉽게 할 수 있다:\n$ git diff HEAD~2 mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change\ngit show를 사용해서도 커밋 메시지뿐만 아니라 이전 커밋과 변경사항을 보여준다.\ngit diff는 작업 디렉터리와 커밋 사이 차이나는 부분을 보여준다. \n$ git show HEAD~2 mars.txt\n\ncommit 34961b159c27df3b475cfe4415d94a6d1fcd064d\nAuthor: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;\nDate:   Thu Aug 22 10:07:21 2013 -0400\n\n    Start notes on Mars as a base\n\ndiff --git a/mars.txt b/mars.txt\nnew file mode 100644\nindex 0000000..df0654a\n--- /dev/null\n+++ b/mars.txt\n@@ -0,0 +1 @@\n+Cold and dry, but everything is my favorite color\n이런 방식으로, 연쇄 커밋 사슬을 구성할 수 있다.\n가장 최근 사슬의 끝값은 HEAD로 조회된다.\n~ 표기법을 사용하여 이전 커밋을 조회할 수 있다.\n그래서 HEAD~1(“head 마이너스 1”으로 읽는다.)은 “바로 앞선 커밋”을 의미하고,\nHEAD~123은 지금 있는 위치에서 123번째 이전 수정으로 간다는 의미가 된다.\n커밋된 것을 git log 명령어로 화면에 출력되는 숫자와 문자로 구성된 긴 문자열을 사용하여 조회할 수도 있다.\n변경사항에 대해서 중복되지 않는 ID로, “중복되지 않는(unique)”의 의미는 정말 유일하다는 의미다.\n특정 컴퓨터에 있는 임의 파일 집합에 대한 모든 변경사항은 중복되지 않는 40-문자 식별자가 붙어있다.\n첫 번째 커밋은 ID로 f22b25e3233b4645dabd0d81e651fe074bd8e73b가 주어졌다.\n그래서 다음과 같이 시도해 보자:\n$ git diff f22b25e3233b4645dabd0d81e651fe074bd8e73b mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..93a3e13 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change\n올바른 정답이지만, 40-문자로 된 난수 문자열을 타이핑하는 것은 매우 귀찮은 일이다.\n그래서 Git은 앞의 몇 개 문자만으로도 사용할 수 있게 했다:\n$ git diff f22b25e mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..93a3e13 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change\n좋았어요!\n파일에 변경사항을 저장할 수 있고 변경된 것을 확인할 수 있다.\n어떻게 옛 버전 파일을 되살릴 수 있을까?\n우연히 파일을 덮어썼다고 가정하자:\n$ nano mars.txt  \n$ cat mars.txt\n\nWe will need to manufacture our own oxygen\n이제 git status를 통해서 파일이 변경되었다고 하지만,\n변경사항은 아직 준비영역(Staging area)에 옮겨지지 않은 것으로 확인된다: \n$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\ngit checkout 명령어를 사용해서 과거에 있던 상태로 파일을 되돌릴 수 있다:\n$ git checkout HEAD mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\n이름에서 유추할 수 있듯이, git checkout 명령어는 파일의 옛 버전을 확인하고 가져온다. 즉, 되살린다.\n이 경우 HEAD에 기록된 가장 최근에 저장된 파일 버전을 되살린다.\n더 오래된 버전을 되살리고자 한다면, 대신에 커밋 식별자를 사용한다: \n$ git checkout f22b25e mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\n$ git status\n\n# On branch master\nChanges to be committed:\n  (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n# Changes not staged for commit:\n#   (use \"git add &lt;file&gt;...\" to update what will be committed)\n#   (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n#\n#   modified:   mars.txt\n#\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n변경사항은 준비영역에 머물러 있는 것에 주목한다. 다시, git checkout 명령어를 사용해서 이전 버전으로 되돌아간다:\n$ git checkout HEAD mars.txt\n\n\n\n\n\n\n힌트헤드(HEAD)를 잃지 말자\n\n\n\nf22b25e 커밋 상태로 mars.txt 파일을 되돌리는데 앞서 다음 명령어를 사용했다.\n$ git checkout f22b25e mars.txt\n하지만 주의하자! checkout 명령어는 다른 중요한 기능을 가지고 있어서, 만약 타이핑에 오류가 있다면 Git이 의도를 오해할 수 있다.\n예를 들어, 앞선 명령에서 mars.txt를 빼먹게 되면…\n$ git checkout f22b25e\n\nNote: checking out 'f22b25e'.\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\n git checkout -b &lt;new-branch-name&gt;\nHEAD is now at f22b25e Start notes on Mars as a base\n“detached HEAD”는 “보기는 하지만 건드리지는 마시오”와 같다. 따라서 현재 상태에서 어떤 변경도 만들지 말아야 한다. 저장소의 지난 상태를 살펴본 후에 git checkout master 명령어로 HEAD를 다시 붙인다.\n\n\n실행 취소를 하는 변경사항을 만들기 전에 저장소 상태를 확인하는 커밋 번호를 사용해야 한다는 것을 기억하는 것이 중요하다.\n흔한 실수는 커밋 번호를 사용하지 않는 것이다. 아래 예제에서는 커밋 번호가 f22b25e인 가장 최신 커밋(HEAD~1) 이전의 상태로 다시 되돌리고자 한다:\n\n\n\n\n\n\n그림 18.1: Git 복원(Checkout)\n\n\n\n그래서, 모두 한데 모아보자.\n\n\n\n\n\n\n그림 18.2: Git 동작방식 도식화\n\n\n\n\n\n\n\n\n\n힌트흔한 사례 단순화\n\n\n\ngit status 출력 결과를 주의 깊게 읽게 되면, 힌트가 포함된 것을 볼 수 있다.\n(use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n출력 결과가 언급하는 바는, 버전 식별자 없이 git checkout 명령어를 실행하게 되면\nHEAD에 저장된 상태로 파일을 원복시킨다는 것이다. 더블 대시 --가 필요한 경우는 명령어 자체로부터 복구해야 되는 파일명을 구별할 때다. 없는 경우, Git은 커밋 식별자에 파일명을 사용한다.\n\n\n파일이 하나씩 옛 상태로 되돌린다는 사실이 사람들이 작업을 조직하는 방식에 변화를 주는 경향이 있다.\n모든 것이 하나의 큰 문서로 되어 있다면,\n나중에 결론 부분에 변경사항을 실행 취소하지 않고, 소개 부분에 변경을 다시 되돌리기가 쉽지 않다(하지만 불가능하지는 않다).\n다른 한편으로 만약 소개 부분과 결론 부분이 다른 파일에 저장되어 있다면,\n시간 앞뒤로 이동하기가 훨씬 쉽다.\n\n\n\n\n\n\n힌트파일의 이전 버전 복구하기\n\n\n\n정훈이가 몇 주 동안 작업한 파이썬 스크립트에 변경을 했고, 오늘 아침 정훈이가 작업한 변경 사항이 스크립트를 “망가뜨려서” 더 이상 실행이 되지 않는다. 백업도 없이, 버그를 고치는 데 1시간 이상 소모했다…\n다행스럽게도, Git을 사용한 프로젝트 버전을 추적하고 있었다! 다음 아래 명령어 중 어떤 것이 data_cruncher.py로 불리는 파이썬 스크립트의 가장 최근 버전을\n복구하게 할까?\n\n$ git checkout HEAD\n$ git checkout HEAD data_cruncher.py\n$ git checkout HEAD~1 data_cruncher.py\n$ git checkout &lt;unique ID of last commit&gt; data_cruncher.py\n2번과 4번 모두\n\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n정답은 (5)-2번과 4번 모두.\ncheckout 명령어는 저장소에서 파일을 복원하여 작업 디렉토리에 있는 파일을 덮어쓴다. 답안 2번과 4번은 모두 저장소에 있는 data_cruncher.py 파일의 최신 버전을 복원한다. 답안 2번은 최신 버전을 나타내기 위해 HEAD를 사용하고, 답안 4번은 HEAD가 의미하는 바로 그 마지막 커밋의 고유한 ID를 사용한다는 차이만 있다.\n답안 3번은 HEAD 이전 커밋에서 data_cruncher.py의 버전을 가져오는데, 이는 원하는 바가 아니다.\n답안 1번은 위험할 수 있다! 파일명이 없으면 git checkout은 현재 디렉토리(및 그 아래의 모든 디렉토리)에 있는 모든 파일을 지정된 커밋 상태로 복원한다. 이 명령어는 data_cruncher.py를 최신 커밋 버전으로 복원하지만, 변경된 다른 모든 파일도 해당 버전으로 복원하여 해당 파일들에 대해 수행했을 수 있는 모든 변경 사항을 지워버린다! 위에서 논의했듯이, HEAD가 분리된 상태로 남게 되는데, 그런 상태에 놓여지는 것은 위험하다.\n\n\n\n\n\n\n\n\n\n\n\n힌트커밋 되돌리기\n\n\n\n정훈이는 동료와 함께 파이썬 코드를 협업해서 작성하고 있다. 그룹 저장소에 마지막으로 커밋한 것이 잘못된 것을 알게 되어서, 실행 취소하여 원복하고자 한다.\n정훈이는 실행 취소를 올바르게 해서 그룹 저장소를 사용하는\n모든 구성원이 제대로 된 변경사항을 가지고 작업을 계속하길 원한다. git revert [잘못된 커밋 ID] 명령어는 정훈이가 이전에 잘못 커밋했던 작업에 대해 실행 취소하는 커밋을 새로 생성시킨다. \n따라서, git revert는 git checkout [커밋 ID]와 다른데 이유는 checkout이 그룹 저장소에 커밋되지 않는 로컬 변경사항에\n대해서 적용된다는 점에서 차이가 난다. 정훈이가 git revert를 사용할 올바른 절차와 설명이 아래에 나와 있다. 빠진 명령어가 무엇일까?\n\n`________ # 커밋 ID를 찾을 수 있도록 Git 프로젝트 이력을 살펴본다.\nID를 복사한다. (ID의 첫 문자 몇 개만 사용한다. 예를 들어, 0b1d055).\ngit revert [커밋 ID]\n새로운 커밋 메시지를 타이핑한다.\n저장하고 종료한다.\n\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n명령어 git log는 커밋 ID와 함께 프로젝트 이력을 나열한다.\n명령어 git show HEAD는 최신 커밋에서 이루어진 변경 사항을 보여주고, 커밋 ID를 나열한다. 그러나 정훈이는 그것이 정확한 커밋인지, 그리고 다른 누군가 저장소에 변경 사항을 커밋하지 않았는지 다시 한 번 확인해야 한다.\n\n\n\n\n\n\n\n\n\n\n\n힌트작업흐름과 이력 이해하기\n\n\n\n다음 마지막 명령의 출력 결과는 무엇일까?\n$ cd planets\n$ echo \"Venus is beautiful and full of love\" &gt; venus.txt\n$ git add venus.txt\n$ echo \"Venus is too hot to be suitable as a base\" &gt;&gt; venus.txt\n$ git commit -m \"Comment on Venus as an unsuitable base\"\n$ git checkout HEAD venus.txt\n$ cat venus.txt #this will print the contents of venus.txt to the screen\n\n   Venus is too hot to be suitable as a base\n   Venus is beautiful and full of love\n   Venus is beautiful and full of love\n   Venus is too hot to be suitable as a base\n   Error because you have changed venus.txt without committing the changes\n\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n정답은 2번이다.\ngit add venus.txt 명령어는 venus.txt의 현재 버전을 준비 영역에 올려놓는다. 두 번째 echo 명령어로 인한 파일의 변경사항은 작업 복사본에만 적용되고, 준비 영역에 있는 버전에는 적용되지 않는다.\n따라서 git commit -m \"Comment on Venus as an unsuitable base\"가 실행될 때, 저장소에 커밋되는 venus.txt의 버전은 준비 영역에 있는 것으로, 한 줄만 가지고 있다.\n이때 작업 복사본은 여전히 두 번째 줄을 가지고 있고(git status는 파일이 수정되었음을 보여줄 것이다). 그러나 git checkout HEAD venus.txt는 작업 복사본을 venus.txt의 가장 최근에 커밋된 버전으로 대체한다.\n그래서 cat venus.txt는 다음과 같이 출력될 것이다.\nVenus is beautiful and full of love.\n\n\n\n\n\n\n\n\n\n\n\n힌트git diff 이해 확인하기\n\n\n\ngit diff HEAD~3 mars.txt 명령어를 고려해 보자. 이 명령어를 실행하게 되면 실행 결과로 예상하는 바를 말해보자. 명령어를 실행하게 되면 어떤 일이 발생하는가? 그리고 이유는 무엇인가? \n또 다른 명령어 git diff [ID] mars.txt를 시도해 보자.\n여기서, [ID]를 가장 최근 커밋 식별자로 치환한다. 무슨 일이 생길까? 그리고 실제로 생긴 일은 무엇인가?\n\n\n\n\n\n\n\n\n힌트준비 단계 변경사항(Staged Changes) 제거하기\n\n\n\ngit checkout 명령어를 통해서 준비영역으로 올라오지 않은 변경사항이 있을 때, 이전 커밋을 복구할 수 있었다. 하지만, git checkout은 준비영역에 올라왔지만, 커밋되지 않는 변경사항에 대해서도 동작한다. mars.txt 파일에 변경사항을 만들고, 변경사항을 추가하고 나서,\ngit checkout 명령어를 사용하게 되면 변경사항이 사라졌는지 살펴보자.\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n변경사항을 추가한 후에는 git checkout을 직접 사용할 수 없다. git status 출력 결과를 살펴보자.\nOn branch main\nChanges to be committed:\n  (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n\n        modified:   mars.txt\n동일한 출력 결과가 나오지 않는다면 파일 변경을 잊었거나, 추가하고 커밋까지 한 상태일 수 있다.\n이 상태에서 git checkout -- mars.txt 명령어를 사용하면 오류는 발생하지 않지만, 파일도 복원되지 않는다. Git은 파일을 unstage하기 위해 먼저 git reset을 사용해야 한다고 친절하게 알려준다. \n$ git reset HEAD mars.txt\n\nUnstaged changes after reset:\nM   mars.txt\n이제 git status를 실행하면 다음과 같은 결과가 화면에 출력된다.\n$ git status\n\nOn branch main\nChanges not staged for commit:\n(use \"git add &lt;file&gt;...\" to update what will be committed)\n(use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n      modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n이는 이제 git checkout을 사용하여 파일을 이전 커밋 상태로 복원할 수 있다는 것을 의미하게 된다.\n\n$ git checkout -- mars.txt\n$ git status\n\nOn branch main\nnothing to commit, working tree clean\n\n\n\n\n\n\n\n\n\n\n\n힌트변경 이력 탐색과 요약\n\n\n\n변경 이력 탐색은 Git에 있어 중요한 부분 중의 하나로,\n특히 커밋이 수개월 전에 이뤄졌다면, 올바른 커밋 ID를 찾는 것이 종종 크나큰 도전과제가 된다. planets 프로젝트가 50개 파일 이상으로 구성되었다고 상상해 보자.\nmars.txt 파일에 특정 텍스트가 변경된 커밋을 찾고자 한다. git log를 타이핑하게 되면 매우 긴 목록이 출력된다. 어떻게 하면 검색 범위를 좁힐 수 있을까? git diff 명령어가 특정 파일만 탐색할 수 있다는 점을 상기하자.\n예를 들어, git diff mars.txt. 이 문제에 유사한 아이디어를 적용해 보자.\n$ git log mars.txt\n불행하게도 커밋 메시지 일부는 매우 애매모호하다. 예를 들어, update files. 어떻게 하면 파일을 잘 검색할 수 있을까? git diff, git log 명령어 모두 매우 유용하다. 두 명령어 모두 변경 이력의 다른 부분을 요약해 준다. 둘을 조합하는 것은 가능할까? 다음 명령어를 실행해 보자:\n$ git log --patch mars.txt\n엄청 긴 출력 목록이 나타난다. 각 커밋마다 커밋 메시지와 차이가 쭉 출력된다. 질문: 다음 명령어는 무슨 작업을 수행할까요?\n$ git log --patch HEAD~3 *.txt",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>이력 탐색</span>"
    ]
  },
  {
    "objectID": "git-ignore.html",
    "href": "git-ignore.html",
    "title": "19  추적 대상에서 제외",
    "section": "",
    "text": "만약 Git이 추적하기를 원하지 않는 파일이 있다면 어떻게 해야 할까요? 편집기에서 자동 생성되는 백업 파일이나 자료 분석 중에 생성되는 임시 파일들이 좋은 예가 될 수 있다. 몇 개의 더미(dummy) 파일을 생성해 보자. \n$ mkdir results\n$ touch a.dat b.dat c.dat results/a.out results/b.out\n그러면 Git은 다음과 같이 보여줍니다:\n$ git status\n\nOn branch master\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    a.dat\n    b.dat\n    c.dat\n    results/\nnothing added to commit but untracked files present (use \"git add\" to track)\n버전 관리 아래 이런 파일들을 두는 것은 디스크 공간 낭비다. 더 나쁜 것은, 이런 파일들을 모두 관리 목록에 넣으면 실제로 중요한 변경 사항을 관리하는 데 집중하기 어렵다는 점이다. 그래서 Git에게 이런 중요하지 않은 파일들은 무시하라고 알려준다.\n프로젝트의 루트 디렉터리에 .gitignore라는 파일을 생성하고 무시할 파일들을 명시함으로써 해당 작업을 수행할 수 있다. \n$ nano .gitignore\n$ cat .gitignore\n\n*.dat\nresults/\n위의 패턴은 .dat 확장자를 가진 모든 파일과 results 디렉터리에 있는 모든 것을 무시하라는 의미다. (하지만 이들 중 일부 파일이 이미 추적되고 있다면, Git은 계속해서 추적할 것이다.)\n.gitignore 파일을 생성하자마자, git status 출력 결과는 훨씬 깔끔해졌다.\n$ git status\n\nOn branch master\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    .gitignore\nnothing added to commit but untracked files present (use \"git add\" to track)\n이제 Git이 알아차리는 유일한 것은 새로 생성된 .gitignore 파일뿐이다. 이 파일들을 추적하여 관리하지 않아도 된다고 생각할 수 있지만, 저장소를 공유하는 다른 모든 사람들도 우리가 추적하지 않는 것과 동일한 파일들을 무시하기를 원할 것이다. 그러므로 .gitignore를 추가하고 커밋한다.\n$ git add .gitignore\n$ git commit -m \"Ignore data files and the results folder.\"\n$ git status\n\n# On branch master\nnothing to commit, working directory clean\n보너스로, .gitignore는 실수로 추적하고 싶지 않은 파일이 저장소에 추가되는 것을 방지하는 데 도움이 된다.\n$ git add a.dat\n\nThe following paths are ignored by one of your .gitignore files:\na.dat\nUse -f if you really want to add them.\n만약 .gitignore 설정에도 불구하고 파일을 추가하려면, git add -f를 사용하여 강제로 Git에 파일을 추가할 수 있다. 예를 들어, git add -f a.dat와 같이 사용한다. 추적되지 않는 파일의 상태를 항상 보려면 다음 명령어를 사용하면 된다.\n$ git status --ignored\n\nOn branch master\nIgnored files:\n (use \"git add -f &lt;file&gt;...\" to include in what will be committed)\n\n        a.dat\n        b.dat\n        c.dat\n        results/\n\nnothing to commit, working directory clean\n\n\n\n\n\n\n힌트중첩된 파일 추적하지 않기\n\n\n\n디렉터리 구조가 다음과 같다고 가정해 보자.\nresults/data\nresults/plots\nresults/plots만 추적하지 않고, results/data 디렉터리는 추적하려면 어떻게 해야 할까?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n대부분의 프로그래밍 이슈와 마찬가지로, 이 문제를 해결하는 몇 가지 방법이 있다. results/plots 디렉터리의 내용만 추적하지 않기로 한다면, .gitignore 파일에서 /plots/ 폴더만 추적하지 않도록 다음과 같이 수정하면 된다.\nresults/plots/\n반대로 /results/ 디렉터리의 모든 것을 추적하지 않되, results/data만 예외로 추적하고 싶다면,\n.gitignore 파일에 results/를 추가하고 results/data/에 대해서는 예외 처리를 해주면 된다. 다음 도전 과제에서 이러한 유형의 해법을 다루게 될 것이다.\n종종 ** 패턴이 사용하기 편리한데, 이는 다수의 디렉터리와 매칭될 수 있기 때문이다. 예를 들어, **/results/plots/*은 루트 디렉터리 아래 어디에 있든 results/plots 디렉터리를 추적하지 않는다.\n\n\n\n\n\n\n\n\n\n\n\n힌트특정 파일만 포함시키기\n\n\n\nfinal.data 파일만 제외하고 모든 .data 파일을 추적하지 않으려면 어떻게 하면 될까? 힌트: ! (느낌표 연산자)가 수행하는 작업을 알아본다. \n\n\n\n\n\n\n주의해답\n\n\n\n\n\n.gitignore 파일에 다음 두 줄을 추가한다:\n*.data           # 모든 data 파일을 추적하지 않는다.\n!final.data      # final.data 파일은 예외로 추적한다. \n느낌표 연산자는 앞서 제외된 항목을 다시 포함시키는 역할을 한다.\n\n\n\n\n\n\n\n\n\n\n\n힌트중첩된 파일 무시하기: 변형\n\n\n\n앞선 중첩 파일 연습과 유사하지만, 약간 다른 디렉터리 구조를 가진 디렉터리 구조가 있다고 하자.\nresults/data\nresults/images\nresults/plots\nresults/analysis\nresults/data는 제외하고 results 폴더의 모든 내용을 무시하려면 어떻게 해야 할까?\n힌트: 이전에 ! 연산자로 예외를 만든 방법에 대해 조금 생각해 보자.\n\n\n\n\n\n\n주의해답\n\n\n\n\n\nresults/의 내용은 무시하되 results/data/의 내용은 무시하지 않으려면, .gitignore에서 results 폴더의 내용을 무시하되 results/data 하위 폴더의 내용에 대해서는 예외를 만들면 된다. 이 경우 .gitignore 파일은 다음과 같이 작성하면 된다.\nresults/*               # results 폴더의 모든 내용을 무시한다\n!results/data/          # results/data/의 내용은 무시하지 않는다\n\n\n\n\n\n\n\n\n\n\n\n힌트디렉터리의 모든 파일 추적하지 않기\n\n\n\n디렉터리 구조가 다음과 같다고 가정해 본다.\nresults/data/position/gps/a.data\nresults/data/position/gps/b.data\nresults/data/position/gps/c.data\nresults/data/position/gps/info.txt\nresults/plots\nresults/data/position/gps 디렉터리의 모든 .data 파일을 추적하지 않도록 .gitignore 파일에 규칙을 작성한다면, 가장 간결한 규칙은 무엇일까? 단, info.txt 파일은 추적되어야 한다.\n\n\n\n\n\n\n주의해답\n\n\n\n\n\nresults/data/position/gps/*.data 규칙은 results/data/position/gps 디렉터리에서 .data로 끝나는 모든 파일과 매칭된다. results/data/position/gps/info.txt 파일은 확장자가 다르기 때문에 계속 추적될 것다.\n\n\n\n\n\n\n\n\n\n\n\n힌트특정 디렉토리의 모든 파일 추적하지 않기\n\n\n\n저장소의 여러 하위 디렉터리에 많은 .csv 파일이 있다고 가정해 본다. 예를 들어 다음과 같은 파일 디렉토리 구조를 가질 수 있다.\nresults/a.csv\ndata/experiment_1/b.csv \ndata/experiment_2/c.csv\ndata/experiment_2/variation_1/d.csv\n해당 폴더의 이름을 명시적으로 나열하지 않고, 모든 .csv 파일을 무시하려면 어떻게 해야 할까?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n.gitignore 파일에 다음과 같이 작성한다.\n**/*.csv\n이렇게 하면 디렉토리 트리에서의 위치에 상관없이 모든 .csv 파일이 무시된다. 느낌표 연산자를 사용하여 특정 파일은 예외로 여전히 포함시킬 수도 있다.\n\n\n\n\n\n\n\n\n\n\n\n힌트적용 규칙 순서\n\n\n\n.gitignore 파일에 다음 내용이 포함되어 있다고 가정해 본다.\n*.csv\n!*.csv\n어떤 결과가 나올까?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n! 연산자는 이전에 정의된 제외 패턴을 부정한다. 따라서 .gitignore 파일에서 !*.csv 규칙은 앞서 제외했던 모든 .csv 파일을 다시 포함시킨다. 결과적으로 어떤 파일도 제외되지 않고, 모든 .csv 파일이 추적 대상이 된다.\n\n\n\n\n\n\n\n\n\n\n\n힌트로그 파일\n\n\n\n여러분이 작성한 스크립트가 log_01, log_02, log_03과 같은 형식의 중간 로그 파일을 다수 생성한다고 가정해 본다. 로그 파일들은 보관하고 싶지만, git으로 추적하고 싶지는 않은 경우가 있다.\n\nlog_01, log_02 등의 형식을 가진 모든 파일을 추적에서 제외하는 .gitignore 규칙을 하나 작성한다.\nlog_01 형식의 더미 파일을 생성하여 “제외 패턴”을 테스트한다.\n결국 log_01 파일이 매우 중요하다는 것을 알게 되어, .gitignore 파일은 변경하지 않고 해당 파일만 추적 대상에 포함시킨다.\n.gitignore를 통해 추적을 제외하고 싶은, 디렉터리에 있을 수 있는 다른 유형의 파일에는 어떤 것이 있을지 옆 사람과 의논해 보자.\n\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n\nlog_* 혹은 log* 규칙을 .gitignore 파일에 추가한다.\ngit add -f log_01 명령어를 사용하여 log_01 파일만 강제로 추적한다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>추적 대상에서 제외</span>"
    ]
  },
  {
    "objectID": "git-github.html",
    "href": "git-github.html",
    "title": "20  GitHub 원격 작업",
    "section": "",
    "text": "20.1 원격 저장소 생성\n버전 제어(version control)는 다른 사람과 협업할 때 진정으로 그 가치를 발휘한다. 우리는 이미 버전 제어를 위해 필요한 대부분의 작업을 수행했다. 한 가지 빠진 것은 한 저장소에서 다른 저장소로 변경 사항을 복사하는 것이다.\nGit 같은 시스템은 임의 두 저장소 사이에 작업 내용을 옮길 수 있는 기능을 제공한다. 하지만 실무에서는 다른 사람의 노트북이나 PC보다는 중앙 허브에 웹 방식으로 하나의 원본을 두고 사용하는 것이 가장 쉽다.\n대부분의 프로그래머는 프로그램 마스터 원본을 GitHub, BitBucket, GitLab 호스팅 서비스에 두고 사용한다. 이번 장 마지막 부분에서 이러한 접근법의 장점과 단점을 살펴본다.\n세상 사람들과 현재 프로젝트에서 변경한 사항을 공유하는 것에서부터 시작해보자. GitHub에 로그인하고 나서, 우측 상단 아이콘을 클릭해서 planets 이름으로 신규 저장소를 생성한다.\n저장소 이름을 “planets”으로 만들고 “Create Repository”를 클릭한다.\n저장소가 생성되자마자, GitHub는 URL을 가진 페이지와 로컬 저장소 환경 설정 방법에 대한 정보를 화면에 출력한다.\n다음 명령어가 실제로 GitHub 서버에서 자동으로 수행된다.\nmars.txt 파일을 추가하고 커밋한 이전 장을 상기한다면, 로컬 저장소는 다음과 같이 도식적으로 표현할 수 있다.\n이제 저장소가 두 개로 늘어서, 도식적으로 표현하면 다음과 같다.\n현재 로컬 저장소는 여전히 mars.txt 파일에 대한 이전 작업 정보를 담고 있다. 하지만 GitHub의 원격 저장소에는 아직 어떠한 파일도 담고 있지 않다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-github.html#원격-저장소-생성",
    "href": "git-github.html#원격-저장소-생성",
    "title": "20  GitHub 원격 작업",
    "section": "",
    "text": "그림 20.1: (1단계) GitHub 저장소 생성\n\n\n\n\n\n\n\n\n\n\n그림 20.2: (2단계) GitHub 저장소 생성\n\n\n\n\n\n\n\n\n\n\n그림 20.3: (3단계) GitHub 저장소 생성\n\n\n\n\n$ mkdir planets\n$ cd planets\n$ git init\n\n\n\n\n\n\n\n그림 20.4: Git 준비영역(Staging) 로컬 저장소\n\n\n\n\n\n\n\n\n\n\n그림 20.5: 신선한 신규 GitHub 저장소",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-github.html#로컬-저장소를-원격-저장소-연결",
    "href": "git-github.html#로컬-저장소를-원격-저장소-연결",
    "title": "20  GitHub 원격 작업",
    "section": "20.2 로컬 저장소를 원격 저장소 연결",
    "text": "20.2 로컬 저장소를 원격 저장소 연결\n 다음 단계는 두 저장소를 연결하는 것이다. 로컬 저장소를 위해서 GitHub 저장소를 원격(remote)으로 만들어 두 저장소를 연결한다. GitHub의 저장소 홈페이지에 식별하는 데 필요한 문자열이 포함되어 있다.\n\n\n\nGitHub 저장소 URL 발견장소\n\n\nHTTPS에서 SSH로 프로토콜(protocol)을 변경하려면 ‘SSH’ 링크를 클릭한다.\n브라우저에서 해당 URL을 복사한 후, 로컬 planets 저장소로 이동하여 아래 명령어를 실행한다.\n$ git remote add origin git@github.com:vlad/planets.git\n단, Vlad의 저장소 URL이 아닌 여러분의 저장소 URL을 사용해야 한다. 유일한 차이점은 vlad 대신 사용자 이름을 사용해야 한다는 것이다.\norigin이라는 이름은 원격 저장소에 대한 로컬 별명이다. 원한다면 다른 명칭을 사용할 수도 있지만, origin이 가장 일반적인 선택이다.\ngit remote -v 명령어를 실행해서 명령어가 제대로 작동했는지 확인한다.\n$ git remote -v\n\norigin   git@github.com:vlad/planets.git (fetch)\norigin   git@github.com:vlad/planets.git (push)\n\n\n\n\n\n\n힌트HTTPS vs. SSH\n\n\n\n \n여기서 SSH를 사용하는데, 이는 추가적인 설정이 필요하지만 많은 애플리케이션에서 널리 사용되는 보안 프로토콜이기 때문이다. 아래 단계는 GitHub를 위한 최소한의 수준에서 SSH를 설명하고 있다.\n\n\n\n\n\nGitHub 저장소 URL 변경",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-github.html#ssh-배경과-환경설정",
    "href": "git-github.html#ssh-배경과-환경설정",
    "title": "20  GitHub 원격 작업",
    "section": "20.3 SSH 배경과 환경설정",
    "text": "20.3 SSH 배경과 환경설정\n드라큘라가 원격 저장소에 연결하기 전에, 컴퓨터가 GitHub와 인증할 수 있는 방법을 설정해야 한다. 이를 통해 GitHub은 원격 저장소에 연결하려는 사람이 바로 드라큘라 본인임을 알 수 있다.\n많은 다양한 서비스에서 명령줄(command line)에 대한 접근을 인증하기 위해 일반적으로 사용되는 방법을 설정할 것이다. 방법을 보안 쉘 프로토콜(Secure Shell Protocol, SSH)이라고 한다. SSH는 보안이 안전하지 않은 네트워크에서도 컴퓨터 간에 안전한 통신을 가능하게 하는 암호화 네트워크 프로토콜이다.\nSSH는 키 쌍(key pair)이라는 것을 사용한다. 접근을 검증하기 위해 함께 작동하는 두 개의 키이다. 하나의 키는 공개적으로 알려져 있으며 공개 키(public key)라고 하고, 다른 키는 비밀 키(private key)라고 하며 비공개로 유지된다. 명칭 자체가 매우 직관적이다. \n공개 키는 자물쇠로, 본인만이 자물쇠를 열 수 있는 키(비밀 키)를 가지고 있다고 생각할 수 있다. GitHub 계정과 같이 안전한 통신 방법이 필요한 곳에 공개 키를 사용한다. 이 자물쇠, 즉 공개 키를 GitHub에 제공하고 “내 계정에 대한 통신을 이 키로 잠그세요. 그러면 내 비밀 키를 가진 컴퓨터만이 통신을 잠금 해제하고 내 GitHub 계정으로 git 명령을 보낼 수 있습니다.”라고 말한다.\n지금 할 일은 SSH 키를 설정하고 공개 키를 GitHub 계정에 추가하는 데 필요한 최소한의 작업이다. 가장 먼저 할 일은 현재 사용 중인 컴퓨터에서 해당 작업이 이미 완료되었는지 확인하는 것이다. 일반적으로 이러한 설정은 한 번만 이루어지면 되고, 이후에는 신경 쓸 필요가 없기 때문이다.\n\n\n\n\n\n\n힌트키 안전하게 보관하기\n\n\n\nSSH 키는 계정을 안전하게 유지하기 때문에 실제로 잊어서는 안 된다. 특히 여러 컴퓨터에서 계정에 접속하는 경우라면 가끔씩 보안 쉘 키를 점검하는 것이 좋은 습관이다.\n\n\n컴퓨터에 이미 존재하는 키 쌍을 확인하기 위해 ls 명령어를 실행한다.\nls -al ~/.ssh\n출력 결과는 사용자별로 사용 중인 컴퓨터에 SSH가 설정되어 있는지 여부에 따라 약간 달라진다. 드라큘라는 컴퓨터에 SSH를 설정한 적이 전혀 없으므로, 출력 결과는 다음과 같다.\nls: cannot access '/c/Users/Vlad Dracula/.ssh': No such file or directory\n만약 사용 중인 컴퓨터에 SSH가 설정되어 있다면, 공개 키와 비밀 키 쌍이 나열될 것이다. 파일 이름은 키 쌍이 설정된 방식에 따라 id_ed25519/id_ed25519.pub 또는 id_rsa/id_rsa.pub 중 하나다. 드라큘라 컴퓨터에는 이러한 키 쌍이 존재하지 않으므로, 다음 명령어를 사용하여 키 쌍을 생성한다.\n\n20.3.1 SSH 키 쌍 생성\nSSH 키 쌍을 생성하기 위해 드라큘라는 다음 명령어를 사용하는데, 여기서 -t 옵션은 사용할 알고리즘 유형을 지정하고 -C는 키에 주석(여기서는 드라큘라의 이메일)을 첨부한다.\n$ ssh-keygen -t ed25519 -C \"vlad@tran.sylvan.ia\"\n만약 Ed25519 알고리즘을 지원하지 않는 레거시 시스템을 사용 중이라면, 다음 명령어(ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\")를 사용한다.\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/c/Users/Vlad Dracula/.ssh/id_ed25519):\n기본 파일을 사용하고 싶으므로, 그냥 Enter 키를 누른다.\nCreated directory '/c/Users/Vlad Dracula/.ssh'.\nEnter passphrase (empty for no passphrase):\n이제 드라큘라에게 암호 문구(Passphrase)1를 입력하라고 요청한다. 다른 사람들이 가끔 접근할 수 있는 연구실 노트북을 사용하고 있기 때문에, 암호 문구를 생성하고 싶어 한다. “비밀번호 재설정” 옵션이 없으므로 기억하기 쉬운 것을 사용하거나 암호 문구를 어딘가에 저장해 두어야 한다.\nEnter same passphrase again:\n동일한 패스프레이즈를 한 번 더 입력한 후, 확인 메시지를 받는다.\nYour identification has been saved in /c/Users/Vlad Dracula/.ssh/id_ed25519\nYour public key has been saved in /c/Users/Vlad Dracula/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:SMSPIStNyA00KPxuYu94KpZgRAYjgt9g4BA4kFy3g1o vlad@tran.sylvan.ia\nThe key's randomart image is:\n+--[ED25519 256]--+\n|^B== o.          |\n|%*=.*.+          |\n|+=.E =.+         |\n| .=.+.o..        |\n|....  . S        |\n|.+ o             |\n|+ =              |\n|.o.o             |\n|oo+.             |\n+----[SHA256]-----+\n“identification”은 실제로 비밀 키이다. 비밀 키를 절대 공유해서는 안 된다. 공개 키는 적절하게 명명되었다. “key fingerprint”는 공개 키의 짧은 버전이다.\n이제 SSH 키를 생성했으므로, 확인해 보면 SSH 파일들을 찾을 수 있다.\n$ ls -al ~/.ssh\n\ndrwxr-xr-x 1 Vlad Dracula 197121   0 Jul 16 14:48 ./\ndrwxr-xr-x 1 Vlad Dracula 197121   0 Jul 16 14:48 ../\n-rw-r--r-- 1 Vlad Dracula 197121 419 Jul 16 14:48 id_ed25519\n-rw-r--r-- 1 Vlad Dracula 197121 106 Jul 16 14:48 id_ed25519.pub\n\n\n20.3.2 공개 키를 GitHub에 복사\n이제 SSH 키 쌍을 가지고 있고, GitHub 인증여부를 확인하기 위해 다음 명령어를 실행할 수 있다.\n$ ssh -T git@github.com\n\nThe authenticity of host 'github.com (192.30.255.112)' can't be established.\nRSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\nThis key is not known by any other names\nAre you sure you want to continue connecting (yes/no/[fingerprint])? y\nPlease type 'yes', 'no' or the fingerprint: yes\nWarning: Permanently added 'github.com' (RSA) to the list of known hosts.\ngit@github.com: Permission denied (publickey).\n맞다. GitHub에 공개 키를 제공해야 한다는 것을 잊었다!\n먼저, 공개 키를 복사해야 한다. 그렇지 않으면 비밀 키와 혼동을 일으킬 수 있기 때문에 .pub 확장자를 반드시 포함해야 한다.\n$ cat ~/.ssh/id_ed25519.pub\n\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDmRA3d51X0uu9wXek559gfn6UFNF69yZjChyBIU2qKI vlad@tran.sylvan.ia\n이제 &lt;GitHub.com&gt;에 접속하여, 오른쪽 상단 모서리에 있는 프로필 아이콘을 클릭하여 드롭다운 메뉴를 연다. “Settings”를 클릭하고, 설정 페이지에서 왼쪽의 “Account settings” 메뉴에서 “SSH and GPG keys”를 클릭한다. 오른쪽의 “New SSH key” 버튼을 클릭한다. 이제 제목을 추가할 수 있다(드라큘라는 원래 키 쌍 파일이 어디에 있는지 기억할 수 있도록 “Vlad’s Lab Laptop”이라는 제목을 사용한다). SSH 키를 필드에 붙여넣고 “Add SSH key”를 클릭하여 설정을 완료한다.\n이제 설정이 완료되었으니, 명령줄에서 인증을 다시 확인해 보자.\n$ ssh -T git@github.com\n\nHi Vlad! You've successfully authenticated, but GitHub does not provide shell access.\n좋다! 출력결과는 SSH 키가 의도한 대로 작동함을 확인해 준다. 이제 작업 내용을 원격 저장소에 푸시할 준비가 되었다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-github.html#로컬-변경사항-원격-저장소-푸시",
    "href": "git-github.html#로컬-변경사항-원격-저장소-푸시",
    "title": "20  GitHub 원격 작업",
    "section": "20.4 로컬 변경사항 원격 저장소 푸시",
    "text": "20.4 로컬 변경사항 원격 저장소 푸시\n이제 인증 설정이 완료되었으므로, 원격 저장소로 돌아갈 수 있다. 다음 명령어는 로컬 저장소에서의 변경 사항을 GitHub 저장소로 푸시한다.\n$ git push origin main\n드라큘라가 암호 문구(passphrase)를 설정했기 때문에, 명령어 실행 시 암호 문구를 입력하라는 프롬프트가 표시된다. 만약 인증에 대한 고급 설정을 완료했다면, 암호 문구를 요구하지 않을 것이다.\nEnumerating objects: 16, done.\nCounting objects: 100% (16/16), done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (11/11), done.\nWriting objects: 100% (16/16), 1.45 KiB | 372.00 KiB/s, done.\nTotal 16 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), done.\nTo https://github.com/vlad/planets.git\n * [new branch]      main -&gt; main\n\n\n\n\n\n\n힌트프록시(Proxy)\n\n\n\n만약 연결된 네트워크가 프록시를 사용한다면, “Could not resolve hostname” 오류 메시지로 인해서 마지막 명령어가 실패할 가능성이 있다. 이 문제를 해결하기 위해서는 프록시에 대한 정보를 Git에 전달할 필요가 있다.\n$ git config --global http.proxy http://user:password@proxy.url\n$ git config --global https.proxy http://user:password@proxy.url\n프록시를 사용하지 않는 또 다른 네트워크에 연결될 때는 Git에게 프록시 기능을 사용하지 않도록 다음 명령어를 사용하여 알려준다.\n$ git config --global --unset http.proxy\n$ git config --global --unset https.proxy\n\n\n\n\n\n\n\n\n힌트비밀번호 관리자\n\n\n\n운영체제에 비밀번호 관리자(password manager)가 설정되어 있다면, 사용자이름(username)과 비밀번호(password)가 필요할 때, git push 명령어가 이를 사용하려 한다. “Git Bash on Windows”를 사용하면 기본 디폴트 행동이다. 관리자 비밀번호를 사용하는 대신에, 터미널에서 사용자이름과 비밀번호를 입력하려면, git push를 실행하기 전에 터미널에서 다음과 같이 타이핑한다.\n$ unset SSH_ASKPASS\ngit uses SSH_ASKPASS for all credential entry에도 불구하고, SSH나 HTTPS를 경유하여 Git을 사용하든 SSH_ASKPASS를 설정하고 싶지 않을 수도 있다.\n~/.bashrc 파일 하단에 unset SSH_ASKPASS를 추가해서 Git으로 하여금 사용자명과 비밀번호를 사용하도록 기본설정으로 둘 수도 있다.\n\n\n이제 로컬 저장소와 원격 저장소는 다음과 같은 상태가 된다. \n\n\n\n\n\n\n그림 20.6: 첫 번째 푸시(Push) 다음 GitHub 저장소\n\n\n\n\n\n\n\n\n\n힌트‘-u’ 플래그(flag)\n\n\n\nGit 문서에서 git push와 함께 사용되는 -u 옵션을 볼 수 있다. git branch 명령어에 대한 --set-upstream-to 옵션과 동의어에 해당되는 옵션이다. 원격 브랜치를 현재 브랜치와 연결시키는 데 사용된다. 그래서 git pull 명령어가 아무런 인자 없이 사용될 수 있다. 원격 저장소가 설정되면, git push -u origin master 명령어만 실행시키면 연결 작업이 완료된다.\n\n\n또한, 원격 저장소에서 로컬 저장소로 변경 사항을 풀(pull)해서 가져올 수도 있다.\n$ git pull origin main\n\nFrom https://github.com/vlad/planets\n * branch            master     -&gt; FETCH_HEAD\nAlready up-to-date.\n이 경우 가져오기 하는 풀(pull)은 아무런 결과가 없는데, 이유는 두 저장소가 이미 동기화되어 있기 때문이다. 하지만 만약 누군가 GitHub 저장소에 변경 사항을 푸시했다면, 상기 명령어는 변경된 사항을 로컬 저장소로 다운로드한다.\n\n\n\n\n\n\n힌트GitHub 브라우저에서 직접 파일 업로드\n\n\n\nGitHub에서는 명령줄(command line)을 거치지 않고 브라우저를 떠나지 않은 채로 파일을 직접 저장소에 업로드할 수 있는 기능도 제공한다. 두 가지 방법이 있다. 첫째는 파일 트리 상단의 툴바에 있는 “Upload files” 버튼을 클릭하는 것이고, 둘째는 데스크톱에서 파일을 파일 트리로 드래그 앤 드롭하는 것이다. 이에 대한 자세한 내용은 GitHub 페이지에서 확인할 수 있다.\n\n\n\n\n\n\n\n\n힌트GitHub GUI\n\n\n\n\nGitHub 웹사이트에서 planets 저장소를 찾아간다. Code 탭 아래 “XX commits”(“XX”는 숫자) 텍스트를 클릭한다. 각 커밋 우측의 버튼 세 개를 여기저기 둘러보고, 클릭해 본다. 버튼을 눌러서 어떤 정보를 모을 수 있거나 탐색할 수 있는가? 쉘에서 동일한 정보를 어떻게 얻을 수 있을까?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n(클립보드 그림을 갖는) 가장 좌측 버튼은 클립보드에 커밋 식별자 전체를 복사한다. 쉘에서 git log 명령어가 각 커밋에 대한 전체 커밋 식별자를 보여준다.\n중간 버튼을 클릭하게 되면, 특정 커밋으로 변경한 내용 전체를 확인할 수 있다. 녹색 음영선은 추가를 붉은색 음영선은 삭제를 의미한다. 쉘에서 동일한 작업을 git diff로 할 수 있다. 특히, git diff ID1..ID2(ID1와 ID2는 커밋 식별자다) 명령어(즉, git diff a3bf1e5..041e637)는 두 커밋 사이 차이를 보여준다.\n가장 우측 버튼은 커밋 당시에 저장소의 모든 파일을 보여준다. 쉘로 이런 작업을 수행하려면, 해당 시점의 저장소를 checkout 해야 한다. 쉘에서 git checkout ID(여기서 ID는 살펴보려고 하는 커밋 식별자) 명령어를 실행하면 된다. checkout 하게 되면, 나중에 저장소를 올바른 상태로 되돌려 놓아야 된다는 것을 기억해야 한다.\n\n\n\n\n\n\n\n\n\n\n\n힌트GitHub 시간도장\n\n\n\n\nGitHub에 원격 저장소를 생성한다. 로컬 저장소의 콘텐츠를 원격 저장소로 푸시한다. 로컬 저장소에 변경 사항을 만들고, 변경 사항을 푸시한다.\n방금 생성한 GitHub 저장소로 가서 GitHub 변경 사항에 대한 시간도장(timestamps)을 살펴본다. GitHub이 시간 정보를 어떻게 기록하는가? 왜 그런가?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\nGitHub은 시간도장을 사람이 읽기 쉬운 형태로 표시한다(즉, “22 hours ago” 혹은 “three weeks ago”). 하지만 시간도장을 이리저리 살펴보면, 파일의 마지막 변경이 발생된 정확한 시간을 볼 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n힌트푸시(Push) vs. 커밋(Commit)\n\n\n\n \n이번 장에서, “git push” 명령어를 소개했다. “git push” 명령어가 “git commit” 명령어와 어떻게 다른가?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n변경 사항을 푸시하면, 로컬에서 변경한 사항을 원격 저장소와 상호 협의하여 최신 상태로 갱신한다. (흔히 다른 사람이 변경시킨 것을 공유하는 것도 이에 해당된다.) 커밋은 로컬 저장소만 갱신한다는 점에서 차이가 난다.\n\n\n\n\n\n\n\n\n\n\n\n힌트원격 설정 고치기\n\n\n\n원격 URL에 오탈자가 발생되는 일이 실무에서 흔히 발생한다. 이번 연습문제는 이런 유형의 이슈를 어떻게 고칠 수 있는지에 대한 것이다. 먼저 잘못된 URL을 원격(remote)에 추가하면서 시작해 보자.\ngit remote add broken https://github.com/this/url/is/invalid\ngit remote로 추가할 때 오류를 받았나요? 원격 URL이 적법한지 확인해 주는 명령어를 생각해 낼 수 있나요? URL을 어떻게 수정할 수 있을까요? (팁: git remote -h를 사용한다.) 이번 연습문제를 수행한 다음에 원격(remote)을 지워버리는 것을 잊지 말자.\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n원격(remote)를 추가할 때 어떤 오류 메시지도 볼 수 없다. (원격 remote를 추가하는 것은 Git에게 알려주기만 할 뿐 아직 사용하지는 않았기 때문이다.)\ngit push 명령어를 사용하자마자, 오류 메시지를 보게 된다. git remote set-url 명령어를 통해서 잘못된 원격 URL을 바꿔 문제를 해결하게 된다.\n\n\n\n\n\n\n\n\n\n\n\n힌트GitHub 라이선스와 README 파일\n\n\n\n이번 장에서 GitHub에 원격 저장소를 생성하는 방법을 배웠다. 하지만 GitHub 저장소를 초기화할 때 README.md 혹은 라이선스 파일을 추가하지 않았다. 로컬 저장소와 원격 저장소를 연결시킬 때 두 파일을 갖게 되면 무슨 일이 발생될 것으로 생각하는가?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n\n이런 경우, 관련없는 이력 때문에 병합 충돌(merge conflict)이 발생한다. GitHub에서 README.md 파일을 생성시키고 원격 저장소에서 커밋 작업을 수행한다. 로컬 저장소로 원격 저장소를 풀(pull)로 땡겨오면, Git이 origin과 공유되지 않는 이력을 탐지하고 병합(merge)을 거부해 버린다.\n$ git pull origin master\n \nFrom https://github.com/vlad/planets\n  * branch            master     -&gt; FETCH_HEAD\n  * [new branch]      master     -&gt; origin/master\nfatal: refusing to merge unrelated histories\n--allow-unrelated-histories 옵션으로 두 저장소를 강제로 병합(merge)시킬 수 있다. 이런 옵션을 사용할 때는 주의해야 한다. 병합하기 전에 로컬 저장소와 원격 저장소의 콘텐츠를 면밀히 조사해야 한다.\n$ git pull --allow-unrelated-histories origin master\n \nFrom https://github.com/vlad/planets\n  * branch            master     -&gt; FETCH_HEAD\nMerge made by the 'recursive' strategy.\nREADME.md | 1 +\n1 file changed, 1 insertion(+)\ncreate mode 100644 README.md",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-github.html#footnotes",
    "href": "git-github.html#footnotes",
    "title": "20  GitHub 원격 작업",
    "section": "",
    "text": "암호 문구는 암호(Password)와 비슷하지만 띄어쓰기를 포함한 더 긴 문장이나 구절을 사용한다는 점이 다르다. 예를 들어, “I love coding with ChatGPT!”와 같이 여러 단어로 이루어진 문장을 Passphrase로 사용할 수 있다. 암호 문구가 암호보다 길기 때문에 보안성이 더 높다고 여겨진다. 추측하거나 무작위로 대입하기가 더 어렵기 때문으로 IT 분야에서 암호 대신 Passphrase를 사용하는 것이 점점 더 일반화되고 있는 추세다.↩︎",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>GitHub 원격 작업</span>"
    ]
  },
  {
    "objectID": "git-open.html",
    "href": "git-open.html",
    "title": "21  공개 과학과 협업",
    "section": "",
    "text": "21.1 협업\n정보의 자유로운 공유는 과학에서 이상적일지 모르지만, 현실은 좀 더 복잡하다. 현재 일반적인 현장 상황은 다음과 같다.\n하지만 점점 더 많은 과학자들이 진행하는 연구 프로세스는 다음과 같다.\n이러한 공개 연구 모형은 발견을 가속화한다. 연구 작업이 더 많이 공개될수록 더 많이 인용되고 재사용된다. 하지만 이런 방식으로 작업하고 연구하고자 하는 사람들은 실무에서 “공개(open)”가 정확히 무엇을 의미하는지에 대해 몇 가지 결정을 내릴 필요가 있다. 공개 과학(Open Science)에 관한 다른 측면에 대해서는 Opening Science를 참고한다.\n이것이 버전 제어(version control)를 가르치는 (많은) 이유 중 하나다. 버전 제어가 꾸준히 사용될 때, 컴퓨터 작업에 대한 공유 가능한 전자 연구 노트로 활용되어 “방법”에 대한 질문에 답을 한다.\n앞서 개인 이력관리와 GitHub 저장소에 중점을 두었다면 공개과학을 위한 협업방법을 살펴보자. 먼저, 짝을 이룬다. 한 사람이 “소유자”(연습을 시작하는 데 사용될 GitHub 저장소 주인)가 되고, 다른 사람이 “협력자”(소유자 저장소를 복제해서 변경을 하는 사람)가 된다. 목표는 협력자가 변경 사항을 소유자 저장소에 추가하는 것이다. 마지막에는 역할을 바꿔서 두 사람 모두 소유자와 협력자의 역할을 수행한다.\n소유자가 협력자에게 접근 권한을 부여할 필요가 있다. GitHub에서 오른쪽에 ‘setting’ 버튼을 클릭해서 협력자(Collaborators)를 선택하고 파트너 이름을 입력한다.\n소유자 저장소에 접근 권한이 부여되면 협력자(Collaborator)는 https://github.com/notifications으로 이동한다. 그곳에서 소유자 저장소의 접근을 수락하면 된다.\n다음으로 협력자(Collaborator)는 소유자 저장소 사본을 본인 컴퓨터로 내려받는다. 이런 작업을 “저장소 복제(cloning a repo)”라고 부른다. 소유자의 저장소를 본인 바탕화면(Desktop) 폴더에 클론하려면 협력자는 다음 명령어를 입력한다.\n’vlad’를 소유자 사용자 이름(저장소를 소유하고 있는 사람)으로 바꾼다.\n앞서 작업했던 것과 정확히 동일한 방식으로 협력자는 이제 소유자의 저장소 클론에서 변경을 마음대로 할 수 있다:\n그리고 나서 변경 사항을 GitHub의 소유자 저장소로 푸시한다:\n주목할 점은 origin이라는 원격 저장소를 생성할 필요가 없다는 것이다. 저장소를 복제(clone)할 때 Git이 자동으로 origin 이름을 붙여준다. (수작업으로 원격 설정을 할 때 앞에서 왜 origin 이름을 사용한 것이 현명한 선택인지 이해할 수 있다.)\n이제 GitHub 웹사이트에서 소유자 저장소를 살펴본다(아마도 웹 브라우저를 새로 고침해야 할 수 있다). 협력자가 신규 커밋을 한 것을 확인할 수 있다.\n소유자 로컬 컴퓨터로 GitHub 원본 저장소의 변경 사항을 다운로드하려면 소유자는 다음과 같이 입력한다.\n저장소를 복제(clone)할 때 Git이 자동으로 origin 이름을 붙여주기 때문에, origin이라는 원격 저장소를 따로 생성할 필요가 없다는 점에 주목한다. (이것이 앞에서 원격 설정을 수작업으로 할 때 origin 이름을 사용한 것이 현명한 선택이었던 이유다.)\nGitHub에서 소유자 저장소를 다시 살펴보면, 협력자가 만든 새로운 커밋을 볼 수 있다. 새로운 커밋을 보려면 브라우저를 새로 고침해야 할 수도 있다.\nGitHub에서 협력자의 변경 사항을 다운로드하기 위해 이제 소유자는 다음을 입력한다.\n이제 저장소 3개(소유자 로컬 저장소, 협력자 로컬 저장소, GitHub의 소유자 저장소) 모두 동기화되었다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>공개 과학과 협업</span>"
    ]
  },
  {
    "objectID": "git-open.html#git-collab",
    "href": "git-open.html#git-collab",
    "title": "21  공개 과학과 협업",
    "section": "",
    "text": "힌트혼자 훈련하기\n\n\n\n혼자서 쭉 진행해 왔다면 두 번째 터미널을 열어서 계속 실습을 진행할 수 있다. 두 번째 윈도우가 여러분의 협력자를 나타내고 다른 컴퓨터에서 작업하고 있는 것으로 볼 수 있다. GitHub 접근 권한을 다른 사람에게 줄 필요가 없어졌다. 왜냐하면 두 협렵 ‘파트너’ 모두 본인이기 때문이다.\n\n\n\n\n\n\n\n\n\n그림 21.1: GitHub에 협업자(collaborators) 추가\n\n\n\n\n\n$ git clone https://github.com/vlad/planets.git ~/Desktop/vlad-planets\n\n\n\n\n\n\n\n그림 21.2: 저장소 클론한 후 모습\n\n\n\n\n$ cd ~/Desktop/vlad-planets\n$ nano pluto.txt\n$ cat pluto.txt\n\nIt is so a planet!\n$ git add pluto.txt\n$ git commit -m \"Add notes about Pluto\"\n\n 1 file changed, 1 insertion(+)\n create mode 100644 pluto.txt\n\n$ git push origin main\n\nCounting objects: 4, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 306 bytes, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo https://github.com/vlad/planets.git\n   9272da5..29aba7c  master -&gt; master\n\n\n\n$ git pull origin main\n\nremote: Counting objects: 4, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 3 (delta 0)\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/vlad/planets\n * branch            master     -&gt; FETCH_HEAD\nUpdating 9272da5..29aba7c\nFast-forward\n pluto.txt | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 pluto.txt\n\n\n\n\n\n\n\n\n힌트원격 저장소에 대해 좀 더 알아보기\n\n\n\n이제 로컬 저장소는 origin이라고 불리는 하나의 “원격 저장소”를 가지고 있었다. 원격 저장소는 다른 곳에 호스팅되어 있는 저장소의 복사본으로, 푸시(push)하고 풀(pull)할 수 있는 곳이며, 하나의 원격 저장소로만 작업해야 할 이유는 없다. 예를 들어, 대규모 프로젝트에서는 자신의 GitHub 계정에 자신만의 복사본을 가질 수도 있고(이를 origin이라고 부를 수 있음), 또한 메인 “상위” 프로젝트 저장소(예제에서는 이를 upstream이라고 부르겠음)를 가질 수 있다. 다른 사람들이 커밋한 최신 업데이트를 받기 위해 수시로 upstream에서 풀을 받을 것이다.\n원격 저장소에 부여하는 이름은 로컬에서만 존재한다는 것을 기억하자. 임의로 선택한 원격 저장소 별칭으로 origin이든, upstream이든, fred든 - 원격 저장소 고유한 것은 절대 아니다.\ngit remote 명령어 계열은 저장소와 연결된 원격 저장소를 설정하고 변경하는 데 사용된다. 가장 유용한 명령어들로 다음과 같은 것들이 있다.\n\ngit remote -v: 설정된 모든 원격 저장소를 나열한다.\ngit remote add [name] [url]: 새로운 원격 저장소를 추가하는 데 사용된다.\ngit remote remove [name]: 원격 저장소를 제거한다. 원격 저장소 자체에는 전혀 영향을 미치지 않고, 단지 로컬 저장소에서 그것에 대한 링크만 제거한다는 점에 유의한다.\ngit remote set-url [name] [newurl]: 원격 저장소와 연결된 URL을 변경한다. 원격 저장소가 이동했을 때 (예: 다른 GitHub 계정으로, 혹은 GitHub에서 다른 호스팅 서비스로), 또는 원격 저장소를 추가할 때 오타를 냈을 때 유용하다!\ngit remote rename [oldname] [newname]: 원격 저장소의 로컬 별칭, 즉 이름을 변경한다. 예를 들어, 이를 사용하여 upstream을 fred로 변경할 수 있다.\n\n\n\n\n$ git pull origin main\n\nremote: Enumerating objects: 4, done.\nremote: Counting objects: 100% (4/4), done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/vlad/planets\n * branch            main     -&gt; FETCH_HEAD  \n   9272da5..29aba7c  main     -&gt; origin/main\nUpdating 9272da5..29aba7c\nFast-forward\n pluto.txt | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 pluto.txt\n\n\n\n\n\n\n\n힌트기본적인 협업 작업 흐름\n\n\n\n\n실무에서 협업하는 저장소의 가장 최신 버전을 갖도록 확인하는 것이 좋다. 어떤 변경을 가하기 전에 git pull 명령어를 먼저 실행해야 한다. 기본적인 협업 작업 흐름은 다음과 같다:\n\ngit pull origin main 명령어로 본인 로컬 저장소를 최신 상태로 갱신한다.\n변경 작업을 수행하고 git add 명령어로 준비 단계(staging area)로 보낸다.\ngit commit -m 명령어로 변경 사항을 커밋한다.\nGitHub에 git push origin main 명령어로 변경 사항을 업로드한다.\n\n상당한 변경 사항을 포함한 단 한 번의 커밋보다는 작은 변화를 준 커밋을 많이 하는 것이 좋다. 작은 커밋이 가독성도 좋고 리뷰하기도 더 편하다.\n\n\n\n\n\n\n\n\n힌트역할을 바꾸고 반복한다\n\n\n\n역할을 바꿔서 전체 과정을 반복한다.\n\n\n\n\n\n\n\n\n힌트변경 사항 리뷰\n\n\n\n협력자에게 어떤 정보도 주지 않고 소유자가 저장소에 커밋을 푸시했다. 협력자는 명령줄(command line)을 통해 무엇이 변경되었는지 어떻게 알 수 있을까?\n\n\n\n\n\n\n주의해답\n\n\n\n\n\n명령줄에서 협력자는 로컬 저장소에 원격 저장소 변경 사항을 git fetch origin master 명령어를 사용해서 가져올 수 있다. 하지만 그 자체로 병합(merge)되는 것은 아니다. git diff master origin/main 명령어를 실행해서 협력자는 터미널에 변경 사항을 확인할 수 있다. \nGitHub에서도 협력자는 포크된 저장소로 가서 “This branch is 1 commit behind Our-Repository:master.” 메시지를 볼 수 있다. Compare 아이콘과 링크가 걸려 있다. Compare 페이지에서 협력자는 base fork를 본인 저장소로 변경하고 나서 “compare across forks” 위에 링크를 클릭한다. 마지막으로 head fork를 주 저장소로 변경한다. 이 작업을 하게 되면 차이 나는 모든 커밋을 볼 수 있게 된다.\n\n\n\n\n\n\n\n\n\n\n\n힌트GitHub에서 변경 사항 주석 달기\n\n\n\n협력자는 소유자가 변경한 한 줄에 대해 질문을 가질 수 있고 일부 제안 사항도 있다.\nGitHub으로 커밋 차이에 대해 주석을 다는 것도 가능하다. 파란색 주석 아이콘(comment icon)을 클릭하면 주석 윈도우(comment window)를 열 수 있다.\n협력자는 GitHub 인터페이스를 사용해서 코멘트와 제안을 남길 수 있다.\n\n\n\n\n\n\n\n\n힌트버전 이력, 백업, 그리고 버전 제어\n\n\n\n일부 백업 소프트웨어는 파일 버전에 대한 이력을 기록하고 있다. 또한 특정 버전을 복구하는 기능도 제공하고 있다. 이러한 기능이 버전 제어와 어떻게 다른가? 버전 제어, Git, GitHub을 사용하는 좋은 점은 무엇인가?",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>공개 과학과 협업</span>"
    ]
  },
  {
    "objectID": "git-open.html#git-licensing",
    "href": "git-open.html#git-licensing",
    "title": "21  공개 과학과 협업",
    "section": "21.2 라이선싱",
    "text": "21.2 라이선싱\n\n21.2.1 소프트웨어 라이선스\n\n소스 코드, 원고, 다른 창의적 저작물을 갖는 저장소가 공개될 때는 저장소 기반 디렉터리에 LICENSE 혹은 LICENSE.txt 파일을 포함해서 콘텐츠가 어떤 라이선스로 이용 가능한지를 명확히 기술해야 한다. 이유는 소스 코드가 창의적 저작물로서 자동적으로 지적재산(따라서 저작권) 보호 대상에 부합되기 때문이다. 자유로이 이용 가능한 것으로 보여지거나 명시적으로 광고되는 코드라고 해서 그런 보호가 유예되는 것은 아니다. 따라서 라이선스 문장이 없는 코드를 (재)사용하는 누구나 스스로 위험에 처하게 된다. 왜냐하면 소프트웨어 코드 저자가 언제라도 일방적으로 재사용을 불법화할 수 있기 때문이다. 즉, 저작권 소유자가 당신을 저작권법 위반으로 고소할 수 있다.\n라이선스는 그렇지 않다면 보유하지 못할 권리를 다른 사람(라이선스 허여자, licensee)에게 부여함으로써 이 문제를 해결한다. 어떤 조건 아래서 무슨 권리가 부여될지는 라이선스마다 다소 차이가 난다. 독점적 라이선스와 대조적으로, Open Source Initiative에서 공인된 오픈 라이선스(open licences)는 최소한 다음에 나온 권리를 모두 부여한다. 이런 권리를 오픈 소스 정의(Open Source Definition)로 부른다: \n\n소스 코드는 제약 없이 이용 가능하고 사용되고 재배포될 수 있다. 종합 배포의 일부로서도 포함된다.\n변형 혹은 다른 파생 저작물도 허락되고 또한 재배포될 수 있다.\n\n이런 권리를 누가 받느냐의 질문이 차별의 조건이 되지 않는다. 예를 들어 상업적 혹은 학술적처럼 노력 분야에 의해서가 아님도 포함된다.\n\n특히 지금까지 라이선스 몇 개가 인기를 얻고 있는데, choosealicense.com 웹사이트에서 본인 상황에 적합한 일반적인 라이선스를 선택하는 데 도움이 된다. 주요한 고려사항에는 다음이 포함된다:\n\n특허권을 주장하고자 하는가?\n파생 저작물을 배포하는 데 다른 사람도 소스 코드를 배포하도록 강제할 것인가?\n라이선싱하는 콘텐츠가 소스 코드인가?\n이왕이면 소스 코드도 라이선스할 것인가?\n\n적절한 라이선스를 가장 잘 선택하는 것이 상당히 많은 가능한 조합이 있어 주눅이 들 수도 있다. 실무에서 일부 라이선스만 지금까지 가장 인기가 있고 다음이 그 범주에 포함된다: \n\nGNU 일반공중 라이선스 (GPL),\nMIT 라이선스,\nBSD 라이선스,\n아파치 라이선스, 버전 2.0.\n\nGPL은 다른 대부분의 공개 소스 라이선스와 다른데, 전염성이 있는(infective) 특징이 있다. 코드의 수정된 버전을 배포하는 누구나 혹은 GPL 코드를 포함한 어느 것이든지 자신의 코드도 동일하게 자유로이 공개 가능하게 만들어야 한다.\n흔히 사용되는 라이선스를 선택하는 것이 기여자나 사용자의 삶을 편하게 한다. 왜냐하면 기여자나 사용자 모두 해당 라이선스에 친숙해서 사용할 때 상당한 양의 전문 용어를 꼼꼼히 살펴볼 필요가 없기 때문이다.\nOpen Source Initiative와 Free Software Foundation 모두 좋은 선택이 될 수 있는 라이선스 목록을 유지 관리하고 있다.\n코드를 작성하는 과학자 관점에서 라이선싱과 라이선싱 선택지에 대한 전반적인 정보를 [@Morin2012] 에서 살펴볼 수 있다.\n결국 가장 중요한 것은 라이선스가 무엇인지에 대해 분명한 문장이 있는지와 라이선스가 OSI와 FSF에서 승인되고 이미 검증된 것인지 여부다. 또한 저장소에 공개된 것이 아닐지라도, 처음부터 최선으로 라이선스를 선택해야 한다. 결정을 미루는 것은 나중에 더 복잡해진다. 왜냐하면 매번 새로운 협력자가 기여하기 시작하면 협력자도 저작권을 갖게 되기 때문이다. 따라서 라이선스를 고르자마자 승인을 득해야 할 필요가 있다.\n\n\n\n\n\n\n힌트본인이 오픈 라이선스를 사용할 수 있나요?\n\n\n\n여러분이 작성하고 있는 소프트웨어에 오픈 소스 소프트웨어 라이선스를 적용할 수 있는지 알아본다. 여러분이 라이선스 적용을 일방적으로 할 수 있는가? 혹은 여러분의 기관이나 조직의 다른 사람에게서 허락이 필요한가? 만약 그렇다면 누구일까?\n\n\n\n\n\n\n\n\n힌트본인은 어떤 라이선스를 이미 승인했나요?\n\n\n\n매일 사용하는 대다수 소프트웨어는 오픈 소스 소프트웨어로 출시되었다. 아래 목록 혹은 본인이 직접 고른 GitHub 사이트에서 프로젝트를 하나 고른다. 라이선스를 찾아(보통 LICENSE 혹은 COPYING 이름이 붙은 파일)보고, 소프트웨어 사용을 어떻게 제약하는지 살펴본다. 이번 절에서 논의된 라이선스 중 하나인가? 차이점은 어떻게 나는가?\n\nGit, 소스 코드 관리 도구\nCPython, 파이썬 언어 구현\nJupyter, 웹 기반 파이썬 노트북 프로젝트\nEtherPad, 실시간 협업 편집기\n\n\n\n\n\n21.2.2 콘텐츠 라이선스\n \n만약 저장소 콘텐츠가 소프트웨어가 아닌 데이터, 창의적 저작물(매뉴얼, 기술 보고서, 원고) 같은 연구 제품이 포함되면, 소프트웨어를 위해 설계된 라이선스 대부분은 적합하지 않다.\n\n데이터: 대부분 국가 사법권에서 데이터 유형 대부분은 자연에 대한 사실로 간주된다. 그러므로 저작권 보호를 받을 자격이 없다. (단, 아마도 사진과 의료 영상 정보 등은 예외) 따라서 저작자 표시로 사회적 혹은 학자적 기대치를 알리려고 저작권을 정의로 주장하는 방식으로 라이선스를 사용하는 것은 단지 법적으로 혼탁한 상황만 조장할 뿐이다. 크리에이티브 커먼즈 제로(Creative Commons Zero, CC0) 처럼 공중 도메인 권리 포기를 지지하는법적 표시를 분명히 하는 것이 더 낫다. Dryad 데이터 저장소는 사실 이를 요구하고 있다.\n창의적 저작물(Creative works): 매뉴얼, 보고서, 원고, 기타 창의적 저작물은 지적재산 보호 대상이 된다. 따라서 소프트웨어와 마찬가지로 자동으로 저작권으로 보호된다. 크리에이티브 커먼즈(Creative Commons) 조직이 기본 제약사항 4개를 조합해서 라이선스 집합을 마련했다:\n\n저작자 표시(Attribution): 파생 저작물에 대해서 최초 저작자의 이름, 출처 등의 정보를 반드시 표시해야 한다.\n변경 금지(No Derivative): 저작물을 복사할 수도 있으나 저작물을 변경하거나 저작물을 이용하여 2차적 저작물 제작을 금한다.\n동일조건변경허락(Share Alike): 2차적 저작물을 제작할 수 있으나, 2차적 저작물은 원래 저작물과 동일한 라이선스를 적용한다.\n비영리(Noncommercial): 저작물을 영리 목적으로 사용할 수 없다. 영리 목적을 위해서는 별도의 계약이 필요하다.\n\n\n출처 표시 (CC-BY)와 동일조건변경허락(CC-BY-SA) 라이선스만이 “오픈 라이선스”로 간주된다. \n소프트웨어 카펜트리는 가능하면 폭넓게 재사용될 수 있도록 수업 자료에 대해서는 CC-BY, 코드에는 MIT 라이선스를 사용한다. 다시 한번, 가장 중요한 것은 프로젝트 루트 디렉터리에 있는 LICENSE 파일에 라이선스가 무엇인지 분명하게 언급하는 것이다. 본인 프로젝트를 참조하는 방법을 기술하는 데 CITATION 혹은 CITATION.txt 파일을 포함할 수도 있다. 소프트웨어 카펜트리 사례는 다음과 같다:\nTo reference Software Carpentry in publications, please cite both of the following:\n\nGreg Wilson: \"Software Carpentry: Lessons Learned\". arXiv:1307.5448, July 2013.\n\n@online{wilson-software-carpentry-2013,\n  author      = {Greg Wilson},\n  title       = {Software Carpentry: Lessons Learned},\n  version     = {1},\n  date        = {2013-07-20},\n  eprinttype  = {arxiv},\n  eprint      = {1307.5448}\n}",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>공개 과학과 협업</span>"
    ]
  },
  {
    "objectID": "git-open.html#git-hosting",
    "href": "git-open.html#git-hosting",
    "title": "21  공개 과학과 협업",
    "section": "21.3 호스팅",
    "text": "21.3 호스팅\n\n저작물이나 작업을 공개하고자 하는 그룹에서 가지는 두 번째 큰 질문은 코드와 데이터를 어디에 호스팅할지 정하는 것이다. 방법 중 하나는 연구실, 학과, 혹은 대학이 서버를 제공하여 계정 관리와 백업 등을 관리하는 것이다. 주된 장점은 누가 무엇을 소유하는지 명확하다는 점이다. 특히 민감한 정보(예를 들어, 사람에 대한 실험 정보 혹은 특허 출원에 사용될 수도 있는 정보)가 있다면 중요하다. 큰 단점은 서비스 제공 비용과 수명이다. 데이터를 수집하는 데 10년을 보낸 과학자가 지금부터 10년 후에도 여전히 이용 가능하기를 원하지만, 학교 인프라를 지원하는 대부분의 연구 기금의 수명이 턱없이 짧다.\n또 다른 선택지는 도메인을 구입하고 호스팅하는 데 ISP(인터넷 서비스 제공자, Internet Service Provider)에 비용을 지불하는 것이다. 이 접근법은 개인이나 그룹에게 좀 더 많은 제어권을 주고 학교나 기관을 바꿀 때 생기는 문제도 비켜갈 수 있다. 하지만 위나 아래 선택지보다 초기 설정하는 데 더 많은 시간과 노력이 요구된다.\n세 번째 선택지는 GitHub, BitBucket, 혹은 SourceForge 같은 공개 호스팅 서비스를 채용하는 것이다. 웹 인터페이스를 통해서 저장소 코드를 생성하고, 보고, 편집할 수 있게 한다. 이러한 서비스는 이슈 추적, 위키 페이지, 이메일 통보, 코드 리뷰를 포함한 커뮤니케이션과 프로젝트 관리 도구도 제공한다. 이러한 서비스는 규모의 경제와 네트워크 효과로 모두 이익을 볼 수 있다. 즉, 동일한 표준을 갖는 작은 많은 서비스를 실행하는 것보다 큰 서비스 하나를 실행하는 것이 더 쉽다. 또한 사람들이 협업하기도 더 쉽다. 대중적인 서비스를 사용하면 이미 동일한 서비스를 사용하는 커뮤니티와 본인 프로젝트를 연결하는 데 도움이 된다.\n예를 들어 소프트웨어 카펜트리는 GitHub에 있어서 해당 페이지에 대한 소스 코드를 찾아볼 수 있다. GitHub 계정을 갖는 누구나 해당 페이지에 변경 사항을 제안할 수 있다.\nGitHub 저장소에서 Zenodo에 릴리스(release)를 연결하면 DOI를 부여할 수도 있다. 예를 들어 10.5281/zenodo.57467이 “Git 소개”에 대해 주조된 DOI다.\n규모가 크고 잘 정립된 서비스를 사용하는 것이 빠르게 강력한 도구의 장점을 흡수하는 데 도움을 줄 수도 있다. 지속적 통합(Continuous Integration, CI)이 그런 도구 중 하나로 자동으로 소프트웨어 빌드를 돌리고 코드가 커밋되거나 풀 요청이 제출될 때마다 실행된다. 온라인 호스팅 서비스와 CI의 직접 통합은 어떤 풀 요청에도 해당 정보가 존재해서 코드 완결성과 품질 표준을 유지하는 데 도움을 준다는 것을 의미한다. 여전히 CI가 자가 구축한 호스팅 환경에서도 이용 가능하지만 온라인 서비스 사용과 연계되면 초기 설정과 유지 보수 업무를 줄일 수 있다. 더욱이 이러한 도구가 오픈 소스 프로젝트에 무료로 제공되기도 한다. 사설 저장소에 대해서만 비용 일부를 지불하고 이용 가능하다.\n\n\n\n\n\n\n노트제도적 장벽\n\n\n\n공유가 과학에는 이상적이지만 많은 기관에서 공유에 제약을 가한다. 예를 들어 잠재적으로 특허 가능한 지적재산을 보호하는 데 말이다. 만약 여러분이 그런 제약과 마주한다면 특정 프로젝트 혹은 도메인에 예외를 요청하거나, 제도 혁파를 통해서 더 공개된 과학을 지지하도록 좀 더 앞서 나가는 데 근본적인 동기에 관해 질의하는 것이 더 생산적일 수 있다.\n\n\n\n\n\n\n\n\n힌트본인 작업을 공개할 수 있을까?\n\n\n\n본인 작업을 공개 저장소에 공개할 수 있는지 알아보자. 공개 작업을 일방적으로 할 수 있을까? 혹은 속한 조직의 누군가로부터 허락이 필요한가? 만약 그렇다면 조직의 누구일까?\n\n\n\n\n\n\n\n\n힌트본인 작업을 어디에 공개할 수 있을까?\n\n\n\n본인 논문, 데이터, 소프트웨어를 공유하려면 이용 가능한 저장소가 소속 기관에 갖추어져 있는가? 소속 기관 저장소는 arXiV, figshare, GitHub, GitLab과 같은 데이터 저장소 서비스와 비교하여 어떤 차이점이 있는가?",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>공개 과학과 협업</span>"
    ]
  },
  {
    "objectID": "git-conflict.html",
    "href": "git-conflict.html",
    "title": "22  충돌",
    "section": "",
    "text": "사람들이 병렬로 작업을 할 수 있게 됨에 따라, 누군가 다른 사람 작업 영역에 발을 들여 넣을 가능성이 생겼다. 혼자서 작업할 경우에도 이런 현상이 발생한다. 만약 개인 노트북과 연구실 서버에서 소프트웨어 개발을 한다면, 각 작업본에 다른 변경 사항을 만들 수 있다. 버전 제어(version control)는 겹치는 변경 사항을 해결(resolve)하는 도구를 제공함으로써 이러한 충돌(conflicts)을 관리할 수 있게 돕는다.\n충돌을 어떻게 해소할 수 있는지 확인하기 위해서 먼저 파일을 하나 생성하자. mars.txt 파일은 현재 두 협업하는 사람의 planets 저장소 사본에서 다음과 같이 보인다.\n파트너 사본에만 한 줄을 추가하자.\n그리고 나서 변경 사항을 GitHub에 푸시하자.\n이제 다른 파트너가 GitHub에서 갱신(update)하지 않고 본인 사본에 다른 변경 사항을 작업한다.\n로컬 저장소에 변경 사항을 커밋할 수 있다.\n하지만 Git이 GitHub에는 푸시할 수 없게 한다.\nGit이 푸시를 거절한다. 이유는 로컬 브랜치로 반영되지 않는 새로운 업데이트가 원격 저장소에 있음을 Git이 탐지했기 때문이다. 즉, 본인이 작업한 변경 사항이 다른 사람이 작업한 변경 사항과 중첩되는 것을 Git이 탐지해서 앞에서 작업한 것을 덮어쓰지 않도록 정지시킨다. 이제 해야 할 작업은 GitHub에서 변경 사항을 풀(Pull)해서 가져오고 현재 작업 중인 작업본과 병합(merge)해서 푸시한다. 풀(Pull)부터 시작하자.\ngit pull 명령어는 로컬 저장소를 갱신할 때 원격 저장소에 이미 반영된 변경 사항을 포함시키도록 한다. 원격 저장소 브랜치에서 변경 사항을 가져온(fetch) 후에 로컬 저장소 사본의 변경 사항이 원격 저장소 사본과 겹치는 것을 탐지해냈다. 따라서 앞서 작업한 것이 덮어쓰지 않도록 서로 다른 두 버전의 병합(merge)을 승인하지 않고 거절한 것이다. 해당 파일에 충돌나는 부분을 다음과 같이 표시해 놓는다.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD로 시작되는 부분에 본인 변경 사항이 나와 있다. Git이 자동으로 =======를 넣어 충돌나는 변경 사항 사이에 구분자로 넣고, &gt;&gt;&gt;&gt;&gt;&gt;&gt;기호는 GitHub에서 다운로드된 파일 내용의 마지막을 표시한다. (&gt;&gt;&gt;&gt;&gt;&gt;&gt;표시자 다음에 문자와 숫자로 구성된 문자열은 방금 다운로드한 커밋 번호의 식별자다.)\n파일을 편집해서 표시자/구분자를 제거하고 변경 사항을 일치시키는 것은 전적으로 여러분에게 달려 있다. 원하는 것이면 무엇이든 할 수 있다. 예를 들어 로컬 저장소의 변경 사항을 반영하든, 원격 저장소의 변경 사항을 반영하든, 로컬과 원격 저장소의 내용을 대체하는 새로운 것을 작성하든, 혹은 변경 사항을 완전히 제거하는 것도 가능하다. 로컬과 원격 모두 교체해서 다음과 같이 파일이 보이도록 하자.\n병합을 마무리하기 위해 병합으로 생성된 변경 사항을 mars.txt 파일에 추가하고 커밋한다.\n이제 변경 사항을 GitHub에 푸시할 수 있다.\nGit이 병합하면서 수행한 것을 모두 추적하고 있어서 수작업으로 다시 고칠 필요는 없다. 처음 변경 사항을 만든 협력자 프로그래머가 다시 풀하게 되면 다음과 같은 결과를 얻는다.\n병합된 파일을 얻게 된다.\n다시 병합할 필요는 없는데, 다른 누군가 작업을 했다는 것을 Git이 알기 때문이다.\n충돌을 해소하는 Git 기능은 매우 유용하지만, 충돌 해소에는 시간과 노력이 수반되고, 충돌이 올바르게 해소되지 않으면 오류가 스며들게 된다. 프로젝트 와중에 상당량의 충돌을 해소하는 데 시간을 쓰고 있다고 생각되면, 충돌을 줄일 수 있는 기술적인 접근법도 고려해 보는 것이 좋다.\n좀 더 자주 upstream을 풀(Pull)하기, 특히 새로운 작업을 시작하기 전이라면 더욱 그렇다. 작업을 구별하기 위해 토픽 브랜치를 사용해서 작업을 완료하면 메인(main) 브랜치에 병합시킨다. 좀 더 작게 원자 수준 커밋을 한다. 논리적으로 적절하다면 큰 파일을 좀 더 작은 것으로 쪼갠다. 그렇게 함으로써 두 저자가 동시에 동일한 파일을 변경하는 것을 줄일 수 있을 듯 싶다. 프로젝트 관리 전략으로 충돌을 최소화할 수도 있다.\n프로젝트 관리 전략으로 충돌을 최소화할 수도 있다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>충돌</span>"
    ]
  },
  {
    "objectID": "git-conflict.html#footnotes",
    "href": "git-conflict.html#footnotes",
    "title": "22  충돌",
    "section": "",
    "text": "AFK는 “Away From Keyboard”의 약자로 사용자가 컴퓨터 앞에 있지 않다는 것을 나타내는 데 사용된다. 주로 게임이나 채팅 중에 자리를 비울 때 다른 사용자들에게 알리기 위해 사용된다.↩︎",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>충돌</span>"
    ]
  },
  {
    "objectID": "git-ide.html",
    "href": "git-ide.html",
    "title": "23  통합개발환경",
    "section": "",
    "text": "연습문제\n데이터 분석 스크립트를 개발할 때 버전 제어(version control)는 매우 유용하다. R 프로그래밍 언어 전용 통합개발환경 RStudio는 Git과 통합이 잘 되어 있다. 몇몇 고급 Git 기능은 명령 프롬프트가 필요하지만, 일반적인 Git 작업에 대한 좋은 인터페이스를 RStudio을 통해 무료로 제공되고 있다.\nRStudio에서 작업 디렉토리와 연관된 프로젝트를 생성을 통해 관련 파일을 추적한다. Rstudio 프로젝트에 Git을 통합시켜 버전 제어를 함으로써 프로젝트 개발과정을 시간에 따라 추적하고, 이전 버전으로 되돌릴 수 있으며, 다른 사람과 협업을 원활히 수행할 수 있다. RStudio에서 Git을 이용하여 시작하려면, 새 프로젝트를 생성한다.\n프로젝트 생성 방식에 대해 묻는 대화 상자가 열린다. 여기서 몇 가지 옵션을 선택할 수 있다. 가령 이미 만들어 둔 planets 저장소를 RStudio에서 Git 저장소로 재사용한다고 가정해 보자. 저장소가 컴퓨터 디렉토리에 있으므로, “Existing Directory”(“기존 디렉토리”) 옵션을 선택한다.\n다음으로, RStudio가 기존 디렉토리를 사용하려는지 물어보게 된다. “Browse…”(“찾아보기…”)를 클릭해서 원하는 디렉토리로 이동한 후 “Create Project”(“프로젝트 생성”)를 클릭한다.\n이제 완성! 기존 planets 저장소에 RStudio 새 프로젝트를 생성했다. 메뉴에서 “Git” 메뉴를 확인해 보자. RStudio는 현재 디렉토리를 Git 저장소로 올바르게 인식했다. 또한, RStudio를 통해 Git을 자유롭게 활용할 수 있도록 필요한 다양한 도구들이 제공된다.\n저장소 기존 파일들을 편집하기 위해서, 우측 하단 “Files”(“파일”) 패널에서 클릭할 수 있다. 이제 명왕성에 대한 몇 가지 추가 정보를 명왕성 파일(pluto.txt)에 추가한다.\n파일을 편집한 후 Git 메뉴에서 “Commit…”(“커밋…”)을 클릭하여 변경사항을 저장할 수 있다.\n이제 어떤 파일을 커밋할지 선택할 수 있게 하고, 커밋 메시지를 입력할 수 있는 대화 상자를 연다. (“Staged” 적절한 상자를 체크하면 된다). “Status” 아이콘은 각 파일의 현재 상태를 나타낸다. 파일을 클릭하면 변경사항에 대한 정보가 아래 패널에 펼쳐진다.(git diff 출력이 활용된다). 모든 것이 원하는 대로 되면, “커밋”(“Commit”)을 클릭한다.\n변경사항을 푸시하려면 Git 메뉴에서 “브랜치 푸시”(“Push Branch”)를 선택하면 된다. 원격 저장소에서 가져오는(“Pull Branch”) 옵션도 있으며, 커밋 이력(“History”)을 보는 옵션도 있다:\n만약 “이력”(“History”)을 클릭한다면, 콘솔에서 git log 출력과 것과 같은 그래픽 버전으로 확인할 수 있다.\nRStudio는 프로젝트를 추적하는 데 많은 파일들을 자동생성한다. 종종 추적하고 싶지 않은 경우가 있다. 예를 들어, 데이터 크기가 큰 파일이나 API 인증키 같은 보안 정보가 포함된 파일들이다. 이럴 경우 파일명 혹은 디렉토리명을 .gitignore 파일에 추가한다.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>통합개발환경</span>"
    ]
  },
  {
    "objectID": "git-ide.html#연습문제",
    "href": "git-ide.html#연습문제",
    "title": "23  통합개발환경",
    "section": "",
    "text": "새로운 디렉토리를 만들어서 프로젝트에 graphs 디렉토리를 추가하시오.\n.gitignore 파일을 수정하여 graphs 디렉토리를 버전 제어에서 제외시키시오.",
    "crumbs": [
      "**3부** 버전제어와 협업",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>통합개발환경</span>"
    ]
  },
  {
    "objectID": "tool-regex.html",
    "href": "tool-regex.html",
    "title": "24  정규 표현식",
    "section": "",
    "text": "24.1 문자 매칭\n지금까지 파일을 훑어서 패턴을 찾고, 관심 있는 라인에서 다양한 비트(bits)를 뽑아냈다. stringr 패키지 str_split, str_detect 같은 문자열 함수를 사용하였고, 라인에서 일정 부분을 뽑아내기 위해서 리스트와 문자열 슬라이싱(slicing)을 사용했다.\n검색하고 추출하는 작업은 너무 자주 있는 일이어서 R과 파이썬 모두 상기와 같은 작업을 매우 우아하게 처리하는 정규 표현식(regular expressions)으로 불리는 매우 강력한 라이브러리를 제공한다. 정규 표현식을 책의 앞부분에 소개하지 않은 이유는 정규 표현식 라이브러리가 매우 강력하지만, 약간 복잡하고, 구문에 익숙해지는 데 시간이 필요하기 때문이다.\n정규표현식은 문자열을 검색하고 파싱하는 데 그 자체가 작은 프로그래밍 언어다. 사실, 책 전체가 정규 표현식을 주제로 쓰여진 책이 몇 권 있다. 이번 장에서는 정규 표현식의 기초만을 다룰 것이다. 정규 표현식의 좀 더 자세한 사항은 다음을 참조한다.\nR에서 정규표현식을 지원하는 패키지는 많지만, 대표적으로 stringr 패키지가 활용 사례도 많고 문서화도 충실하다. 정규 표현식 패키지를 사용하기 전에 패키지를 가져와야 한다. 정규 표현식 패키지의 가장 간단한 쓰임은 str_detect() 검색 함수다. 다음 프로그램은 검색 함수의 사소한 사용 예를 보여준다.\n파일을 열고, 각 라인을 루프로 반복해서 정규 표현식 stringr::str_detect() 함수를 호출하여 문자열 “From”이 포함된 라인만 출력한다. 상기 프로그램에는 진정으로 강력한 정규 표현식 기능이 사용되지 않았다. 왜냐하면, 다른 함수를 가지고도 동일한 결과를 쉽게 구현할 수 있기 때문이다.\n정규 표현식의 강력한 기능은 문자열에 해당하는 라인을 좀 더 정확하게 제어하기 위해서 검색 문자열에 특수문자를 추가할 때 확인될 수 있다. 매우 적은 코드를 작성할지라도, 정규 표현식에 특수 문자를 추가하는 것만으로도 정교한 일치(matching)와 추출이 가능하게 한다.\n예를 들어, 탈자 기호(caret)는 라인의 “시작”과 일치하는 정규 표현식에 사용된다. 다음과 같이 “From:”으로 시작하는 라인만 일치하도록 응용프로그램을 변경할 수 있다.\n“From:” 문자열로 시작하는 라인만 일치할 수 있다. 여전히 매우 간단한 프로그램으로 다른 패키지에서도 다양한 함수로 동일하게 수행할 수 있다. 하지만, 무엇을 정규 표현식과 매칭하는가에 대해서 특수 액션 문자(^)를 담아 강력한 제어를 수행하는 정규 표현식 개념을 소개하기에는 충분하다.\n좀 더 강력한 정규 표현식을 작성할 수 있는 다른 특수문자는 많이 있다. 가장 자주 사용되는 특수 문자는 임의 문자를 매칭하는 마침표다.\n다음 예제에서 정규 표현식 “F..m:”은 “From:”, “Fxxm:”, “F12m:”, “F!@m:’ 같은 임의 문자열을 매칭한다. 왜냐하면 정규 표현식 마침표 문자가 임의의 문자와 매칭되기 때문이다.\n정규 표현식에 “*”, “+’ ’ 문자를 사용하여 문자가 원하는 만큼 반복을 나타내는 기능과 결합되었을 때는 더욱 강력해진다.”*“,”+’ ’ 특수 문자가 검색 문자열에 문자 하나만을 매칭하는 대신에 별표 기호인 경우 0회 혹은 그 이상의 매칭, 더하기 기호인 경우 1회 혹은 그 이상의 문자의 매칭을 의미한다.\n다음 예제에서 반복 와일드 카드(wild card) 문자를 사용하여 매칭하는 라인을 좀 더 좁힐 수 있다.\n검색 문자열 “^From:.+@” 은 “From:” 으로 시작하고, “.+” 하나 혹은 그 이상의 문자들, 그리고 @ 기호와 매칭되는 라인을 성공적으로 찾아낸다. 그래서 다음 라인은 매칭이 될 것이다.\nFrom: stephen.marquard@uct.ac.za\n콜론(:)과 @ 기호 사이의 모든 문자들을 매칭하도록 확장하는 것으로 “.+” 와일드 카드를 간주할 수 있다.\nFrom:.+ @\n더하기와 별표 기호를 “밀어내기(pushy)” 문자로 생각하는 것이 좋다. 예를 들어, 다음 문자열은 “.+” 특수문자가 다음에 보여주듯이 밖으로 밀어내는 것처럼 문자열 마지막 @ 기호를 매칭한다.\nFrom:stephen.marquard@uct.ac.za, csev@umich.edu, and cwen @iupui.edu\n다른 특수문자를 추가함으로써 별표나 더하기 기호가 너무 “탐욕(greedy)”스럽지 않게 만들 수 있다. 와일드 카드 특수문자의 탐욕스러운 기능을 끄는 것에 대해서는 자세한 정보를 참조하기 바란다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-char-matching",
    "href": "tool-regex.html#regex-char-matching",
    "title": "24  정규 표현식",
    "section": "",
    "text": "R\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-extraction",
    "href": "tool-regex.html#regex-extraction",
    "title": "24  정규 표현식",
    "section": "\n24.2 데이터 추출",
    "text": "24.2 데이터 추출\nR stringr 패키지로 문자열에서 데이터를 추출하려면, str_extract_all() 함수를 사용해서 정규 표현식과 매칭되는 모든 부속 문자열을 추출할 수 있다. 형식에 관계없이 임의 라인에서 전자우편 주소 같은 문자열을 추출하는 예제를 사용해보자. 예를 들어, 다음 각 라인에서 전자우편 주소를 뽑아내고자 한다.\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\nReturn-Path: &lt;postmaster@collab.sakaiproject.org&gt;\n          for &lt;source@collab.sakaiproject.org&gt;;\nReceived: (from apache@localhost)\nAuthor: stephen.marquard@uct.ac.za\n각각의 라인에 대해서 다르게 쪼개고, 슬라이싱하면서 라인 각각의 형식에 맞추어 코드를 작성하고는 싶지는 않다. 다음 프로그램은 str_extract_all() 함수를 사용하여 전자우편 주소가 있는 라인을 찾아내고 하나 혹은 그 이상의 주소를 뽑아낸다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_extract_all() 함수는 두 번째 인자 패턴을 갖는 문자열을 찾아서 전자우편 주소처럼 보이는 모든 문자열을 리스트로 반환한다. 공백이 아닌 문자(\\\\S)와 매칭되는 가운데 @을 갖는 두 문자열 시퀀스(sequence)를 매칭한다.\n프로그램의 출력은 다음과 같다.\n\n[[1]]\n[1] \"csev@umich.edu\" \"cwen@iupui.edu\"\n\n정규 표현식을 해석하면, 적어도 하나의 공백이 아닌 문자, @과 적어도 하나 이상의 공백이 아닌 문자를 가진 부속 문자열을 찾는다. 또한, “\\\\S+” 특수 문자는 가능한 많이 공백이 아닌 문자를 매칭한다. (정규 표현식에서 “탐욕(greedy)” 매칭이라고 부른다.)\n정규 표현식은 두 번 매칭(csev@umich.edu, cwen@iupui.edu)하지만, 문자열 “@2PM”은 매칭을 하지 않는다. 왜냐하면, @ 기호 앞에 공백이 아닌 문자가 하나도 없기 때문이다. 프로그램의 정규 표현식을 사용해서 파일의 모든 라인을 읽고 다음과 같이 전자우편 주소처럼 보이는 모든 문자열을 출력한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n각 라인을 읽어 들이고, 정규 표현식과 매칭되는 모든 부속 문자열을 추출한다. str_extract() 함수는 문자 벡터를 반환하기 때문에, 전자우편 처럼 보이는 부속 문자열을 적어도 하나 찾아서 출력하기 위해서 반환 리스트 요소 숫자가 NA 여부를 간단히 확인한다.\n원데이터 mbox.txt 파일에 프로그램을 실행하면, 다음 출력을 얻는다.\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"&lt;postmaster@collab.sakaiproject.org&gt;\"\n[1] \"&lt;200801051412.m05ECIaH010327@nakamura.uits.iupui.edu&gt;\"\n[1] \"&lt;source@collab.sakaiproject.org&gt;;\"\n[1] \"&lt;source@collab.sakaiproject.org&gt;;\"\n[1] \"&lt;source@collab.sakaiproject.org&gt;;\"\n[1] \"apache@localhost)\"\n[1] \"source@collab.sakaiproject.org;\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"louis@media.berkeley.edu\"\n...\n전자우편 주소 몇몇은 “&lt;”, “;” 같은 잘못된 문자가 앞과 뒤에 붙어있다. 문자나 숫자로 시작하고 끝나는 문자열 부분만 관심 있다고 하자.\n그러기 위해서, 정규 표현식의 또 다른 기능을 사용한다. 매칭하려는 다중 허용 문자 집합을 표기하기 위해서 꺾쇠 괄호를 사용한다. 그런 의미에서 “\\S”은 공백이 아닌 문자 집합을 매칭하게 한다. 이제 매칭하려는 문자에 관해서 좀 더 명확해졌다.\n여기 새로운 정규 표현식이 있다.\n[a-zA-Z0-9]\\\\S*@\\\\S*[a-zA-Z]\n약간 복잡해졌다. 왜 정규 표현식이 자신만의 언어인가에 대해서 이해할 수 있다. 이 정규 표현식을 해석하면, 0회 혹은 그 이상의 공백이 아닌 문자(“\\\\S*”)로 하나의 소문자, 대문자 혹은 숫자(“[a-zA-Z0-9]”)를 가지며, @ 다음에 0회 혹은 그 이상의 공백이 아닌 문자(“\\\\S*”)로 하나의 소문자, 대문자 혹은 숫자(“[a-zA-Z0-9]”)로 된 부속 문자열을 찾는다. 0회 혹은 그 이상의 공백이 아닌 문자를 나타내기 위해서 “+”에서 “”으로 바꿨다. 왜냐하면 ”[a-zA-Z0-9]” 자체가 이미 하나의 공백이 아닌 문자이기 때문이다. ””, “+”는 단일 문자에 별표, 더하기 기호 왼편에 즉시 적용됨을 기억한다. \n프로그램에 정규 표현식을 사용하면, 데이터가 훨씬 깔끔해진다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"postmaster@collab.sakaiproject.org\"\n[1] \"200801051412.m05ECIaH010327@nakamura.uits.iupui.edu\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"apache@localhost\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"stephen.marquard@uct.ac.za\"\n[1] \"louis@media.berkeley.edu\"\n[1] \"postmaster@collab.sakaiproject.org\"\n[1] \"200801042308.m04N8v6O008125@nakamura.uits.iupui.edu\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"source@collab.sakaiproject.org\"\n[1] \"apache@localhost\"\n...\n“source@collab.sakaiproject.org” 라인에서 문자열 끝에 “&gt;” 문자를 정규 표현식으로 제거한 것을 주목한다. 정규 표현식 끝에 “[a-zA-Z]”을 추가하여서 정규 표현식 파서가 찾는 임의 문자열은 문자로만 끝나야 되기 때문이다. 그래서, “sakaiproject.org&gt;;”에서 “&gt;”을 봤을 때, “g”가 마지막 맞는 매칭이 되고, 거기서 마지막 매칭을 마치고 중단한다.\nstr_extract_all() 프로그램의 출력은 리스트의 단일 요소를 가진 문자열로 R 리스트이다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-search-extraction",
    "href": "tool-regex.html#regex-search-extraction",
    "title": "24  정규 표현식",
    "section": "\n24.3 검색과 추출 조합",
    "text": "24.3 검색과 추출 조합\n다음과 같은 “X-” 문자열로 시작하는 라인의 숫자를 찾고자 한다면,\nX-DSPAM-Confidence: 0.8475\nX-DSPAM-Probability: 0.0000  \n임의의 라인에서 임의 부동 소수점 숫자가 아니라 상기 구문을 가진 라인에서만 숫자를 추출하고자 한다.\n라인을 선택하기 위해서 다음과 같이 정규 표현식을 구성한다.\n^X-.*: [0-9.]+\n정규 표현식을 해석하면, ^에서 “X-”으로 시작하고, “.*“에서 0회 혹은 그 이상의 문자를 가지며, 콜론(”:“)이 나오고 나서 공백을 만족하는 라인을 찾는다. 공백 뒤에”[0-9.]+“에서 숫자(0-9) 혹은 점을 가진 하나 혹은 그 이상의 문자가 있어야 한다. 꺾쇠 기호 사이에 마침표는 실제 마침표만 매칭함을 주목하기 바란다. (즉, 꺾쇠 기호 사이는 와일드 카드 문자가 아니다.)\n관심을 가지고 있는 특정한 라인과 매우 정확하게 매칭이 되는 매우 빠듯한 정규 표현식으로 다음과 같다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램을 실행하면, 잘 걸러져서 찾고자 하는 라인만 볼 수 있다.\n[1] \"X-DSPAM-Confidence: 0.8475\"\n[1] \"X-DSPAM-Probability: 0.0000\"\n[1] \"X-DSPAM-Confidence: 0.6178\"\n[1] \"X-DSPAM-Probability: 0.0000\"\n[1] \"X-DSPAM-Confidence: 0.6961\"\n...\n하지만, 이제 str_split() 함수를 사용해서 숫자를 뽑아내는 문제를 해결해야 한다. str_split()을 사용하는 것이 간단해 보이지만, 동시에 라인을 검색하고 파싱하기 위해서 정규 표현식의 또 다른 기능을 사용할 수 있다.\n\n괄호는 정규 표현식의 또 다른 특수 문자다. 정규 표현식에 괄호를 추가한다면, 문자열이 매칭될 때, 무시된다. 하지만, str_match()를 사용할 때, 매칭할 전체 정규 표현식을 원할지라도, 정규 표현식을 매칭하는 부속 문자열의 부분만을 뽑아낸다는 것을 괄호가 표시한다.\n \n그래서, 프로그램을 다음과 같이 수정한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_detect()을 호출하는 대신에, 매칭 문자열의 부동 소수점 숫자만 뽑아내는 데 str_match()에 원하는 부동 소수점 숫자를 표현하는 정규 표현식 부분에 괄호를 추가한다.\n프로그램의 출력은 다음과 같다.\n[1] \"0.8475\"\n[1] \"0.0000\"\n[1] \"0.6178\"\n[1] \"0.0000\"\n[1] \"0.6961\"\n[1] \"0.0000\"\n[1] \"0.7565\"\n[1] \"0.0000\"\n[1] \"0.7626\"\n...\n숫자가 여전히 리스트에 있어서 문자열에서 부동 소수점으로 변환할 필요가 있지만, 흥미로운 정보를 찾아 뽑아내기 위해서 정규 표현식의 강력한 힘을 사용했다.\n이 기술을 활용한 또 다른 예제로, 파일을 살펴보면, 폼(form)을 가진 라인이 많다.\nDetails: http://source.sakaiproject.org/viewsvn/?view=rev&rev=39772\n상기 언급한 동일한 기법을 사용하여 모든 변경 번호(라인의 끝에 정수 숫자)를 추출하고자 한다면 다음과 같이 프로그램을 작성할 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n작성한 정규 표현식을 해석하면, “Details:”로 시작하는 “.*“에 임의의 문자들로,”rev=“을 포함하고 나서, 하나 혹은 그 이상의 숫자를 가진 라인을 찾는다. 전체 정규 표현식을 만족하는 라인을 찾고자 하지만, 라인 끝에 정수만을 추출하기 위해서”[0-9]+“을 괄호로 감쌌다.\n프로그램을 실행하면, 다음 출력을 얻는다.\n[1] \"39772\"\n[1] \"39771\"\n[1] \"39770\"\n[1] \"39769\"\n[1] \"39766\"\n[1] \"39765\"\n[1] \"39764\"\n...\n“[0-9]+”은 “탐욕(greedy)”스러워서, 숫자를 추출하기 전에 가능한 큰 문자열 숫자를 만들려고 한다는 것을 기억하라. 이런 “탐욕(greedy)”스러운 행동으로 인해서 왜 각 숫자로 모두 5자리 숫자를 얻은 이유가 된다. 정규 표현식 라이브러리는 양방향으로 파일 처음이나 끝에 숫자가 아닌 것을 마주칠 때까지 뻗어 나간다.\n이제 정규 표현식을 사용해서 각 전자우편 메시지의 요일에 관심이 있었던 책 앞의 연습 프로그램을 다시 작성한다. 다음 형식의 라인을 찾는다.\nFrom stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008\n그리고 나서, 각 라인의 요일의 시간을 추출하고자 한다. 앞에서 str_split를 두 번 호출하여 작업을 수행했다. 첫 번째는 라인을 단어로 쪼개고, 다섯 번째 단어를 뽑아내서, 관심 있는 두 문자를 뽑아내기 위해서 콜론 문자에서 다시 쪼갰다.\n작동을 할지 모르지만, 실질적으로 정말 부서지기 쉬운 코드로 라인이 잘 짜여져 있다고 가정하에 가능하다. 잘못된 형식의 라인이 나타날 때도 결코 망가지지 않는 프로그램을 담보하기 위해서 충분한 오류 검사 기능을 추가하거나 커다란 try/except 블록을 넣으면, 참 읽기 힘든 10-15 라인 코드로 커질 것이다.\n다음 정규 표현식으로 훨씬 간결하게 작성할 수 있다.\n^From .* [0-9][0-9]:\n상기 정규 표현식을 해석하면, 공백을 포함한 “From”으로 시작해서, “.*“에 임의 개수의 문자, 그리고 공백, 두 개의 숫자”[0-9][0-9]” 뒤에 콜론(:) 문자를 가진 라인을 찾는다. 일종의 찾고 있는 라인에 대한 정의다.\nstr_extract() 함수를 사용해서 단지 시간만 뽑아내기 위해서, 두 숫자에 괄호를 다음과 같이 추가한다.\n^From .* ([0-9][0-9]):\n작업 결과는 다음과 같이 프로그램에 반영한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램을 실행하면, 다음 출력 결과가 나온다.\n[1] \"09\"\n[1] \"18\"\n[1] \"16\"\n[1] \"15\"\n[1] \"15\"\n[1] \"14\"\n[1] \"11\"\n[1] \"11\"\n...",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-escape",
    "href": "tool-regex.html#regex-escape",
    "title": "24  정규 표현식",
    "section": "\n24.4 이스케이프 문자",
    "text": "24.4 이스케이프 문자\n라인의 처음과 끝을 매칭하거나, 와일드 카드를 명세하기 위해서 정규 표현식의 특수 문자를 사용했기 때문에, 정규 표현식에 사용된 문자가 “정상(normal)”적인 문자임을 표기할 방법이 필요하고 달러 기호와 탈자 기호(^) 같은 실제 문자를 매칭하고자 한다.\n역슬래시(\\)을 가진 문자를 앞에 덧붙여서 문자를 단순히 매칭하고자 한다고 나타낼 수 있다. 예를 들어, 다음 정규표현식으로 금액을 찾을 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n역슬래시 달러 기호를 앞에 덧붙여서(\\\\$), 실제로 “라인 끝(end of line)” 매칭 대신에 입력 문자열의 달러 기호와 매칭한다. 정규 표현식 나머지 부분은 하나 혹은 그 이상의 숫자 혹은 소수점 문자를 매칭한다. 주목: 꺾쇠 괄호 내부에 문자는 “특수 문자”가 아니다. 그래서 “[0-9.]”은 실제 숫자 혹은 점을 의미한다. 꺾쇠 괄호 외부에 점은 “와일드 카드(wild-card)” 문자이고 임의의 문자와 매칭한다. 꺾쇠 괄호 내부에서 점은 점일 뿐이다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-summary",
    "href": "tool-regex.html#regex-summary",
    "title": "24  정규 표현식",
    "section": "\n24.5 요약",
    "text": "24.5 요약\n지금까지 정규 표현식의 표면을 긁은 정도지만, 정규 표현식 언어에 대해서 조금 학습했다. 정규 표현식은 특수 문자로 구성된 검색 문자열로 “매칭(matching)”을 정의하고 매칭된 문자열로부터 추출된 결과물을 정규 표현식 시스템과 프로그래머가 의도한 바를 의사소통하는 것이다. 다음에 특수 문자 및 문자 시퀀스의 일부가 있다.\n\n\n^ 라인의 처음을 매칭.\n\n$ 라인의 끝을 매칭.\n\n. 임의의 문자를 매칭(와일드 카드)\n\ns 공백 문자를 매칭.\n\nS 공백이 아닌 문자를 매칭.(s 의 반대).\n\n* 바로 앞선 문자에 적용되고 0회 혹은 그 이상의 앞선 문자와 매칭을 표기.\n\n*? 바로 앞선 문자에 적용되고 0회 혹은 그 이상의 앞선 문자와 매칭을 “탐욕적이지 않은(non-greedy) 방식”으로 표기.\n\n+ 바로 앞선 문자에 적용되고 1회 혹은 그 이상의 앞선 문자와 매칭을 표기.\n\n+? 바로 앞선 문자에 적용되고 1회 혹은 그 이상의 앞선 문자와 매칭을 “탐욕적이지 않은(non-greedy) 방식”으로 표기.\n\n[aeiou] 명세된 집합 문자에 존재하는 단일 문자와 매칭. 다른 문자는 안 되고, “a”, “e”, “i”, “o”, “u” 문자만 매칭되는 예제.\n\n[a-z0-9] 음수 기호로 문자 범위를 명세할 수 있다. 소문자이거나 숫자인 단일 문자만 매칭되는 예제.\n\n[^A-Za-z] 집합 표기의 첫 문자가 ^인 경우, 로직을 거꾸로 적용한다. 대문자나 혹은 소문자가 아닌 임의 단일 문자만 매칭하는 예제.\n\n( ) 괄호가 정규표현식에 추가될 때, 매칭을 무시한다. 하지만 str_extract()을 사용할 때 전체 문자열보다 매칭된 문자열의 상세한 부속 문자열을 추출할 수 있게 한다.\n\n\\b 빈 문자열을 매칭하지만, 단어의 시작과 끝에만 사용.\n\n\\B 빈 문자열을 매칭하지만, 단어의 시작과 끝이 아닌 곳에 사용.\n\n\\d 임의 숫자와 매칭하여 [0-9] 집합에 상응.\n\n\\D 임의 숫자가 아닌 문자와 매칭하여 [^0-9] 집합에 상응.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#unix-users",
    "href": "tool-regex.html#unix-users",
    "title": "24  정규 표현식",
    "section": "\n24.6 유닉스 사용자 보너스",
    "text": "24.6 유닉스 사용자 보너스\n\n정규 표현식을 사용하여 파일을 검색하는 기능은 1960년대 이래로 유닉스 운영 시스템에 내장되어 여러 가지 형태로 거의 모든 프로그래밍 언어에서 이용 가능하다.\n사실, str_detect() 예제에서와 거의 동일한 기능을 하는 grep (Generalized Regular Expression Parser)으로 불리는 유닉스 내장 명령어 프로그램이 있다. 그래서, 맥킨토시나 리눅스 운영 시스템을 가지고 있다면, 명령어 창에서 다음 명령어를 시도할 수 있다.\n$ grep '^From:' mbox-short.txt\nFrom: stephen.marquard@uct.ac.za\nFrom: louis@media.berkeley.edu\nFrom: zqian@umich.edu\nFrom: rjlowe@iupui.edu\ngrep을 사용하여, mbox-short.txt 파일 내부에 “From:” 문자열로 시작하는 라인을 보여준다. grep 명령어를 가지고 약간 실험을 하고 grep에 대한 문서를 읽는다면, 파이썬에서 지원하는 정규표현식과 grep에서 지원되는 정규 표현식과 차이를 발견할 것이다. 예를 들어, grep은 공백이 아닌 문자 “\\S”을 지원하지 않는다. 그래서 약간 더 복잡한 집합 표기 “[^ ]”을 사용해야 한다. “[^ ]”은 간단히 정리하면, 공백을 제외한 임의의 문자와 매칭한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#regex-debugging",
    "href": "tool-regex.html#regex-debugging",
    "title": "24  정규 표현식",
    "section": "\n24.7 디버깅",
    "text": "24.7 디버깅\nR에 대해서 도움을 어떻게 받을 수 있을까?\n만약 특정 함수의 정확한 이름을 기억해 내기 위해서 빠르게 생각나게 하는 것이 필요하다면 도움이 많이 될 수 있는 간단하고 초보적인 내장 문서가 R에 포함되어 있다. 내장 문서 도움말은 인터랙티브 모드의 R 인터프리터에서 볼 수 있다.\n\n24.7.1 도움말 파일 읽어오기\n특정한 패키지를 사용하고자 한다면, ls(pos = \"package:패키지명) 명령어를 사용하여 다음과 같이 패키지에 포함된 함수를 찾을 수 있다. stringr 패키지는 파이썬 내장 re 패키지와 유사한 패턴 매칭 함수를 제공한다.\n\nls(pos = \"package:stringr\")\n#&gt;  [1] \"%&gt;%\"               \"boundary\"          \"coll\"             \n#&gt;  [4] \"fixed\"             \"fruit\"             \"invert_match\"     \n#&gt;  [7] \"regex\"             \"sentences\"         \"str_c\"            \n#&gt; [10] \"str_conv\"          \"str_count\"         \"str_detect\"       \n#&gt; [13] \"str_dup\"           \"str_ends\"          \"str_equal\"        \n#&gt; [16] \"str_escape\"        \"str_extract\"       \"str_extract_all\"  \n#&gt; [19] \"str_flatten\"       \"str_flatten_comma\" \"str_glue\"         \n#&gt; [22] \"str_glue_data\"     \"str_interp\"        \"str_length\"       \n#&gt; [25] \"str_like\"          \"str_locate\"        \"str_locate_all\"   \n#&gt; [28] \"str_match\"         \"str_match_all\"     \"str_order\"        \n#&gt; [31] \"str_pad\"           \"str_rank\"          \"str_remove\"       \n#&gt; [34] \"str_remove_all\"    \"str_replace\"       \"str_replace_all\"  \n#&gt; [37] \"str_replace_na\"    \"str_sort\"          \"str_split\"        \n#&gt; [40] \"str_split_1\"       \"str_split_fixed\"   \"str_split_i\"      \n#&gt; [43] \"str_squish\"        \"str_starts\"        \"str_sub\"          \n#&gt; [46] \"str_sub_all\"       \"str_sub&lt;-\"         \"str_subset\"       \n#&gt; [49] \"str_to_lower\"      \"str_to_sentence\"   \"str_to_title\"     \n#&gt; [52] \"str_to_upper\"      \"str_trim\"          \"str_trunc\"        \n#&gt; [55] \"str_unique\"        \"str_view\"          \"str_view_all\"     \n#&gt; [58] \"str_which\"         \"str_width\"         \"str_wrap\"         \n#&gt; [61] \"word\"              \"words\"\n\nR과 모든 팩키지는 함수에 대한 도움말 파일을 제공한다. 네임스페이스(인터랙티브 R 세션)에 적재된 팩키지에 있는 특정 함수에 대한 도움말은 다음과 같이 찾는다.\n\n?function_name\nhelp(function_name)\n\nRStudio에 도움말 페이지에 도움말이 표시된다. (혹은 R 자체로 일반 텍스트로 표시된다) 각 도움말 페이지는 절(section)로 구분된다:\n\n기술(Description): 함수가 어떤 작업을 수행하는가에 대한 충분한 기술\n사용법(Usage): 함수 인자와 기본 디폴트 설정값\n인자(Arguments): 각 인자가 예상하는 데이터 설명\n상세 설명(Details): 알고 있어야 되는 중요한 구체적인 설명\n값(Value): 함수가 반환하는 데이터\n함께 보기(See Also): 유용할 수 있는 연관된 함수.\n예제(Examples): 함수 사용법에 대한 예제들.\n\n함수마다 상이한 절을 갖추고 있다. 하지만, 상기 항목이 알고 있어야 하는 핵심 내용이다.\n\n\n\n\n\n\n힌트도움말 파일 불러 읽어오기\n\n\n\nR에 대해 가장 기죽게 되는 한 측면이 엄청난 함수 갯수다. 모든 함수에 대한 올바른 사용법을 기억하지 못하면, 엄두가 나지 않을 것이다. 운 좋게도, 도움말 파일로 인해 기억할 필요가 없다!\n\n\n\n24.7.2 특수 연산자\n특수 연산자에 대한 도움말을 찾으려면, 인용부호를 사용한다:\n\n?\"&lt;-\"\n\n\n24.7.3 팩키지 도움말 얻기\n많은 팩키지에 “소품문(vignettes)”이 따라온다. 활용법과 풍부한 예제를 담은 문서. 어떤 인자도 없이, vignette() 명령어를 입력하면 설치된 모든 팩키지에 대한 모든 소품문 목록이 출력된다, vignette(package=\"package-name\") 명령어는 package-name 팩키지명에 대한 이용 가능한 모든 소품문 목록을 출력하고, vignette(\"vignette-name\") 명령어는 특정된 소품문을 연다.\n팩키지에 어떤 소품문도 포함되지 않는다면, 일반적으로 help(\"package-name\") 명령어를 타이핑해서 도움말을 얻는다.\n\n24.7.4 함수가 기억나지 않을 때\n함수가 어느 팩키지에 있는지 확신을 못하거나, 구체적인 철자법을 모르는 경우, 퍼지 검색(fuzzy search)을 실행한다.\n\n??function_name\n\n\n24.7.5 시작조차 난감할 때\n어떤 함수 혹은 팩키지가 필요한지 모르는 경우, CRAN Task Views 사이트가 좋은 시작점이 된다. 유지 관리되는 팩키지 목록이 필드로 묶여 잘 정리되어 있다.\n\n24.7.6 코드가 동작하지 않을 때\n동료로부터 도움을 구해 코드가 동작하지 않는 이슈를 해결한다. 함수 사용에 어려움이 있는 경우, 10 에 9 경우에 찾는 정답이 이미 Stack Overflow에 답글이 달려 있다. 검색할 때 [r] 태그를 사용한다.\n원하는 답을 찾지 못한 경우, 동료에게 질문을 만드는 데 몇 가지 유용한 함수가 있다.\n\n?dput\n\ndput() 함수는 작업하고 있는 데이터를 텍스트 파일 형식으로 덤프해서 저장한다. 그래서 다른 사람 R 세션으로 복사해서 붙여넣기 좋게 돕는다.\n\nsessionInfo()\n#&gt; R version 4.5.0 (2025-04-11)\n#&gt; Platform: aarch64-apple-darwin20\n#&gt; Running under: macOS Sonoma 14.6.1\n#&gt; \n#&gt; Matrix products: default\n#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#&gt; \n#&gt; locale:\n#&gt; [1] ko_KR.UTF-8/ko_KR.UTF-8/ko_KR.UTF-8/C/ko_KR.UTF-8/ko_KR.UTF-8\n#&gt; \n#&gt; time zone: Asia/Seoul\n#&gt; tzcode source: internal\n#&gt; \n#&gt; attached base packages:\n#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] showtext_0.9-7   showtextdb_3.0   sysfonts_0.8.9   JuliaCall_0.17.6\n#&gt;  [5] rvest_1.0.4      gtExtras_0.6.0   gt_1.1.0         lubridate_1.9.4 \n#&gt;  [9] forcats_1.0.0    stringr_1.5.2    dplyr_1.1.4      purrr_1.1.0     \n#&gt; [13] readr_2.1.5      tidyr_1.3.1      tibble_3.3.0     ggplot2_4.0.0   \n#&gt; [17] tidyverse_2.0.0 \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;  [1] generics_0.1.4     xml2_1.4.0         stringi_1.8.7     \n#&gt;  [4] extrafontdb_1.1    hms_1.1.3          digest_0.6.37     \n#&gt;  [7] magrittr_2.0.4     evaluate_1.0.5     grid_4.5.0        \n#&gt; [10] timechange_0.3.0   RColorBrewer_1.1-3 fastmap_1.2.0     \n#&gt; [13] jsonlite_2.0.0     processx_3.8.6     chromote_0.5.1    \n#&gt; [16] rematch2_2.1.2     ps_1.9.1           promises_1.3.3    \n#&gt; [19] httr_1.4.7         scales_1.4.0       cli_3.6.5         \n#&gt; [22] rlang_1.1.6        withr_3.0.2        yaml_2.3.10       \n#&gt; [25] tools_4.5.0        tzdb_0.5.0         paletteer_1.6.0   \n#&gt; [28] vctrs_0.6.5        R6_2.6.1           lifecycle_1.0.4   \n#&gt; [31] fs_1.6.6           htmlwidgets_1.6.4  fontawesome_0.5.3 \n#&gt; [34] pkgconfig_2.0.3    pillar_1.11.1      later_1.4.4       \n#&gt; [37] gtable_0.3.6       glue_1.8.0         Rcpp_1.1.0        \n#&gt; [40] xfun_0.53          tidyselect_1.2.1   knitr_1.50        \n#&gt; [43] extrafont_0.20     farver_2.1.2       websocket_1.4.4   \n#&gt; [46] htmltools_0.5.8.1  rmarkdown_2.30     Rttf2pt1_1.3.14   \n#&gt; [49] compiler_4.5.0     S7_0.2.0\n\nsessionInfo()는 R 현재 버전 정보와 함께 적재된 팩키지 정보를 출력한다. 이 정보가 다른 사람이 여러분 문제를 재현하고 디버그하는 데 유용할 수 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#r-regex-terminology",
    "href": "tool-regex.html#r-regex-terminology",
    "title": "24  정규 표현식",
    "section": "\n24.8 용어 정의",
    "text": "24.8 용어 정의\n\n\n부서지기 쉬운 코드(brittle code):입력 데이터가 특정한 형식일 경우에만 작동하는 코드. 하지만 올바른 형식에서 약간이도 벗어나게 되면 깨지기 쉽다. 쉽게 부서지기 때문에 “부서지기 쉬운 코드(brittle code)”라고 부른다.\n\n욕심쟁이 매칭(greedy matching):정규 표현식의 “+”, “*” 문자는 가능한 큰 문자열을 매칭하기 위해서 밖으로 확장하는 개념. \n\ngrep: 정규 표현식에 매칭되는 파일을 탐색하여 라인을 찾는데 대부분의 유닉스 시스템에서 사용 가능한 명령어. “Generalized Regular Expression Parser”의 약자. \n\n정규 표현식(regular expression): 좀 더 복잡한 검색 문자열을 표현하는 언어. 정규 표현식은 특수 문자를 포함해서 검색 라인의 처음 혹은 끝만 매칭하거나 많은 비슷한 것을 매칭한다. \n\n와일드 카드(wild card): 임의 문자를 매칭하는 특수 문자. 정규 표현식에서 와일드 카드 문자는 마침표 문자다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-regex.html#r-regex-ex",
    "href": "tool-regex.html#r-regex-ex",
    "title": "24  정규 표현식",
    "section": "연습문제",
    "text": "연습문제\n\n유닉스의 grep 명령어를 모사하는 간단한 프로그램을 작성한다. 사용자가 정규 표현식을 입력하고 정규 표현식에 매칭되는 라인 수를 세는 프로그램이다.\n\n$ Rscript grep.R\nEnter a regular expression: ^Author\nmbox.txt had 1798 lines that matched ^Author\n\n$ Rscript grep.R\nEnter a regular expression: ^X-\nmbox.txt had 14368 lines that matched ^X-\n\n$ Rscript grep.R\nEnter a regular expression: java$\nmbox.txt had 4218 lines that matched java$\n\n다음 형식의 라인만을 찾는 프로그램을 작성하세요.\n\nNew Revision: 39772\n그리고, 정규 표현식과 str_extract() 함수를 사용하여 각 라인으로부터 숫자를 추출한다. 숫자들의 평균을 구하고 출력한다.\nEnter file:mbox.txt \n38549.7949721\n\nEnter file:mbox-short.txt\n39756.9259259",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>정규 표현식</span>"
    ]
  },
  {
    "objectID": "tool-network.html",
    "href": "tool-network.html",
    "title": "25  네트워크 프로그램",
    "section": "",
    "text": "25.1 하이퍼텍스트 전송 프로토콜\n지금까지 책의 많은 예제는 파일을 읽고 파일 속 정보를 찾는 데 집중했지만, 다양한 많은 정보의 원천이 인터넷에 있다. 이번 장에서는 웹 브라우저로 가장하고 HTTP 프로토콜(HyperText Transport Protocol, HTTP)을 사용하여 웹페이지를 검색할 것이다. 웹페이지 데이터를 읽고 파싱할 것이다.\n웹에 동력을 공급하는 네트워크 프로토콜(HyperText Transport Protocol - HTTP)은 실제로 매우 단순하다. 파이썬에는 소켓(sockets)이라고 불리는 내장 지원 모듈이 있다. 파이썬 프로그램에서 소켓 모듈을 통해서 네트워크 연결을 하고, 데이터 검색을 매우 용이하게 한다.\n소켓(socket)은 단일 소켓으로 두 프로그램 사이에 양방향 연결을 제공한다는 점을 제외하고 파일과 매우 유사하다. 동일한 소켓에 읽거나 쓸 수 있다. 소켓에 무언가를 쓰게 되면, 소켓의 다른 끝에 있는 응용프로그램에 전송된다. 소켓으로부터 읽게 되면, 다른 응용 프로그램이 전송한 데이터를 받게 된다.\n하지만, 소켓의 다른쪽 끝에 프로그램이 어떠한 데이터도 전송하지 않았는데 소켓을 읽으려고 하면, 단지 앉아서 기다리기만 한다. 만약 어떠한 것도 보내지 않고 양쪽 소켓 끝의 프로그램 모두 기다리기만 한다면, 모두 매우 오랜 시간 동안 기다리게 될 것이다.\n인터넷으로 통신하는 프로그램의 중요한 부분은 특정 종류의 프로토콜을 공유하는 것이다. 프로토콜(protocol)은 정교한 규칙의 집합으로 누가 메시지를 먼저 보내고, 메시지로 무엇을 하며, 메시지에 대한 응답은 무엇이고, 다음에 누가 메시지를 보내는지 등을 포함한다. 이런 관점에서 소켓 끝의 두 응용프로그램이 함께 춤을 추고 있으니, 다른 사람 발을 밟지 않도록 확인해야 한다.\n네트워크 프로토콜을 기술하는 문서가 많이 있다. 하이퍼텍스트 전송 프로토콜(HyperText Transport Protocol)은 다음 문서에 기술되어 있다.\nhttp://www.w3.org/Protocols/rfc2616/rfc2616.txt\n매우 상세한 176페이지나 되는 장문의 복잡한 문서다. 흥미롭다면 시간을 가지고 읽어보기 바란다. RFC2616에 36페이지를 읽어보면, GET 요청(request)에 대한 구문을 발견하게 된다. 꼼꼼히 읽게 되면, 웹서버에 문서를 요청하기 위해서, 80 포트로 www.py4inf.com 서버에 연결을 하고 나서 다음 양식 한 라인을 전송한다.\nGET http://www.py4inf.com/code/romeo.txt HTTP/1.0\n두 번째 매개변수는 요청하는 웹페이지가 된다. 그리고 또한 빈 라인도 전송한다. 웹서버는 문서에 대한 헤더 정보와 빈 라인 그리고 문서 본문으로 응답한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#network-http",
    "href": "tool-network.html#network-http",
    "title": "25  네트워크 프로그램",
    "section": "",
    "text": "경고웹브라우저 실행금지 사유\n\n\n\nwebr pyodide는 웹 브라우저 샌드박스 환경에서 R, 파이썬을 실행하며, 브라우저 보안 제한으로 인해 일반 R, 파이썬 환경에서와 같은 네트워크 소켓에 대한 직접적인 접근이 불가능하다. 접근을 허용하는 것이 중대한 보안 위험을 초래할 수 있기 때문에 웹 브라우저에서 실행이 되지 않게 되어 있어 오류가 나는 것이 정상이다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#network-web-browser",
    "href": "tool-network.html#network-web-browser",
    "title": "25  네트워크 프로그램",
    "section": "\n25.2 가장 간단한 웹 브라우저",
    "text": "25.2 가장 간단한 웹 브라우저\n아마도 HTTP 프로토콜이 어떻게 작동하는지 알아보는 가장 간단한 방법은 매우 간단한 파이썬 프로그램을 작성하는 것이다. 웹서버에 접속하고 HTTP 프로토콜 규칙에 따라 문서를 요청하고 서버가 다시 보내주는 결과를 보여주는 것이다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n처음에 프로그램은 www.py4e.com 서버에 80 포트로 연결한다. “웹 브라우저” 역할로 작성된 프로그램이 하기 때문에 HTTP 프로토콜은 GET 명령어를 공백 라인과 함께 보낸다.\n\n\n\n\n\n그림 25.1: 소켓 개념도\n\n\n공백 라인을 보내자마자, 512 문자 덩어리의 데이터를 소켓에서 받아 더 이상 읽을 데이터가 없을 때까지(즉, recv()이 빈 문자열을 반환한다.) 데이터를 출력하는 루프를 작성한다.\n프로그램 실행 결과 다음을 얻을 수 있다.\nHTTP/1.1 200 OK\nDate: Wed, 11 Apr 2018 18:52:55 GMT\nServer: Apache/2.4.7 (Ubuntu)\nLast-Modified: Sat, 13 May 2017 11:22:22 GMT\nETag: \"a7-54f6609245537\"\nAccept-Ranges: bytes\nContent-Length: 167\nCache-Control: max-age=0, no-cache, no-store, must-revalidate\nPragma: no-cache\nExpires: Wed, 11 Jan 1984 05:00:00 GMT\nConnection: close\nContent-Type: text/plain\n\nBut soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n출력결과는 웹서버가 문서를 기술하기 위해서 보내는 헤더(header)로 시작한다. 예를 들어, Content-Type 헤더는 문서가 일반 텍스트 문서(text/plain)임을 표기한다.\n서버가 헤더를 보낸 후에, 빈 라인을 추가해서 헤더 끝임을 표기하고 나서 실제 파일romeo.txt을 보낸다.\n이 예제를 통해서 소켓을 통해서 저수준(low-level) 네트워크 연결을 어떻게 하는지 확인할 수 있다. 소켓을 사용해서 웹서버, 메일 서버 혹은 다른 종류의 서버와 통신할 수 있다. 필요한 것은 프로토콜을 기술하는 문서를 찾고 프로토콜에 따라 데이터를 주고받는 코드를 작성하는 것이다.\n하지만, 가장 흔히 사용하는 프로토콜은 HTTP (즉, 웹) 프로토콜이기 때문에, 파이썬에는 HTTP 프로토콜을 지원하기 위해 특별히 설계된 라이브러리가 있다. 이것을 통해서 웹상에서 데이터나 문서 검색을 쉽게 할 수 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#socket-images",
    "href": "tool-network.html#socket-images",
    "title": "25  네트워크 프로그램",
    "section": "\n25.3 HTTP 경유 이미지 가져오기",
    "text": "25.3 HTTP 경유 이미지 가져오기\n \n상기 예제에서는 파일에 줄바꿈(newline)이 있는 일반 텍스트 파일을 가져왔다. 그리고 나서, 프로그램을 실행해서 데이터를 단순히 화면에 복사했다. HTTP를 사용하여 이미지를 가져오도록 비슷하게 프로그램을 작성할 수 있다. 프로그램 실행 시에 화면에 데이터를 복사하는 대신에, 데이터를 문자열로 누적하고, 다음과 같이 헤더를 잘라내고 나서 파일에 이미지 데이터를 저장한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램을 실행하면, 다음과 같은 출력을 생성한다.\n$ python urljpeg.py\n5120 5120\n5120 10240\n4240 14480\n5120 19600\n...\n5120 214000\n3200 217200\n5120 222320\n5120 227440\n3167 230607\nHeader length 393\nHTTP/1.1 200 OK\nDate: Wed, 11 Apr 2018 18:54:09 GMT\nServer: Apache/2.4.7 (Ubuntu)\nLast-Modified: Mon, 15 May 2017 12:27:40 GMT\nETag: \"38342-54f8f2e5b6277\"\nAccept-Ranges: bytes\nContent-Length: 230210\nVary: Accept-Encoding\nCache-Control: max-age=0, no-cache, no-store, must-revalidate\nPragma: no-cache\nExpires: Wed, 11 Jan 1984 05:00:00 GMT\nConnection: close\nContent-Type: image/jpeg\n상기 url에 대해서, Content-Type 헤더가 문서 본문이 이미지(image/jpeg)를 나타내는 것을 볼 수 있다. 프로그램이 완료되면, 이미지 뷰어로 stuff.jpg 파일을 열어서 이미지 데이터를 볼 수 있다.\n프로그램을 실행하면, recv() 메서드를 호출할 때마다 5120 문자는 전달받지 못하는 것을 볼 수 있다. recv() 호출하는 순간마다 웹서버에서 네트워크로 전송되는 가능한 많은 문자를 받을 뿐이다. 매번 5120 문자까지 요청하지만, 1460 혹은 2920 문자만 전송받는다.\n결과값은 네트워크 속도에 따라 달라질 수 있다. recv()메서드 마지막 호출에는 스트림 마지막인 1681 바이트만 받았고,recv()다음 호출에는 0 길이 문자열을 전송받아서, 서버가 소켓 마지막에close()` 메서드를 호출하고 더 이상의 데이터가 없다는 신호를 준다. \n주석 처리한 time.sleep()을 풀어줌으로써 recv() 연속 호출을 늦출 수 있다. 이런 방식으로 매번 호출 후에 0.25초 기다리게 한다. 그래서, 사용자가 recv() 메서드를 호출하기 전에 서버가 먼저 도착할 수 있어서 더 많은 데이터를 보낼 수가 있다. 정지 시간을 넣어서 프로그램을 다시 실행하면 다음과 같다.\n$ python urljpeg.py\n5120 5120\n5120 10240\n5120 15360\n...\n5120 225280\n5120 230400\n207 230607\nHeader length 393\nHTTP/1.1 200 OK\nDate: Wed, 11 Apr 2018 21:42:08 GMT\nServer: Apache/2.4.7 (Ubuntu)\nLast-Modified: Mon, 15 May 2017 12:27:40 GMT\nETag: \"38342-54f8f2e5b6277\"\nAccept-Ranges: bytes\nContent-Length: 230210\nVary: Accept-Encoding\nCache-Control: max-age=0, no-cache, no-store, must-revalidate\nPragma: no-cache\nExpires: Wed, 11 Jan 1984 05:00:00 GMT\nConnection: close\nContent-Type: image/jpeg\nrecv() 메서드 호출의 처음과 마지막을 제외하고, 매번 새로운 데이터를 요청할 때마다 이제 5120 문자가 전송된다.\n서버 send() 요청과 응용프로그램 recv() 요청 사이에 버퍼가 있다. 프로그램에 지연을 넣어 실행하게 될 때, 어느 지점엔가 서버가 소켓 버퍼를 채우고 응용프로그램이 버퍼를 비울 때까지 잠시 멈춰야 된다. 송신하는 응용프로그램 혹은 수신하는 응용프로그램을 멈추게 하는 행위를 “흐름 제어(flow control)”라고 한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#httr",
    "href": "tool-network.html#httr",
    "title": "25  네트워크 프로그램",
    "section": "\n25.4 httr 웹페이지 가져오기",
    "text": "25.4 httr 웹페이지 가져오기\n수작업으로 소켓 라이브러리를 사용하여 HTTP로 데이터를 주고받을 수 있지만, httr 패키지를 사용하여 R에서 동일한 작업을 수행하는 좀 더 간편한 방식이 있다. httr을 사용하여 파일처럼 웹페이지를 다룰 수가 있다. 단순하게 어느 웹페이지를 가져올 것인지만 지정하면 httr 라이브러리가 모든 HTTP 프로토콜과 헤더 관련 사항을 처리해 준다.\nGET() 함수를 사용하여 웹페이지를 열게 되면, 파일처럼 다룰 수 있고 content() 함수를 사용해서 데이터를 읽을 수 있다. 프로그램을 실행하면, 파일 내용 출력결과만을 볼 수 있다. 헤더 정보는 여전히 전송되었지만, GET() 함수가 헤더를 받아 내부적으로 처리하고, 사용자에게는 단지 데이터만 반환한다. 파이썬으로 웹에서 romeo.txt 파일을 읽도록 urllib를 사용하여 동일한 기능을 구현할 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n예제로, romeo.txt 데이터를 가져와서 파일의 각 단어 빈도를 계산하는 프로그램을 다음과 같이 작성할 수 있다. 웹페이지를 로컬 텍스트로 변환시킨 후에 공백과 \\n으로 텍스트를 잘게 쪼개고, 단어 빈도수를 table()로 계산한 후 단어 빈도수를 확인한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n다시 한번, 웹페이지를 열게 되면, 로컬 파일처럼 웹페이지를 읽을 수 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#html-webscraping",
    "href": "tool-network.html#html-webscraping",
    "title": "25  네트워크 프로그램",
    "section": "\n25.5 HTML 파싱과 웹 스크래핑",
    "text": "25.5 HTML 파싱과 웹 스크래핑\n \nR httr 패키지를 활용하는 일반적인 사례는 웹 스크래핑(scraping)이다. 웹 스크래핑은 웹 브라우저를 가장한 프로그램을 작성하는 것이다. 웹페이지를 가져와서, 패턴을 찾아 페이지 내부의 데이터를 꼼꼼히 조사한다. 예로, 구글 같은 검색엔진은 웹 페이지의 소스를 조사해서 다른 페이지로 가는 링크를 추출하고, 그 해당 페이지를 가져와서 링크 추출하는 작업을 반복한다. 이러한 기법으로 구글은 웹상의 거의 모든 페이지를 거미(spiders)줄처럼 연결한다.\n구글은 또한 발견한 웹페이지에서 특정 페이지로 연결되는 링크 빈도를 사용하여 얼마나 중요한 페이지인지를 측정하고 검색결과에 페이지가 얼마나 높은 순위로 노출되어야 하는지 평가한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#webscarping-regex",
    "href": "tool-network.html#webscarping-regex",
    "title": "25  네트워크 프로그램",
    "section": "\n25.6 정규 표현식 HTML 파싱",
    "text": "25.6 정규 표현식 HTML 파싱\nHTML을 파싱하는 간단한 방식은 정규 표현식을 사용하여 특정한 패턴과 매칭되는 부속 문자열을 반복적으로 찾아 추출하는 것이다.\n여기 간단한 웹페이지가 있다.\n&lt;h1&gt;The First Page&lt;/h1&gt;\n&lt;p&gt;\nIf you like, you can switch to the\n&lt;a href=\"http://www.dr-chuck.com/page2.htm\"&gt;\nSecond Page&lt;/a&gt;.\n&lt;/p&gt;\n모양 좋은 정규표현식을 구성해서 다음과 같이 상기 웹페이지에서 링크를 매칭하고 추출할 수 있다.\nhref=\"http://.+?\"\n작성된 정규 표현식은 “href=http://”로 시작하고, 하나 이상의 문자를 “.+?” 가지고 큰 따옴표를 가진 문자열을 찾는다. “.+?”에 물음표가 갖는 의미는 매칭이 “욕심쟁이(greedy)” 방식보다 “비욕심쟁이(non-greedy)” 방식으로 수행됨을 나타낸다. 비욕심쟁이(non-greedy) 매칭 방식은 가능한 가장 적게 매칭되는 문자열을 찾는 방식이고, 욕심 방식은 가능한 가장 크게 매칭되는 문자열을 찾는 방식이다. \n추출하고자 하는 문자열이 매칭된 문자열의 어느 부분인지를 표기하기 위해서 정규 표현식에 괄호를 추가하여 다음과 같이 프로그램을 작성한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nstr_extract_all 정규 표현식 함수는 정규 표현식과 매칭되는 모든 문자열 리스트를 추출하여 큰 따옴표 사이에 링크 텍스트만을 반환한다. 프로그램을 실행하면, 다음 출력을 얻게 된다.\n$ Rscript.exe ./code/extract_link.R\n웹사이트 입력 - http://www.dr-chuck.com/page1.htm\n[1] \"href=\\\"http://www.dr-chuck.com/page2.htm\\\"\"\n\n$ Rscript.exe ./code/extract_link.R\n웹사이트 입력 - http://www.py4inf.com/book.htm\n [1] \"href=\\\"http://amzn.to/1KkULF3\\\"\"\n [2] \"href=\\\"http://www.py4e.com/book\\\"\"\n [3] \"href=\\\"http://amzn.to/1KkULF3\\\"\"\n [4] \"href=\\\"http://amzn.to/1hLcoBy\\\"\"\n [5] \"href=\\\"http://amzn.to/1KkV42z\\\"\"\n [6] \"href=\\\"http://amzn.to/1fNOnbd\\\"\"\n [7] \"href=\\\"http://amzn.to/1N74xLt\\\"\"\n [8] \"href=\\\"http://do1.dr-chuck.net/py4inf/EN-us/book.pdf\\\"\"\n [9] \"href=\\\"http://do1.dr-chuck.net/py4inf/ES-es/book.pdf\\\"\"\n[10] \"href=\\\"http://do1.dr-chuck.net/py4inf/PT-br/book.pdf\\\"\"\n[11] \"href=\\\"http://www.xwmooc.net/python/\\\"\"\n[12] \"href=\\\"http://fanwscu.gitbooks.io/py4inf-zh-cn/\\\"\"\n[13] \"href=\\\"http://itunes.apple.com/us/book/python-for-informatics/id554638579?mt=13\\\"\"\n[14] \"href=\\\"http://www-personal.umich.edu/~csev/books/py4inf/ibooks//python_for_informatics.ibooks\\\"\"\n[15] \"href=\\\"http://www.py4inf.com/code\\\"\"\n[16] \"href=\\\"http://www.greenteapress.com/thinkpython/thinkCSpy/\\\"\"\n[17] \"href=\\\"http://allendowney.com/\\\"\"\n정규 표현식은 HTML이 예측 가능하고 잘 구성된 경우에 멋지게 작동한다. 하지만, “망가진” HTML 페이지가 많아서, 정규 표현식만을 사용하는 솔루션은 유효한 링크를 놓치거나 잘못된 데이터만 찾고 끝날 수 있다.\n이 문제는 강건한 HTML 파싱 라이브러리를 사용해서 해결될 수 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#rvest-scraping",
    "href": "tool-network.html#rvest-scraping",
    "title": "25  네트워크 프로그램",
    "section": "\n25.7 rvest HTML 파싱",
    "text": "25.7 rvest HTML 파싱\n\nHTML을 파싱하여 페이지에서 데이터를 추출할 수 있는 R 패키지는 많이 있다. 패키지 각각은 강점과 약점이 있어서 사용자 필요에 따라 취사선택한다.\n예로, 간단하게 HTML 입력을 파싱하여 rvest 라이브러리를 사용하여 링크를 추출할 것이다.\nHTML이 XML처럼 보이고 몇몇 페이지는 XML로 되도록 꼼꼼하게 구축되었지만, 일반적으로 대부분의 HTML이 깨져서 XML 파서가 HTML 전체 페이지를 잘못 구성된 것으로 간주하고 받아들이지 않는다. rvest 패키지는 결점 많은 HTML 페이지에 내성이 있어서 사용자가 필요로 하는 데이터를 쉽게 추출할 수 있게 한다.\nhttr 패키지를 사용하여 페이지를 읽어들이고, rvest를 사용해서 앵커 태그(a)로부터 href 속성을 추출한다. \n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램이 웹 주소를 입력받고, 웹페이지를 열고, 데이터를 읽어서 BeautifulSoup 파서에 전달하고, 그리고 나서 모든 앵커 태그를 불러와서 각 태그별로 href 속성을 출력한다. 프로그램을 실행하면, 아래와 같다.\n$ Rscript.exe ./code/extract_link_rvest.R\n웹사이트 입력 - http://www.dr-chuck.com/page1.htm\n[1] \"http://www.dr-chuck.com/page2.htm\"\n\n$ Rscript.exe ./code/extract_link_rvest.R\n웹사이트 입력 - http://www.py4inf.com/book.htm\n [1] \"http://amzn.to/1KkULF3\"\n [2] \"http://www.py4e.com/book\"\n [3] \"http://amzn.to/1KkULF3\"\n [4] \"http://amzn.to/1hLcoBy\"\n [5] \"http://amzn.to/1KkV42z\"\n [6] \"http://amzn.to/1fNOnbd\"\n [7] \"http://amzn.to/1N74xLt\"\n [8] \"http://do1.dr-chuck.net/py4inf/EN-us/book.pdf\"\n [9] \"http://do1.dr-chuck.net/py4inf/ES-es/book.pdf\"\n[10] \"https://twitter.com/fertardio\"\n[11] \"http://do1.dr-chuck.net/py4inf/PT-br/book.pdf\"\n[12] \"https://twitter.com/victorjabur\"\n[13] \"translations/KO/book_009_ko.pdf\"\n[14] \"http://www.xwmooc.net/python/\"\n[15] \"http://fanwscu.gitbooks.io/py4inf-zh-cn/\"\n[16] \"book_270.epub\"\n[17] \"translations/ES/book_272_es4.epub\"\n[18] \"https://www.gitbook.com/download/epub/book/fanwscu/py4inf-zh-cn\"\n[19] \"html-270/\"\n[20] \"html_270.zip\"\n[21] \"http://itunes.apple.com/us/book/python-for-informatics/id554638579?mt=13\"\n[22] \"http://www-personal.umich.edu/~csev/books/py4inf/ibooks//python_for_informatics.ibooks\"\n[23] \"http://www.py4inf.com/code\"\n[24] \"http://www.greenteapress.com/thinkpython/thinkCSpy/\"\n[25] \"http://allendowney.com/\"\nrvest을 사용하여 다음과 같이 각 태그별로 다양한 부분을 뽑아낼 수 있다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n상기 프로그램은 다음을 출력한다.\n$ Rscript.exe ./code/extract_link_tag.R\n웹사이트 입력 - http://www.dr-chuck.com/page1.htm\n경고메시지(들):\nfor (name in names(public_methods)) lockBinding(name, public_bind_env)에서:\n  사용되지 않는 커넥션 3 (stdin)를 닫습니다\nTAG: &lt;a href=\"http://www.dr-chuck.com/page2.htm\"&gt;\nSecond Page&lt;/a&gt;\nURL: http://www.dr-chuck.com/page2.htm\nContent:\nSecond Page\nAttrs: href: http://www.dr-chuck.com/page2.htm\nHTML을 파싱하는 데 rvest가 가진 강력한 기능을 예제로 보여줬다. 좀 더 자세한 사항은 https://rvest.tidyverse.org/에서 문서와 예제를 살펴보기 바란다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#GET-binary",
    "href": "tool-network.html#GET-binary",
    "title": "25  네트워크 프로그램",
    "section": "\n25.8 바이너리 파일 읽기",
    "text": "25.8 바이너리 파일 읽기\n이미지나 비디오 같은 텍스트가 아닌 (혹은 바이너리) 파일을 가져올 때가 종종 있다. 일반적으로 이런 파일 데이터를 출력하는 것은 유용하지 않다. 하지만, download.file() 함수를 사용하여, 하드 디스크 로컬 파일에 URL 사본을 쉽게 만들 수 있다.\n\ndownload.file() 함수 내부에 인터넷에 공개된 이미지 url을 적고, destfile에는 로컬 파일에 저장할 파일명을 적어준다. 중요한 것은 텍스트가 아니라 바이너리 이미지라 mode = \"wb\"를 지정한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n작성된 프로그램은 네트워크로 모든 데이터를 한번에 읽어서 컴퓨터 cover.jpg 파일을 다운로드받아 로컬 디스크에 지정한 디렉터리 파일명으로 데이터를 쓴다. 이 방식은 파일 크기가 사용자 컴퓨터의 메모리 크기보다 작다면 정상적으로 작동한다.\n\n\n\n\n\n그림 25.2: 바이너리 파일 다운로드\n\n\n하지만, 오디오 혹은 비디오 파일 대용량이면, 상기 프로그램은 멈추거나 사용자 컴퓨터 메모리가 부족할 때 극단적으로 느려질 수 있다. 메모리 부족을 회피하기 위해서, 데이터를 블록 혹은 버퍼로 가져와서, 다음 블록을 가져오기 전에 디스크에 각각의 블록을 쓴다. 이런 방식으로 사용자가 가진 모든 메모리를 사용하지 않고 어떠한 크기 파일도 읽어올 수 있다.\nFannie Mae and Freddie Mac은 주택금융공사에 상응하는 기관으로 주택 구매자에게 저리의 장기 고정금리 주택담보대출을 제공하고 주택 모기지를 재융자하는 역할을 통해 주택 금융 시장의 안정을 도모하고 국민의 주거 안정에 기여한다. 웹사이트에 공공데이터로 인터넷에 공개된 주택담보대출 나름 크기가 큰 데이터를 가져온다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nUNIX 혹은 매킨토시 컴퓨터를 가지고 있다면, 다음과 같이 상기 동작을 수행하는 명령어가 운영체제 자체에 내장되어 있다. \ncurl -O https://www.dr-chuck.com/py4inf/cover.jpg",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#network-terminology",
    "href": "tool-network.html#network-terminology",
    "title": "25  네트워크 프로그램",
    "section": "\n25.9 용어 정의",
    "text": "25.9 용어 정의\n\n\nBeautifulSoup: 파이썬 라이브러리로 HTML 문서를 파싱하고 브라우저가 일반적으로 생략하는 HTML의 불완전한 부분을 보정하여 HTML 문서에서 데이터를 추출한다. www.crummy.com 사이트에서 BeautifulSoup 코드를 다운로드 받을 수 있다. \n\nrvest: 파이썬 BeautifulSoup에 대응되는 R 크롤링 패키징 \n\n포트(port): 서버에 소켓 연결을 만들 때, 사용자가 무슨 응용프로그램을 연결하는지 나타내는숫자. 예로, 웹 트래픽은 통상 80 포트, 전자우편은 25 포트를 사용한다. \n\n스크래핑(scraping): 프로그램이 웹 브라우저를 가장하여 웹페이지를 가져와서 웹 페이지의 내용을 검색한다. 종종 프로그램이 한 페이지의 링크를 따라 다른 페이지를 찾게 된다. 그래서, 웹페이지 네트워크 혹은 소셜 네트워크 전체를 훑을 수 있다. \n\n소켓(socket): 두 응용프로그램 사이 네트워크 연결. 두 응용프로그램은 양방향으로 데이터를 주고받는다. \n\n스파이더(spider):검색 색인을 구축하기 위해서 한 웹페이지를 검색하고, 그 웹페이지에 링크된 모든 페이지 검색을 반복하여 인터넷에 있는 거의 모든 웹페이지를 가져오기 위해서 사용되는 검색엔진 행동.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-network.html#network-ex",
    "href": "tool-network.html#network-ex",
    "title": "25  네트워크 프로그램",
    "section": "연습문제",
    "text": "연습문제\n\n소켓 프로그램 socket1.py을 변경하여 임의 웹페이지를 읽을 수 있도록 URL을 사용자가 입력하도록 수정한다. split('/')을 사용하여 URL을 컴포넌트로 쪼개서 소켓 connect 호출에 대해 호스트 명을 추출할 수 있다. 사용자가 적절하지 못한 형식 혹은 존재하지 않는 URL을 입력하는 경우를 처리할 수 있도록 try, except를 사용하여 오류 검사기능을 추가한다.\n소켓 프로그램을 변경하여 전송받은 문자를 계수(count)하고 3000 문자를 출력한 후에 그 이상 텍스트 출력을 멈추게 한다. 프로그램은 전체 문서를 가져와야 하고, 전체 문자를 계수(count)하고, 문서 마지막에 문자 계수(count)결과를 출력해야 한다.\nhttr 패키지를 사용하여 이전 예제를 반복한다. (1) 사용자가 입력한 URL에서 문서 가져오기 (2) 3000 문자까지 화면에 보여주기 (3) 문서의 전체 문자 계수(count)하기. 이 연습문제에서 헤더에 대해서는 걱정하지 말고, 단지 문서 본문에서 첫 3000 문자만 화면에 출력한다.\nurllinks.R 프로그램을 변경하여 가져온 HTML 문서에서 문단(p) 태그를 추출하고 프로그램의 출력물로 문단을 계수(count)하고 화면에 출력한다. 문단 텍스트를 화면에 출력하지 말고 단지 숫자만 센다. 작성한 프로그램을 작은 웹페이지뿐만 아니라 조금 큰 웹 페이지에도 테스트한다.\n(고급) 소켓 프로그램을 변경하여 헤더와 빈 라인 다음에 데이터만 보이도록 개발한다. recv는 라인이 아니라 문자(새줄(newline)과 모든 문자)를 전송받는다는 것을 기억한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>네트워크 프로그램</span>"
    ]
  },
  {
    "objectID": "tool-web.html",
    "href": "tool-web.html",
    "title": "26  웹서비스 사용하기",
    "section": "",
    "text": "26.1 XML\n프로그램을 사용하여 HTTP상에서 문서를 가져와서 파싱하는 것이 익숙해지면, 다른 프로그램(즉, 브라우저에서 HTML로 보여지지 않는 것)에서 활용되도록 특별히 설계된 문서를 생성하는 것은 그다지 오래 걸리지 않는다.\n웹상에서 데이터를 교환할 때 두 가지 형식이 많이 사용된다. XML(“eXtensible Markup Language”)은 오랜 기간 사용되어 왔고 문서-형식(document-style) 데이터를 교환하는 데 가장 적합하다. 딕셔너리, 리스트 혹은 다른 내부 정보를 프로그램으로 서로 교환할 때, JSON(JavaScript Object Notation, www.json.org)을 사용한다. 두 가지 형식에 대해 모두 살펴볼 것이다.\nXML(eXtensible Markup Language)은 HTML과 매우 유사하지만, XML이 HTML보다 좀 더 구조화되어 있다. 여기 XML 문서 샘플이 있다.\n&lt;person&gt;\n  &lt;name&gt;Chuck&lt;/name&gt;\n  &lt;phone type=\"intl\"&gt;\n     +1 734 303 4456\n   &lt;/phone&gt;\n   &lt;email hide=\"yes\"/&gt;\n&lt;/person&gt;\n종종 XML 문서를 나무 구조(tree structure)로 생각하는 것이 도움이 된다. 최상단 person 태그가 있고, phone 같은 다른 태그는 부모 노드의 자식(children) 노드로 표현된다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-xml",
    "href": "tool-web.html#ws-xml",
    "title": "26  웹서비스 사용하기",
    "section": "",
    "text": "그림 26.1: XML 나무구조 도식화",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-xml-parsing",
    "href": "tool-web.html#ws-xml-parsing",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.2 XML 파싱",
    "text": "26.2 XML 파싱\n \n다음은 XML을 파싱하고 XML에서 데이터 요소를 추출하는 간단한 응용프로그램이다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nxml2 패키지 read_xml() 함수를 사용하여 XML 문자열 표현을 XML 노드 ’나무(tree)’로 변환한다. XML이 나무 구조로 되었을 때, XML에서 데이터 일부분을 추출하기 위해서 호출하는 함수가 있다. xml_find_first() 함수는 XML 나무를 훑어서 XPath 표현을 사용하여 특정한 태그와 매칭되는 노드(node)를 검색한다. 각 노드는 텍스트, 속성(즉, hide 같은), 그리고 “자식(child)” 노드로 구성된다. 각 노드는 노드 나무의 최상단이 될 수 있다.\nName:  Chuck \nAttr:  yes \nxml2 같은 XML 패키지를 사용하는 것은 장점이 있다. 상기 예제의 XML은 매우 간단하지만, 적합한 XML에 관해서 규칙이 많이 있고, XML 구문 규칙에 얽매이지 않고 xml2를 사용해서 XML에서 데이터를 추출할 수 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-xml-nodes",
    "href": "tool-web.html#ws-xml-nodes",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.3 노드 반복하기",
    "text": "26.3 노드 반복하기\n\n종종 XML이 다중 노드를 가지고 있어서 모든 노드를 처리하는 루프를 작성할 필요가 있다. 다음 프로그램에서 모든 user 노드를 루프로 반복한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nxml_find_all() 함수는 R 리스트의 하위 나무를 가져온다. 리스트는 XML 나무에서 user 구조를 표현한다. 그리고 나서, for 루프를 작성해서 각 user 노드 값을 확인하고 name, id 텍스트 요소와 user 노드에서 x 속성도 가져와서 출력한다.\nUser count: 2 \nName:  Chuck \nId:  001 \nAttribute:  2 \nName:  Brent \nId:  009 \nAttribute:  7",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#webservice-json",
    "href": "tool-web.html#webservice-json",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.4 JSON",
    "text": "26.4 JSON\n \nJSON(JavaScript Object Notation) 형식은 자바스크립트 언어에서 사용되는 객체와 배열 형식에서 영감을 얻었다. 하지만 파이썬이 자바스크립트 이전에 개발되어서 딕셔너리와 리스트의 파이썬 구문이 JSON 구문에 영향을 주었다. 그래서 JSON 포맷이 거의 파이썬 리스트와 딕셔너리의 조합과 일치한다.\n상기 간단한 XML에 대략 상응하는 JSON으로 작성한 것이 다음에 있다.\n\n{\n  \"name\" : \"Chuck\",\n  \"phone\" : {\n    \"type\" : \"intl\",\n    \"number\" : \"+1 734 303 4456\"\n   },\n   \"email\" : {\n     \"hide\" : \"yes\"\n   }\n}\n\n몇 가지 차이점에 주목하세요. 첫째로 XML에서는 “phone” 태그에 “intl” 같은 속성을 추가할 수 있다. JSON에서는 단지 키-값 페어(key-value pair)다. 또한 XML “person” 태그는 사라지고 외부 중괄호 세트로 대체되었다.\n일반적으로 JSON 구조가 XML보다 간단하다. 왜냐하면, JSON이 XML보다 적은 역량을 보유하기 때문이다. 하지만 JSON이 딕셔너리와 리스트의 조합에 직접 매핑된다는 장점이 있다. 그리고, 거의 모든 프로그래밍 언어가 파이썬 딕셔너리와 리스트에 상응하는 것을 갖고 있어서, JSON이 협업하는 두 프로그램 사이에서 데이터를 교환하는 매우 자연스러운 형식이 된다.\nXML에 비해서 상대적으로 단순하기 때문에, JSON이 응용프로그램 간 거의 모든 데이터를 교환하는 데 있어 빠르게 선택되고 있다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#webservice-json-parsing",
    "href": "tool-web.html#webservice-json-parsing",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.5 JSON 파싱하기",
    "text": "26.5 JSON 파싱하기\n딕셔너리(객체)와 리스트를 중첩함으로써 JSON을 생성한다. 이번 예제에서, 사용자 리스트를 표현하는데, 각 사용자가 키-값 페어(key-value pair, 즉, 딕셔너리)다. 그래서 리스트 딕셔너리가 있다.\n다음 프로그램에서 내장된 json 라이브러리를 사용하여 JSON을 파싱하여 데이터를 읽어온다. 이것을 상응하는 XML 데이터, 코드와 비교해 보세요. JSON은 조금 덜 정교해서 사전에 미리 리스트를 가져오고, 리스트가 사용자이고, 각 사용자가 키-값 페어 집합임을 알고 있어야 한다. JSON은 좀 더 간략(장점)하고 하지만 좀 더 덜 서술적(단점)이다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nJSON과 XML에서 데이터를 추출하는 코드를 비교하면, jsonlite 패키지 fromJSON() 함수는 JSON 파일을 즉시 정형 데이터프레임으로 변환시킨다. 프로그램 출력은 정확하게 상기 XML 버전과 동일한 정보를 데이터프레임으로 표현하고 있어 후속 작업에 훨씬 유연하게 대응할 수 있다.\n\nUser count: 2\nName Chuck\nId 001\nAttribute 2\nName Brent\nId 009\nAttribute 7\n\n일반적으로 웹서비스에 대해서 XML에서 JSON으로 옮겨가는 산업 경향이 뚜렷하다. JSON이 프로그래밍 언어에서 이미 갖고 있는 네이티브 자료 구조와 좀 더 직접적이며 간단히 매핑되기 때문에, JSON을 사용할 때 파싱하고 데이터 추출하는 코드가 더욱 간단하고 직접적이다. 하지만 XML이 JSON보다 좀 더 자기 서술적이고 XML이 강점을 가지는 몇몇 응용프로그램 분야가 있다. 예를 들어, 대부분의 워드 프로세서는 JSON보다는 XML을 사용하여 내부적으로 문서를 저장한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-api",
    "href": "tool-web.html#ws-api",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.6 API",
    "text": "26.6 API\n \n이제 HTTP를 사용하여 응용프로그램 간에 데이터를 교환할 수 있게 되었다. 또한, XML 혹은 JSON을 사용하여 응용프로그램 간에도 복잡한 데이터를 주고받을 수 있는 방법을 습득했다.\n다음 단계는 상기 학습한 기법을 사용하여 응용프로그램 간에 “계약(contract)”을 정의하고 문서화한다. 응용프로그램-대-응용프로그램 계약에 대한 일반적 명칭은 API 응용 프로그램 인터페이스(Application Program Interface)다. API를 사용할 때, 일반적으로 하나의 프로그램이 다른 응용 프로그램에서 사용할 수 있는 가능한 서비스 집합을 생성한다. 또한, 다른 프로그램이 서비스에 접근하여 사용할 때 지켜야 하는 API (즉, “규칙”)도 게시한다.\n다른 프로그램에서 제공되는 서비스에 접근을 포함하여 프로그램 기능을 개발할 때, 이러한 개발법을 SOA, Service-Oriented Architecture(서비스 지향 아키텍처)라고 부른다. SOA 개발 방식은 전반적인 응용 프로그램이 다른 응용 프로그램 서비스를 사용하는 것이다. 반대로, SOA가 아닌 개발 방식은 응용 프로그램이 하나의 독립된 응용 프로그램으로 구현에 필요한 모든 코드를 담고 있다.\n웹을 사용할 때 SOA 사례를 많이 찾아볼 수 있다. 웹사이트 하나를 방문해서 비행기표, 호텔, 자동차를 단일 사이트에서 예약 완료한다. 호텔 관련 데이터는 물론 항공사 컴퓨터에 저장되어 있지 않다. 대신에 항공사 컴퓨터는 호텔 컴퓨터와 계약을 맺어 호텔 데이터를 가져와서 사용자에게 보여준다. 항공사 사이트를 통해서 사용자가 호텔 예약을 동의할 경우, 항공사 사이트에서 호텔 시스템의 또 다른 웹서비스를 통해서 실제 예약을 한다. 전체 거래(transaction)를 완료하고 카드 결제를 진행할 때, 다른 컴퓨터가 프로세스에 관여하여 처리한다.\n\n\n\n\n\n그림 26.2: 서비스 지향 아키텍처\n\n\n서비스 지향 아키텍처는 많은 장점이 있다. (1) 항상 단 하나의 데이터만 유지 관리한다. 이중으로 중복 예약을 원치 않는 호텔 같은 경우에 매우 중요하다. (2) 데이터 소유자가 데이터 사용에 대한 규칙을 정한다. 이러한 장점으로, SOA 시스템은 좋은 성능과 사용자 요구를 모두 만족하기 위해서 신중하게 설계되어야 한다.\n응용프로그램이 웹상에 이용 가능한 API로 서비스 집합을 만들 때, 웹서비스(web services)라고 부른다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#google-geocoding",
    "href": "tool-web.html#google-geocoding",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.7 지오코딩 웹서비스",
    "text": "26.7 지오코딩 웹서비스\n \n구글이 자체적으로 구축한 대용량 지리 정보 데이터베이스를 누구나 이용할 수 있게 하는 훌륭한 웹서비스가 있다. “Ann Arbor, MI” 같은 지리 검색 문자열을 지오코딩 API에 넣으면, 검색 문자열이 의미하는 지도상에 위치와 근처 주요 지형지물 정보를 나름 최선을 다해서 예측 제공한다.\n지오코딩 서비스는 무료지만 사용량이 제한되어 있어서, 상업적 응용프로그램에 API를 무제한 사용할 수는 없다. 하지만, 최종 사용자가 자유 형식 입력 박스에 위치 정보를 입력하는 설문 데이터가 있다면, 구글 API를 사용하여 데이터를 깔끔하게 정리하는 데는 유용하다.\n구글 지오코딩 API 같은 무료 API를 사용할 때, 자원 사용에 대한 지침을 준수해야 한다. 너무나 많은 사람이 서비스를 남용하게 되면, 구글은 무료 서비스를 중단하거나, 상당 부분 줄일 수 있다.\n\nWhen you are using a free API like Google’s geocoding API, you need to be respectful in your use of these resources. If too many people abuse the service, Google might drop or significantly curtail its free service.\n\n서비스에 대해서 자세한 사항을 온라인 문서를 정독할 수 있지만, 무척 간단해서 브라우저에 다음 URL을 입력해서 테스트까지 할 수 있다.\nhttp://maps.googleapis.com/maps/api/geocode/json?sensor=false &address=Ann+Arbor%2C+MI\n웹 브라우저에 붙여넣기 전에, URL만 뽑아냈고 URL에서 모든 공백을 제거했는지 확인한다. 그리고, 브라우저에 붙여 넣기한다.\n다음은 간단한 응용 프로그램이다. 사용자가 검색 문자열을 입력하고 구글 지오코딩 API를 호출하여 반환된 JSON에서 정보를 추출한다. 구글 지리정보 API는 상용으로 전환되었기에 다음카카오 지도 API를 대체하여 동일한 개발 작업을 수행한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n                      주소             경도             위도\n1 서울 강남구 테헤란로 152 127.036508620542 37.5000242405515\n\n프로그램이 사용자로부터 검색 문자열을 받는다. 적절히 인코딩된 매개변수로 검색 문자열을 변환하여 URL을 만든다. 그리고 나서 httr 패키지를 사용하여 카카오 지오코딩 API에서 텍스트를 가져온다. 고정된 웹페이지와 달리, 반환되는 데이터는 전송한 매개변수와 카카오 서버에 저장된 지리정보 데이터에 따라 달라진다.\nJSON 데이터를 가져오면, jsonlite 패키지로 파싱하고 전송받은 데이터가 올바른지 확인하는 몇 가지 절차를 거친 후에 찾고자 하는 정보를 추출한다.\nRscript 프로그램 실행을 위해서 사용자 입력과 API 키 외부 유출 방지를 위한 조치를 취한 후에 일반화를 위해 코드를 일부 수정한다.\n\n\nR\n파이썬\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n프로그램 출력결과는 다음과 같다.\n$ Rscript code/api_address.R \n\n주소를 입력하세요 - '서울특별시 강남구 역삼동 737'\n                      주소             경도             위도\n1 서울 강남구 테헤란로 152 127.036508620542 37.5000242405515\n다음카카오 지도 API 외 다른 지오코딩 관련 자세한 사항은 공간통계를 위한 데이터 사이언스 - 지리정보 API - 주소와 위도경도 웹사이트를 참조한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-security",
    "href": "tool-web.html#ws-security",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.8 보안과 API 사용",
    "text": "26.8 보안과 API 사용\n \n상용 업체 API를 사용하기 위해서는 일종의 “API 키(API key)”가 일반적으로 필요하다. 서비스 제공자 입장에서 누가 서비스를 사용하고 있으며 각 사용자가 얼마나 사용하고 있는지를 알고자 한다. 상용 API 제공 업체는 서비스에 대한 무료 사용자와 유료 사용자에 대한 구분을 두고 있다. 특정 기간 동안 한 개인 사용자가 사용할 수 있는 요청 수에 대해 제한을 두는 정책을 두고 있다.\n때때로 API 키를 얻게 되면, API를 호출할 때 POST 데이터의 일부로 포함하거나 URL의 매개변수로 키를 포함시킨다.\n또 다른 경우에는 업체가 서비스 요청에 대한 보증을 강화해서 공유 키와 비밀번호를 암호화된 메시지 형식으로 보내도록 요구한다. 인터넷을 통해서 서비스 요청을 암호화하는 일반적인 기술을 OAuth라고 한다. http://www.oauth.net 사이트에서 OAuth 프로토콜에 대해 더 많은 정보를 만날 수 있다.\n트위터(현 x.com) API가 점차적으로 가치 있게 됨에 따라 트위터가 공개된 API에서 API를 매번 호출할 때마다 OAuth 인증을 거치도록 API를 바꾸었다. 다행스럽게도 편리한 OAuth 라이브러리가 많이 있다.\n그래서 명세서를 읽고 아무것도 없는 상태에서 OAuth 구현하는 것을 피할 수 있게 되었다. 이용 가능한 라이브러리는 복잡성도 다양한 만큼 기능적으로도 다양하다. OAuth 웹사이트에서 다양한 OAuth 라이브러리 정보를 확인할 수 있다.\nOAuth 보안 요구사항을 충족하기 위해 추가된 다양한 매개변수 의미를 좀 더 자세히 알고자 한다면, OAuth 명세서를 읽어보기 바란다.\n이와 같은 보안 API 키는 누가 트위터 API를 사용하고 어느 정도 수준으로 트위터를 사용하는지에 대해서 트위터가 확고한 신뢰를 갖게 한다. 사용량에 한계를 두고 서비스를 제공하는 방식은 단순히 개인적인 목적으로 데이터 검색을 할 수는 있지만, 하루에 수백만 API 호출로 데이터를 추출하여 제품을 개발하지 못하게 제한하는 기능도 동시에 한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-web.html#ws-term",
    "href": "tool-web.html#ws-term",
    "title": "26  웹서비스 사용하기",
    "section": "\n26.9 용어 정의",
    "text": "26.9 용어 정의\n\n\nAPI: 응용 프로그램 인터페이스(Application Program Interface) - 두 응용 프로그램 컴포넌트 간에 상호작용하는 패턴을 정의하는 응용 프로그램 간의 계약. \n\nElementTree: XML 데이터를 파싱하는 데 사용되는 파이썬 내장 라이브러리. \n\nxml2: XML 데이터를 파싱하는 데 사용되는 R 내장 라이브러리. \n\nJSON: JavaScript Object Notation - 자바스크립트 객체(JavaScript Objects) 구문을 기반으로 구조화된 데이터 마크업(markup)을 허용하는 형식. \n\nREST: REpresentational State Transfer - HTTP 프로토콜을 사용하여 응용 프로그램 내부에 자원에 접근을 제공하는 일종의 웹서비스 스타일. \n\nSOA: 서비스 지향 아키텍처(Service Oriented Architecture) - 응용 프로그램이 네트워크에 연결된 컴포넌트로 구성될 때. \n\nXML: 확장 마크업 언어(eXtensible Markup Language) - 구조화된 데이터의 마크업을 허용하는 형식.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>웹서비스 사용하기</span>"
    ]
  },
  {
    "objectID": "tool-database.html",
    "href": "tool-database.html",
    "title": "27  데이터베이스와 SQL",
    "section": "",
    "text": "27.1 용어정의",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "tool-database.html#db-terminology",
    "href": "tool-database.html#db-terminology",
    "title": "27  데이터베이스와 SQL",
    "section": "",
    "text": "속성(attribute): 튜플 내부에 값의 하나. 좀더 일반적으로 “열”, “칼럼”, “필드”로 불린다. \n\n\n제약(constraint): 데이터베이스가 테이블의 필드나 행에 규칙을 강제하는 것. 일반적인 제약은 특정 필드에 중복된 값이 없도록 하는 것(즉, 모든 값이 유일해야 한다.) \n\n\n커서(cursor): 커서를 사용해서 데이터베이스에서 SQL 명령어를 수행하고 데이터베이스에서 데이터를 가져온다. 커서는 네트워크 연결을 위한 소켓이나 파일의 파일 핸들러와 유사하다. \n\n\n데이터베이스 브라우져(database browser): 프로그램을 작성하지 않고 직접적으로 데이터베이스에 연결하거나 데이터베이스를 조작할 수 있는 소프트웨어. \n\n\n외부 키(foreign key): 다른 테이블에 있는 행의 주키를 가리키는 숫자 키. 외부 키는 다른 테이블에 저장된 행사이에 관계를 설정한다. \n\n\n인텍스(index): 테이블에 행이 추가될 때 정보 검색하는 것을 빠르게 하기 위해서 데이터베이스 소프트웨어가 유지관리하는 추가 데이터. \n\n\n논리 키(logical key): “외부 세계”가 특정 행의 정보를 찾기 위해서 사용하는 키. 사용자 계정 테이블의 예로, 사람의 전자우편 주소는 사용자 데이터에 대한 논리 키의 좋은 후보자가 될 수 있다. \n\n\n정규화(normalization): 어떠한 데이터도 중복이 없도록 데이터 모델을 설계하는 것. 데이터베이스 한 장소에 데이터 각 항목 정보를 저장하고 외부키를 이용하여 다른 곳에서 참조한다. \n\n\n주키(primary key): 다른 테이블에서 테이블의 한 행을 참조하기 위해서 각 행에 대입되는 숫자 키. 종종 데이터베이스는 행이 삽입될 때 주키를 자동 삽입하도록 설정되었다. \n\n\n관계(relation): 튜플과 속성을 담고 있는 데이터베이스 내부 영역. 좀더 일반적으로 “테이블(table)”이라고 한다. \n\n\n튜플(tuple):데이터베이스 테이블에 단일 항목으로 속성 집합이다. 좀더 일반적으로 “행(row)”이라고 한다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>데이터베이스와 SQL</span>"
    ]
  },
  {
    "objectID": "tool-viz.html",
    "href": "tool-viz.html",
    "title": "28  시각화",
    "section": "",
    "text": "28.1 나이팅게일 신화탄생\n코딩에서 데이터 시각화로의 전환은 단순한 기술적 변화를 넘어서, 복잡한 데이터셋을 시각적으로 해석하고 전달하는 새로운 차원으로의 도약을 의미한다. 코딩이 데이터를 처리하고 분석하는 데 필수적이지만, 시각화는 데이터가 전달하는 이야기를 더 잘 이해하고 공유할 수 있게 함으로써, 기술적 능력과 창의적 표현을 결합하는 과정이며, 데이터에 내재된 패턴과 통찰을 명확하고 강력한 시각적 형태로 변환하는 작업이다.\n시각화는 데이터를 보다 인간 중심적으로 만들며, 복잡한 수치와 추세를 누구나 이해할 수 있는 형태로 재구성하는 데 기여한다. 이러한 과정에서 코딩은 도구로서 역할을 하고, 시각적 스토리텔링은 데이터가 지닌 의미를 풍부하게 전달하는 매개체가 된다.\n플로렌스 나이팅게일의 데이터 시각화 작업은 데이터의 힘을 보여주는 역사적인 사례로, 이를 통해 복잡한 데이터를 명확하고 효과적으로 전달하는 방법의 중요성을 인식하게 되었다. 19세기 공중 보건과 군의학 분야에 혁신을 통해 데이터가 단순한 정보의 전달을 넘어 사회 변화와 인류 보건 위생 개선에 중요한 기여를 할 수 있음을 증명했다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#나이팅게일-신화탄생",
    "href": "tool-viz.html#나이팅게일-신화탄생",
    "title": "28  시각화",
    "section": "",
    "text": "28.1.1 배경\n \n크림 전쟁은 1853년부터 1856년까지 일어난 큰 전쟁이었다. 한쪽에는 러시아, 반면 다른 한쪽에는 영국, 프랑스, 오스만 제국(현대 튀르키예), 그리고 나중에 사르디니아(현대 이탈리아의 일부)가 동맹을 구성하여 전쟁을 치렀다. 전쟁이 바로 시작된 이유는 러시아가 오스만 제국 내 정교회 신자들을 보호하려는 명분을 내세웠지만, 사실 더 많은 영토를 차지하기 위함이었다. 양측 간 전쟁은 흑해를 두고 남하하는 러시아에 맞서 동맹군이 크림반도에서 발생하여 “크림전쟁”(Crimean War)으로 불린다. 영화로 소개된 경기병대의 돌격(“Charge of the Light Brigade”), 영국 간호사 플로렌스 나이팅게일의 활약, 전신과 철도의 본격적인 도입으로 큰 의미를 갖는 전쟁이기도 하다. 많은 전투와 많은 사람들이 죽은 후, 1856년 파리 조약으로 전쟁은 마무리되어, 러시아의 확장은 잠시 멈추게 되었고, 오스만 제국도 한숨 돌린 계기가 되었다.\n크림 전쟁 중 스쿠타리 막사는 튀르키예(구 터키)의 스쿠타리 병원(Scutari Hospital, Turkey)이 영국 군 병원으로 개조되었다. 크림전쟁에서 부상을 당한 수많은 병사가 치료를 위해 이곳으로 보내졌지만, 병자와 부상병들을 감당할 수 있도록 설계되지 않았고 제대로 된 역할도 수행하지 못했다. 1854년 나이팅게일이 간호사 일행과 함께 도착했을 때, 비위생적인 환경과 고통받는 병사들을 보고 경악했다. 나이팅게일의 스쿠타리 병원에서의 경험은 병원과 의료 서비스를 개선하여 이와 같은 고통과 비극이 재발하지 않도록 향후 프로젝트의 중요한 동기와 방향이 되었다.\n\n\n\n\n\n그림 28.1: 스쿠타리 병원의 한 병동 석판화 그림 (William Simpson)\n\n\n환자의 사망률을 42%에서 2%로 낮추고 집중치료실(ICU)을 설치하여 상태가 중한 환자를 격리하여 집중 관리하는 등 근대적인 간호체계를 수립하는 데 기여했다.\n\n28.1.2 원본 데이터\n크림 전쟁 중 튀르키예의 스쿠타리 병원에서 몇 년간에 걸쳐 수작업으로 종이에 분석 가능한 형태의 자료를 만들어내는 것은 결코 쉬운 작업이 아니다.\n\n\n\n\n\n그림 28.2: 원본 데이터\n\n\n\n28.1.3 그래프 진화\n복잡한 논거를 제시하는 대신 구체적인 주장에 데이터 시각화와 데이터 스토리텔링(Storytelling)을 통해 청중에 한걸음 더 다가섰다. 나이팅게일의 스토리텔링은 열악한 위생 상태와 과밀로 인해 불필요한 죽음이 얼마나 많이 발생하는지 이해하기 쉬운 비교를 통해 이야기를 구성해서 설득해 나갔다. 예를 들어, 군대 사망률을 민간인 사망률(유사한 환경의 맨체스터)과 비교하는 프레임을 제시하고, 군대 막사에서 생활하는 평시 병사들이 비슷한 연령대 민간인 남성보다 더 높은 비율로 사망하는 것을 제시했다. 이를 통해, 데이터가 보여주는 현실을 부정할 수 없게 만들었고, 군대 행정에 극적인 개혁을 이끌어냈다. 1\n\n\n\n\n\n\n\n\n\n(a) 막대그래프\n\n\n\n\n\n\n\n\n\n(b) 맨체스터 사망\n\n\n\n\n\n\n빅토리아 여왕 보고(I)\n\n\n\n\n\n빅토리아 여왕 보고(II)\n\n\n\n\n\n빅토리아 여왕 보고(III)\n\n\n\n\n\n그림 28.3: 나이팅게일 그래프 진화과정\n\n\n\n28.1.4 설득\n\n나이팅게일은 크림 전쟁 중 병원에서의 위생 문제와 관련된 데이터를 수집하고 분석하여 그 결과를 시각화했고, 병원에서의 사망 원인 중 대부분이 감염성 질병으로 인한 것임을 발견했다. 이러한 감염성 질병은 부적절한 위생 조건과 밀접한 관련이 있음을 확인했다.\n나이팅게일은 병원의 위생 상태 개선을 통해 수많은 생명을 구할 수 있다는 사실을 확인했고, 연구 결과와 권장 사항을 다양한 영국 정부 부처에 제출했으며, 특히 1858년에 영국의 장관들에게 보고서를 제출했다. 이를 통해서 군 병원의 위생 조건을 개선하는 데 큰 영향을 미쳤다.\n\n\n\n\n\n그림 28.4: 나이팅게일과 빅토리아 여왕\n\n\n\n28.1.5 성과와 영향\n\n나이팅게일 캠페인이 민간 공중보건에 미친 가장 큰 영향은 실현되기까지 오랜 기간에 걸쳐 다각도로 검토되었고, 마침내 1875년 영국 공중보건법(British Public Health Act)에 법제화되었다. 이 법에는 잘 정비된 하수도, 깨끗한 수돗물, 건축법 규제 등의 요건이 담겨있다. 질병에 대한 면역력을 강화하는 백신과 농작물 수확량을 획기적으로 늘리는 인공비료 개발과 함께 이 제도적인 노력으로 평균 수명을 두 배로 늘리는 원동력이 되었다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#작업과정",
    "href": "tool-viz.html#작업과정",
    "title": "28  시각화",
    "section": "\n28.2 작업과정",
    "text": "28.2 작업과정\n\n28.2.1 디지털 데이터\n \n스페인 R-ladies GitHub 저장소 rladies/spain_nightingale에서 엑셀 형태로 된 데이터를 가져와서 전처리 작업을 진행한다.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\ndeath_raw &lt;- read_excel(\"data/datos_florence.xlsx\", sheet = \"Sheet1\", skip = 1)\n\ndeath_tbl &lt;- death_raw |&gt; \n  janitor::clean_names() |&gt; \n  set_names(c(\"Month\", \"Army\", \"Disease\", \"Wounds\", \"Other\", \"Disease.rate\", \"Wounds.rate\", \"Other.rate\")) |&gt; \n  mutate(Date = lubridate::my(Month)) |&gt; \n  separate(Month, into = c(\"Month\", \"Year\"), sep = \" |_\") |&gt; \n  select(Date, Month, Year, everything()) \n\ndeath_tbl\n#&gt; # A tibble: 24 × 10\n#&gt;   Date       Month Year   Army Disease Wounds Other Disease.rate Wounds.rate\n#&gt;   &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 1854-04-01 Apr   1854   8571       1      0     5          1.4         0  \n#&gt; 2 1854-05-01 May   1854  23333      12      0     9          6.2         0  \n#&gt; 3 1854-06-01 Jun   1854  28333      11      0     6          4.7         0  \n#&gt; 4 1854-07-01 Jul   1854  28722     359      0    23        150           0  \n#&gt; 5 1854-08-01 Aug   1854  30246     828      1    30        328.          0.4\n#&gt; 6 1854-09-01 Sep   1854  30290     788     81    70        312.         32.1\n#&gt; # ℹ 18 more rows\n#&gt; # ℹ 1 more variable: Other.rate &lt;dbl&gt;\n\nHistDate 패키지에 동일한 데이터셋이 잘 정제되어 있어 이를 바로 활용해도 좋다.\n\nlibrary(HistData)\n\nHistData::Nightingale |&gt; \n  as_tibble()\n#&gt; # A tibble: 24 × 10\n#&gt;   Date       Month  Year  Army Disease Wounds Other Disease.rate Wounds.rate\n#&gt;   &lt;date&gt;     &lt;ord&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;  &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 1854-04-01 Apr    1854  8571       1      0     5          1.4         0  \n#&gt; 2 1854-05-01 May    1854 23333      12      0     9          6.2         0  \n#&gt; 3 1854-06-01 Jun    1854 28333      11      0     6          4.7         0  \n#&gt; 4 1854-07-01 Jul    1854 28722     359      0    23        150           0  \n#&gt; 5 1854-08-01 Aug    1854 30246     828      1    30        328.          0.4\n#&gt; 6 1854-09-01 Sep    1854 30290     788     81    70        312.         32.1\n#&gt; # ℹ 18 more rows\n#&gt; # ℹ 1 more variable: Other.rate &lt;dbl&gt;\n\n\n28.2.2 데이터와 사투\n앞서 준비한 death_tbl 데이터프레임에서 사망 관련 데이터를 처리하고 시각화하기 위한 전처리를 수행하여 시각화를 위한 준비작업을 수행한다. 먼저 Date, Disease.rate, Wounds.rate, Other.rate 칼럼을 선택하고, pivot_longer 함수를 사용해 시각화에 적합한 데이터로 재구조화한다. str_replace_all 함수를 사용하여 칼럼 이름에서 “.rate”를 제거하고, ifelse 함수를 이용해 날짜를 기준으로 나이팅게일 팀이 준비한 방식을 적용하기 전과 후의 “이전”과 “이후” 체제로 구분한다. factor 함수를 사용하여 범주 순서를 정의하고, 마지막으로 month 함수를 이용해 날짜에서 해당 월을 추출하고 death_viz에 저장한다.\n\ndeath_viz &lt;- death_tbl %&gt;% \n  select(Date, Disease.rate, Wounds.rate, Other.rate) %&gt;% \n  pivot_longer(-Date, names_to = \"사망원인\", values_to = \"사망자수\") |&gt; \n  mutate(사망원인 = str_replace_all(사망원인, \"\\\\.rate\", \"\"), \n         체제 = ifelse(Date &lt;= as.Date(\"1855-03-01\"), \"조치이전\", \"조치이후\")) %&gt;% \n  mutate(체제 = factor(체제, levels = c(\"조치이전\", \"조치이후\"))) %&gt;%  \n  mutate(해당월 = month(Date, label = TRUE, abbr = TRUE)) |&gt; \n  mutate(사망원인 = case_when(사망원인 == \"Disease\" ~ \"질병\",\n                              사망원인 == \"Wounds\" ~ \"부상\",\n                              사망원인 == \"Other\" ~ \"기타\")) |&gt; \n  mutate(사망원인 = factor(사망원인, levels = c(\"질병\", \"부상\", \"기타\")))\n\ndeath_viz\n#&gt; # A tibble: 72 × 5\n#&gt;   Date       사망원인 사망자수 체제     해당월\n#&gt;   &lt;date&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;    &lt;ord&gt; \n#&gt; 1 1854-04-01 질병          1.4 조치이전 \" 4\"  \n#&gt; 2 1854-04-01 부상          0   조치이전 \" 4\"  \n#&gt; 3 1854-04-01 기타          7   조치이전 \" 4\"  \n#&gt; 4 1854-05-01 질병          6.2 조치이전 \" 5\"  \n#&gt; 5 1854-05-01 부상          0   조치이전 \" 5\"  \n#&gt; 6 1854-05-01 기타          4.6 조치이전 \" 5\"  \n#&gt; # ℹ 66 more rows",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#시각화",
    "href": "tool-viz.html#시각화",
    "title": "28  시각화",
    "section": "\n28.3 시각화",
    "text": "28.3 시각화\n \n‘ggplot2’ 패키지를 이용하여 크림전쟁 나이팅게일 활약상을 담은 데이터를 시각화한다. 나이팅게일 활약 전과 후로 데이터(death_viz)를 나눠 “크림전쟁 병사 사망원인”에 대한 극좌표계 시각화를 통해 이해하기쉬운 설득력 있는 시각화 결과물을 제시하고 있다. 추가적으로, ‘showtext’ 패키지로 구글 “Noto Serif KR” 글꼴을 선택 적용하고, ‘hrbrthemes’ 라이브러리를 이용하여 뒷배경 검정색을 사용하여 붉은색 질병으로 인한 사망자 수의 확연한 감소를 시각적으로 강조한다.\n\nlibrary(hrbrthemes) \nlibrary(showtext)\nshowtext.auto()\nfont_add_google(name = \"Noto Serif KR\", family = \"noto_serif\")\nnoto_font &lt;- \"noto_serif\"\n\ndeath_gg &lt;- death_viz %&gt;% \n  ggplot(aes(x = 해당월, y = 사망자수, fill = 사망원인)) +\n  geom_col(color = \"grey20\") + \n  theme_modern_rc(base_family = noto_font, subtitle_family = noto_font) + \n  scale_fill_manual(values = c(\"firebrick\", \"orange\", \"#365181\"), name = \"\") +\n  scale_y_sqrt() +\n  facet_wrap(~ 체제) + \n  coord_equal(ratio = 1) +  \n  coord_polar() +\n  labs(title = \"크림전쟁 병사 사망원인\", \n       subtitle = \"데이터 시각화와 커뮤니케이션\", \n       caption = \"데이터 출처: 크림전쟁 사망자\") + \n  theme(legend.position = \"top\", \n        text = element_text(family = noto_font, size = 18),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks = element_blank(),\n        axis.text.x   = element_text(family = \"MaruBuri\", color = \"white\", size = 50),\n        axis.text.y   = element_text(family = \"MaruBuri\", color = \"white\", size = 50),\n        plot.margin = unit(rep(0.7, 4), \"cm\"),\n        plot.title = element_text(color = \"white\", family = noto_font, size = 100),\n        plot.subtitle = element_text(color = \"grey70\", size = 70),\n        plot.caption = element_text(color = \"grey70\", family = noto_font, size = 54),\n        legend.title = element_text(color = \"white\", size = 70),\n        legend.text = element_text(color = \"white\", size = 55),\n        strip.text = element_text(color = \"white\", size = 80, face = \"bold\", family = noto_font, hjust = 0.5))\n\ndeath_gg\n\nragg::agg_jpeg(\"images/viz_death_gg.jpeg\", width = 10, height = 7, units = \"in\", res = 600)\ndeath_gg\ndev.off()\n\n\n\n\n\n\n그림 28.5: 크림전쟁 병사 사망원인 조치전후 시각화\n\n\n\n28.3.1 선그래프\n \n나이팅게일은 간호 분야의 선구자로 잘 알려져 있지만, 통계학자로서 “콕스콤(CoxComb)” 또는 “장미 다이어그램”(Rose Diagram)으로 알려진 원그래프를 제시하였지만 현재는 시간의 흐름에 따라 병사 사망자 수 변화를 조치 전후로 명확히 하는 방법으로 선그래프가 기본 기법으로 자리 잡고 있다.\n\ndeath_new_gg &lt;- death_viz |&gt; \n  ggplot(aes(x = Date, y = 사망자수, color = 사망원인)) +\n    geom_line() +\n    geom_point() +\n    geom_vline(xintercept = as.Date(\"1855-03-15\"), linetype= 2) +\n    theme_ipsum_pub(base_family = noto_font, subtitle_family = noto_font) +\n    labs(title = \"크림전쟁 병사 사망원인\", \n         subtitle = \"데이터 시각화와 커뮤니케이션\", \n         caption = \"데이터 출처: 크림전쟁 사망자\",\n         x = \"월일\") + \n    scale_y_continuous(labels = scales::comma, limits = c(0, 1150)) +\n    theme(legend.position = \"top\", \n          text = element_text(family = noto_font, size = 35),\n          axis.ticks = element_blank(),\n          plot.margin = unit(rep(0.7, 4), \"cm\"),\n          axis.title.x   = element_text(family = \"MaruBuri\", size = 45),\n          axis.title.y   = element_text(family = \"MaruBuri\", size = 45),\n          axis.text.x    = element_text(family = \"MaruBuri\", size = 35),\n          axis.text.y    = element_text(family = \"MaruBuri\", size = 35),\n          plot.title = element_text(color = \"black\", family = noto_font, size = 100),\n          plot.subtitle = element_text(color = \"black\", family = noto_font, size = 80),\n          plot.caption = element_text(color = \"grey10\", family = noto_font, size = 37),\n          legend.text = element_text(color = \"black\", size = 45)) +\n    geom_segment(x = as.Date(\"1854-03-01\"), y = 1100,\n                 xend = as.Date(\"1855-03-01\"), yend = 1100,\n                 color = \"gray70\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    geom_segment(x = as.Date(\"1855-04-01\"), y = 1100,\n                 xend = as.Date(\"1856-03-01\"), yend = 1100,\n                 color = \"gray15\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    annotate(\"text\", x = as.Date(\"1854-09-01\"), y = 1140, label = \"조치이전\",\n             size = 20.5, color = \"gray30\", family = noto_font) +\n    annotate(\"text\", x = as.Date(\"1855-09-01\"), y = 1140, label = \"조치이후\",\n             size = 20.5, color = \"gray15\", family = noto_font)          \n\ndeath_new_gg\n\nragg::agg_jpeg(\"images/death_new_gg.jpeg\", width = 10, height = 7, units = \"in\", res = 600)\ndeath_new_gg\ndev.off()\n\n\n\n\n\n\n그림 28.6: 크림전쟁 병사 사망원인 조치전후 선 그래프\n\n\n\n28.3.2 막대그래프\n동일한 정보를 막대그래프를 통해 시각화를 할 수도 있다. 원그래프와 비교하여 보면 명확하게 사망자 수를 직관적으로 비교할 수 있다는 점에서 큰 장점이 있다.\n\ndeath_bar_gg &lt;- death_viz |&gt; \n  ggplot() +\n    geom_col(aes(x = Date, y = 사망자수, fill = 사망원인), colour=\"white\") +\n    geom_vline(xintercept = as.Date(\"1855-03-15\"), linetype= 2) +\n    scale_fill_manual(values = c(\"firebrick\", \"orange\", \"#365181\")) + \n    # theme_ipsum_pub(base_family = noto_font, subtitle_family = noto_font) +\n    labs(title = \"크림전쟁 병사 사망원인\", \n         subtitle = \"데이터 시각화와 커뮤니케이션\", \n         caption = \"데이터 출처: 크림전쟁 사망자\",\n         x = \"월일\") + \n    scale_y_continuous(labels = scales::comma, limits = c(0, 1150)) +\n    theme(legend.position = \"top\", \n          text = element_text(family = noto_font, size = 35),\n          axis.ticks = element_blank(),\n          plot.margin = unit(rep(0.7, 4), \"cm\"),\n          axis.title.x   = element_text(family = \"MaruBuri\", size = 45),\n          axis.title.y   = element_text(family = \"MaruBuri\", size = 45),\n          axis.text.x    = element_text(family = \"MaruBuri\", size = 35),\n          axis.text.y    = element_text(family = \"MaruBuri\", size = 35),\n          plot.title = element_text(color = \"black\", family = noto_font, size = 100),\n          plot.subtitle = element_text(color = \"black\", family = noto_font, size = 80),\n          plot.caption = element_text(color = \"grey10\", family = noto_font, size = 37),\n          legend.title = element_text(color = \"black\", size = 70),\n          legend.text = element_text(color = \"black\", size = 45)) +\n    geom_segment(x = as.Date(\"1854-03-01\"), y = 1100,\n                 xend = as.Date(\"1855-03-01\"), yend = 1100,\n                 color = \"gray70\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    geom_segment(x = as.Date(\"1855-04-01\"), y = 1100,\n                 xend = as.Date(\"1856-03-01\"), yend = 1100,\n                 color = \"gray15\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    annotate(\"text\", x = as.Date(\"1854-09-01\"), y = 1140, label = \"조치이전\",\n             size = 8.5, color = \"gray30\", family = noto_font) +\n    annotate(\"text\", x = as.Date(\"1855-09-01\"), y = 1140, label = \"조치이후\",\n             size = 8.5, color = \"gray15\", family = noto_font) \n\ndeath_bar_gg\n\nragg::agg_jpeg(\"images/death_bar_gg.jpeg\", width = 10, height = 7, units = \"in\", res = 600)\ndeath_bar_gg\ndev.off()\n\n\n\n\n\n\n그림 28.7: 크림전쟁 병사 사망원인 조치전후 막대 그래프",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#표-문법",
    "href": "tool-viz.html#표-문법",
    "title": "28  시각화",
    "section": "\n28.4 표 문법",
    "text": "28.4 표 문법\n \n데이터 문법, 그래프 문법에 이어 최근 “표 문법”이 새롭게 자리를 잡아가고 있다. 표 문법에 맞춰 나이팅게일 크림전쟁 사망자 수를 조치 이전과 조치 이후로 나눠 요약하면 확연한 차이를 파악할 수 있다.\ngt와 gtExtras 패키지를 활용하여 death_viz 데이터프레임을 사망 원인별 사망자 수를 “조치 이전”과 “조치 이후”로 구분하여 표를 두 개 생성한다. 각 표는 날짜, 질병, 부상, 기타 범주로 사망자 수와 그 합계를 표시하며, 총 사망자 수가 250명을 초과하는 행에 대한 강조 색상을 입히고 나서 두 표를 나란히 배치하여 조치 전후 효과를 시각적으로 비교한다.\n\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(patchwork)\n\nbefore_tbl &lt;- death_viz |&gt; \n  filter(체제 == \"조치이전\")\n\nafter_tbl &lt;- death_viz |&gt; \n  filter(체제 == \"조치이후\")\n\nbefore_gt &lt;- before_tbl |&gt; \n  pivot_wider(names_from = 사망원인, values_from = 사망자수) |&gt; \n  select(날짜 = Date, 질병, 부상, 기타) |&gt; \n  mutate(합계 = 질병 + 부상 + 기타) |&gt; \n  gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer( columns = 질병:합계) |&gt; \n    tab_spanner(label = \"조치 이전\", columns = c(질병, 부상, 기타)) |&gt; \n    data_color(\n      columns = c(질병, 부상, 기타, 합계),\n      rows = 합계 &gt; 250,      \n      method = \"numeric\",\n      palette = \"ggsci::red_material\")\n\nafter_gt &lt;- after_tbl |&gt; \n  pivot_wider(names_from = 사망원인, values_from = 사망자수) |&gt; \n  select(날짜 = Date, 질병, 부상, 기타) |&gt; \n  mutate(합계 = 질병 + 부상 + 기타) |&gt; \n  gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer( columns = 질병:합계) |&gt; \n  tab_spanner(label = \"조치 이후\", columns = c(질병, 부상, 기타)) |&gt; \n  data_color(\n    columns = c(질병, 부상, 기타, 합계),\n    rows = 합계 &gt; 250,      \n    method = \"numeric\",\n    palette = \"ggsci::red_material\")\n\n# before_gt |&gt; \n#    gtsave(\"before_gt.png\", path = \"images\")\n# after_gt  |&gt; \n#    gtsave(\"after_gt.png\", path = \"images\")\n\nlibrary(cowplot)\np111 &lt;- ggdraw() + draw_image(\"images/before_gt.png\", scale = 1.0)\np112 &lt;- ggdraw() + draw_image(\"images/after_gt.png\", scale = 0.9)\nplot_grid(p111, p112)\n\n\n\n\n\n\n그림 28.8: 조치 전후 변화를 표 시각화",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#커뮤니케이션",
    "href": "tool-viz.html#커뮤니케이션",
    "title": "28  시각화",
    "section": "\n28.5 커뮤니케이션",
    "text": "28.5 커뮤니케이션\n \n데이터를 기반으로 뭔가 유용한 것을 창출한 후에 이를 알리기 위해 커뮤니케이션 단계를 거치게 된다. 가장 흔히 사용하는 방식은 엑셀, 워드, 파워포인트와 같은 MS 오피스 제품을 활용하는 방식이다. 과거 SAS, SPSS, 미니탭 등 외산 통계 패키지로 데이터를 분석하고 유용한 모형 등을 찾아낸 후에 이를 커뮤니케이션하기 위해 MS 오피스 제품을 통해 커뮤니케이션을 하기도 했다. 하지만, 각각은 별개의 시스템으로 분리되어 있어 일일이 사람 손이 가는 번거로움이 많았다. 이를 해결하기 위한 방법은 하나의 도구 혹은 언어로 모든 작업을 처리하는 것이다. 2\n우선 엑셀은 tidyverse로 대체가 되고, 워드는 R 마크다운을 거쳐 쿼토(Quarto), 파워포인트도 R 마크다운(xaringan 등)에서 진화한 reveal.js 기반 쿼토 슬라이드가 빠르게 자리를 잡아가고 있다.\n\n\n\n\n\n그림 28.9: 오피스 기반 커뮤니케이션 현재 상태점검\n\n\n데이터 과학을 커뮤니케이션하는 방식은 다양한 방식이 존재하지만 직장상사뿐만 아니라 집단지성을 넘어 AI를 적극 도입하여 데이터 분석 역량을 고도화하는 데 동료 개발자 및 협업하시는 분들과 커뮤니케이션뿐만 아니라 불특정 다수를 대상으로 한 인터넷 공개와 공유를 통해 새로운 관계를 맺어가는 것도 그 중요성을 더해가고 있다.\n\n동료 개발자나 협업하시는 분: .qmd 파일\n직장상사\n\nPDF 파일: \\(\\LaTeX\\), pandoc, quarto\n\n파워포인트 슬라이드덱: reveal.js 기반 quarto\n\n대시보드: flexdashboard를 지나 quarto\n\n\n\n일반 공개\n\n웹사이트: distill을 지나 quarto\n\n블로그: blogdown을 지나 quarto\n\n책: bookdown을 지나 quarto\n\n\n\n프로그래밍\n\n과학기술: 줄리아(julia)\n웹 데이터 시각화: observable JS, plotly, leaflet 등\n데이터 과학: R\n기계학습과 딥러닝: 파이썬\n데이터베이스: SQL\n자동화: 유닉스 쉘\n버전제어와 협업: git, github, gitlab, bitbucket 등\n\n\n\n데이터 과학 커뮤니케이션에서 동료 개발자나 협업하는 분들과 의사소통할 때는 .qmd 파일을 사용한다. 직장상사와 커뮤니케이션할 때는 PDF 파일, 파워포인트 슬라이드덱, 대시보드 등 다양한 방식을 활용하는데, PDF 파일은 \\(\\LaTeX\\), pandoc, quarto를 사용하고, 파워포인트 슬라이드덱은 reveal.js 기반 quarto를, 대시보드는 flexdashboard를 지나 quarto 대시보드를 사용한다. 일반 공개를 위해서는 웹사이트, 블로그, 책 등의 형태로 공유하는데, 웹사이트는 distill을 지나 quarto 웹사이트를, 블로그는 blogdown을 지나 quarto 블로그를, 책은 bookdown을 지나 quarto 책(book)을 활용한다.\n\n\n\n\n\n그림 28.10: 이해당사자 쿼토 커뮤니케이션",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-viz.html#footnotes",
    "href": "tool-viz.html#footnotes",
    "title": "28  시각화",
    "section": "",
    "text": "출처: How Florence Nightingale Changed Data Visualization Forever - The celebrated nurse improved public health through her groundbreaking use of graphic storytelling↩︎\nMeghan Hall (June 15, 2021), “Extending R Markdown”, RStudio: R in Sports Analytics,↩︎",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>시각화</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html",
    "href": "tool-gpt.html",
    "title": "\n29  챗GPT 코딩\n",
    "section": "",
    "text": "29.1 코딩 패러다임\n1950년대부터 본격적으로 컴퓨터가 도입되면서 CLI를 필두로 다양한 사용자 인터페이스(User Interface)가 적용되었다. 스티브 잡스의 애플사는 매킨토시 GUI에 이어 아이폰 모바일 인터페이스를 일반화시켰다면, 최근 챗GPT는 언어 사용자 인터페이스(LUI)를 통해 각 분야에 혁신을 예고하고 있다. 챗GPT[1] 데이터 과학도 사용자 관점에서 보자. 기존 R, 파이썬, SQL, 엑셀 등 데이터 과학 구문을 머리속에 암기하고 있거나 구글이나 네이버를 통해 중요 키워드를 통해 문제를 해결해야 했었다. 하지만, 이제 챗GPT가 자연어를 이해하기 때문에 데이터 전처리, 통계 작업, 데이터 분석, 시각화, 모형개발 등 데이터 과학 전반에 변화는 필연적이다. [2], [3], wickham2019welcome?\n챗GPT[4]는 인터넷에서 방대한 양의 데이터를 학습하여 이를 정말 잘 압축한 하나의 저장소로 이해할 수 있다. 따라서, 압축을 풀게 되면 정확히 원본을 복원할 수 있는 부분도 있지만, 그렇지 못한 부분도 당연히 있게 된다. 챗GPT를 “웹의 흐릿한 JPEG”[5]으로 비유하고 있다. JPEG 기술 자체는 손실 압축기술로 무손실 압축기술로 대표적인 PNG와 대비된다. 흐릿한 이미지가 선명하지 않거나 정확하지 않은 것처럼 챗GPT도 항상 완벽한 답변을 제공하거나 모든 질문을 제대로 이해하는 것은 아니다. 하지만 사용자와의 대화를 기반으로 끊임없이 학습하고 개선하고 있다. 더 많은 사람들이 챗GPT를 사용할수록 사람의 언어를 더 잘 이해하고 반응할 수 있게 개발된 기술이다.\n코딩 세계는 끊임없이 진화한다. 전통적인 코딩 방식에서 시작하여 기계학습 코딩, 최근 챗GPT와 같은 대규모 언어모델(LLM)을 활용한 프롬프트 기반 코딩에 이르기까지, 새로운 패러다임이 계속해서 등장하고 있다.\n전통적인 코딩은 프로그래머가 직접 모든 코드를 작성하고 논리를 구축하는 방식으로 개발자 전문성과 경험에 크게 의존하며, 코드 품질과 효율성은 프로그래머의 역량에 달려 있다. 하지만 이러한 접근법은 시간이 많이 소요되고 반복적인 작업이 많아 생산성이 낮아 통합개발환경(IDE), 소프트웨어 공학, 소프트웨어 아키텍처, 디자인 패턴 등의 방법론과 도구가 발전하며 개선되어 왔고 현재 주류를 형성하고 있다.\n기계학습 코딩은 데이터와 알고리즘을 활용하여 컴퓨터 스스로 코드를 생성하고 최적화할 수 있게 하는 방식으로 전통적인 코딩 방식으로 풀 수 없는 복잡한 문제를 해결할 수 있다. 기계학습 코딩 방식은 대규모 데이터셋과 복잡한 알고리즘을 필요로 하지만, 일단 학습이 완료되면 개발자가 작성한 코드보다 월등한 성능을 보인다. 다만 기계학습 모형의 성능은 데이터의 질과 양, 알고리즘의 복잡성, 컴퓨팅 자원에 따라 크게 좌우된다.\n최근 챗GPT와 같은 대규모 언어모델을 활용한 프롬프트 기반 코딩이 주목받고 있다. 자연어 프롬프트를 입력하면 언어모델이 이해하고 관련 코드를 생성한다는 점에서 일종의 생성형 모형으로 볼 수 있다. 프롬프트 기반 코딩은 전통적인 코딩 방식과 기계학습 코딩의 장점을 결합했다. 프로그래머는 자연어로 의도를 표현할 수 있고, LLM은 의도를 파악하여 코드로 변환해주어 생산성과 효율성을 높일 수 있어 매우 유용하다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#코딩-패러다임",
    "href": "tool-gpt.html#코딩-패러다임",
    "title": "\n29  챗GPT 코딩\n",
    "section": "",
    "text": "그림 29.2: 코딩 패러다임 변화",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#프롬프트-공학",
    "href": "tool-gpt.html#프롬프트-공학",
    "title": "\n29  챗GPT 코딩\n",
    "section": "\n29.2 프롬프트 공학",
    "text": "29.2 프롬프트 공학\n \n프롬프트 공학(Prompt Engineering)은 챗GPT와 같은 AI 언어 모형으로부터 구체적이고 정확하며 관련성 있는 응답을 도출하기 위해 프롬프트(Prompt, 지시명령어)를 설계하고 개선하는 과정이다. 프롬프트의 품질이 GPT 모형 출력결과에 큰 영향을 미칠 수 있기 때문에 이 작업은 매우 중요하다. 프롬프트 엔지니어링의 목표는 사용자와 AI 모델 사이의 커뮤니케이션을 최적화하여 AI 시스템의 유용성과 효율성을 향상시키는 것이다.\n프롬프트 엔지니어링은 반복적인 작업과정으로 AI의 응답에 따라 프롬프트를 조정하고 개선해야 할 수도 있다는 점을 항상 염두에 두고, 다음 프롬프트 구성요소를 프롬프트에 녹여 제작할 경우 AI 언어 모델이 목표에 부합하는 정확하고 관련성 있는 구체적인 답변을 효과적으로 생성할 수 있다.\n프롬프트 공학을 코딩에 적용할 때의 장점은 자연어로 의도를 표현할 수 있어 코딩 입문자도 쉽게 접근할 수 있고, 수많은 프로그래밍 언어에 대한 장벽이 크게 낮아진 것을 들 수 있다. 또한 기존 코드를 수정하거나 새로운 코드를 작성할 때 생산성을 높일 수 있고, 언어모델이 제공하는 광범위한 지식을 활용할 수 있어 코드의 품질이 향상되었다. 하지만, 프롬프트를 잘 설계하기 위해서는 프롬프트 공학에 대한 지식과 경험이 필요하기 때문에 프롬프트 공학에 대한 깊은 이해가 필요하고, 언어모델 출력 결과가 완벽하지 않기 때문에 필연적으로 전문 개발자의 검토와 수정이 필요하며 저작권을 비롯한 보안 및 윤리 문제를 풀어야 하는 숙제가 남아있다.\n프롬프트 공학을 코딩에 적용하는 절차는 전통적인 코딩 절차와 별반 다르지 않다. 첫째로 목표를 설정하고, 작성하려는 코드의 정확한 기능과 요구사항을 명시하여 코드가 어떤 입력을 받고, 어떤 출력을 내야 하는지 파악한다. 둘째로 목표를 자연어 프롬프트에 담아낸다. 가능한 상세하고 구체적인 프롬프트를 작성하고 사례, 제약조건 등도 포함한다. 셋째로 프롬프트를 대규모 언어모델에 입력한다. 언어모형이 프롬프트를 이해하고 관련 코드를 생성하는 본 작업을 진행하고 필요한 경우 추가 프롬프트를 언어모형에 피드백을 제공한다. 넷째로 생성된 코드를 주의 깊게 검토하고 오류, 비효율성, 스타일 이슈 등을 반영하여 코드품질을 향상시킨다. 다섯째로 다양한 입력 값으로 코드를 실행하고 출력을 검증하며 발견된 오류는 디버깅하여 수정한다. 마지막으로 테스트 결과를 바탕으로 프롬프트를 개선할 점을 파악하고, 프롬프트를 수정하여 새로운 코드를 생성한 후 결과를 비교하는 과정을 반복한다.\n\n\n\n\n\n그림 29.3: 챗GPT 코딩 작업흐름\n\n\n챗GPT 코딩 구성요소는 프롬프트와 언어모형으로 구성되어 있다고 보면 된다. 자연어 프롬프트를 통해 생성하고자 하는 코드의 목적과 요구사항을 명시하여 언어모형에 전달하면 언어모형은 프롬프트를 이해하고 관련 코드를 생성한다. 몇년전 영어가 가장 뜨거운 프로그래밍 언어라는 주장이 허언은 아닌 것이다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#챗gui-인터페이스",
    "href": "tool-gpt.html#챗gui-인터페이스",
    "title": "\n29  챗GPT 코딩\n",
    "section": "\n29.3 챗GUI 인터페이스",
    "text": "29.3 챗GUI 인터페이스\n \nOpenAI 챗GPT, 구글 Gemini, 앤트로픽 클로드 등을 사용하여 코드를 생성시킬 수 있다. 챗GPT를 비롯한 대규모 언어모형은 API도 제공하고 있어서 챗 인터페이스가 불편한 경우 API를 통해 개발하고 있는 프로그램에 직접 적용할 수도 있다. 먼저 최근 인기를 얻고 있는 챗GPT 대항마로 떠오르고 있는 앤트로픽 클로드(claude)를 통해 코드를 생성하는 방법을 알아보자.\n\n\n프롬프트\n출력결과\n\n\n\n초등학교 5학년을 대상으로 프로그래밍을 처음 시작하려 합니다. 정말 읽기 쉽고 코딩에 흥미를 가질 수 있는 R 코드를 작성해줘\n\n\n\n\n\n그림 29.4: 앤트로픽 클로드 챗 인터페이스\n\n\n\n\n초등학생을 대상으로 R 프로그래밍을 가르치려면 단계적이고 재미있는 접근이 필요합니다. 여기 간단한 예제 코드를 제공하겠습니다:\n# 안녕하세요! R은 재미있는 프로그래밍 언어예요.\n# 이번 시간에는 숫자와 문자를 다뤄볼 거예요.\n\n# 숫자 계산하기\n숫자1 &lt;- 5\n숫자2 &lt;- 3\n합계 &lt;- 숫자1 + 숫자2\nprint(합계) # 8이 출력됩니다.\n\n# 문자 다루기\n이름 &lt;- \"철수\"\nprint(paste(\"안녕하세요,\", 이름, \"님!\")) # \"안녕하세요, 철수 님!\"이 출력됩니다.\n\n# 조건문 사용하기\n나이 &lt;- 10\nif (나이 &gt;= 20) {\n  print(\"어른이군요!\")\n} else {\n  print(\"아직 어려운 친구예요.\")\n} # \"아직 어려운 친구예요.\"가 출력됩니다.\n\n# 반복문 사용하기\nfor (숫자 in 1:5) { # 1부터 5까지 반복합니다.\n  print(paste(숫자, \"번째 반복입니다.\"))\n}\n\n# 벡터(여러 개의 값을 한번에 다루기)\n과일 &lt;- c(\"사과\", \"바나나\", \"딸기\")\nprint(과일) # \"사과\" \"바나나\" \"딸기\"가 출력됩니다.\n이 코드에서는 다음과 같은 개념들을 다룹니다:\n\n변수 할당과 연산\n문자열 다루기\n조건문 (if-else)\n반복문 (for 루프)\n벡터 (여러 값을 한번에 저장)\n\n각 개념마다 친숙한 예시를 사용하여 학생들이 이해하기 쉽도록 하였습니다. 또한 print() 함수를 활용하여 결과를 바로 확인할 수 있게 하였습니다.\n이 코드를 바탕으로 학생들과 함께 살펴보며 R 프로그래밍의 기초를 익힐 수 있을 것입니다. 궁금한 점이 더 있다면 언제든 물어보세요!",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#프로그래밍",
    "href": "tool-gpt.html#프로그래밍",
    "title": "\n29  챗GPT 코딩\n",
    "section": "\n29.4 프로그래밍",
    "text": "29.4 프로그래밍\n \nGUI 챗팅 인터페이스를 사용하면 직관적으로 R 코드를 생성할 수 있지만, 자동화를 할 수 없다는 문제와 함께 재사용도 매번 복사하여 붙여넣기를 해야한다는 문제가 있다. 대신 프로그래밍을 통해 R 혹은 파이썬 코드 생성작업을 자동화하고 재사용할 수 있도록 한걸음 더 들어가 보자.\n자연어로 시각화하는 프로그램 작성을 본격적으로 들어가기 전에 기본적인 설정을 다음과 같이 한다. 다양한 언어로 OpenAI API를 활용하는 것이 가능하지만 지면관계상 파이썬으로 OpenAI GPT 모델을 사용해 사용자 질문에 자동으로 답하는 스크립트를 작성한다. 헬로월드(“Hello World!”)를 통해 기본 설정이 정상동작하는지 확인한다. \n\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"R 언어가 뭔지 간략하게 설명해줘\",\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\nprint(chat_completion.choices[0].message.content)\n\n\n\n모듈 가져오기:\n\n\nos는 운영 체제와 상호작용하고, 환경 변수에 접근하는 데 사용된다.\n\nopenai는 OpenAI의 파이썬 클라이언트 라이브러리로, GPT 모델을 사용하는 데 필요하다.\n\ndotenv는 .env 파일에서 환경 변수를 로드하는 데 사용된다.\n\n\n\n환경 변수 로드:\n\n\nload_dotenv()는 프로젝트 루트의 .env 파일로부터 환경 변수를 로드한다. .env 파일에 저장된 OPENAI_API_KEY 환경변수를 가져온다.\n\n\n\nOpenAI 클라이언트 초기화:\n\n\nOpenAI를 사용해 API 클라이언트를 생성한다.\n\napi_key=os.getenv('OPENAI_API_KEY')는 환경 변수에서 OPENAI_API_KEY를 가져와 클라이언트를 인증한다.\n\n\n\n채팅 완성 생성:\n\n\nclient.chat.completions.create는 OpenAI의 채팅 완성 API를 사용해 채팅 대화를 생성한다.\n\nmessages는 사용자의 입력 메시지를 담고 있다. 이 경우 “R 언어가 뭔지 간략하게 설명해줘”라는 질문이 포함되어 있다.\n\nmodel=\"gpt-3.5-turbo\"는 사용할 GPT 모델을 지정한다.\n\n\n\n결과 출력:\n\n\nprint(chat_completion.choices[0].message.content)는 생성된 채팅 대화에서 첫 번째 선택 항목의 메시지 내용을 출력한다. 이는 GPT 모델이 생성한 답변을 보여준다.\n\n\n\nR 언어는 통계 분석 및 데이터 시각화를 위한 프로그래밍 언어로, 특히 데이터 분석 및 머신러닝 분야에서 널리 사용됩니다. R은 무료로 사용할 수 있고 다양한 통계 및 그래픽 라이브러리를 제공하여 데이터 분석가들이 데이터를 쉽게 다룰 수 있도록 도와줍니다. R 언어는 벡터화된 연산을 통해 효율적으로 대용량 데이터를 다룰 수 있는 장점을 가지고 있습니다.\nOpenAI GPT-3.5 모델이 정상적으로 응답하는 것을 확인한 후, 다음 단계로 진행한다. 챗GPT 인터페이스로 작성된 프롬프트를 바탕으로, \"\"\" 안에 빈도수를 계산할 romeo.txt 파일 본문과 자연어로 텍스트에서 빈도수가 높은 단어를 화면에 출력하는 R 코드를 만들도록 하면, API 프로그래밍으로 만들어진 파이썬 스크립트에 적용된 인증 과정을 거친 후 R 코드를 생성하게 된다.\n\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.getenv('OPENAI_API_KEY'),\n)\n\ncode_message = \"\"\"\nYou are an expert in R language. \nThe following text have been provided to you. \nPlease convert my query into an appropriate r codes.\n\nBut soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n\n\nLet's write an r program to count the most frequent words on the screen.\n\"\"\"\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": code_message,\n        }\n    ],\n    model=\"gpt-3.5-turbo\",\n)\n\nprint(chat_completion.choices[0].message.content)\n\n출력결과가 상당히 만족스럽다. 영어로 되어있지만 주석과 함께 R 코드가 잘 생성된 것을 확인할 수 있다. 생성된 결과물 중 R 코드에 대한 부분만 추출하여 실제 실행시켜도 오류 없이 정상 실행됨이 확인된다.\n\n# Create a vector of the provided text\ntext &lt;- c(\"But soft what light through yonder window breaks\",\n          \"It is the east and Juliet is the sun\",\n          \"Arise fair sun and kill the envious moon\",\n          \"Who is already sick and pale with grief\")\n\n# Convert the text to lowercase\ntext &lt;- tolower(text)\n\n# Flatten the text into a single string\ntext &lt;- paste(text, collapse = \" \")\n\n# Split the text into individual words\nwords &lt;- strsplit(text, \"\\\\W+\")\n\n# Convert the list of words into a single vector\nwords &lt;- unlist(words)\n\n# Count the frequency of each word\nword_counts &lt;- table(words)\n\n# Sort the words by frequency\nword_counts &lt;- sort(word_counts, decreasing = TRUE)\n\n# Print the 5 most frequent words\nhead(word_counts, 5)\n#&gt; words\n#&gt;     and      is     the     sun already \n#&gt;       3       3       3       2       1\n\nOpenAI GPT-3.5 LLM 모형은 범용 언어모형이지만, 제시된 텍스트에서 가장 빈도수가 많은 단어를 추출하는 작업을 수행하는 R 코드를 생성했다. 생성된 R 코드는 주어진 텍스트를 소문자로 변환하고, 단어로 분리한 후, 각 단어 빈도수를 계산하여 가장 빈도수가 높은 단어 5개를 출력하는 코드를 제시했다.\nOpenAI GPT-3.5 모델이 GPT-4 모형과 비교하여 성능이 떨어지는 것으로 알려져 있지만, 단순한 텍스트 처리와 빈도수 계산에 대한 R 코드를 생성하는 데는 충분히 사용할 수 있을 것으로 보인다.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#심슨의-역설",
    "href": "tool-gpt.html#심슨의-역설",
    "title": "\n29  챗GPT 코딩\n",
    "section": "\n29.5 심슨의 역설",
    "text": "29.5 심슨의 역설\n\n심슨의 역설(Simpson’s Paradox)은 데이터를 취합할 때 의미 있는 변수를 생략하면 변수 간에 관찰되는 추세가 역전되는 데이터 현상이다. 부리의 길이와 깊이는 전체적으로 음의 상관관계를 보이지만, 종을 포함하면 이러한 추세가 반전되어 종 내에서는 부리 길이와 부리 깊이 사이에 양의 상관관계가 뚜렷하게 나타난다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n다음 코드에서 group 인수를 species로 설정하게 되면, 기존 부리 길이와 깊이 관계가 음의 상관에서 양의 상관관계로 변화함을 확인하게 되어 패러독스가 발생함을 확인할 수 있다.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "tool-gpt.html#프로젝트",
    "href": "tool-gpt.html#프로젝트",
    "title": "\n29  챗GPT 코딩\n",
    "section": "프로젝트",
    "text": "프로젝트\n\n28 장 나이팅게일 데이터를 이용하여 크림전쟁 사망자수를 위생조치를 취함으로써 줄인 시각화를 생성한다. 28 장 R 코드를 OpenAI 챗GPT, 구글 제미나이, 앤스로픽 클로드를 이용하여 파이썬 코드를 생성하고 파이썬 코드를 실행하여 정상 동작여부, 코드 품질, 시각화 결과물을 28 장 R 코드를 이용하여 생성한 결과물과 비교한다.\n\n\n\n\n[1] \nA. Vaswani 기타, “Attention is all you need”, Advances in neural information processing systems, vol 30, 2017.\n\n\n[2] \nH. Wickham, M. Çetinkaya-Rundel, 와/과 G. Grolemund, R for data science. \" O’Reilly Media, Inc.\", 2023.\n\n\n[3] \nR. Gozalo-Brizuela 와/과 E. C. Garrido-Merchan, “ChatGPT is not all you need. A State of the Art Review of large Generative AI models”, arXiv preprint arXiv:2301.04655, 2023.\n\n\n[4] \nT. Wu 기타, “A brief overview of ChatGPT: The history, status quo and potential future development”, IEEE/CAA Journal of Automatica Sinica, vol 10, 호 5, pp 1122–1136, 2023.\n\n\n[5] \nT. Chiang, “ChatGPT is a blurry JPEG of the web”, The New Yorker, vol 9, p 2023, 2023.",
    "crumbs": [
      "**4부** 분야별 코딩",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 코딩</span>"
    ]
  },
  {
    "objectID": "ide.html",
    "href": "ide.html",
    "title": "30  IDE 선택과 발전",
    "section": "",
    "text": "30.1 IDE 탄생과 발전\n소프트웨어 개발 세계는 끊임없이 진화하는 도구 생태계다. 중심에는 개발자 생산성을 극대화하는 통합 개발 환경(IDE, Integrated Development Environment)이 있다. IDE는 단순한 코드 편집기를 넘어, 컴파일, 디버깅, 버전 관리 등 개발 전 과정을 하나의 창에서 처리하는 강력한 작업 공간이다.\n모든 개발자에게 완벽한 단 하나의 IDE는 없다. 프로젝트 종류, 주 사용 언어, 개발 스타일에 따라 최적 도구는 달라진다. 본문에서는 IDE 역사부터 최신 AI 트렌드까지 살펴보고, 자신에게 맞는 IDE 선택과 구성에 필요한 지식을 다룬다.\n그림 30.1 는 오픈소스 소프트웨어(OSS) VS Code 기반 현대 데이터 과학 IDE(Positron, Cursor 등) 아키텍처다. 클라이언트 레이어(UI), Extension Host(확장 프로그램 실행), 커널 레이어(코드 실행), 외부 서비스 연동이 명확히 분리되어 있다.\nIDE 역사는 ’어떻게 하면 개발을 더 편하고 효율적으로 할 수 있을까?’라는 고민의 역사와 같다. 60년이 넘는 시간 동안 IDE는 기술 패러다임의 변화와 함께 진화해왔다.\n그림 30.2 은 1964년부터 2025년까지 IDE 진화를 5개 기술 시대로 구분해 보여준다. 각 시대는 당시 컴퓨팅 환경 특성을 반영한다. 메인프레임 시대에는 시분할 시스템으로 원격 터미널을 통해 대화형 프로그래밍이 가능해졌다. 1964년 다트머스 베이직(Dartmouth BASIC)은 학생들이 터미널에서 직접 코드를 입력하고 결과를 즉시 확인할 수 있는 최초의 대화형 환경을 제공했다.\nPC 시대가 열리면서 IDE는 개인 컴퓨터 위에서 작동하는 독립적인 소프트웨어가 되었다. 1983년 터보 파스칼(Turbo Pascal)은 앤더스 헤일스버그(Anders Hejlsberg)가 개발한 혁명적 제품으로, 초고속 컴파일과 통합 에디터를 $49.99라는 파격적 가격에 제공하며 상업용 IDE를 대중화했고 볼란드(Borland) 전성기였다. 1991년 Visual Basic은 드래그 & 드롭 GUI로 비주얼 프로그래밍 패러다임을 열었고, RAD(Rapid Application Development) 혁명을 일으켰다. 개발자가 폼 디자이너에서 버튼을 배치하고 속성을 설정하면 코드가 자동 생성되는 방식은 당시로서는 놀라운 생산성 향상이었다.\n인터넷 시대에는 오픈소스 IDE가 부상했다. 2001년 이클립스(Eclipse)가 플러그인 아키텍처로 자바(Java) 표준 IDE가 되었고, IBM의 대규모 지원으로 확장 생태계를 구축했다. 같은 해 등장한 인텔리제이(IntelliJ) IDEA는 심층 코드 분석과 리팩토링 혁신으로 “스마트 IDE” 기준을 세웠다. 젯브레인즈(JetBrains)가 내건 “즐거운 개발(Develop with Pleasure)” 슬로건은 단순히 개발자 경험을 개선하겠다는 선언이었고, 이후 Kotlin 언어까지 탄생시키는 혁신의 기반이 되었다.\n클라우드 시대는 개발 환경에 대한 물리적 제약을 허물었다. 2015년 등장한 VS Code는 일렉트론(Electron) 기반 크로스 플랫폼 편집기로 시작해, 모나코 편집기(Monaco Editor) 웹 기술과 30,000개 이상의 확장 프로그램으로 시장을 지배하게 되었다. 2020년 GitHub Codespaces는 브라우저 IDE로 설치 없이 즉시 개발할 수 있는 환경을 제공했으며, 컨테이너 기반으로 개발 환경을 정의하면 클라우드에서 즉시 실행되는 클라우드 네이티브 개발 방식이 확산되었다.\nAI IDE 시대는 2021년 GitHub Copilot 등장으로 본격화되었다. 생성형 코드로 개발자 생산성을 혁신했고, OpenAI Codex 기반 AI 페어 프로그래머는 주석이나 함수명만으로도 전체 함수를 자동 생성했다. 2024-25년에는 포지트론(Positron)이 R/Python 데이터 과학 특화 IDE로, Claude Code가 CLI 기반 자율 에이전트로 등장하며 AI 코딩의 새 지평을 열고 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-history",
    "href": "ide.html#sec-ide-history",
    "title": "30  IDE 선택과 발전",
    "section": "",
    "text": "그림 30.2: IDE 발전사: 60년의 진화",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-kernel",
    "href": "ide.html#sec-ide-kernel",
    "title": "30  IDE 선택과 발전",
    "section": "30.2 IDE 작동 원리: 커널 아키텍처",
    "text": "30.2 IDE 작동 원리: 커널 아키텍처\n60년 역사를 거치며 진화한 IDE는 어떤 구조로 파이썬, R, Julia, SQL 등 수십 가지 언어를 동시에 지원하는가? 비결은 커널(Kernel) 아키텍처에 있다.\n주피터(Jupyter) 프로젝트에서 시작해 이제는 많은 IDE 표준이 된 커널 아키텍처는 IDE(프론트엔드)와 언어 실행 엔진(백엔드)을 명확히 분리한다. 프론트엔드는 개발자가 코드를 입력하는 UI 부분이다. 주피터 노트북의 코드 셀이나 VS Code의 인터랙티브 창이 여기 해당한다. 프론트엔드 자체는 코드 실행 능력이 없고, 사용자가 입력한 코드를 커널에 전달하는 메신저 역할만 한다.\n실제 코드 실행은 커널이 담당한다. 커널은 별도 독립 프로세스로 백그라운드에서 동작한다. 파이썬 코드를 실행하면 IPython 커널이, R 코드를 실행하면 IRkernel이 작동하며, 프론트엔드로부터 받은 코드를 해당 언어 인터프리터로 실행한다. 프론트엔드와 커널은 ZeroMQ(ZMQ) 고성능 메시징 라이브러리로 통신한다. 메시지 종류와 형식은 주피터 메시징 프로토콜로 표준화되어 있다.\n주요 메시지 4가지가 있다. execute_request로 프론트엔드가 코드 실행을 요청하면, 커널은 실행 과정에서 stream으로 print() 같은 텍스트 출력을 실시간 전송하고, display_data로 그래프, 이미지, 표를 특정 포맷(image/png, text/html)으로 포장해 보낸다. 모든 실행이 끝나면 execute_reply로 완료결과를 전송한다.\n커널 아키텍처의 가장 큰 장점은 확장성이다. 새로운 언어를 지원하려면 주피터 메시징 프로토콜을 따르는 커널만 만들면 된다. IDE 프론트엔드는 수정할 필요가 없다. 주피터 생태계가 수백 개 언어 커널을 가질 수 있고, VS Code가 파이썬 확장 프로그램 하나로 복잡한 데이터 과학 워크플로우를 지원하는 비결이 여기 있다. 언어 서버 프로토콜(LSP, Language Server Protocol)이 언어 ‘분석’ 기능을 분리하고 표준화한 것처럼, 커널 아키텍처는 언어 ‘실행’ 기능을 분리하고 표준화해 놀라운 유연성과 확장성을 제공한다.\n\n\n\n\n\n\n그림 30.3: 커널 아키텍처 - 프론트엔드와 실행 엔진의 분리\n\n\n\n그림 30.3 는 IDE 프론트엔드(사용자 인터페이스)와 커널(언어 실행 엔진) 분리 구조와 ZeroMQ, 주피터 메시징 프로토콜을 통한 통신을 보여준다. 이러한 분리 덕분에 하나의 IDE가 여러 프로그래밍 언어를 지원한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-features",
    "href": "ide.html#sec-ide-features",
    "title": "30  IDE 선택과 발전",
    "section": "30.3 IDE 핵심 기능",
    "text": "30.3 IDE 핵심 기능\nIDE 구조를 이해했으니 이제 실전에서 사용하는 핵심 기능을 살펴보자. 현대 IDE는 단순한 텍스트 편집기를 넘어 개발 전 과정을 통합한 작업 환경으로, 마우스 클릭보다는 키보드 단축키로 모든 기능을 빠르게 호출하는 것이 효율적인 워크플로우의 핵심이다.\n\n\n\n\n\n\n그림 30.4: IDE 핵심 기능: 키보드 중심 워크플로우\n\n\n\n그림 30.4 는 현대 오픈소스 IDE의 화면 구성과 키보드 중심 워크플로우를 보여준다. 화면은 크게 4개 영역으로 나뉜다. 왼쪽 탐색기는 프로젝트 파일 트리를 표시하며, 중앙 편집기는 코드를 작성하는 메인 작업 공간이다. 하단 터미널은 명령어를 실행하고, 최하단 상태 바는 Git 브랜치, 오류 개수, 언어 버전을 한눈에 보여준다.\n편집기 영역을 자세히 보면 AI가 개발에 깊이 통합된 모습이 드러난다. 9번 라인에서 df.dropna() 다음에 .reset_index(drop=True) 메서드가 회색으로 표시되는데, 이것은 GitHub Copilot의 AI 자동완성 제안이다. 개발자가 코드 문맥을 읽고 다음에 필요할 로직을 미리 제안하는 것이다. Tab 키를 누르면 제안을 수락하고, 무시하려면 계속 타이핑하면 된다. 더 나아가 Cmd+I 단축키로 AI 편집 모드를 열어 “파일 없음 에러 처리 추가”처럼 자연어로 의도를 설명하면, AI가 직접 코드를 생성하거나 수정한다. 이것은 코딩 패러다임의 근본적 변화다.\nCmd+Shift+P 명령 팔레트는 IDE 숨겨진 보물이다. 마우스로 메뉴를 탐색하지 않고도 2,000개 이상의 명령에 즉시 접근한다. “Python: Select Interpreter”를 입력하면 파이썬 버전을 바꾸고, “Terminal: Create New Terminal”로 터미널을 추가하며, “Git: Commit”으로 커밋한다. 모든 작업이 키보드에서 손을 떼지 않고 진행된다.\n기존 개발 워크플로우는 에러가 발생하면 브라우저로 전환해 StackOverflow를 검색하고, 코드를 복사해 붙여넣은 뒤 디버깅하는 방식이었다. 현대 AI 네이티브 워크플로우는 다르다. Cmd+I로 “에러 설명해줘”라고 물으면 AI가 즉시 답하고, Tab으로 상용구 코드(boilerplate)를 자동 완성하며, IDE를 벗어나지 않고 플로우를 유지한다. 컨텍스트 전환이 사라지면서 생산성이 2-3배 향상되는 이유다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide.html#sec-ide-evolution",
    "href": "ide.html#sec-ide-evolution",
    "title": "30  IDE 선택과 발전",
    "section": "30.4 IDE 진화",
    "text": "30.4 IDE 진화\n최근 IDE는 두 가지 방향으로 진화하고 있다. 하나는 특정 개발 영역에 깊이 파고들어 전문화되는 것이고, 다른 하나는 AI로 개발 방식 자체를 근본적으로 바꾸는 것이다. 데이터 과학 분야는 두 트렌드가 모두 적용되는 대표적인 영역으로, 전문화된 기능과 AI 통합이 동시에 진행되고 있다.\n\n30.4.1 데이터 과학 IDE\n데이터 과학 IDE는 일반 프로그래밍 IDE와 다른 특화된 기능을 갖춘다. 코드 실행 결과로 생성된 플롯이나 그래프를 IDE 내에서 직접 확인하고 상호작용하는 데이터 시각화 도구가 핵심이다. 변수 탐색기는 현재 실행 환경의 데이터프레임, 변수, 객체 등을 실시간으로 보여주며, 데이터 구조와 값을 쉽게 파악하게 한다. 주피터(Jupyter) 노트북 통합은 코드, 텍스트, 시각화를 하나의 문서로 엮어 재현가능한 분석 보고서를 만든다. 패키지 및 환경 관리 기능은 uv나 conda로 프로젝트별로 격리된 환경을 구성하고, pandas나 scikit-learn 같은 데이터 과학 라이브러리를 손쉽게 설치하고 업데이트한다.\n\n\n30.4.2 AI 에이전트 개발 환경\n최근 LLM 활용 AI 에이전트 개발이 급부상하며 특화된 개발 환경이 등장했다. 에이전트 동작 흐름을 시각적으로 설계하고, 여러 에이전트 간 상호작용을 테스트하며, 복잡한 프롬프트 체인을 관리하는 도구들이다.\nLangSmith는 LangChain 기반 에이전트 동작을 추적하고 디버깅하는 플랫폼이다. 에이전트가 어떤 도구를 호출했고, 어떤 프롬프트를 사용했으며, 왜 특정 결정을 내렸는지 시각화한다. AutoGen Studio는 여러 에이전트 팀을 손쉽게 만들고 테스트하는 시각 인터페이스를 제공한다. 코드 작성 에이전트, 리뷰 에이전트, 테스트 에이전트가 협업하는 과정을 그래프로 보여준다. Flowise와 Langflow는 코드 없이 드래그 & 드롭으로 LLM 애플리케이션을 만드는 시각 IDE 역할을 한다. 프롬프트 노드, LLM 노드, 데이터 처리 노드를 연결해 복잡한 AI 워크플로우를 구축한다.\n\n\n30.4.3 AI 통합\nAI 코딩 도구는 지난 3년간 급격히 진화했다. 처음에는 개발자가 별도 웹사이트를 방문해야 했던 챗 인터페이스에서 시작해, IDE 내부로 통합된 확장 프로그램으로 발전했고, 이제는 프로젝트 전체를 자율적으로 편집하는 에이전트 단계에 이르렀다. 진화 과정의 핵심은 AI가 개발자 작업 흐름 속으로 점점 더 깊숙이 들어와 컨텍스트 전환을 최소화하는 것이다.\n\n\n\n\n\n\n그림 30.5: AI 코딩 진화 - 챗 인터페이스에서 IDE 통합까지\n\n\n\n그림 30.5 는 AI 코딩 도구의 4단계 진화 과정을 보여준다. 1단계(2022-2023)는 챗GPT(ChatGPT) 웹사이트를 별도로 방문하는 방식이었다. IDE에서 코드를 작성하다가 질문이 생기면 브라우저로 전환하고, 챗GPT에 질문하고, 답변을 복사해서 IDE로 돌아와 붙여넣었다. 컨텍스트 전환이 빈번하고 코드 컨텍스트를 수동으로 복사해야 했으며, 플로우 상태가 깨지면서 생산성이 저하되었다.\n2단계(2023)는 GitHub Copilot 같은 IDE 확장이 등장하면서 시작되었다. AI가 IDE 내부로 들어와 자동완성을 제공했다. 코드 문맥을 자동으로 인식하고, Tab으로 제안을 수락하며, IDE를 벗어나지 않게 되었다. 하지만 자동완성만 지원할 뿐 대화형 설명이나 복잡한 요청은 어려웠다.\n3단계(2024)는 커서(Cursor)와 윈드서프(Windsurf) 같은 AI 네이티브 IDE가 깊은 통합을 실현했다. Cmd+K로 인라인 편집 모드를 열고, 자연어로 의도를 설명하면 AI가 코드를 직접 수정한다. 대화하며 결과를 개선할 수 있다. 하지만 여전히 IDE 내부로 제한되고, 파일 단위 작업이며, 자율성은 제한적이었다.\n4단계(2024-2025)는 클로드 코드(Claude Code)와 구글 앤티그래비티(Google Antigravity) 같은 자율 에이전트다. 2025년 11월 구글이 제미나이(Gemini) 3와 함께 발표한 앤티그래비티는 “에이전트 우선” 개발 플랫폼이다. Editor View(AI 기반 IDE)와 에이전트 관리자(Agent Manager)라는 두 가지 모드를 제공한다. Agent Manager에서는 에이전트를 생성하고, 오케스트레이션하며, 비동기로 작업하는 과정을 관찰한다. 에이전트는 작업 목록, 구현 계획, 스크린샷, 브라우저 녹화 같은 아티팩트(Artifacts)를 생성해 로직을 검증 가능하게 한다. 제미나이 3 Pro뿐 아니라 클로드 소넷(Claude Sonnet) 4.5, OpenAI 모델도 지원하며 무료 공개 프리뷰로 제공된다.\nCLI 명령으로 작업을 요청하면 프로젝트 전체를 이해하고, 다중 파일을 자율적으로 편집하며, Git 커밋까지 자동화한다. 프로젝트 전체 컨텍스트를 유지하고, 스스로 의사결정하며, 개발자의 플로우를 완전히 유지한다. 생산성이 10-100배 향상되는 혁명적 단계다.\n진화의 핵심은 컨텍스트 전환 최소화다. AI가 개발자의 작업 공간 밖에 있을 때는 지속적으로 전환해야 했지만, IDE 안으로 들어오고, 더 깊이 통합되고, 마침내 자율 에이전트가 되면서 개발자는 플로우 상태를 유지한 채로 AI의 도움을 받게 되었다.\n💡 생각해볼 점\n60년 IDE 역사가 보여준 패턴은 명확하다. 컴퓨팅 패러다임이 바뀔 때마다 새로운 IDE가 등장했고, 이전 도구는 레거시가 되었다. 메인프레임 시대 시분할 시스템, PC 시대 터보 파스칼, 인터넷 시대 이클립스, 클라우드 시대의 VS Code, 지금 AI 시대 커서와 구글 앤티그래비티. 중요한 것은 “현재 패러다임에 최적화된 도구를 빠르게 습득”하는 능력이다. 2025년 12월 현재 AI 통합 수준이 IDE 선택의 가장 중요한 기준이 되었다.\n키보드 중심 워크플로우는 생산성의 핵심이다. Cmd+P, Cmd+Shift+P, Cmd+I, F5, F9, Ctrl+\\ - 6개 단축키만 암기해도 마우스 의존도가 80% 줄어든다. 명령 팔레트(Cmd+Shift+P)로 2,000개 이상의 기능에 즉시 접근하고, AI 편집(Cmd+I)으로 자연어를 코드로 바꾸며, 디버거(F5, F9)로 버그를 추적한다. 근육 기억이 형성되면 플로우 상태가 유지되고, 생산성이 2-3배 향상된다.\nAI 도구 선택은 통합 수준으로 판단한다. 아직 별도 챗GPT 웹사이트에서 복사-붙여넣기 사용한다면 1단계다. GitHub Copilot으로 자동완성을 받는다면 2단계, 커서로 대화하며 코드를 수정한다면 3단계다. 구글 앤티그래비티나 클로드 코드처럼 에이전트 관리자에서 에이전트가 프로젝트 전체를 자율적으로 편집하고 아티팩트(Artifacts)를 생성하며 검증하는 4단계가 현재 최전선이다. 단계가 높을수록 컨텍스트 전환은 줄고 작업플로우는 유지된다.\n다음 장에서는 데이터 과학에 특화된 포지트론(Positron) IDE를 설치하고, R과 파이썬 환경을 구성하며, 키보드 단축키를 실전에서 활용하는 방법을 다룬다. 이론을 넘어 실제로 “작업플로우에서 AI와 함께 코딩하는” 환경을 직접 구축한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>IDE 선택과 발전</span>"
    ]
  },
  {
    "objectID": "ide_positron.html",
    "href": "ide_positron.html",
    "title": "31  포지트론",
    "section": "",
    "text": "31.1 포지트론 철학\n데이터 과학 세계는 빠르게 변화하고 있으며, 이제 R과 파이썬(Python) 강력한 언어를 함께 사용하는 것이 표준이 되었다. R은 통계 분석과 시각화에 독보적 강점을 가지며, 파이썬은 머신러닝, 범용 프로그래밍, 시스템 통합에 널리 쓰인다. 하지만 오랫동안 데이터 과학자들은 두 언어를 동시에 편안하게 사용할 완벽한 통합 개발 환경(IDE)을 찾기 어려웠다. R 사용자에게는 RStudio가, 파이썬 사용자에게는 다양한 선택지가 있었지만, 두 세계를 자연스럽게 넘나들기에는 항상 아쉬움이 남았다.\n이런 문제의식에서 출발한 것이 포짓(Posit, 과거 RStudio)사가 개발한 차세대 데이터 과학 IDE 포지트론(포지트론)이다. 포지트론은 “하나의 팀, 두 개의 언어” 현실을 받아들이고, R과 파이썬을 모두 일급 시민1으로 대우하는 현대 ‘다언어(polyglot)’ 개발 환경을 지향한다.\n포지트론 핵심 철학은 RStudio 데이터 과학 전문성과 Visual Studio Code(VS Code) 현대적 개발 경험 결합이다. 포지트론은 VS Code 오픈소스 버전인 ‘Code OSS’ 기반으로 구축되었다. VS Code의 빠르고 유연한 인터페이스, 방대한 확장 기능 생태계, 강력한 코드 편집 기능을 가져오면서, RStudio가 수십 년간 쌓은 데이터 과학 워크플로우 이해를 녹여냈다.\n그림 31.1 는 포지트론 전체 화면 구성을 보여준다. 왼쪽 탐색기는 프로젝트 파일 트리를, 중앙 편집기는 R 코드를, 오른쪽 패널은 변수 탐색기와 플롯 창을, 하단은 R 콘솔을 표시한다. 콘솔 상단 드롭다운으로 R과 파이썬을 즉시 전환할 수 있다. 편집기에서는 AI가 회색으로 다음 코드를 제안하며, 변수 탐색기는 메모리에는 데이터프레임을 포함한 모든 객체를 실시간으로 보여준다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-philosophy",
    "href": "ide_positron.html#sec-positron-philosophy",
    "title": "31  포지트론",
    "section": "",
    "text": "그림 31.1: 포지트론 화면 구성 - R/Python 동시 지원 UI\n\n\n\n\n\n\n\n\n\n노트왜 RStudio를 두고 포지트론을 만들었나?\n\n\n\n포짓 답변은 명확하다: “RStudio는 계속된다.”\n포지트론 개발은 RStudio 대체가 아니다. RStudio와 포지트론은 서로 다른 목표와 사용자를 가진다. RStudio는 R 언어에 깊이 집중하는 데이터 분석가와 통계학자를 위한 최고의 R 개발 환경으로 계속 발전하고 유지된다. 반면 포지트론은 R과 파이썬을 함께 사용하는 다언어 데이터 과학 팀과 개발자를 위한 새로운 선택지다.\n포지트론은 ‘R 전용’ RStudio의 성공적 틀을 넘어, ’R과 파이썬 모두’를 필요로 하는 현대 데이터 과학의 새로운 요구에 부응하기 위한 포짓의 전략적 확장이자 AI 시대 경쟁에서 밀릴 수 없다는 전략적 노림수다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-ai",
    "href": "ide_positron.html#sec-positron-ai",
    "title": "31  포지트론",
    "section": "\n31.2 AI 시대 포지트론",
    "text": "31.2 AI 시대 포지트론\n포지트론 가장 큰 혁신은 단순 다언어 지원을 넘어, AI 기능을 데이터 과학 워크플로우에 깊이 통합한 점이다. 포지트론 AI 어시스턴트는 일반 코딩 도우미와 근본적으로 다르다. 현재 실행 중인 R/파이썬 세션 내부 상태(메모리 데이터, 변수, 플롯 등)를 직접 파악하고 상호작용하기 때문이다.\n탐색적 데이터 분석(EDA) 단계를 예로 들어보자. “penguins 데이터셋에서 종(species)별로 몸무게(body_mass_g) 분포를 박스플롯으로 그려줘”라고 자연어로 요청하면, AI는 현재 메모리에 있는 penguins 데이터프레임 구조를 이해하고 즉시 ggplot2나 matplotlib 코드를 생성해 실행 결과를 플롯 창에 보여준다. 탐색적 데이터 탐색 단계가 몇 분에서 몇 초로 단축된다.\n데이터 전처리(data wrangling)도 마찬가지다. “결측치가 있는 행을 제거하고, ‘bill_length_mm’와 ’bill_depth_mm’ 열만 선택해줘”라는 요청을 dplyr이나 pandas 코드로 즉시 변환한다. 개발자는 파이프 연산자 문법이나 메서드 체이닝(method chaining)을 기억하는 데 에너지를 쏟지 않고, 데이터 분석에 대한 큰 그림과 로직에 집중할 수 있다.\n더 나아가 AI는 코드뿐 아니라 통계 모델 결과까지 해석한다. “방금 실행한 선형 회귀 모델의 \\(R^2\\) 값은 무엇을 의미하지?” 또는 “복잡한 purrr 코드를 단계별로 설명해줘” 같은 질문에, AI는 통계학적 배경 지식과 함께 깊이 있는 답변을 제공한다. 데이터 과학자가 더 나은 통찰(insight)을 얻도록 돕는 지능형 파트너 역할도 한다.\n\n\n\n\n\n\n힌트IDE 선택 가이드\n\n\n\n표 31.1 비교 정보를 바탕으로 선택은 명확하다. R만 사용하는 통계학자라면 R 패키지 개발, Shiny 앱 배포, R Markdown 프로파일링 같은 고급 기능이 완벽히 통합된 RStudio가 가장 안정적이고 편리하다. 웹 개발, 시스템 프로그래밍 등 범용 목적이라면 수많은 확장 기능을 갖춘 VS Code가 최고 유연성을 제공한다. 하지만 R과 파이썬을 함께 사용하며 최신 AI 기능을 적극 활용하고 싶다면, 포지트론은 두 언어를 매끄럽게 오가며 AI 지원을 받을 수 있는 현재 가장 진보적 환경이다.\n\n\n\n\n\n\n\n\n특성\nRStudio\nVS Code\n포지트론\n\n\n\n주력 언어\nR\n범용 (모든 언어)\nR & Python\n\n\n주요 사용자\nR 데이터 분석가, 통계학자\n모든 종류의 개발자\n다언어 데이터 과학자\n\n\n설정\n거의 불필요 (R 최적화)\n높은 유연성 (직접 구성)\n낮은 설정 (R/Python 최적화)\n\n\n장점\nR 생태계 완벽 통합\n최고의 유연성과 확장성\nR/Python 동시 작업 및 AI 통합\n\n\n단점\nPython 지원 제한적\n데이터 과학 초기 설정 복잡\n일부 고급 기능 아직 개발 중\n\n\n\n\n\n\n\n표 31.1: IDE 비교: RStudio vs VS Code vs 포지트론",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-install",
    "href": "ide_positron.html#sec-positron-install",
    "title": "31  포지트론",
    "section": "\n31.3 포지트론 설치",
    "text": "31.3 포지트론 설치\n포지트론을 설치하기 전에 시스템이 최소 요구사항을 충족하는지 확인한다. 윈도우(Windows) 10 이상, 맥OS(macOS) 11 이상, 리눅스(Linux)(우분투(Ubuntu) 20.04+)를 지원한다. 메모리는 최소 4GB지만 8GB 이상을 권장한다. 디스크 여유 공간은 500MB 이상 필요하다. R 버전은 4.0 이상, 파이썬(Python) 버전은 3.8 이상이 필요하며, 각각 4.3+와 3.11+를 권장한다.\n포지트론은 포짓 공식 웹사이트에서 무료로 다운로드할 수 있다. https://positron.posit.co에 접속해 운영체제에 맞는 설치 파일을 받는다. 맥OS는 .dmg 파일을 열고 Applications 폴더로 드래그한다. 윈도우는 .exe 설치 파일 실행 후 기본 설정으로 진행한다. 리눅스는 .deb 또는 .rpm 패키지를 설치한다.\n첫 실행 시 초기 설정 마법사가 나타난다. R과 파이썬 인터프리터를 자동으로 감지하며, 없다면 설치를 안내한다. 인터프리터 경로가 자동으로 감지되지 않으면 수동으로 지정할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-features",
    "href": "ide_positron.html#sec-positron-features",
    "title": "31  포지트론",
    "section": "\n31.4 주요 기능 활용 사례",
    "text": "31.4 주요 기능 활용 사례\n포지트론 핵심 기능을 실제 데이터 과학 워크플로우에서 어떻게 활용하는지 살펴보자. 다언어 콘솔 전환부터 변수 탐색기, AI 어시스턴트까지 세 가지 핵심 기능을 통해 포지트론이 제공하는 생산성 향상을 직접 경험할 수 있다.\n\n31.4.1 다언어 콘솔 전환\n포지트론 핵심 강점은 R과 파이썬을 즉시 전환하며 작업하는 것이다. 화면 하단 콘솔 영역 오른쪽 상단에 언어 선택 드롭다운이 있다. 여기서 “R” 또는 “Python”을 선택하면 즉시 해당 언어의 REPL(Read-Eval-Print Loop) 환경으로 전환된다.\n데이터 과학에서 가장 흔한 사례를 살펴보자. R 콘솔에서 ggplot2로 시각화를 그린다. 파이썬 콘솔로 전환해 scikit-learn으로 머신러닝 모델을 훈련한다. 다시 R로 전환해 통계 모델을 검증한다. 세션 전환 없이 모든 작업이 동일 IDE 내에서 이뤄진다.\n\n31.4.2 변수 탐색기\n화면 오른쪽 사이드바에 변수 탐색기가 있다. 현재 실행 중인 R/파이썬 세션 모든 변수, 데이터프레임, 리스트를 실시간으로 보여준다. 데이터프레임 이름을 클릭하면 테이블 뷰어가 열린다. 데이터 정렬, 필터링, 열 타입 확인이 가능하다. 대용량 데이터(수백만 행)도 가상화 기술로 빠르게 탐색할 수 있다.\n\n31.4.3 AI 어시스턴트 사용법\n포지트론 AI 어시스턴트는 단순한 코드 자동완성을 넘어 세션 상태를 이해하는 지능형 도우미다. 현재 메모리에 로드된 데이터, 설치된 패키지, 변수 구조를 직접 파악하기 때문에 자연어 요청만으로도 즉시 실행 가능한 코드를 생성한다.\n\n\n\n\n\n그림 31.2: 포지트론 AI 워크플로우 - 세션 상태 인식 기반 코드 생성\n\n\n그림 31.2 는 포지트론 AI 어시스턴트 작동 방식을 보여준다. 사용자가 자연어로 요청하면, AI는 현재 R/파이썬 세션의 메모리 데이터, 설치된 패키지, 변수 구조를 직접 파악할 수 있다. 파악된 정보를 바탕으로 즉시 실행 가능한 코드를 생성하고, 실행 결과를 플롯 창에 시각화한다. 일반 AI 챗봇과 달리 세션 상태를 알기 때문에 “penguins가 무엇인지” 따로 설명할 필요가 없다.\n자연어 요청 예시를 살펴보자. “mtcars 데이터셋에서 mpg와 wt의 상관관계를 산점도로 그려줘”라고 입력하면, AI는 다음 R 코드를 자동생성한다.\nlibrary(ggplot2)\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"MPG vs Weight\",\n       x = \"Weight (1000 lbs)\",\n       y = \"Miles per Gallon\")\nAI는 현재 메모리에 mtcars가 로드되어 있는지 확인하고, ggplot2 패키지가 설치되었는지 검증한 후 코드를 생성한다. 바로 실행하면 플롯 창에 결과가 나타난다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#sec-positron-migration",
    "href": "ide_positron.html#sec-positron-migration",
    "title": "31  포지트론",
    "section": "\n31.5 RStudio에서 포지트론 전환",
    "text": "31.5 RStudio에서 포지트론 전환\nRStudio를 오랫동안 사용해온 데이터 과학자라면 포지트론 전환이 생각보다 자연스럽다. 두 IDE 모두 데이터 과학자를 염두에 두고 포짓에서 개발했기 때문에 화면 레이아웃 구성이 유사하고, 익숙한 단축키도 대부분 그대로 작동한다. RStudio에서 쌓아온 작업 습관을 버리지 않고도 포지트론 다언어 지원과 AI 통합 기능을 즉시 무리없이 활용할 수 있다.\n\n\n\n\n\n그림 31.3: 포지트론 vs RStudio 레이아웃 비교\n\n\n그림 31.3 는 RStudio와 포지트론의 화면 레이아웃 차이를 보여준다. RStudio는 4개 패널(Source, Console, Environment, Files)로 R 중심 워크플로우에 최적화되어 있다. 포지트론은 VS Code 기반으로 왼쪽 탐색기, 중앙 편집기, 오른쪽 변수/플롯 패널, 하단 콘솔 구조를 가지며, 콘솔에서 R과 파이썬을 드롭다운으로 즉시 전환할 수 있다.\n포지트론 설치 후 기존 R 프로젝트 폴더를 연다. .Rproj 파일이 있다면 자동으로 프로젝트로 인식한다. R 콘솔에서 renv::restore()로 패키지 복원한다. 단축키 설정을 “RStudio” 프리셋으로 변경할 수 있다(설정 → Keybindings → “RStudio”).\n현재(2025년 베타) 포지트론은 일부 기능이 아직 구현되지 않았다. R Markdown 프로파일링(메모리, 성능 분석), Shiny 앱 배포 버튼(shinyapps.io, Posit Connect), R 패키지 개발 전용 도구(devtools 통합), .Rproj 설정 일부 옵션이 개발중에 있다.\n포지트론은 아직 베타 버전이며 RStudio 일부 기능(예: R Markdown 프로파일링, 간편한 앱 배포)이 아직 완전히 구현되지 않았다는 한계가 있다. 하지만 R과 파이썬이 공존하는 현대 데이터 과학 흐름을 가장 잘 반영하고, AI를 개발 워크플로우 핵심으로 가져왔다는 점에서 미래가 기대된다.\n포지트론은 단순히 새로운 도구가 아니다. 포짓 팀이 생각하는 미래 데이터 과학 작업 환경의 구체적 실험이다. AI와 함께 더 빠르고 깊이 있게 데이터 문제를 해결하고 싶은 데이터 과학자라면, 포지트론은 여정을 함께할 흥미로운 파트너가 될 수 있다.\n💡 생각해볼 점\n포지트론은 AI가 촉발시킨 데이터 과학 워크플로우의 근본적 변화를 반영한다. 과거에는 “R 또는 파이썬” 중 하나를 선택해야 했지만, 이제는 “R과 파이썬 모두”를 사용하는 것이 표준이 되었다. 포지트론은 이러한 변화를 받아들이고, 두 언어를 동등하게 지원하며, AI로 생산성을 극대화하는 첫 번째 IDE 중 하나다.\n전환은 점진적으로 시작한다. 작은 EDA 프로젝트에서 포지트론을 시도해보자. R로 통계 분석을 하다가 파이썬 scikit-learn이 필요하면 콘솔을 전환한다. AI 어시스턴트에게 자연어로 요청하고, 생성된 코드를 즉시 실행한다. 이러한 과정을 몇 번 반복하면 포지트론 없이는 일하기 힘들어진다.\n다음 장에서는 포지트론의 진정한 힘을 발휘하는 확장 프로그램(extension) 설치와 설정을 다룬다. 포지트론 기본 설치만으로는 부족하며, R과 파이썬 언어 서버, 쿼토, 린터 등 필수 확장 프로그램을 설치해야 완전한 개발 환경이 갖춰진다. 이론을 넘어 실제로 작동하는 포지트론 환경을 구축한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_positron.html#footnotes",
    "href": "ide_positron.html#footnotes",
    "title": "31  포지트론",
    "section": "",
    "text": "일급 시민(first-class citizen)은 시스템에서 완전한 지원을 받는 대상을 의미한다. 포지트론에서 R과 파이썬 모두 동등하게 완전한 기능을 제공받으며, 어느 한쪽이 부차적으로 취급되지 않는다.↩︎",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>포지트론</span>"
    ]
  },
  {
    "objectID": "ide_extension.html",
    "href": "ide_extension.html",
    "title": "32  IDE 확장 프로그램",
    "section": "",
    "text": "32.1 IDE 확장 프로그램 아키텍처\n현대 통합 개발 환경(IDE)의 가장 큰 힘은 ’확장성’에 있다. 어떤 IDE도 세상의 모든 프로그래밍 언어, 프레임워크, 도구를 기본 지원할 수는 없다. 그렇게 시도한다면 IDE는 극도로 무거워지고 복잡해져 사용할 수 없게 된다.\n문제 해결의 핵심 아이디어가 바로 확장 프로그램(Extensions)이다. IDE는 핵심 기능(텍스트 편집, UI)만 제공하고, 추가 기능들은 사용자가 필요에 따라 ’레고 블록’처럼 조립해 사용한다. 이번 장에서 IDE 확장 프로그램이 왜 필요하며, 어떤 아키텍처로 안정적으로 구현되는지 살펴본다.\n확장 프로그램이 IDE를 무너뜨리지 않으면서도 강력한 기능을 제공하려면 어떻게 해야 할까? 현대 IDE는 이러한 문제를 해결하기 위해 공통된 아키텍처 패턴을 따른다. 핵심은 ‘격리’다. 확장 프로그램을 메인 프로세스에서 분리하고, 언어 기능을 표준 프로토콜로 분리하며, 기여 지점을 명확히 정의한다. 비주얼 스튜디오 Code(VS Code)는 세 가지 원칙을 가장 성공적으로 구현한 대표 사례로, 30,000개 이상의 확장 프로그램을 지원하면서도 가볍고 안정적인 성능을 유지한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-extension-architecture",
    "href": "ide_extension.html#sec-extension-architecture",
    "title": "32  IDE 확장 프로그램",
    "section": "",
    "text": "32.1.1 확장 프로그램 격리\nVS Code는 확장 프로그램을 IDE 메인 프로세스가 아닌, ‘확장 호스트(Extension Host)’ 라고 불리는 별도 독립 프로세스에서 실행한다. 이러한 격기 구조의 가장 큰 목적은 안정성이다. 특정 확장 프로그램이 과도한 메모리를 사용하거나 오류를 일으켜 멈추더라도, IDE 메인 프로세스(UI, 텍스트 편집 등)는 전혀 영향을 받지 않는다. 사용자는 문제가 된 확장 프로그램을 비활성화하거나 재시작할 수 있으며, 작업 내용은 안전하게 보존된다.\n\n\n\n\n\n\n그림 32.1: VS Code 안정성 비결 - 확장 프로그램 격리 아키텍처\n\n\n\n그림 32.1 는 VS Code가 메인 프로세스와 확장 호스트를 분리해 안정성을 확보하는 방식을 보여준다. 확장 프로그램이 오류를 일으켜도 메인 프로세스는 안전하게 작동한다.\n\n\n32.1.2 LSP: 언어 기능 분리\n과거에는 C++ 언어 ‘코드 자동 완성’ 기능을 만들려면, VS Code용, Sublime Text용, 아톰용 코드를 각각 따로 만들어야 했다. 언어 개발자(m)와 IDE 개발자(n) 모두에게 m x n의 비효율적 개발 부담을 주었다.\n마이크로소프트가 개발해 표준으로 제안한 언어 서버 프로토콜(Language Server Protocol, LSP)은 이 문제를 해결했다. LSP는 언어 관련 기능(코드 분석, 자동 완성, 오류 검출 등)을 ‘언어 서버’ 라는 독립 프로세스로 분리한다. IDE(클라이언트)는 표준화된 JSON-RPC 메시지로 언어 서버와 통신하며 정보를 주고받는다.\n효과는 획기적이었다. C++ 언어 개발자는 ‘C++ 언어 서버’ 하나만 만들면 된다. LSP를 지원하는 모든 IDE(VS Code, 이클립스, 주피터 등)는 별도 노력 없이 C++ 언어의 모든 지능형 기능을 사용할 수 있다. 개발 부담을 m + n으로 획기적으로 줄였고, 새로운 언어가 빠르게 다양한 IDE에 채택될 수 있는 길을 열었다.\n\n\n\n\n\n\n그림 32.2: 언어 서버 프로토콜 (LSP): m × n 문제의 해결\n\n\n\n그림 32.2 는 LSP가 m × n 문제를 m + n으로 해결한 과정을 보여준다. 과거에는 각 언어와 IDE마다 별도 통합 작업이 필요했지만, LSP로 언어 서버 하나만 만들면 모든 LSP 지원 IDE에서 사용할 수 있게 되었다.\n\n\n32.1.3 기능 기여 모델\n확장 프로그램은 package.json이라는 Manifest(설명서) 파일로 IDE 메뉴, 아이콘, 명령어 목록에 자신의 기능을 추가한다. 매니페스트 파일에는 확장 프로그램 이름, 버전, 설명 등 기본 정보와 함께, ‘어떤 조건에서 활성화될지’(Activation Events), ‘IDE 어느 부분에 어떤 기능을 추가할지’(Contribution Points)가 명시되어 있다.\nVS Code는 확장 프로그램이 기여할 수 있는 ’슬롯’을 미리 정의해 두었다. 예를 들어, contributes.commands는 새로운 명령어를, contributes.menus는 메뉴 항목을, contributes.views는 사이드바에 새로운 UI 창을 추가한다. IDE는 시작될 때 package.json 파일들을 읽어들여 전체 UI와 기능을 구성한다.\n\n\n\n\n\n\n경고아톰 편집기 교훈: 자유도 vs 안정성\n\n\n\n아톰(Atom) 편집기는 VS Code의 성공적 아키텍처를 이해하는 데 좋은 대조 사례다. 아톰 역시 일렉트론(Electron) 기반으로 만들어졌고 ‘핵킹 가능한(hackable)’ 편집기를 표방하며 엄청난 유연성을 제공했지만, VS Code와 결정적 아키텍처 차이가 있었다.\n아톰은 확장 프로그램을 격리된 ’확장 호스트’에서 실행하지 않았다. 모든 확장 프로그램은 편집기 UI와 동일한 렌더러 프로세스에서 실행되었다. 이러한 구조는 편집기 거의 모든 부분을 수정할 수 있는 극강의 자유도를 제공했지만, 치명적 단점을 낳았다. 확장 하나가 오작동하거나 느려지면 편집기 전체가 버벅거리거나 멈추는 현상이 잦았다. 결국 아톰은 성능 저하 문제로 사용자를 잃었다.\n아톰 사례는 확장 프로그램 아키텍처에서 ‘격리’ 가 왜 중요한지 명확히 보여준다. VS Code가 확장 호스트로 안정성과 성능을 모두 잡을 수 있었던 것은 아톰 편집기 단점을 반면교사로 삼았기 때문이다. 소프트웨어 설계에서 한 가지를 얻으면 다른 것을 포기해야 하는 절충은 피할 수 없다. 중요한 것은 사용자가 진정으로 원하는 것이 무엇인지 정확히 파악하는 것이다. 개발자들은 “자유롭지만 느린” 편집기보다 “약간 제한적이지만 빠르고 안정적인” 편집기를 선택했다.\n(참고: 아톰 프로젝트는 2022년 12월 공식 개발 중단)\n\n\n\n\n32.1.4 VS Code 아키텍처 영향\n최근 포지트론(Positron), 커서(Cursor) 등 많은 IDE가 VS Code 오픈소스 코어인 ‘Code - OSS’ 기반으로 만들어지고 있다. VS Code 확장 프로그램 아키텍처가 그만큼 뛰어나고, 현대 IDE 개발의 ’성공 공식’이 되었다는 의미다.\n새로운 IDE가 VS Code 기반으로 만들어진다는 것은, 수만 개의 기존 VS Code 확장 프로그램을 거의 그대로 사용할 수 있다는 뜻이다. 새로운 IDE는 처음부터 모든 언어 지원, 테마, 도구를 만들 필요 없이, 이미 검증된 거대한 생태계를 즉시 활용해 개발을 시작한다. VS Code ‘확장 호스트’ 같은 멀티 프로세스 아키텍처는 안정성과 성능이 이미 검증되었다. 새로운 IDE는 복잡한 기반을 직접 설계하는 대신, 자신만의 핵심적 특화 기능 개발에만 집중한다.\n전 세계 수많은 개발자가 이미 VS 코드 UI와 사용 방식에 익숙하다는 점도 중요하다. VS 코드 기반으로 만들어진 IDE는 사용자가 별도 학습 없이도 쉽고 빠르게 적응할 수 있다. VS 코드 확장 프로그램 아키텍처는 단순 기술적 성공을 넘어, 다른 IDE가 활용할 수 있는 강력한 플랫폼이자 생태계를 창조했다. 많은 현대 IDE가 ’바퀴를 재발명’하는 대신 VS Code라는 거인의 어깨 위에 올라타는 이유다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-positron-extensions",
    "href": "ide_extension.html#sec-positron-extensions",
    "title": "32  IDE 확장 프로그램",
    "section": "32.2 포지트론 필수 확장 프로그램",
    "text": "32.2 포지트론 필수 확장 프로그램\n포지트론이 데이터 과학 IDE로서 진정한 힘을 발휘하려면 핵심 확장 프로그램들을 설치해야 한다. 포지트론은 VS Code 기반이므로 VS Code 확장 생태계를 그대로 활용하면서, 데이터 과학에 특화된 확장들을 추가로 제공한다.\n\n\n\n\n\n\n노트Positron vs VS Code: 내장 기능 차이\n\n\n\nPositron IDE는 R (Ark Kernel), Python, Jupyter 기능이 이미 내장되어 있다. VS Code 사용자는 이 확장들을 별도로 설치해야 하지만, Positron 사용자는 설치 없이도 즉시 사용할 수 있다. 아래 목록에서 “* Positron 내장” 표시가 있는 확장은 Positron에서 이미 제공되므로, VS Code에서만 추가 설치가 필요하다.\n\n\n\n\n\n\n\n\n그림 32.3: 포지트론 데이터 과학 확장 프로그램 생태계\n\n\n\n그림 32.3 는 포지트론에서 실제로 사용하는 15종 핵심 확장 프로그램을 3개 그룹으로 보여준다. 1) 엔진 & 앱 개발: R, Python, Shiny Publisher, Quarto, Thunder Client로 Shiny/Streamlit 앱 개발과 배포를 지원한다. 2) 인터랙티브 데이터 분석: SandDance, Data Wrangler, SQLTools, Geo Data Viewer, Rainbow CSV로 다양한 데이터 탐색과 변환을 수행한다. 3) AI, 협업 & 운영: Jupyter, GitHub Copilot, Live Share, Remote-SSH, Docker로 노트북, AI 코딩, 원격 협업, 컨테이너화를 통합한다.\n\n32.2.1 언어 지원: R & Python\nR (Positron 내장, VS Code: REditorSupport.r)는 R 언어 지원의 핵심이다. Positron은 자체 개발한 Ark Kernel로 R을 실행하며, VS Code보다 훨씬 빠르고 안정적이다. R 언어 서버(LSP)를 통해 코드 자동완성, 함수 시그니처 도움말, 정의로 이동 기능을 제공한다. R 콘솔에서 install.packages(c(\"lintr\", \"styler\"))로 린터와 포맷터를 설치하면, 코드 스타일 문제를 실시간으로 감지하고 tidyverse 스타일로 자동 정리한다.\nPython (Positron 내장, VS Code: ms-python.python)은 파이썬 개발 환경을 완성한다. Pylance 언어 서버로 빠른 타입 체크와 자동완성을 지원하고, venv, conda 환경을 자동 감지한다. 파이썬 디버거는 중단점, 변수 검사, 단계별 실행을 제공한다.\n\n\n32.2.2 앱 배포: Shiny Publisher\nShiny & Publisher (posit.publisher)는 Shiny 앱과 Streamlit 앱을 Posit Connect 또는 shinyapps.io에 원클릭으로 배포한다. 로컬에서 개발한 인터랙티브 대시보드를 프로덕션 환경에 즉시 올리고, 팀원들과 공유하며, 버전 관리와 롤백을 지원한다.\n설치는 “Posit Publisher”를 검색해 설치한다. Shiny 앱 디렉토리에서 Cmd+Shift+P → “Publish Content”를 실행하면 배포 대상(Connect, shinyapps.io)을 선택하고, 계정 인증 후 자동으로 배포된다. 배포 히스토리를 추적하고 이전 버전으로 롤백할 수 있다.\n\n\n32.2.3 API 테스트: Thunder Client\nThunder Client (rangav.vscode-thunder-client)는 Postman처럼 API 엔드포인트를 테스트하는 도구다. R Plumber나 Python FastAPI로 만든 모델 API를 IDE 내에서 바로 테스트한다. GET/POST 요청을 보내고, JSON 응답을 확인하며, 환경 변수를 관리한다.\n설치는 “Thunder Client”를 검색해 설치한다. 좌측 사이드바에 번개 아이콘이 생기며, 클릭하면 REST 클라이언트가 열린다. “New Request” → URL 입력 → Send로 API를 테스트한다. 요청을 컬렉션으로 저장해 재사용한다.\n\n\n32.2.4 문서 작성: Quarto\nQuarto (quarto.quarto)는 재현가능한 데이터 분석 보고서 작성의 핵심이다. .qmd 파일에서 R과 파이썬 코드 청크를 실행하고, 결과를 즉시 미리보기로 확인한다. Render 버튼 클릭으로 HTML, PDF, Word, 슬라이드로 변환한다. 실시간 미리보기는 수정 사항을 즉시 반영하며, 코드, 텍스트, 시각화, 표를 하나의 문서로 엮어 논문, 기술 보고서, 블로그 포스트를 작성한다.\n설치는 확장 마켓플레이스에서 “Quarto”를 검색해 설치한다. .qmd 파일을 열면 자동으로 활성화되며, Cmd+Shift+K (macOS) 또는 Ctrl+Shift+K (Windows/Linux)로 렌더링한다. YAML 헤더에서 출력 형식(format: html, format: pdf)을 지정하고, R/파이썬 코드 청크는 ```{r} 또는 ```{python}로 시작한다.\n\n\n32.2.5 시각적 탐색: SandDance\nSandDance (msrvida.vscode-sanddance)는 마이크로소프트 리서치가 개발한 혁신적인 3D/2D 데이터 시각화 도구다. 코드 없이 데이터를 드래그 앤 드롭으로 탐색하며, 산점도, 바차트, 밀도 플롯을 실시간으로 전환해 데이터 패턴을 발견한다. 수십만 행 데이터도 WebGL로 부드럽게 렌더링한다.\n설치는 “SandDance”를 검색해 설치한다. CSV나 JSON 파일을 우클릭 → “View in SandDance”를 선택하면 인터랙티브 시각화 창이 열린다. 축을 변경하고, 색상을 매핑하며, 필터를 적용해 탐색적 데이터 분석(EDA)을 몇 초 만에 수행한다.\n\n\n32.2.6 데이터베이스: SQLTools\nSQLTools (mtxr.sqltools)는 PostgreSQL, MySQL, SQLite 등 다양한 데이터베이스에 연결해 쿼리를 실행하고 결과를 시각화한다. IDE 내에서 데이터베이스 탐색, 테이블 스키마 확인, SQL 자동완성, 쿼리 히스토리 관리를 수행한다.\n설치는 “SQLTools”를 검색해 설치한다. 좌측 사이드바에 데이터베이스 아이콘이 생기며, “Add New Connection”으로 DB 연결 정보를 입력한다. SQL 파일을 열고 Cmd+E Cmd+E로 쿼리를 실행하면 결과가 테이블로 표시된다.\n\n\n32.2.7 지도 시각화: Geo Data Viewer\nGeo Data Viewer (randomfractals.geo-data-viewer)는 GeoJSON, Shapefile, KML 같은 지리 데이터를 즉시 지도로 시각화한다. 공간 데이터 분석 프로젝트에서 지도를 코드 없이 확인하고, 레이어를 토글하며, 속성을 검사한다.\n설치는 “Geo Data Viewer”를 검색해 설치한다. .geojson 파일을 열면 자동으로 지도가 표시되며, 줌/팬으로 탐색한다. 속성 테이블을 클릭해 각 지형지물의 메타데이터를 확인한다.\n\n\n32.2.8 데이터 탐색: Rainbow CSV\nRainbow CSV (mechatroner.rainbow-csv)는 CSV 파일을 다루는 필수 도구다. CSV 파일을 열면 각 열을 다른 색으로 표시해 가독성을 높인다. SQL 쿼리로 CSV를 탐색하고(SELECT * FROM this WHERE age &gt; 30), 열 정렬, 필터링, 통계 요약을 제공한다. 큰 CSV 파일(수백만 행)도 가상화 기술로 빠르게 열린다.\n설치는 “Rainbow CSV”를 검색해 설치한다. CSV 파일을 열면 자동으로 각 열에 색상이 적용된다. 열 구분자(쉼표, 탭, 파이프 등)를 자동 감지하며, Cmd+Shift+P → “Rainbow CSV: Query”로 SQL 쿼리 모드를 연다. SELECT name, age FROM this WHERE age &gt; 25 ORDER BY age DESC 같은 쿼리로 데이터를 탐색하고, 결과를 새 창에 표시한다.\n\n\n32.2.9 AI 코딩: GitHub Copilot\nGitHub Copilot (GitHub.copilot)은 포지트론에서도 그대로 작동한다. 주석이나 함수 이름을 입력하면 전체 함수 구현을 제안하고, Tab 키로 수락한다. 데이터 과학 코드에 특화되어 ggplot2, dplyr, pandas, scikit-learn 패턴을 잘 이해한다. “결측치 제거하고 표준화”처럼 자연어 주석을 입력하면 즉시 코드를 생성한다.\n설치는 GitHub 계정으로 로그인하고 Copilot 구독이 필요하다. 확장 마켓플레이스에서 “GitHub Copilot”을 설치하고, GitHub 계정으로 인증한다. 회색 텍스트로 표시되는 제안을 Tab으로 수락하고, Esc로 거부한다. Alt+]로 다음 제안을, Alt+[로 이전 제안을 확인한다.\n\n\n32.2.10 데이터 변환: Data Wrangler\nData Wrangler (ms-toolsai.datawrangler)는 데이터 탐색과 변환을 시각적으로 수행하는 마이크로소프트 확장이다. 변수 탐색기에서 데이터프레임을 클릭하고 “Open in Data Wrangler”를 선택하면 그래픽 인터페이스가 열린다. 필터링, 정렬, 그룹화, 피벗 작업을 드래그 앤 드롭으로 수행하고, 모든 작업은 자동으로 R 또는 파이썬 코드로 변환된다.\n설치는 “Data Wrangler”를 검색해 설치한다. 복잡한 전처리 파이프라인을 GUI로 만들고, “Export Code” 버튼으로 dplyr이나 pandas 코드를 생성한다. 코드를 복사해 스크립트에 붙여넣으면 재현 가능한 전처리 워크플로우가 완성된다.\n\n\n32.2.11 노트북: Jupyter\nJupyter (Positron 내장, VS Code: ms-toolsai.jupyter)는 .ipynb 노트북 파일을 네이티브로 실행한다. 코드 셀, 마크다운 셀, 출력 결과를 하나의 문서로 통합하며, 변수 탐색기와 연동해 노트북 실행 중 생성된 변수를 실시간으로 확인한다. Jupyter 커널(IPython, IRkernel)을 자동 감지하고 전환한다.\nPositron은 Jupyter를 내장하므로 별도 설치가 필요 없다. VS Code 사용자는 “Jupyter”를 검색해 설치한다. .ipynb 파일을 열면 자동으로 활성화되며, Shift+Enter로 셀을 실행한다. 상단 커널 선택 드롭다운에서 Python/R 커널을 전환하고, 노트북 결과를 HTML/PDF로 내보낼 수 있다.\n\n\n32.2.12 실시간 협업: Live Share\nLive Share (ms-vsliveshare.vsliveshare)는 실시간 동시 편집을 가능하게 한다. Google Docs처럼 여러 개발자가 동일 코드를 동시에 편집하고, 디버깅 세션을 공유하며, 터미널까지 함께 사용한다. 원격 페어 프로그래밍과 코드 리뷰에 혁명을 일으킨 도구다.\n설치는 “Live Share”를 검색해 설치한다. Cmd+Shift+P → “Live Share: Start Collaboration Session”으로 세션을 시작하고, 공유 링크를 팀원에게 전송한다. 팀원이 링크로 접속하면 실시간으로 코드를 함께 편집하고, 커서 위치와 선택 영역이 실시간으로 동기화된다.\n\n\n32.2.13 원격 개발: Remote-SSH\nRemote - SSH (ms-vscode-remote.remote-ssh)는 고성능 GPU 서버에 SSH로 연결해 원격 개발 환경을 로컬처럼 사용한다. 딥러닝 모델 훈련처럼 고사양 컴퓨팅이 필요한 작업을 원격 서버에서 수행하면서도, IDE는 로컬 컴퓨터에서 부드럽게 작동한다.\n설치는 “Remote - SSH”를 검색해 설치한다. Cmd+Shift+P → “Remote-SSH: Connect to Host”로 서버 정보를 입력한다. 연결되면 좌측 하단에 “SSH: 서버명”이 표시되며, 모든 파일 탐색, 편집, 터미널 명령이 원격 서버에서 실행된다.\n\n\n32.2.14 컨테이너화: Docker\nDocker (ms-azuretools.vscode-docker)는 분석 환경을 컨테이너로 패키징해 재현성을 보장한다. Dockerfile로 R/Python 패키지, 시스템 라이브러리를 정의하면, 어디서나 동일한 환경을 재현할 수 있다. 컨테이너 빌드, 실행, 디버깅을 IDE 내에서 수행한다.\n설치는 “Docker”를 검색해 설치한다. Dockerfile을 우클릭 → “Build Image”로 이미지를 빌드하고, 좌측 사이드바 Docker 아이콘에서 컨테이너를 관리한다. 컨테이너 내부 터미널을 열어 환경을 테스트하고, Docker Compose로 다중 컨테이너를 오케스트레이션한다.\n\n\n32.2.15 확장 설치 및 관리\n포지트론에서 확장을 설치하는 방법은 간단하다. 좌측 사이드바에서 확장 아이콘(네모 4개)을 클릭하고, 검색창에 확장 이름을 입력한다. “Install” 버튼을 누르면 자동으로 다운로드되고 활성화된다.\n데이터 과학자를 위한 필수 확장 15종 (그룹별 설치 권장):\n1) 엔진 & 앱 개발: 1. R (REditorSupport.r) - R 언어 지원, Shiny 실행 2. Python (ms-python.python) - Python 언어, Streamlit 지원 3. Shiny Publisher (posit.publisher) - 앱 배포 (Connect/ShinyApps) 4. Quarto (quarto.quarto) - 재현가능한 문서, 대시보드 5. Thunder Client (rangav.vscode-thunder-client) - API 테스트\n2) 인터랙티브 데이터 분석: 6. SandDance (msrvida.vscode-sanddance) - 3D/2D 시각화 7. Data Wrangler (ms-toolsai.datawrangler) - GUI 데이터 변환 8. SQLTools (mtxr.sqltools) - DB 연결 & 쿼리 9. Geo Data Viewer (randomfractals.geo-data-viewer) - 지도 시각화 10. Rainbow CSV (mechatroner.rainbow-csv) - CSV 탐색\n3) AI, 협업 & 운영: 11. Jupyter (ms-toolsai.jupyter) - 노트북 실행 12. GitHub Copilot (GitHub.copilot) - AI 코딩 (유료) 13. Live Share (ms-vsliveshare.vsliveshare) - 실시간 협업 14. Remote-SSH (ms-vscode-remote.remote-ssh) - 원격 GPU 서버 15. Docker (ms-azuretools.vscode-docker) - 컨테이너화\n확장 충돌이나 성능 문제가 발생하면 Cmd+Shift+P → “Extensions: Disable All Installed Extensions”으로 모든 확장을 비활성화한 후, 하나씩 다시 활성화하며 문제를 찾는다. 확장 개수가 너무 많으면 IDE 시작 속도가 느려질 수 있으므로, 실제 사용하는 확장만 활성화하고 나머지는 비활성화한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_extension.html#sec-extension-conclusion",
    "href": "ide_extension.html#sec-extension-conclusion",
    "title": "32  IDE 확장 프로그램",
    "section": "32.3 결론",
    "text": "32.3 결론\n현대 IDE 확장 프로그램 아키텍처는 ‘분리와 표준화’ 두 가지 핵심 원칙에 기반한다. Extension Host로 각 확장 프로그램을 분리해 안정성을 확보하고, LSP라는 표준화된 프로토콜로 언어 기능을 재사용 가능하게 만든다.\n영리한 아키텍처 덕분에 VS Code 같은 현대 IDE는 수많은 언어와 도구를 지원하는 거대한 생태계를 구축하면서도, 가볍고 안정적인 성능을 유지한다. IDE가 더 이상 하나의 회사가 만드는 단일 제품이 아니라, 전 세계 개발자 커뮤니티가 함께 만들어가는 ’플랫폼’이 되었다.\n💡 생각해볼 점\n확장 프로그램 생태계가 IDE의 핵심 경쟁력이 된 시대다. Positron을 선택했다면 R과 Python이 이미 내장되어 있으므로, Shiny Publisher, Quarto, SandDance부터 설치해 즉시 인터랙티브 앱과 문서를 만들어보자. VS Code를 사용한다면 R, Python, Jupyter를 먼저 설치하고 언어 기반을 구축한 뒤 나머지 확장을 추가한다.\n15개 확장을 한 번에 설치하기보다는, 프로젝트 성격에 따라 선택적으로 설치한다. Shiny 대시보드 개발 프로젝트라면 Shiny Publisher와 Thunder Client를, 공간 데이터 분석이라면 Geo Data Viewer와 SQLTools를, 원격 GPU 서버에서 딥러닝을 훈련한다면 Remote-SSH와 Docker를 먼저 설치한다. 필요할 때마다 하나씩 추가하며 자신만의 최적 환경을 구축하는 것이 가장 효율적이다.\n협업 프로젝트에서는 Live Share로 실시간 페어 프로그래밍을 시도해보자. 주니어 개발자가 막힌 부분을 시니어가 원격으로 함께 디버깅하거나, 코드 리뷰를 화면 공유 없이 IDE 내에서 직접 수행하는 경험은 협업 방식을 근본적으로 바꾼다.\n확장 생태계는 계속 진화한다. 2025년 현재 15개 필수 확장이 데이터 과학 워크플로우를 완성하지만, 1년 후에는 새로운 AI 도구, 시각화 확장, 협업 플랫폼이 등장할 것이다. 중요한 것은 “어떤 확장이 있는지” 지속적으로 탐색하고, “내 워크플로우에 필요한지” 빠르게 판단하는 능력이다. 확장 마켓플레이스에서 “data science”, “visualization”, “collaboration” 키워드로 정기적으로 검색하며 새로운 도구를 발견하자.\n다음 장에서는 이론을 넘어 실제로 포지트론 개발 환경을 구축한다. 운영체제별 설치, R/Python 인터프리터 설정, 필수 확장 15종 설치, 키보드 단축키 암기까지 완전한 작업 환경을 처음부터 끝까지 구성한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>IDE 확장 프로그램</span>"
    ]
  },
  {
    "objectID": "ide_setup.html",
    "href": "ide_setup.html",
    "title": "33  개발 환경 구축",
    "section": "",
    "text": "33.1 Git 설치\nAI로 데이터 과학 문제를 해결하기 위한 첫걸음은 강력한 프로그래밍 언어와 안정적인 개발 환경 구축이다. 본 장에서는 필수적인 버전 관리 도구 Git과 재현 가능한 환경을 위한 도커(Docker), 워크플로우 자동화를 위한 Make를 시작으로, 데이터 과학의 양대 산맥인 R과 파이썬(Python)을 설치하고, 마지막으로 이들을 통합해 사용할 포지트론 IDE 설정 전 과정을 안내한다.\n그림 33.1 는 데이터 과학 개발 환경 구축의 전체 단계를 보여준다. Git, 도커, Make 같은 필수 도구를 먼저 설치하고, R과 파이썬을 설치한 후, 마지막으로 포지트론 IDE를 설치한다.\n본격적인 개발 환경 구축에 앞서, 가장 중요한 버전 관리 시스템 Git을 먼저 설치한다. Git은 코드 변경 이력을 추적하고, 여러 개발자가 협업하게 하며, AI 모델 개발 시 다양한 실험을 관리하는 필수 도구다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-git",
    "href": "ide_setup.html#sec-setup-git",
    "title": "33  개발 환경 구축",
    "section": "",
    "text": "33.1.1 Git 설치\n맥OS(macOS)에서는 터미널을 열고 xcode-select --install 명령어를 실행하면 뜨는 팝업창에서 ’설치’를 클릭한다. Xcode Command Line Tools에 Git이 포함되어 있다. 이미 설치되어 있다면 git --version 명령어로 확인한다.\n윈도우(Windows)에서는 git-scm.com 공식 다운로드 페이지에 접속해 최신 버전 설치 파일을 다운로드한다. 설치 프로그램을 실행하고 대부분 옵션을 기본값으로 두고 설치를 진행한다. ’Git Bash’가 함께 설치되어 강력한 명령어 환경을 제공한다.\n리눅스(Linux, 우분투/데비안)에서는 터미널을 열고 다음 명령어를 실행한다:\nsudo apt-get update\nsudo apt-get install git\n\n33.1.2 설치 확인\n터미널에서 다음 명령어를 실행해 Git이 정상 설치되었는지 확인한다:\n$ git --version\ngit version 2.39.2 (Apple Git-143)\n\n33.1.3 최초 설정\nGit 설치 후, 터미널에서 다음 두 명령어를 실행해 사용자 이름과 이메일 주소를 반드시 설정한다. 정보는 코드를 변경하고 저장(커밋)할 때마다 기록된다.\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n\"Your Name\"과 \"youremail@example.com\" 부분을 본인의 정보로 바꿔서 입력하세요.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#컨테이너-환경-도커-설치",
    "href": "ide_setup.html#컨테이너-환경-도커-설치",
    "title": "33  개발 환경 구축",
    "section": "\n33.2 컨테이너 환경: 도커 설치",
    "text": "33.2 컨테이너 환경: 도커 설치\nAI/머신러닝 프로젝트는 복잡한 라이브러리, 시스템 의존성, 드라이버 버전 등으로 내 컴퓨터에서는 잘 동작하던 코드가 다른 사람의 컴퓨터나 서버에서는 동작하지 않는 ’환경 문제’를 자주 겪는다. 도커는 프로젝트에 필요한 모든 것을 ’컨테이너’라는 격리된 공간에 담아 어디서든 동일한 환경을 완벽하게 복제한다. 재현 가능한 연구와 안정적 배포를 위한 현대 AI 개발 필수 도구다.\n\n\n도커 Desktop 설치:\n\n\n도커 공식 웹사이트에 접속해 자신의 운영체제(맥OS, 윈도우, 리눅스)에 맞는 도커 Desktop을 다운로드하고 설치한다.\n\n\n\n설치 확인: 설치 후 도커 Desktop을 실행한다. 터미널에서 다음 명령어를 실행해 정상 설치를 확인한다:\n$ docker --version\nDocker version 24.0.6, build ed223bc\n\n$ docker run hello-world\nHello from Docker!\nThis message shows that your installation appears to be working correctly.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-make",
    "href": "ide_setup.html#sec-setup-make",
    "title": "33  개발 환경 구축",
    "section": "\n33.3 워크플로우 자동화",
    "text": "33.3 워크플로우 자동화\n데이터 과학 프로젝트는 ‘데이터 가져오기 → 전처리 → 모델 학습 → 결과 분석 → 보고서 생성’ 같은 여러 단계 작업 흐름을 가진다. 각 단계를 수동으로 반복 실행하는 것은 비효율적일 뿐 아니라 실수를 유발한다. 1970년대 유닉스 시스템에서 탄생한 make는 이런 반복 작업을 자동화하는 검증된 도구다.\nmake 핵심은 의존성 기반 실행이다. Makefile에 “분석 보고서는 전처리된 데이터에 의존하고, 전처리된 데이터는 원본 데이터에 의존한다”는 관계를 정의하면, make는 변경된 파일만 감지해 필요한 작업만 지능적으로 재실행한다. 예를 들어 원본 데이터가 바뀌면 전처리부터 보고서까지 전부 재생성하지만, 분석 코드만 수정했다면 전처리는 건너뛰고 분석과 보고서만 다시 생성한다. 시간과 컴퓨팅 자원을 크게 절약하는 방식이다.\n\n33.3.1 Make 설치\nmake는 대부분의 운영체제에 이미 설치되어 있거나 개발 도구와 함께 제공된다. 맥OS에서는 Git 설치 시 사용한 Xcode Command Line Tools에 make가 포함되어 있고, 리눅스(우분투/데비안)에서도 기본으로 설치된 경우가 많다. 터미널에서 make --version을 실행해 설치 여부를 확인할 수 있다. 리눅스에서 make가 없다면 sudo apt-get install build-essential 명령어로 컴파일 도구 일체를 설치한다.\n윈도우는 상황이 다르다. Git for Windows를 설치했다면 Git Bash 환경에서 make를 사용할 수 있지만, 네이티브 윈도우 환경에서는 별도 설치가 필요하다. Chocolatey 패키지 매니저가 설치되어 있다면 choco install make 명령어로 간단히 설치할 수 있다.\n\n33.3.2 워크플로우 도구 진화\nmake는 1976년 Stuart Feldman이 Bell Labs에서 C 프로그램 컴파일 자동화를 위해 개발했다. 이후 50년 가까이 소프트웨어 빌드의 표준 도구로 자리잡았지만, 데이터 과학의 부상과 함께 새로운 요구가 생겼다. make의 shell 스크립트 기반 문법은 데이터 분석 파이프라인을 표현하기에 복잡하고, 크로스 플랫폼 지원도 제한적이다. 특히 R이나 Python 생태계와의 통합이 자연스럽지 않다. 이런 한계를 극복하기 위해 언어별, 용도별로 특화된 도구들이 등장했다.\n\n\n\n\n\n그림 33.2: 워크플로우 자동화 도구의 진화\n\n\n지난 50년간 워크플로우 자동화 도구는 세 번의 큰 물결을 거쳤다. 그림 33.2 은 이 진화 과정을 시간순으로 보여준다. 첫 번째 물결은 1976년 make로 시작되었다. C 프로그램 컴파일을 위해 탄생했지만, 곧 소프트웨어 빌드 전반의 표준이 되었다. 두 번째 물결은 2012년 스네이크메이크의 등장이다. 독일 뒤셀도르프 대학의 Johannes Köster가 생물정보학 연구를 위해 개발했는데, 수백 개의 샘플을 처리하는 유전체 분석 파이프라인에서 make의 한계가 명확했기 때문이다. Python 문법을 직접 사용할 수 있고, 클러스터 환경에서 자동 병렬화를 지원하는 스네이크메이크는 곧 생명과학을 넘어 데이터 과학 전반으로 확산되었다. 세 번째 물결은 2017-2020년 사이 동시다발적으로 일어났다. 2017년 Go로 작성된 Task가 YAML 기반의 간결한 문법으로 등장했고, 2018년에는 Rust 기반 Just가 명령어 실행에 특화된 미니멀한 접근으로 개발자들을 끌어모았다. 2020년 R 커뮤니티에서는 Will Landau가 targets를 발표하며 데이터 과학 워크플로우 자동화의 새 장을 열었다. drake 패키지의 후속작인 targets는 R 객체 수준에서 의존성을 추적하고, Quarto와의 완벽한 통합으로 재현가능한 연구의 표준 도구가 되었다.\n\n33.3.3 현대 데이터 과학 도구\nmake가 50년 역사를 자랑하지만, 현대 데이터 과학 프로젝트는 make가 설계되지 않았던 요구사항들을 갖는다. R 데이터 분석 프로젝트는 함수와 데이터 객체 간의 복잡한 의존성을 추적해야 하고, Python 생물정보학 파이프라인은 수천 개의 파일을 클러스터에서 병렬 처리해야 한다. 웹 기반 Quarto 프로젝트는 윈도우와 맥OS, 리눅스에서 동일한 명령어로 작동해야 한다. 이런 특수한 요구를 충족하기 위해 언어별, 용도별로 최적화된 도구들이 등장했다.\n\n\n\n\n\n그림 33.3: 데이터 과학 워크플로우 자동화 도구\n\n\n그림 33.3 는 현대 데이터 과학에서 사용되는 세 가지 워크플로우 자동화 도구를 비교한다. R 커뮤니티는 targets를 통해 데이터 분석의 재현가능성을 한 단계 높였다. 함수 하나를 수정하면 그 함수에 의존하는 모든 타겟이 자동으로 재계산되고, Quarto 보고서까지 연쇄적으로 업데이트된다. Python 생태계는 스네이크메이크로 대규모 데이터 파이프라인을 관리한다. make와 비슷한 규칙 기반 문법에 Python의 강력함을 더해, 생물정보학부터 기계학습 실험 추적까지 폭넓게 활용된다. 범용 빌드 도구로는 Task가 부상했다. YAML 파일 하나로 프로젝트의 모든 반복 작업을 정의하고, 크로스 플랫폼 환경에서 동일하게 실행할 수 있다.\nR 데이터 과학: targets\nR 프로젝트에서는 targets 패키지가 워크플로우 자동화의 표준이다. targets는 함수와 데이터 객체 간의 의존성을 자동으로 추적하고, 변경이 발생한 부분만 재실행한다. 특히 Quarto 문서와의 통합이 뛰어나 데이터 분석부터 보고서 생성까지 하나의 워크플로우로 관리할 수 있다.\nR 콘솔이나 포지트론 터미널에서 다음 명령어로 설치한다:\ninstall.packages(\"targets\")\ninstall.packages(\"tarchetypes\")  # Quarto 통합용\n\n# 설치 확인\nlibrary(targets)\npackageVersion(\"targets\")\ntarchetypes 패키지는 Quarto 문서를 targets 파이프라인에 통합하는 tar_quarto() 함수를 제공한다. 데이터 분석 결과가 변경되면 Quarto 문서도 자동으로 재렌더링된다.\nPython 데이터 과학: Snakemake\n스네이크메이크는 Python 기반 워크플로우 관리 시스템으로, 생물정보학 분야에서 시작해 데이터 과학 전반으로 확산되었다. make와 유사한 규칙 기반 문법에 Python 코드를 결합해 복잡한 파이프라인을 표현할 수 있다. 클러스터나 클라우드 환경에서 대규모 병렬 처리를 지원하며, 재현가능한 연구를 위한 표준 도구로 자리잡았다.\n스네이크메이크는 conda나 pip로 설치할 수 있다. conda를 사용하면 의존성 관리가 자동화되고, 필요한 생물정보학 도구들과 함께 환경을 구성할 수 있다:\n# conda로 설치 (권장 - 범용)\nconda install -c conda-forge snakemake\n\n# 생물정보학 프로젝트라면 bioconda 채널 사용\nconda install -c bioconda snakemake\n\n# pip로도 설치 가능\npip install snakemake\n\n# 설치 확인\nsnakemake --version\nconda-forge는 범용 데이터 과학 프로젝트에 적합하고, bioconda는 유전체 분석 같은 생물정보학 도구들을 함께 사용할 때 유용하다. conda 환경이 없다면 pip로도 충분히 설치할 수 있다.\n범용 빌드: Task\nTask는 make의 현대적 대안으로, YAML 파일에 작업을 정의하고 실행한다. make의 복잡한 문법 대신 읽기 쉬운 YAML을 사용하며, 윈도우와 맥OS, 리눅스 모두에서 동일하게 작동한다. Quarto 프로젝트의 렌더링, 테스트, 배포 같은 반복 작업을 자동화할 때 유용하다.\n운영체제별 설치 방법은 다음과 같다:\n# macOS\nbrew install go-task/tap/go-task\n\n# Windows (Chocolatey)\nchoco install go-task\n\n# Windows (Scoop)\nscoop install task\n\n# Linux\nsh -c \"$(curl --location https://taskfile.dev/install.sh)\" -- -d -b /usr/local/bin\n\n# 설치 확인\ntask --version\n프로젝트 루트에 Taskfile.yml을 생성하고 작업을 정의하면, task 작업명 명령어로 실행할 수 있다. targets나 스네이크메이크처럼 복잡한 의존성 추적은 제공하지 않지만, 간단한 빌드 스크립트를 작성할 때 make보다 훨씬 직관적이다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-isolation-comparison",
    "href": "ide_setup.html#sec-setup-isolation-comparison",
    "title": "33  개발 환경 구축",
    "section": "\n33.4 uv vs 도커",
    "text": "33.4 uv vs 도커\n파이썬 개발 환경 격리 도구인 uv와 도커는 모두 ‘재현 가능한 환경’ 구축을 목표로 하지만, 접근 방식과 범위가 다르다.\n\n\n\n\n\n그림 33.4: 환경 격리 수준 비교: uv vs 도커\n\n\n그림 33.4 는 uv와 도커의 가상화 계층 구조를 보여준다. uv는 파이썬 패키지 수준만 격리하는 반면, 도커는 OS부터 모든 시스템 의존성까지 완전히 격리한다.\n\n33.4.1 유사점\n두 도구 모두 프로젝트마다 독립적 환경을 제공해 의존성 충돌을 방지하는 환경 격리를 목표로 한다. 또한 동일한 환경을 다른 시스템에서 정확히 재현할 수 있는 재현가능성을 보장하며, 프로젝트 의존성을 파일로 명확히 정의한다. uv는 requirements.txt로, 도커는 Dockerfile로 의존성을 명시한다.\n\n33.4.2 차이점\n\n\n\n\n\n\n\n\n특성\nuv\n도커\n\n\n\n격리 수준\n파이썬 패키지 수준 (가상 환경)\nOS 수준 (완전한 컨테이너)\n\n\n범위\n파이썬 패키지만 관리\n파이썬, R, 시스템 라이브러리, OS 설정 등 전체\n\n\n무게\n매우 가볍고 빠름 (러스트 기반)\n상대적으로 무거움 (이미지 크기 수백 MB~GB)\n\n\n시작 속도\n즉시 (초 단위)\n컨테이너 시작 필요 (초~분)\n\n\n학습 곡선\n낮음 (pip/venv 익숙하면 쉬움)\n높음 (Dockerfile, 이미지, 컨테이너 개념)\n\n\n사용 시나리오\n로컬 파이썬 개발\n복잡한 멀티 언어 프로젝트, 배포, CI/CD\n\n\n시스템 의존성\n시스템 라이브러리에 의존\n시스템과 완전 독립\n\n\n\n\n\n\n\n표 33.1: uv와 도커 환경 격리 도구 비교\n\n\n\n\n33.4.3 언제 무엇을 사용하나?\nuv로 충분한 경우:\n순수 파이썬 패키지만 사용하는 프로젝트는 uv로 완벽히 재현 가능하다.\n# 예: 웹 개발, 데이터 분석 기본\npandas, requests, fastapi, pydantic, numpy, scikit-learn\n이런 패키지는 시스템 라이브러리 의존성이 없거나 최소화되어, uv가 파이썬 버전과 패키지만 관리해도 어떤 시스템에서든 동일하게 작동한다.\n도커가 필요한 경우:\n시스템 라이브러리 의존성이 있는 패키지는 도커 권장이다.\n# 예: 컴퓨터 비전, 데이터베이스, 지리정보\nopencv-python     # C++ 라이브러리 (OpenCV)\npsycopg2          # PostgreSQL 라이브러리\nGDAL              # 지리정보 시스템 라이브러리\n이런 패키지는 OS의 시스템 라이브러리가 필요하므로, 도커로 OS부터 완전히 격리하는 것이 안전하다.\n둘 다 사용: 도커 컨테이너 안에서 uv를 사용해 파이썬 패키지를 관리하는 것도 가능하다. 도커로 시스템 라이브러리 환경을 구축하고, uv로 파이썬 패키지를 빠르게 관리하는 조합이다.\n결론: 순수 파이썬 프로젝트는 uv로 시작하고, 시스템 의존성이 생기면 도커를 고려한다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-languages",
    "href": "ide_setup.html#sec-setup-languages",
    "title": "33  개발 환경 구축",
    "section": "\n33.5 코딩 언어 설치",
    "text": "33.5 코딩 언어 설치\nR은 통계 분석, 데이터 시각화, 학술 연구 분야에서 전통적 강점을 가진다. ggplot2 같은 강력한 시각화 라이브러리와 수많은 통계 패키지는 R의 큰 자산이다.\n반면 파이썬은 머신러닝, 딥러닝, 웹 개발, 시스템 자동화 등 범용성과 확장성에서 뛰어나다. TensorFlow, PyTorch 같은 딥러닝 프레임워크와 방대한 커뮤니티를 자랑한다.\n두 언어는 경쟁 관계이기도 하지만, 서로의 단점을 보완하는 강력한 상보 관계이기도 하다. R로 데이터를 깊이 있게 탐색하고 시각화한 후, 파이썬으로 복잡한 머신러닝 모델을 구축하거나 서비스로 배포하는 워크플로우는 매우 효과적이다. 현대 데이터 과학자에게 두 언어 모두를 능숙하게 다루는 능력은 큰 경쟁력이 된다.\n\n33.5.1 R 설치 및 환경 관리\nR 설치\nR은 CRAN(The Comprehensive R Archive Network) 공식 네트워크로 배포된다.\nCRAN 공식 웹사이트에 접속해 자신의 운영체제(리눅스, 맥OS, 윈도우)에 맞는 R 설치 파일을 다운로드하고 실행한다. 설치 과정에서는 대부분 기본 설정을 유지하는 것이 좋다.\n\n참고: RStudio나 Positron은 R을 실행하기 위한 IDE일 뿐, R 자체는 아니다. IDE 사용 전에 반드시 시스템에 R 언어가 먼저 설치되어 있어야 한다.\n\nR 환경 관리: renv\n프로젝트마다 사용하는 R 패키지 버전이 다르면 충돌이 발생할 수 있다. renv는 프로젝트별로 독립된 패키지 라이브러리를 만들어 의존성 문제를 해결하는 도구다.\n중요한 제한사항: renv는 R 패키지만 격리한다. R 인터프리터(언어 실행기) 자체는 시스템에 설치된 것을 공유해 사용한다. renv.lock 파일에 “R 버전 4.3.0”이라고 기록은 하지만, 해당 R 버전이 시스템에 없으면 설치해주지 않고 경고만 표시한다. R 버전까지 완전히 격리하려면 rig (R Installation Manager) 같은 별도 도구와 함께 사용해야 한다.\n이는 파이썬 uv와의 큰 차이다. uv는 uv python install 3.11 명령으로 파이썬 인터프리터 자체를 다운로드하고 관리하지만, renv는 그런 기능이 없다.\n설치 및 사용:\nR 콘솔에서 install.packages(\"renv\")를 실행해 설치한다. RStudio나 Positron에서 새로운 프로젝트를 시작할 때 renv 사용 옵션을 체크하면 프로젝트 폴더에 renv 관련 파일이 생성된다. renv::snapshot()으로 패키지 목록과 버전을 기록하고, renv::restore()로 다른 환경에서 복원한다.\nrig + renv 조합으로 완전한 격리:\nR 버전까지 완전히 격리하려면 rig (R Installation Manager)와 renv를 함께 사용한다. 먼저 rig GitHub에서 운영체제에 맞는 설치 프로그램을 다운로드한다. rig add 4.3.0 명령으로 원하는 R 버전을 설치하고, rig default 4.3.0 또는 .Rprofile 파일로 프로젝트별 R 버전을 고정한다. 이후 renv로 패키지를 관리하면 파이썬 uv처럼 런타임(R 인터프리터)과 패키지 모두 프로젝트별로 격리할 수 있다.\n\n\n\n\n\n그림 33.5: uv vs rig + renv: 런타임 격리 방식 비교\n\n\n\n33.5.2 파이썬 설치 및 환경 관리\n파이썬 설치\n파이썬 설치 방법은 크게 두 가지다.\n공식 파이썬 설치 프로그램 사용 (권장): 파이썬 공식 웹사이트에 접속해 최신 안정화 버전을 다운로드한다. 윈도우 설치 시 첫 화면에서 “Add Python.exe to PATH” 옵션을 반드시 체크해야 터미널에서 python 명령어를 바로 사용할 수 있다. 이 방법은 가장 깔끔하고 표준적인 파이썬 환경을 제공한다.\n아나콘다(Anaconda) 배포판 사용: 아나콘다 배포판은 파이썬 자체뿐 아니라 numpy, pandas, scikit-learn 등 수백 개의 데이터 과학 패키지를 함께 묶어 제공한다. 초보자에게는 편리할 수 있지만, 시스템 환경을 복잡하게 만들 수 있고 용량이 크다는 단점이 있다. 이 책에서는 공식 파이썬 설치를 기준으로 설명한다.\n파이썬 환경 관리: uv\n과거에는 pip로 패키지를 설치하고 venv로 가상 환경을 만드는 등 여러 도구를 조합해야 했지만, 최근에는 uv라는 차세대 통합 도구가 등장해 파이썬 개발 환경 관리가 훨씬 빠르고 간편해졌다. uv는 러스트(Rust)로 작성되어 기존 도구보다 수십 배에서 수백 배 빠른 속도를 자랑한다.\nuv 설치: 터미널에서 운영체제에 맞는 명령어를 실행해 uv를 설치한다. 맥OS/리눅스에서는 curl -LsSf https://astral.sh/uv/install.sh | sh를, 윈도우 파워셸(PowerShell)에서는 powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"를 실행한다.\n가상 환경 생성: 프로젝트 폴더로 이동한 후 터미널에서 uv venv 명령어를 실행하면 .venv라는 폴더에 가상 환경이 생성된다.\n가상 환경 활성화: 윈도우에서는 .\\.venv\\Scripts\\activate를, 맥OS/리눅스에서는 source .venv/bin/activate를 실행한다. 활성화되면 터미널 프롬프트 앞에 (.venv)와 같은 표시가 나타난다.\n패키지 설치: 가상 환경이 활성화된 상태에서 uv pip install 명령어로 패키지를 매우 빠르게 설치할 수 있다. 예를 들어 uv pip install pandas scikit-learn 명령으로 pandas와 scikit-learn을 설치하거나, uv pip install -r requirements.txt 명령으로 requirements.txt 파일로부터 패키지를 설치한다.\n작업이 끝나면 터미널에서 deactivate 명령어를 실행해 가상 환경을 비활성화한다.\n설치 확인: 다음 명령어로 uv가 정상 설치되었는지 확인한다:\n$ uv --version\nuv 0.1.18\n\n$ uv pip list\nPackage    Version\n---------- -------\npip        24.0\nsetuptools 69.0.3",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-ide",
    "href": "ide_setup.html#sec-setup-ide",
    "title": "33  개발 환경 구축",
    "section": "\n33.6 통합 개발 환경 설치",
    "text": "33.6 통합 개발 환경 설치\n\n33.6.1 Positron IDE 설치\nPositron은 R과 파이썬을 모두 지원하는 차세대 데이터 과학 IDE다. VS Code 기반의 현대적인 인터페이스와 RStudio의 강력한 데이터 과학 기능을 결합하여 두 언어를 함께 사용하는 데이터 과학자에게 최적화된 환경을 제공한다.\nPositron 다운로드에서 운영체제(윈도우, 맥OS, 리눅스)에 맞는 설치 프로그램을 다운로드한다. Positron은 현재 베타 버전이므로 최신 정보를 확인하는 것이 중요하다. 다운로드한 파일을 실행하고 안내에 따라 설치를 진행한다. 대부분 경우 기본 설정을 따르는 것이 좋다.\nPositron은 R과 파이썬 인터프리터를 함께 사용한다. 설치 후 Positron을 실행하여 Tools → Global Options 또는 Preferences에서 R 및 파이썬 인터프리터 경로가 올바르게 설정되었는지 확인한다. 이를 통해 Positron이 시스템에 설치된 R 및 파이썬 환경을 정확히 인식하고 활용할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-quarto",
    "href": "ide_setup.html#sec-setup-quarto",
    "title": "33  개발 환경 구축",
    "section": "\n33.7 문학적 프로그래밍",
    "text": "33.7 문학적 프로그래밍\nPositron IDE는 쿼토를 잘 지원하지만, 쿼토의 모든 기능을 활용해 다양한 포맷(특히 PDF)으로 문서를 렌더링하려면 몇 가지 추가 도구가 필요할 수 있다.\n판독(Pandoc): 쿼토는 문서 변환의 핵심 엔진으로 판독을 사용한다. 대부분 경우 쿼토 설치 시 판독이 함께 번들되어 제공되므로 별도로 설치할 필요는 없다. 터미널에서 pandoc --version 명령어를 실행해 설치 여부와 버전을 확인할 수 있다.\n\\(\\LaTeX\\) 배포판 (PDF 출력을 위해 필수): 쿼토로 PDF 문서를 생성하려면 \\(\\LaTeX\\) 배포판이 시스템에 설치되어 있어야 한다. 쿼토는 자동으로 TinyTEX을 설치할 수 있도록 지원하며, 이는 가장 권장되는 방법이다. R 콘솔 또는 Positron의 터미널에서 다음 명령어를 실행해 TinyTEX을 설치한다:\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\nTinyTEX 대신 MiKTEX(윈도우)나 TEX Live(리눅스/맥OS) 같은 다른 \\(\\LaTeX\\) 배포판을 설치할 수도 있다. 하지만 TinyTEX이 가장 가볍고 쿼토와 통합이 용이하다.\n쿼토 CLI 설치 확인: Positron 자체에 쿼토 기능이 통합되어 있더라도 터미널에서 쿼토 명령어를 직접 사용하려면 쿼토 CLI가 설치되어 있어야 한다. 쿼토 공식 웹사이트에서 설치하거나 quarto install 명령어를 통해 설치할 수 있다. Positron이 쿼토를 번들하는 경우도 많으므로 먼저 quarto --version으로 확인하는 것이 좋다.\n설정 확인: 쿼토 관련 설정이 모두 완료되면 터미널에서 quarto check 명령어를 실행해 필요한 도구들이 올바르게 설정되었는지 진단할 수 있다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-fonts",
    "href": "ide_setup.html#sec-setup-fonts",
    "title": "33  개발 환경 구축",
    "section": "\n33.8 개발 글꼴",
    "text": "33.8 개발 글꼴\n개발자가 마주하는 폰트 환경은 세 가지로 나뉜다. 코드 편집기와 터미널에서는 고정폭(monospace) 폰트가 필수다. 웹이나 앱의 UI를 디자인할 때는 시스템과 조화를 이루는 가변폭 산세리프 폰트를 사용한다. 기술 문서나 블로그처럼 장문을 다룰 때는 장시간 읽기에 적합한 폰트가 필요하다.\n\n\n\n\n\n그림 33.6: 개발자 폰트 생태계\n\n\n그림 33.6 은 개발자 폰트 생태계를 용도별로 정리한다. 코딩 환경에서는 JetBrains Mono, Fira Code, D2코딩이 대표적이다. 특히 D2코딩은 한글 가독성이 뛰어나 한국 개발자에게 필수로 꼽힌다. 웹과 앱 UI에서는 프리텐다드가 한국 웹 표준으로 자리잡았고, 글로벌 환경에서는 Inter가 널리 쓰인다. 구글의 Noto Sans CJK는 “No more Tofu”라는 슬로건 아래 800개 이상의 언어를 지원하며, 폰트 깨짐 없는 다국어 환경을 제공한다. 문서 작성에서는 Noto 패밀리가 Sans, Serif, Mono 전방위로 활약하며, IBM Plex Sans나 마루부리 같은 폰트도 기술 블로그와 출판물에 자주 등장한다.\nNoto 프로젝트는 구글이 시작한 범세계적 폰트 이니셔티브다. “Tofu”는 폰트가 없어서 나타나는 □ 문자를 의미하는데, Noto는 이 문제를 해결하고자 탄생했다. 한글, 중국어, 일본어를 포함한 CJK(Chinese, Japanese, Korean) 언어부터 아랍어, 히브리어, 태국어까지 모든 문자를 하나의 통일된 디자인으로 제공한다. 개발자가 다국어 환경을 구축할 때 Noto 패밀리를 사용하면 언어별로 폰트를 따로 관리할 필요 없이 일관된 타이포그래피를 유지할 수 있다.\n\n33.8.1 D2코딩 폰트 설치\n개발 환경에서 폰트를 사용하려면 두 단계를 거친다. 먼저 폰트를 운영체제에 설치하고, 그 다음 IDE 설정에서 해당 폰트를 지정한다. D2코딩은 한글과 영문이 조화롭게 어우러지도록 설계된 모노스페이스 폰트로, 한국 개발자에게 가장 많이 쓰인다.\nD2코딩 GitHub 릴리즈 페이지에서 최신 zip 파일을 다운로드한 뒤 압축을 풀면 .ttf 파일이 나타난다. 이 파일을 더블 클릭하면 윈도우에서는 ‘설치’ 버튼이, 맥OS에서는 ‘서체 설치’ 버튼이 나타난다. 버튼을 클릭하면 시스템 전체에서 D2코딩 폰트를 사용할 수 있게 된다.\n시스템 설치가 끝나면 IDE에서 이 폰트를 지정한다. Positron이나 VS Code에서 Cmd/Ctrl + ,로 설정을 열고 font family를 검색한다. ‘Editor: Font Family’ 항목의 맨 앞에 'D2Coding',을 추가하면 코드 편집기가 D2코딩을 최우선으로 사용한다. 예를 들어 다음과 같은 형태가 된다:\n'D2Coding', \"Apple SD Gothic Neo\", \"Malgun Gothic\", monospace\n폰트 목록의 맨 앞에 배치한 이유는 간단하다. IDE는 목록 순서대로 폰트를 찾아 사용하므로, D2코딩이 설치되어 있으면 이 폰트로 표시하고, 없으면 다음 폰트로 넘어간다. 설정을 저장하면 편집기 화면이 즉시 D2코딩으로 바뀐다.\n\n33.8.2 프리텐다드 가변 글꼴\n프리텐다드는 D2코딩과 달리 웹 환경을 위해 설계된 가변 글꼴이다. 가변 폰트(Variable Font)는 하나의 파일에 여러 weight(두께)를 담는 기술로, 프리텐다드는 Thin(100)부터 Black(900)까지 9단계를 지원한다. 한글, 영문, 일본어를 모두 포괄하며, 윈도우와 맥OS, 리눅스에서 일관된 렌더링을 보장한다. 특히 쿼토로 생성한 HTML 문서나 GitHub Pages, 기술 블로그처럼 웹에 게시되는 콘텐츠에서 시스템 폰트의 한계를 넘어서는 가독성을 제공한다.\n프리텐다드는 사용 목적에 따라 두 가지 방식으로 설치한다. 프리텐다드 GitHub 릴리즈에서 zip 파일을 다운로드하면 여러 형식의 폰트 파일이 들어 있다. IDE나 데스크톱 애플리케이션에서 사용하려면 public/static 폴더의 OTF나 TTF 파일을 시스템에 설치한다. D2코딩과 같은 방식이다.\n웹 페이지에 직접 삽입하려면 web/variable 폴더의 WOFF2 파일을 사용한다. 쿼토 프로젝트의 _quarto.yml이나 CSS 파일에서 @font-face로 선언하면 방문자의 시스템에 폰트가 없어도 웹 페이지에서 프리텐다드를 표시할 수 있다:\n@font-face {\n  font-family: 'Pretendard';\n  src: url('fonts/PretendardVariable.woff2') format('woff2-variations');\n  font-weight: 100 900;\n}\n\nbody {\n  font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif;\n}\n웹 폰트로 사용하면 모든 플랫폼의 방문자에게 일관된 타이포그래피를 제공할 수 있다. 시스템 폰트는 사용자의 OS에 따라 달라지지만, 웹 폰트는 제작자가 의도한 대로 정확히 표시된다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "ide_setup.html#sec-setup-verify",
    "href": "ide_setup.html#sec-setup-verify",
    "title": "33  개발 환경 구축",
    "section": "\n33.9 개발 환경 검증",
    "text": "33.9 개발 환경 검증\n지금까지 포지트론 IDE부터 시작해 R과 파이썬, Git과 도커, 워크플로우 자동화 도구(make, targets, 스네이크메이크, Task), 쿼토 출판 시스템, 개발 글꼴(D2코딩, 프리텐다드)까지 현대 데이터 과학 환경의 핵심 요소들을 설치했다. 각 도구는 독립적으로 작동하지만, 함께 사용할 때 시너지를 발휘한다. 포지트론에서 R 코드로 데이터를 분석하고, targets로 워크플로우를 자동화하며, 쿼토로 결과를 문서화하고, Git으로 버전을 관리하는 통합 환경이 완성된 것이다. 설치가 제대로 되었는지 확인하는 것이 다음 단계다.\n핵심 도구들의 설치 여부를 터미널에서 한번에 확인할 수 있다:\n$ git --version && docker --version && make --version | head -1 && R --version | head -1 && python --version && uv --version\ngit version 2.39.2 (Apple Git-143)\nDocker version 24.0.6, build ed223bc\nGNU Make 3.81\nR version 4.3.0 (2023-04-21) -- \"Already Tomorrow\"\nPython 3.11.5\nuv 0.1.18\n모든 명령어가 버전 정보를 출력하면 기본 환경 구축이 완료된 것이다. 워크플로우 자동화 도구는 필요에 따라 선택적으로 확인한다. R 프로젝트라면 R 콘솔에서 library(targets)를 실행해 targets 패키지가 로드되는지 확인하고, Python 생물정보학 프로젝트라면 snakemake --version으로 스네이크메이크 설치를 점검한다. 범용 빌드 도구인 Task를 설치했다면 task --version으로 확인한다.\n개발 글꼴도 IDE 설정에서 확인한다. 포지트론이나 VS Code의 설정(Cmd/Ctrl + ,)에서 ’Font Family’를 검색하면 D2코딩이나 프리텐다드가 목록 맨 앞에 있는지 확인할 수 있다. 코드 편집기에서 한글과 영문이 조화롭게 표시되면 글꼴 설정이 올바른 것이다.\n모든 검증이 완료되면 포지트론을 실행하고 R과 파이썬 인터프리터 경로를 설정해 첫 데이터 과학 프로젝트를 시작할 준비가 된다.\n💡 생각해볼 점\n개발 환경 구축은 한 번에 완성되지 않는다. Git, Docker, R, Python, Positron, Quarto, 워크플로우 자동화, 개발 글꼴까지 나열된 도구들을 보면 압도될 수 있지만, 모든 것을 한 번에 설치할 필요는 없다. 프로젝트 성격에 따라 점진적으로 추가하는 것이 효율적이다.\n첫 데이터 분석 프로젝트라면 Positron과 R 또는 Python 하나만 설치하고 시작하자. CSV 파일을 열고, 간단한 전처리를 하며, ggplot2나 matplotlib로 그래프를 그려보자. 프로젝트가 커지면서 버전 관리가 필요해지면 Git을 추가한다. 팀원과 협업하거나 재현 가능성이 중요해지면 Docker를 도입한다. 분석 보고서를 작성할 때가 되면 Quarto와 TinyTeX를 설치한다.\n환경 격리 도구 선택은 프로젝트 복잡도로 판단한다. 순수 Python 패키지만 사용하는 데이터 분석이라면 uv로 충분하다. pandas, scikit-learn, matplotlib만으로 대부분의 분석이 가능하다. 하지만 OpenCV(컴퓨터 비전), PostgreSQL(데이터베이스), GDAL(공간 데이터) 같은 시스템 라이브러리가 필요하거나, R과 Python을 함께 사용하는 멀티 언어 프로젝트라면 Docker가 더 안전하다.\nR 사용자는 특별히 주의해야 한다. renv는 패키지만 격리하고 R 버전은 격리하지 않는다. Python의 uv가 uv python install 3.11로 런타임까지 관리하는 것과 대조적이다. R 버전까지 완전히 격리하려면 rig + renv 조합을 사용하거나, 아예 Docker로 R 버전부터 시스템까지 모두 패키징하는 것이 확실하다.\n개발 글꼴은 생산성에 직접적 영향을 준다. D2코딩 하나만 설치해도 한글과 영문이 조화로운 코딩 환경을 얻는다. 1(숫자)과 l(소문자 L), 0(숫자)과 O(대문자 o)를 명확히 구분할 수 있는 글꼴은 버그를 줄이고 눈의 피로를 덜어준다.\n지금 구축한 환경은 “완벽”이 아니라 “시작점”이다. 다음 장부터는 실전 프로젝트를 진행하면서 부족한 부분을 발견하고, 필요한 도구를 추가하며, 자신만의 최적 워크플로우를 만들어간다. Git으로 실험을 추적하고, Quarto로 분석을 문서화하며, Docker로 환경을 공유하는 과정에서 각 도구의 가치를 체감하게 된다.",
    "crumbs": [
      "**5부** 통합 개발 환경",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>개발 환경 구축</span>"
    ]
  },
  {
    "objectID": "docker_concept.html",
    "href": "docker_concept.html",
    "title": "34  도커: 재현 환경",
    "section": "",
    "text": "34.1 가상화 기술의 진화\n2023년 어느 연구팀의 이야기다. 논문 심사 과정에서 심사위원이 “분석 결과를 재현할 수 없습니다”라고 지적했다. 연구자는 당황했다. 6개월 전 자신의 컴퓨터에서는 완벽히 작동했기 때문이다. 코드와 데이터를 다시 실행했지만, 결과 그래프가 달랐다. 그 사이 R이 4.2에서 4.3으로 업그레이드되었고, ggplot2 패키지가 3.4에서 3.5로 바뀌면서 테마 기본값이 변경되었다. 맥OS도 Monterey에서 Sonoma로 업데이트되었다. 원본 환경을 복구하려 했지만, 구버전 R과 패키지를 다시 설치하는 과정에서 새로운 오류들이 발생했다. 결국 논문 게재는 6개월 지연되었다.\n이것이 재현가능성 위기다. “내 컴퓨터에서는 되는데요”는 개발자가 가장 두려워하는 말이다. 동일한 코드, 동일한 데이터인데도 환경 차이로 결과가 달라진다. 의존성(dependency) 문제는 과학 연구의 신뢰성을 위협한다.\n도커(Docker)는 이 문제를 근본적으로 해결한다. 분석 환경 전체를 “스냅샷”으로 저장한다. Ubuntu 20.04, R 4.3.0, ggplot2 3.4.2, 시스템 라이브러리, 데이터까지 모든 것을 하나의 컨테이너로 패키징한다. 이 컨테이너는 어디서나 동일하게 실행된다. 5년이 지나도, 다른 컴퓨터에서도, 클라우드 서버에서도 정확히 같은 결과를 재현한다.\n도커를 이해하려면 가상화 기술의 역사를 알아야 한다. 도커는 갑자기 등장한 기술이 아니라, 50년 가상화 역사의 최신 진화다.\n가상화(Virtualization)는 “하나의 물리적 컴퓨터에서 여러 개의 독립적인 컴퓨터를 실행”하는 기술이다. 1960년대 IBM 메인프레임에서 시작해, 2000년대 VMware가 대중화했고, 2013년 도커가 혁명을 일으켰다.\n1) 가상 머신 (VM) 시대 (1999-2010)\nVMware, VirtualBox 같은 도구는 하드웨어 가상화를 제공한다. 윈도우 위에서 리눅스를 실행하거나, 맥OS 위에서 윈도우를 실행한다. 각 VM은 완전한 OS를 포함하므로 무겁고 느리다. Windows 10 VM 하나가 20GB 디스크를 차지하고, 4GB 메모리를 사용하며, 부팅에 30초가 걸린다. 노트북에서 3개의 VM을 동시에 실행하면 시스템이 느려진다.\n2) 컨테이너 등장 (2008-2012)\n리눅스 컨테이너(LXC)는 OS 수준 가상화를 제공한다. 하나의 리눅스 커널을 여러 컨테이너가 공유하므로 VM보다 훨씬 가볍다. 컨테이너 하나가 몇 MB에서 수백 MB이고, 부팅은 1초 이내다. 하지만 사용법이 복잡하고, 리눅스에서만 작동했다.\n3) 도커 혁명 (2013-현재)\n도커는 컨테이너를 누구나 쉽게 사용할 수 있게 만들었다. 간단한 명령어, 이미지 공유 플랫폼(Docker Hub), 크로스 플랫폼 지원(윈도우/맥OS/리눅스)으로 컨테이너 기술을 대중화했다. 2013년 Solomon Hykes가 PyCon에서 5분 데모를 선보인 후, 몇 년 만에 업계 표준이 되었다.\n그림 34.1 은 가상화 기술의 50년 진화를 보여준다. 가상 머신(VM)은 완전한 OS를 포함해 무겁지만(20GB+, 4GB RAM) 완벽한 격리를 제공한다. 컨테이너는 OS 커널을 공유해 가볍지만(수십 MB, 실사용 메모리만) 리눅스에서만 작동했다. 도커는 컨테이너의 가벼움을 유지하면서도, Windows/macOS에서도 사용할 수 있게 만들었다. Docker Hub로 이미지를 공유하고, 간단한 명령어로 누구나 컨테이너를 사용하게 되었다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-history",
    "href": "docker_concept.html#sec-docker-history",
    "title": "34  도커: 재현 환경",
    "section": "",
    "text": "그림 34.1: 가상화 기술 진화 - VM → 컨테이너 → 도커\n\n\n\n\n\n\n\n\n\n노트도커 vs 쿠버네티스: 데이터 과학자 선택\n\n\n\n그림 34.1 에서 보았듯이 도커(2013) 이후 쿠버네티스(2015)가 등장했다. 쿠버네티스가 더 최신 기술인데, 왜 데이터 과학은 도커에 초점을 맞추는가?\n해결하는 문제가 다르다. 도커는 “환경을 패키징”하는 도구다. 쿠버네티스는 “수백 개 컨테이너를 자동으로 운영”하는 도구다. 넷플릭스가 수천 대 서버에서 마이크로서비스를 운영하거나, 구글이 트래픽 급증 시 자동으로 서버를 늘리는 상황에 필요하다.\n\n\n\n\n\n\n\n\n구분\n도커\n쿠버네티스\n\n\n\n주 사용자\n개발자, 데이터 과학자\nDevOps, 인프라 엔지니어\n\n\n학습 곡선\n몇 시간~며칠\n몇 주~몇 달\n\n\n시작 명령\ndocker run\n클러스터 설정부터\n\n\n운영 규모\n1~10개 컨테이너\n수십~수천 개 컨테이너\n\n\n\n\n\n\n\n표 34.1: 도커와 쿠버네티스 비교\n\n\n\n데이터 과학자 대부분은 개인 또는 소규모 팀으로 작업한다. 탐색적 분석을 빠르게 실행하고 중지하며, 자동 스케일링보다는 “동일 환경 재현”이 핵심 목표다. 노트북에서 docker run 한 줄이면 작업을 시작할 수 있다. 반면 쿠버네티스는 Shiny 앱 동시 접속자가 수천 명에 달하거나, ML API가 초당 수만 건 요청을 처리해야 하거나, 24시간 무중단 서비스가 필요한 상황에 적합하다. 대부분의 데이터 과학자에게 쿠버네티스는 “알면 좋지만 당장 필요하지 않은” 기술이다. 도커만으로 재현가능성, 이식성, 공유성 문제를 충분히 해결할 수 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-concepts",
    "href": "docker_concept.html#sec-docker-concepts",
    "title": "34  도커: 재현 환경",
    "section": "\n34.2 이미지와 컨테이너",
    "text": "34.2 이미지와 컨테이너\n도커를 처음 접하면 “이미지”와 “컨테이너”라는 용어가 혼란스럽다. 둘 다 “가상 환경”처럼 들리지만, 역할이 완전히 다르다. 이미지(Image)는 컴퓨팅 환경 “설계도”다. 프로그래밍 클래스(Class)처럼 “무엇을 포함할지” 정의한 템플릿이다. 컨테이너(Container)는 설계도로 만든 “실제 작동하는 컴퓨팅 환경”이다. 클래스에서 new로 인스턴스를 생성하듯, 이미지에서 docker run으로 컨테이너를 생성한다. 하나의 이미지에서 여러 컨테이너를 만들 수 있고, 각 컨테이너는 독립적으로 실행/중지/삭제할 수 있다.\n\n\n\n\n\n그림 34.2: 도커 이미지와 컨테이너 관계\n\n\n그림 34.2 는 이미지와 컨테이너의 관계를 보여준다. 왼쪽의 rocker/rstudio:4.3.0 이미지 하나에서 오른쪽의 여러 컨테이너가 생성된다. 각 컨테이너는 독립적으로 실행되며, 서로 다른 포트(8787, 8788, 8789)에서 접속할 수 있다. 프로그래밍의 Class와 Instance 관계와 동일하다.\n도커 이미지는 가상 컴퓨터의 “설계도”다. Ubuntu 20.04, R 4.3.0, tidyverse 패키지, 데이터 파일이 포함된 완전한 환경 스냅샷이다. 이미지는 읽기 전용(read-only)이며, 파일로 저장되고 공유된다. Docker Hub에서 전 세계 개발자가 만든 이미지를 다운로드하거나, 자신의 이미지를 업로드해 공유한다.\n도커 컨테이너는 이미지를 “실행한 것”이다. 이미지가 “프로그램 파일”이라면, 컨테이너는 “실행 중인 프로세스”다. 하나의 이미지에서 여러 컨테이너를 동시에 실행할 수 있다. 예를 들어, rocker/rstudio 이미지 하나로 3개의 RStudio 컨테이너를 각각 다른 포트에서 실행할 수 있다.\n\n\n\n\n\n\n힌트데이터 과학 도커 핵심 가치\n\n\n\n1. 재현성: 논문, 보고서, 분석 결과를 도커 이미지와 함께 제공하면, 누구나 정확히 동일한 환경에서 결과를 재현할 수 있다. 5년 후에도, 다른 컴퓨터에서도 같은 결과가 나온다.\n2. 이식성: 로컬 컴퓨터에서 개발한 환경을 GPU 서버로, AWS/GCP 클라우드로, 동료 컴퓨터로 그대로 이동한다. “로컬에서는 되는데 서버에서는 안 돼요” 문제가 사라진다.\n3. 공유성: 팀원에게 코드와 README만 주면 환경 설정에 반나절이 걸린다. 도커 이미지를 주면 docker run 명령 하나로 5분 안에 작업을 시작한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-how",
    "href": "docker_concept.html#sec-docker-how",
    "title": "34  도커: 재현 환경",
    "section": "\n34.3 도커의 작동 원리",
    "text": "34.3 도커의 작동 원리\n도커가 “컴퓨터 안의 컴퓨터”를 만드는 방식은 가상 머신(VM)과 근본적으로 다르다. VM은 하드웨어를 가상화해 완전한 운영체제를 실행하지만, 도커 컨테이너는 호스트의 리눅스 커널을 공유하면서 네임스페이스로 프로세스를 격리하고 cgroups로 자원을 제한한다. 커널을 공유하기 때문에 VM처럼 수십 GB의 디스크와 수 GB의 메모리가 필요하지 않다. 컨테이너는 수십 MB에서 수백 MB로 가볍고, 부팅 시간도 1초 이내다.\n\n\n\n\n\n그림 34.3: 도커 내부 구조\n\n\n그림 34.3 는 컨테이너가 호스트 커널 위에서 작동하는 방식을 보여준다. 컨테이너 A와 B는 각각 독립된 네임스페이스를 갖지만, 맨 아래 리눅스 커널은 공유한다. 이미지 레이어도 공유된다. 두 컨테이너가 같은 Ubuntu 베이스 이미지를 사용하면, 해당 레이어는 디스크에 한 번만 저장된다. cgroups는 각 컨테이너가 사용할 수 있는 CPU와 메모리를 제한해 한 컨테이너가 시스템 자원을 독점하지 못하게 한다.\n도커 이미지는 레이어(layer) 구조로 이루어진다. 마치 투명 필름을 겹치듯 Ubuntu 레이어 위에 R 설치 레이어가 올라가고, 그 위에 tidyverse 레이어가 쌓인다. 각 레이어는 읽기 전용이며, 컨테이너가 실행될 때 맨 위에 쓰기 가능한 얇은 레이어가 추가된다. 컨테이너 안에서 파일을 수정하면 쓰기 레이어에만 기록되고, 원본 이미지는 변경되지 않는다. 레이어 구조의 장점은 캐싱에 있다. Dockerfile에서 코드 파일만 수정했다면 OS와 패키지 레이어는 그대로 재사용되어 빌드 시간이 몇 분에서 몇 초로 단축된다. 여러 이미지가 같은 베이스 레이어를 공유하면 디스크 공간도 절약된다.\n네임스페이스(namespace)는 컨테이너가 마치 독립된 시스템처럼 보이게 하는 리눅스 커널 기능이다. PID 네임스페이스 덕분에 컨테이너 내부에서는 프로세스 ID가 1번부터 시작하고, 다른 컨테이너의 프로세스는 보이지 않는다. NET 네임스페이스는 각 컨테이너에 독립된 네트워크 인터페이스를 제공해 IP 주소와 포트가 충돌하지 않게 한다. MNT 네임스페이스는 파일시스템을 격리해 컨테이너가 호스트의 다른 파일에 접근하지 못하게 한다. cgroups(control groups)는 자원 할당을 제어한다. docker run --cpus=2 --memory=4g 명령으로 컨테이너가 최대 2개 CPU 코어와 4GB 메모리만 사용하도록 제한할 수 있다. 한 컨테이너에서 무한 루프가 돌거나 메모리 누수가 발생해도 다른 컨테이너와 호스트 시스템은 영향받지 않는다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-desktop",
    "href": "docker_concept.html#sec-docker-desktop",
    "title": "34  도커: 재현 환경",
    "section": "\n34.4 Docker Desktop",
    "text": "34.4 Docker Desktop\n도커 데스크톱(Docker Desktop)은 Windows와 macOS 사용자가 도커를 경험하는 첫 관문이다. 도커 컨테이너는 리눅스 커널의 네임스페이스와 cgroups 기술을 기반으로 작동하기 때문에, 리눅스가 아닌 운영체제에서는 직접 실행할 수 없다. Docker Desktop은 내부적으로 경량 리눅스 가상 머신을 실행하고 그 위에서 컨테이너를 구동함으로써 이 문제를 해결한다.\n\n\n\n\n\n그림 34.4: Docker Desktop 아키텍처\n\n\n그림 34.4 은 세 가지 운영체제에서 도커가 작동하는 방식을 보여준다. Windows에서는 WSL 2(Windows Subsystem for Linux 2)와 통합되어 네이티브에 가까운 성능을 제공하고, macOS에서는 Apple Silicon의 Virtualization.framework를 활용한다. 두 환경 모두 사용자가 내부 구조를 의식할 필요 없이 터미널에서 docker run 명령만 실행하면 된다. 리눅스에서는 VM 없이 Docker Engine만 설치해 커널과 직접 통신하므로 가장 효율적이다.\n\n\n\n\n\n그림 34.5: Docker Desktop GUI\n\n\n그림 34.5 는 Docker Desktop 앱의 실제 화면을 보여준다. 왼쪽 사이드바에서 Containers, Images, Volumes 메뉴를 선택하고, 중앙 영역에서 각 컨테이너의 실행 상태, 사용 중인 이미지, 포트 매핑을 한눈에 확인할 수 있다. 녹색 원은 실행 중인 컨테이너, 회색 원은 종료된 컨테이너를 나타낸다. 오른쪽 버튼으로 컨테이너를 시작하거나 중지할 수 있어, 명령어를 외우지 않아도 마우스 클릭만으로 컨테이너를 관리할 수 있다. Docker Compose, Kubernetes(선택) 등 도커 생태계의 핵심 도구도 함께 설치된다.\n# Docker Desktop 설치 후 터미널에서 확인\ndocker --version\n# Docker version 24.0.7, build afdd53b\n\n# 첫 번째 컨테이너 실행 테스트\ndocker run hello-world\n라이선스 정책은 사용 규모에 따라 달라진다. 개인 사용자, 교육 목적, 소규모 기업(직원 250명 미만, 연매출 1,000만 달러 미만)은 무료로 사용할 수 있고, 대기업 환경에서만 유료 구독이 필요하다. 리눅스 서버에서는 Docker Desktop 없이 Docker Engine만 설치하면 되므로 프로덕션 환경에서 라이선스 비용은 발생하지 않는다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-hub",
    "href": "docker_concept.html#sec-docker-hub",
    "title": "34  도커: 재현 환경",
    "section": "\n34.5 Docker Hub",
    "text": "34.5 Docker Hub\nGitHub이 소스 코드를 저장하고 공유하는 플랫폼이라면, 도커 허브(Docker Hub)는 도커 이미지를 저장하고 공유하는 플랫폼이다. 개발자가 GitHub에서 git clone으로 코드를 받듯, Docker Hub에서 docker pull로 이미지를 받는다. 프로젝트의 완전한 재현을 위해서는 코드(GitHub)와 실행 환경(Docker Hub) 둘 다 필요하다.\n\n\n\n\n\n그림 34.6: Docker Hub 구조\n\n\n그림 34.6 는 Docker Hub의 구조를 보여준다. 로컬에서 빌드한 이미지를 docker push로 업로드하면, 서버나 동료가 docker pull로 동일한 이미지를 다운로드한다. Docker Hub에는 rocker/rstudio, python, postgres 같은 공식 이미지와 사용자가 만든 커스텀 이미지가 함께 존재한다.\n버전 태그 시스템은 재현가능성의 핵심이다. rocker/rstudio:4.3.0처럼 특정 버전을 명시하면 5년 후에도 동일한 환경을 보장받는다. 반면 latest 태그는 최신 버전을 가리키므로 시간이 지나면 내용이 바뀔 수 있다. 재현성이 중요한 프로젝트에서는 반드시 특정 버전 태그를 사용해야 한다.\n# Docker Hub에서 이미지 다운로드\ndocker pull rocker/rstudio:4.3.0\n\n# 내 이미지를 Docker Hub에 업로드\ndocker push myname/myimage:1.0",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-rocker",
    "href": "docker_concept.html#sec-docker-rocker",
    "title": "34  도커: 재현 환경",
    "section": "\n34.6 Rocker 프로젝트",
    "text": "34.6 Rocker 프로젝트\nR 환경 설정은 악명 높다. 운영체제마다 다른 설치 방법, 시스템 라이브러리 의존성, 패키지 버전 충돌까지 초보자는 물론 숙련된 개발자도 시간을 허비한다. 특히 sf, terra 같은 지리공간 패키지나 rJava 같은 시스템 의존 패키지는 설치 자체가 하루 일과가 되기도 한다.\nRocker 프로젝트는 이 문제를 해결하기 위해 2014년 Carl Boettiger와 Dirk Eddelbuettel이 시작했다. R 커뮤니티를 위한 공식 도커 이미지를 제공하며, Docker Hub에서 가장 많이 다운로드되는 R 이미지 시리즈다. docker pull rocker/rstudio 한 줄이면 RStudio가 포함된 완전한 R 개발 환경이 준비된다. 시스템 라이브러리 설치, 의존성 해결, 버전 충돌 걱정 없이 바로 분석을 시작할 수 있다.\n\n\n\n\n\n그림 34.7: Rocker 프로젝트 이미지\n\n\n그림 34.7 는 Rocker 이미지 계층 구조를 보여준다. 가장 기본이 되는 rocker/r-ver는 Ubuntu LTS와 R만 포함한 최소 이미지로, R 스크립트 실행에 적합하다. 여기에 RStudio Server를 추가한 rocker/rstudio는 웹 브라우저에서 8787 포트로 접속하는 IDE 환경을 제공한다. 반면 rocker/shiny는 Shiny Server를 포함해 3838 포트에서 앱을 배포한다.\n데이터 분석 작업에는 rocker/tidyverse가 적합하다. tidyverse와 devtools가 사전 설치되어 패키지 설치 시간을 절약한다. 논문이나 보고서 출판이 필요하다면 rocker/verse를 선택한다. Quarto, LaTeX, 폰트가 모두 포함되어 PDF 출력까지 한 번에 해결한다. 머신러닝 작업에는 rocker/ml, 지리공간 분석에는 rocker/geospatial처럼 특화된 이미지도 제공된다.\n모든 Rocker 이미지는 R 버전별 태그를 지원한다. rocker/tidyverse:4.5.0은 R 4.5.0 환경을, rocker/tidyverse:4.3.0은 R 4.3.0 환경을 제공한다. 버전을 명시하지 않으면 latest 태그가 적용되어 최신 버전이 설치된다. 재현성이 중요한 프로젝트에서는 반드시 특정 버전 태그를 사용해야 한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-dockerfile",
    "href": "docker_concept.html#sec-dockerfile",
    "title": "34  도커: 재현 환경",
    "section": "\n34.7 Dockerfile",
    "text": "34.7 Dockerfile\nRocker 이미지는 훌륭한 출발점이지만, 실제 프로젝트에서는 추가 패키지나 설정이 필요하다. Dockerfile은 이미지를 만드는 “레시피”다. 어떤 베이스 이미지에서 시작할지, 어떤 패키지를 설치할지, 어떤 파일을 복사할지 순서대로 기술한다. 요리 레시피처럼 누구나 같은 Dockerfile로 동일한 이미지를 빌드할 수 있다.\n\n\n\n\n\n그림 34.8: Dockerfile 워크플로우\n\n\n그림 34.8 는 Dockerfile에서 커스텀 이미지가 만들어지는 과정을 보여준다. Dockerfile의 각 명령어가 하나의 레이어로 변환되고, 레이어들이 쌓여 최종 이미지가 완성된다. 레이어는 캐시되므로, 코드만 수정했다면 OS와 패키지 레이어는 재사용되어 빌드 시간이 단축된다.\nDockerfile의 핵심 명령어는 다섯 가지다. FROM은 베이스 이미지를 지정한다. RUN은 셸 명령어를 실행해 패키지를 설치하거나 설정을 변경한다. COPY는 로컬 파일을 이미지 안으로 복사한다. WORKDIR은 작업 디렉토리를 설정하고, CMD는 컨테이너 시작 시 실행할 기본 명령을 정의한다.\n# Dockerfile 예시: 데이터 분석 환경\nFROM rocker/rstudio:4.3.0\n\n# 시스템 라이브러리 설치 (sf, terra 패키지용)\nRUN apt-get update && apt-get install -y \\\n    libgdal-dev \\\n    libgeos-dev \\\n    libproj-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# R 패키지 설치\nRUN R -e \"install.packages(c('tidyverse', 'sf', 'terra', 'gt'), repos='https://cloud.r-project.org/')\"\n\n# 프로젝트 파일 복사\nCOPY . /home/rstudio/project\n\n# 작업 디렉토리 설정\nWORKDIR /home/rstudio/project\n\n# RStudio 포트 노출\nEXPOSE 8787\n이미지를 빌드하려면 Dockerfile이 있는 디렉토리에서 docker build 명령을 실행한다. -t 옵션으로 이미지 이름과 태그를 지정한다.\n# 이미지 빌드\ndocker build -t myproject:1.0 .\n\n# 빌드한 이미지 확인\ndocker images\n\n# 컨테이너 실행\ndocker run -d -p 8787:8787 -e PASSWORD=rstudio myproject:1.0\n\n# 브라우저에서 localhost:8787 접속\n포트 매핑(-p)은 컨테이너 내부 포트를 호스트에 노출한다. -p 8787:8787에서 콜론 왼쪽은 호스트 포트, 오른쪽은 컨테이너 포트다. RStudio Server가 컨테이너 내부에서 8787 포트로 실행되고, 이를 호스트의 8787 포트에 연결한다. 호스트 포트를 8888로 바꾸면(-p 8888:8787) 브라우저에서 localhost:8888로 접속한다. 환경 변수(-e)는 컨테이너 실행 시 설정값을 전달한다. Rocker 이미지에서 -e PASSWORD=rstudio는 RStudio 로그인 비밀번호를 지정한다. -e DISABLE_AUTH=true로 인증을 끄거나, -e ROOT=true로 sudo 권한을 부여하는 것도 가능하다.\nDockerfile을 Git으로 버전 관리하면 환경 설정 변경 이력이 남는다. 코드와 함께 Dockerfile을 공유하면 동료는 docker build 한 줄로 동일한 개발 환경을 구축한다. 6개월 후 논문 심사위원이 재현을 요청해도, Dockerfile과 코드만 있으면 정확히 같은 환경에서 분석을 실행할 수 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-volumes",
    "href": "docker_concept.html#sec-docker-volumes",
    "title": "34  도커: 재현 환경",
    "section": "\n34.8 데이터와 볼륨",
    "text": "34.8 데이터와 볼륨\n컨테이너는 격리된 환경이라는 장점이 있지만, 이 격리가 데이터 처리에서는 문제가 된다. 컨테이너 내부에서 생성한 파일은 컨테이너를 삭제하면 함께 사라진다. 밤새 돌린 분석 결과가 docker rm 한 줄로 증발하는 것이다. 데이터 과학자에게 이보다 끔찍한 시나리오는 없다.\n볼륨(Volume)과 바인드 마운트(Bind Mount)는 이 문제를 해결한다. 호스트 시스템의 폴더를 컨테이너 내부에 “연결”하면, 컨테이너에서 생성한 파일이 호스트에 직접 저장된다. 컨테이너가 삭제되어도 데이터는 호스트에 그대로 남는다. 반대로 호스트의 데이터 파일을 컨테이너에서 불러와 분석하는 것도 가능하다.\n\n\n\n\n\n그림 34.9: 도커 볼륨과 바인드 마운트\n\n\n그림 34.9 는 호스트와 컨테이너 간 데이터 흐름을 보여준다. -v 옵션으로 호스트 경로와 컨테이너 경로를 연결하면, 양쪽에서 동일한 파일에 접근할 수 있다. 바인드 마운트는 호스트의 특정 폴더를 직접 연결하고, 네임드 볼륨은 도커가 관리하는 저장소를 사용한다. 읽기 전용(:ro) 옵션은 원본 데이터를 실수로 덮어쓰는 것을 방지한다.\n# 바인드 마운트: 호스트 폴더를 컨테이너에 연결\ndocker run -d -p 8787:8787 \\\n  -v /Users/me/project:/home/rstudio/project \\\n  -e PASSWORD=rstudio \\\n  rocker/rstudio:4.3.0\n\n# 컨테이너 내부에서 /home/rstudio/project 접근 가능\n# 분석 결과를 이 경로에 저장하면 호스트에도 저장됨\n데이터 분석 워크플로우에서는 프로젝트 폴더 전체를 마운트하는 것이 일반적이다. data/ 폴더에 원본 데이터를 두고, scripts/ 폴더에 분석 코드를, output/ 폴더에 결과물을 저장한다. 컨테이너 안에서 RStudio로 작업하면 모든 변경사항이 호스트에 실시간으로 반영된다. Git으로 버전 관리도 가능하고, 컨테이너를 삭제했다가 다시 만들어도 데이터는 그대로다.\n# 실전 예시: 현재 디렉토리를 프로젝트 폴더로 마운트\ndocker run -d -p 8787:8787 \\\n  -v $(pwd):/home/rstudio/project \\\n  -e PASSWORD=rstudio \\\n  rocker/tidyverse:4.3.0\n\n# $(pwd): 현재 작업 디렉토리\n# 프로젝트 내 data/, scripts/, output/ 폴더 모두 접근 가능\n대용량 데이터를 다룰 때는 네임드 볼륨이 유용하다. docker volume create 명령으로 볼륨을 생성하면 도커가 최적화된 저장소를 관리한다. 여러 컨테이너가 같은 볼륨을 공유할 수도 있어, R 컨테이너에서 전처리한 데이터를 Python 컨테이너에서 분석하는 파이프라인도 구성할 수 있다.\n# 네임드 볼륨 생성\ndocker volume create analysis_data\n\n# R 컨테이너에서 데이터 전처리\ndocker run -v analysis_data:/data rocker/tidyverse:4.3.0 \\\n  Rscript -e \"saveRDS(mtcars, '/data/processed.rds')\"\n\n# Python 컨테이너에서 동일 데이터 접근\ndocker run -v analysis_data:/data python:3.11 \\\n  python -c \"import pyreadr; df = pyreadr.read_r('/data/processed.rds')\"\n볼륨을 사용할 때 한 가지 주의할 점은 파일 권한이다. 컨테이너 내부 사용자(보통 rstudio 또는 root)와 호스트 사용자의 UID가 다르면 권한 문제가 발생할 수 있다. Rocker 이미지는 이 문제를 대부분 자동 처리하지만, 권한 오류가 발생하면 --user 옵션으로 UID를 맞추거나 호스트에서 폴더 권한을 조정해야 한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "docker_concept.html#sec-docker-vs-alternatives",
    "href": "docker_concept.html#sec-docker-vs-alternatives",
    "title": "34  도커: 재현 환경",
    "section": "\n34.9 도커 vs 다른 격리 도구",
    "text": "34.9 도커 vs 다른 격리 도구\n환경 격리 도구는 크게 세 가지 계층으로 나뉜다. 가장 가벼운 것은 패키지 수준 격리다. Python의 uv나 R의 renv가 여기에 해당한다. 프로젝트별로 패키지 버전을 고정하고, requirements.txt나 renv.lock 파일로 의존성을 기록한다. 설정이 간단하고 빠르지만, 시스템 라이브러리나 OS에 의존하는 패키지는 여전히 문제가 된다. sf 패키지가 GDAL 버전에 따라 다르게 동작하거나, macOS와 Linux에서 결과가 달라지는 상황은 패키지 격리만으로 해결할 수 없다.\n한 단계 위가 런타임 수준 격리다. pyenv나 rig 같은 도구로 Python이나 R 버전 자체를 프로젝트별로 전환한다. 패키지뿐 아니라 언어 런타임까지 격리되므로 R 4.2와 R 4.3을 오가며 작업할 수 있다. 하지만 여전히 시스템 라이브러리에는 손을 대지 못한다. Ubuntu에서 만든 코드가 macOS에서 실패하는 문제는 그대로다.\nOS 수준 격리가 도커의 영역이다. 운영체제, 시스템 라이브러리, 런타임, 패키지를 모두 포함한 완전한 환경을 패키징한다. Ubuntu 20.04 + GDAL 3.4 + R 4.3.0 + sf 1.0 조합을 그대로 보존하고 어디서든 재현한다. 초기 학습 곡선이 있지만, 한 번 익히면 환경 문제로 고생할 일이 사라진다.\n어떤 도구를 선택할지는 상황에 따라 다르다. 순수 R/Python 패키지만 사용하는 로컬 분석이라면 renv나 uv로 충분하다. 하지만 GDAL, PostgreSQL, OpenCV 같은 시스템 라이브러리에 의존하거나, R과 Python을 함께 사용하거나, Shiny 앱이나 API를 프로덕션에 배포하거나, 5년 후에도 재현을 보장해야 한다면 도커가 답이다. 일반적인 경로는 renv/uv로 시작해 시스템 의존성이나 배포 요구가 생기면 도커로 전환하는 것이다.\n💡 생각해볼 점\n도커가 필요한 순간은 명확하다. 팀원이 “환경 설정이 안 돼요”라고 할 때, Shiny 앱을 서버에 배포할 때, 1년 전 분석을 재현해야 할 때, OpenCV나 GDAL 같은 시스템 라이브러리가 필요할 때, 논문 제출 시 재현성을 증명해야 할 때다. 이런 상황이 오면 도커를 시작하자.\n이미지와 컨테이너 구분은 도커 이해의 핵심이다. 이미지는 설계도(Class)이고, 컨테이너는 실행 인스턴스(Object)다. docker pull로 이미지를 받고, docker run으로 컨테이너를 실행한다. 하나의 이미지에서 여러 컨테이너를 만들 수 있고, 컨테이너를 삭제해도 이미지는 남는다. Rocker 이미지(rocker/rstudio, rocker/tidyverse, rocker/verse)는 R 사용자의 출발점이다. 버전 태그(:4.3.0)를 명시하면 5년 후에도 동일한 환경을 보장받는다.\n볼륨(-v)은 데이터 영속성의 열쇠다. 컨테이너는 삭제되면 내부 데이터도 사라지지만, 호스트 폴더를 마운트하면 분석 결과가 호스트에 남는다. 밤새 돌린 분석이 docker rm 한 줄로 증발하는 비극을 막으려면 반드시 볼륨을 사용해야 한다.\n도커 학습 곡선은 가파르다. 하지만 한 번 익히면 환경 문제로 고생하는 시간이 사라진다. “내 컴퓨터에서는 되는데”라는 말을 더 이상 하지 않게 된다. 다음 장에서는 이론을 넘어 실전으로 들어간다. Docker Desktop 설치, rocker/rstudio 실행, Dockerfile 작성, 이미지 빌드까지 전 과정을 직접 수행한다. 첫 번째 컨테이너를 만들고, 웹브라우저에서 localhost:8787을 열어 RStudio가 뜨는 것을 확인하면, 도커의 가치를 체감하게 된다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>도커: 재현 환경</span>"
    ]
  },
  {
    "objectID": "make_concept.html",
    "href": "make_concept.html",
    "title": "35  Make: 자동화",
    "section": "",
    "text": "35.1 셸 스크립트의 한계\n연구팀 김 박사는 논문 마감을 앞두고 있었다. 지도교수가 “그래프 폰트를 12pt에서 14pt로 바꿔주세요”라고 요청했다. 단순한 수정이었다. 시각화 스크립트를 고치고, 그래프 5개를 다시 생성하고, 결과 테이블을 업데이트하고, 최종 PDF를 렌더링해야 했다. 김 박사는 터미널에 명령어를 하나씩 입력했다.\n30분 후, 지도교수가 다시 메일을 보냈다. “아, 그리고 색상도 컬러에서 흑백으로 바꿔주세요.” 김 박사는 같은 명령어를 다시 입력했다. 이번에는 plot_figure3.py를 빼먹었다. 최종 PDF에 컬러 그래프가 섞여 있었다. 심사위원 지적으로 논문이 반려되었다.\n이것이 수동 워크플로우의 함정이다. 데이터 분석 파이프라인은 여러 단계로 구성된다. 원시 데이터를 처리하고, 통계를 계산하고, 그래프를 그리고, 보고서를 생성한다. 각 단계는 이전 단계의 출력에 의존한다. 수동으로 관리하면 실수가 생기고, 어떤 파일을 다시 만들어야 하는지 기억해야 하며, 전체 파이프라인을 처음부터 다시 실행하느라 시간을 낭비한다.\nMake는 이 문제를 1977년부터 해결해왔다. 파일 간 의존성을 명시적으로 기록하고, 변경된 파일만 자동으로 다시 빌드한다. 시각화 스크립트를 수정하면 그래프만 다시 생성하고, 원시 데이터가 바뀌면 전체 파이프라인이 자동으로 재실행된다. 50년이 지난 지금도 Make는 재현가능한 연구의 핵심 도구다.\n가장 먼저 떠오르는 해결책은 셸 스크립트다. 모든 명령어를 파일에 저장하고 bash run_pipeline.sh 한 줄로 실행한다. 파이프라인을 문서화하고, 타이핑 실수를 방지하며, 재현성을 높인다.\n하지만 셸 스크립트에는 치명적인 한계가 있다. 항상 처음부터 끝까지 전부 실행된다. 시각화 스크립트만 수정했는데 전처리부터 다시 돌려야 한다. 대용량 데이터 처리에 1시간이 걸린다면? 그래프 색상 하나 바꾸는 데 1시간을 기다려야 한다.\n주석 처리로 해결할 수 있다고 생각할 수 있다.\n이 방법은 오류의 온상이다. 어떤 줄을 주석 처리했는지 기억해야 하고, 원시 데이터가 바뀌면 주석을 다시 풀어야 한다. 복잡한 파이프라인에서 의존성을 머릿속으로 추적하다 보면 결국 실수가 생긴다. 김 박사처럼 중간 단계를 빼먹거나, 불필요한 단계를 다시 실행하거나, 잘못된 순서로 실행하게 된다.\nMake는 이 문제를 우아하게 해결한다. 파일 간 의존성(dependency)을 명시적으로 선언하고, 타임스탬프를 비교해 변경된 파일만 다시 빌드한다. “무엇이 무엇에 의존하는가”를 코드로 기록하면, Make가 “무엇을 다시 만들어야 하는가”를 자동으로 판단한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-shell-limits",
    "href": "make_concept.html#sec-make-shell-limits",
    "title": "35  Make: 자동화",
    "section": "",
    "text": "#!/bin/bash\n# run_pipeline.sh - 분석 파이프라인\n\npython preprocess.py data/raw.csv data/clean.csv\npython analyze.py data/clean.csv results/stats.csv\npython visualize.py results/stats.csv figures/plot.png\nquarto render report.qmd\n\n\n#!/bin/bash\n# 이미 실행했으므로 주석 처리\n# python preprocess.py data/raw.csv data/clean.csv\n# python analyze.py data/clean.csv results/stats.csv\n\npython visualize.py results/stats.csv figures/plot.png\nquarto render report.qmd",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-structure",
    "href": "make_concept.html#sec-make-structure",
    "title": "35  Make: 자동화",
    "section": "35.2 Makefile 기본 구조",
    "text": "35.2 Makefile 기본 구조\nMake는 Makefile이라는 파일에서 명령을 읽는다. Makefile은 규칙(rule)들로 구성된다. 각 규칙은 타겟, 의존성, 액션 세 부분으로 이루어진다.\n# 기본 규칙 구조\n타겟: 의존성1 의존성2\n    액션 (TAB으로 들여쓰기)\n\n\n\n\n\n\n그림 35.1: Makefile 규칙 구조\n\n\n\n그림 35.1 은 Makefile 규칙의 세 구성 요소를 보여준다. 타겟(target)은 만들어질 파일이다. 의존성(dependency)은 타겟을 만드는 데 필요한 파일들이다. 액션(action)은 의존성에서 타겟을 만드는 명령어다. 액션은 반드시 TAB 문자로 들여써야 한다. 스페이스 8개가 아니라 TAB 키 한 번이다. 1977년의 유산이지만, 지금도 지켜야 하는 규칙이다.\n실제 예시를 보자. 텍스트 파일에서 단어 빈도를 계산하는 파이프라인이다.\n# 단어 빈도 계산\nresults.dat : books/novel.txt\n    python countwords.py books/novel.txt results.dat\n이 규칙의 의미는 명확하다. results.dat 파일을 만들려면 books/novel.txt 파일이 필요하고, python countwords.py 명령으로 생성한다. Make를 실행하면 다음과 같이 동작한다.\n$ make results.dat\npython countwords.py books/novel.txt results.dat\n이제 같은 명령을 다시 실행해보자.\n$ make results.dat\nmake: 'results.dat' is up to date.\nMake는 results.dat와 books/novel.txt의 타임스탬프를 비교한다. 타겟이 의존성보다 최신이면 아무것도 하지 않는다. 이것이 증분 빌드(incremental build)다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-timestamp",
    "href": "make_concept.html#sec-make-timestamp",
    "title": "35  Make: 자동화",
    "section": "35.3 타임스탬프 기반 빌드",
    "text": "35.3 타임스탬프 기반 빌드\nMake의 핵심 원리는 단순하다. 타겟 파일이 존재하지 않거나, 의존성 파일 중 하나라도 타겟보다 최신이면 액션을 실행한다. 파일의 “최신 여부”는 파일시스템 타임스탬프로 판단한다.\n\n\n\n\n\n\n그림 35.2: Make 타임스탬프 비교\n\n\n\n그림 35.2 는 Make가 빌드 여부를 결정하는 과정을 보여준다. 왼쪽은 타겟이 의존성보다 최신인 경우로, Make는 “이미 최신”이라고 판단하고 액션을 건너뛴다. 오른쪽은 의존성이 타겟보다 최신인 경우로, 타겟을 다시 빌드한다.\ntouch 명령으로 파일 타임스탬프를 갱신해 이 동작을 확인할 수 있다.\n# 의존성 파일의 타임스탬프 갱신 (내용은 그대로)\n$ touch books/novel.txt\n\n# 이제 Make가 다시 빌드\n$ make results.dat\npython countwords.py books/novel.txt results.dat\n파일 내용이 바뀌지 않았더라도 타임스탬프가 갱신되면 Make는 다시 빌드한다. Make는 파일 내용을 비교하지 않고 오직 타임스탬프만 본다. 이 방식은 단순하지만 효과적이다. Git처럼 내용 해시를 계산하는 빌드 도구도 있지만, 대부분의 경우 타임스탬프 비교로 충분하다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-chain",
    "href": "make_concept.html#sec-make-chain",
    "title": "35  Make: 자동화",
    "section": "35.4 의존성 체인",
    "text": "35.4 의존성 체인\n실제 데이터 분석 파이프라인은 여러 단계로 구성된다. 원시 데이터에서 정제 데이터를 만들고, 정제 데이터에서 통계를 계산하고, 통계에서 그래프를 그린다. 각 단계의 출력이 다음 단계의 입력이 된다.\n# 다단계 파이프라인\nclean.csv : raw.csv preprocess.py\n    python preprocess.py raw.csv clean.csv\n\nstats.csv : clean.csv analyze.py\n    python analyze.py clean.csv stats.csv\n\nfigure.png : stats.csv visualize.py\n    python visualize.py stats.csv figure.png\n\n\n\n\n\n\n그림 35.3: Make 의존성 체인\n\n\n\n그림 35.3 은 파일 간 의존성이 체인을 형성하는 모습을 보여준다. figure.png를 만들려면 stats.csv가 필요하고, stats.csv를 만들려면 clean.csv가 필요하다. Make는 이 의존성 그래프를 분석해 필요한 파일만 순서대로 빌드한다.\nMake의 강력함은 의존성의 전이성(transitivity)에 있다. raw.csv를 수정하면 어떻게 될까?\n$ touch raw.csv\n$ make figure.png\npython preprocess.py raw.csv clean.csv\npython analyze.py clean.csv stats.csv\npython visualize.py stats.csv figure.png\nMake는 raw.csv → clean.csv → stats.csv → figure.png 순으로 전체 체인을 자동 재빌드한다. 반면 visualize.py만 수정하면?\n$ touch visualize.py\n$ make figure.png\npython visualize.py stats.csv figure.png\nclean.csv와 stats.csv는 건드리지 않고 figure.png만 다시 생성한다. 데이터 처리에 1시간이 걸려도 시각화 스크립트 수정은 몇 초면 반영된다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-auto-vars",
    "href": "make_concept.html#sec-make-auto-vars",
    "title": "35  Make: 자동화",
    "section": "35.5 자동 변수",
    "text": "35.5 자동 변수\nMakefile에 중복이 많으면 유지보수가 어렵다. 파일명을 바꿀 때마다 여러 곳을 수정해야 한다. Make는 자동 변수(automatic variable)로 이 문제를 해결한다.\n# 중복이 많은 버전\nresults.dat : books/novel.txt\n    python countwords.py books/novel.txt results.dat\n\n# 자동 변수 사용\nresults.dat : books/novel.txt\n    python countwords.py $&lt; $@\n세 가지 자동 변수를 기억하자.\n\n$@: 현재 규칙의 타겟\n$&lt;: 첫 번째 의존성\n$^: 모든 의존성\n\n# 여러 의존성이 있는 경우\nreport.pdf : chapter1.md chapter2.md chapter3.md style.css\n    pandoc $^ -o $@\n# $^ = chapter1.md chapter2.md chapter3.md style.css\n# $@ = report.pdf\n자동 변수는 패턴 규칙(pattern rule)과 함께 사용할 때 진가를 발휘한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-patterns",
    "href": "make_concept.html#sec-make-patterns",
    "title": "35  Make: 자동화",
    "section": "35.6 패턴 규칙",
    "text": "35.6 패턴 규칙\n여러 파일에 같은 처리를 적용해야 할 때, 규칙을 일일이 작성하면 지루하다.\n# 반복적인 규칙\nisles.dat : books/isles.txt countwords.py\n    python countwords.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt countwords.py\n    python countwords.py books/abyss.txt abyss.dat\n\nlast.dat : books/last.txt countwords.py\n    python countwords.py books/last.txt last.dat\n패턴 규칙은 % 와일드카드로 이 중복을 제거한다.\n# 패턴 규칙\n%.dat : books/%.txt countwords.py\n    python countwords.py $&lt; $@\n%는 어떤 문자열과도 매칭된다. isles.dat을 만들 때 %는 isles와 매칭되고, 의존성에서도 같은 값으로 치환된다. 하나의 규칙으로 isles.dat, abyss.dat, last.dat 등 모든 .dat 파일을 생성할 수 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-variables",
    "href": "make_concept.html#sec-make-variables",
    "title": "35  Make: 자동화",
    "section": "35.7 변수와 설정 분리",
    "text": "35.7 변수와 설정 분리\n스크립트 이름이나 실행 옵션이 Makefile 곳곳에 흩어져 있으면 변경이 어렵다. 변수를 사용해 설정을 한 곳에 모은다.\n# 변수 정의\nPYTHON = python3\nCOUNT_SCRIPT = countwords.py\nANALYZE_SCRIPT = testzipf.py\n\n# 변수 사용 - $(변수명)\n%.dat : books/%.txt $(COUNT_SCRIPT)\n    $(PYTHON) $&lt; $@\n\nresults.txt : isles.dat abyss.dat $(ANALYZE_SCRIPT)\n    $(PYTHON) $(ANALYZE_SCRIPT) $^ &gt; $@\n설정을 별도 파일로 분리하면 더 깔끔하다.\n# config.mk\nPYTHON = python3\nCOUNT_SCRIPT = countwords.py\nDATA_DIR = data\nOUTPUT_DIR = results\n# Makefile\ninclude config.mk\n\n%.dat : $(DATA_DIR)/%.txt $(COUNT_SCRIPT)\n    $(PYTHON) $(COUNT_SCRIPT) $&lt; $@\n환경에 따라 config.mk만 바꾸면 된다. 로컬에서는 PYTHON = python3, 서버에서는 PYTHON = /opt/python/3.11/bin/python처럼 설정할 수 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-phony",
    "href": "make_concept.html#sec-make-phony",
    "title": "35  Make: 자동화",
    "section": "35.8 Phony 타겟",
    "text": "35.8 Phony 타겟\n지금까지 타겟은 모두 실제 파일이었다. 하지만 “모든 출력 삭제”나 “전체 빌드” 같은 작업도 Make로 자동화하고 싶다. 이때 사용하는 것이 phony 타겟이다.\n# 실제 파일을 만들지 않는 타겟\n.PHONY : clean all\n\nclean :\n    rm -f *.dat results.txt\n\nall : isles.dat abyss.dat last.dat results.txt\n.PHONY로 선언된 타겟은 파일이 아니라 “명령의 이름”이다. make clean을 실행하면 clean이라는 파일이 있든 없든 항상 액션을 실행한다. .PHONY를 선언하지 않으면, clean이라는 파일이나 디렉토리가 있을 때 Make가 “이미 최신”이라고 판단해 아무것도 하지 않는다.\n관례적으로 사용되는 phony 타겟들이 있다.\n\nall: 기본 타겟, Makefile의 첫 번째 규칙으로 배치\nclean: 생성된 파일 삭제\ninstall: 빌드 결과물 설치\ntest: 테스트 실행\n\n.PHONY : all clean test\n\n# 'make'만 실행하면 all이 기본 타겟\nall : results.txt figures/plot.png\n\nclean :\n    rm -f *.dat results.txt\n    rm -f figures/*.png\n\ntest :\n    python -m pytest tests/",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-workflow",
    "href": "make_concept.html#sec-make-workflow",
    "title": "35  Make: 자동화",
    "section": "35.9 데이터 과학 워크플로우 예시",
    "text": "35.9 데이터 과학 워크플로우 예시\n지금까지 배운 개념을 종합해 실제 데이터 분석 파이프라인을 구성해보자. Zipf의 법칙을 검증하는 프로젝트다. 여러 책의 단어 빈도를 계산하고, 결과를 시각화하고, 최종 보고서를 생성한다.\n# config.mk\nPYTHON = python\nBOOKS = isles abyss last sierra\n\n# 스크립트\nCOUNT_SCRIPT = countwords.py\nPLOT_SCRIPT = plotcounts.py\nZIPF_SCRIPT = testzipf.py\n# Makefile\ninclude config.mk\n\n# 파일 목록 자동 생성\nDAT_FILES = $(patsubst %, %.dat, $(BOOKS))\nPNG_FILES = $(patsubst %, figures/%.png, $(BOOKS))\n\n.PHONY : all clean\n\n# 기본 타겟\nall : results.txt $(PNG_FILES)\n\n# 패턴 규칙: 단어 빈도 계산\n%.dat : books/%.txt $(COUNT_SCRIPT)\n    $(PYTHON) $(COUNT_SCRIPT) $&lt; $@\n\n# 패턴 규칙: 그래프 생성\nfigures/%.png : %.dat $(PLOT_SCRIPT)\n    $(PYTHON) $(PLOT_SCRIPT) $&lt; $@\n\n# 결과 테이블 생성\nresults.txt : $(ZIPF_SCRIPT) $(DAT_FILES)\n    $(PYTHON) $^ &gt; $@\n\n# 정리\nclean :\n    rm -f *.dat results.txt\n    rm -f figures/*.png\n\n\n\n\n\n\n그림 35.4: 데이터 과학 Make 워크플로우\n\n\n\n그림 35.4 는 완성된 파이프라인의 의존성 그래프다. 원시 텍스트에서 최종 결과물까지의 모든 단계가 명시적으로 기록되어 있다. 새로운 책을 추가하려면 config.mk의 BOOKS 변수에 이름만 추가하면 된다. make all 한 줄로 전체 분석이 재현된다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "make_concept.html#sec-make-alternatives",
    "href": "make_concept.html#sec-make-alternatives",
    "title": "35  Make: 자동화",
    "section": "35.10 Make vs 현대 도구들",
    "text": "35.10 Make vs 현대 도구들\nMake는 1977년에 만들어졌다. 거의 50년이 지난 지금, 왜 아직도 Make를 사용하는가? 더 현대적인 도구들이 있지 않은가?\nSnakemake는 Python 기반 워크플로우 도구로, Python 문법으로 규칙을 작성한다. 클러스터 제출, 클라우드 실행, 컨테이너 통합을 지원한다. 바이오인포매틱스 분야에서 특히 인기 있다. targets는 R 전용 워크플로우 도구로, R 객체 수준에서 의존성을 추적한다. R 사용자에게 가장 자연스러운 선택이다. DVC는 Git처럼 데이터와 모델 버전을 관리하면서 파이프라인도 정의할 수 있다. 머신러닝 프로젝트에 적합하다.\nMake를 선택해야 하는 상황이 있다. 언어에 구애받지 않는 파이프라인이 필요할 때다. Python과 R과 셸 스크립트가 섞인 프로젝트에서 Make는 중립적인 조율자 역할을 한다. 레거시 시스템과 통합해야 할 때도 Make가 유리하다. C/Fortran으로 작성된 고성능 컴퓨팅 코드는 대부분 Make로 빌드한다. 단순함이 필요할 때 Make의 가치가 드러난다. 의존성 파일 몇 개에 규칙 몇 줄이면 충분한데 Snakemake나 DVC를 도입하는 것은 과잉이다.\n\n\n\n\n\n\n노트데이터 과학 워크플로우 도구 선택\n\n\n\n\n\n\n상황\n권장 도구\n\n\n\n\n간단한 파이프라인, 다국어 혼용\nMake\n\n\nR 중심 분석, 함수 수준 캐싱\ntargets (R)\n\n\nPython 중심, 클러스터/클라우드\nSnakemake\n\n\nML 모델 버전 관리 필요\nDVC\n\n\n복잡한 DAG, 재시도/에러 처리\nAirflow, Prefect\n\n\n\nMake는 “가장 작은 도구로 문제를 해결”하는 유닉스 철학을 따른다. 복잡한 요구사항이 없다면 Make로 시작하고, 필요할 때 전환해도 늦지 않다.\n\n\n💡 생각해볼 점\nMake의 핵심은 의존성의 명시적 선언이다. 어떤 파일이 어떤 파일에서 만들어지는지 Makefile에 기록하면, Make가 변경 사항을 추적하고 필요한 부분만 다시 빌드한다. 셸 스크립트처럼 “무엇을 실행하는가”만 기록하는 것이 아니라, “무엇이 무엇에 의존하는가”를 기록한다. 이 작은 차이가 재현성과 효율성의 큰 차이를 만든다.\n규칙의 구조는 단순하다. 타겟: 의존성 다음 줄에 TAB으로 들여쓴 액션. 자동 변수($@, $&lt;, $^)로 중복을 줄이고, 패턴 규칙(%)으로 여러 파일에 같은 처리를 적용한다. 변수로 설정을 분리하고, phony 타겟으로 clean이나 all 같은 유틸리티 명령을 정의한다.\nMake는 50년 가까이 살아남았다. C 컴파일러부터 데이터 분석 파이프라인까지, 의존성 기반 워크플로우가 필요한 곳에서 여전히 유효하다. 학습 곡선이 가파르지 않고, 대부분의 유닉스 시스템에 기본 설치되어 있으며, 언어와 도구에 중립적이다. 더 현대적인 대안이 있더라도, Make는 “충분히 좋은” 선택이다. 다음 장에서는 Make를 직접 실습하며, 실제 데이터 분석 프로젝트에 적용하는 방법을 다룬다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Make: 자동화</span>"
    ]
  },
  {
    "objectID": "compendium.html",
    "href": "compendium.html",
    "title": "36  연구 컴펜디엄",
    "section": "",
    "text": "36.1 재현성 4가지 개념\n2024년 한 연구팀의 사례다. Nature 자매지에 게재 승인을 받은 논문에 대해 심사위원이 “코드와 데이터를 공개해주세요”라고 요청했다. 연구자는 당황했다. 코드는 GitHub에 있지만, 10개 스크립트가 어떤 순서로 실행되는지 본인도 기억나지 않았다. 데이터 파일 20개 중 어떤 것이 원본이고 어떤 것이 중간 결과물인지 구분이 안 됐다. 패키지 버전은 기록해두지 않았다. 결국 논문 게재가 3개월 지연되었고, 연구자는 자신의 코드를 다시 이해하는 데 2주를 소비했다.\n2016년 Nature 설문조사에서 연구자 70% 이상이 “다른 연구자의 실험을 재현하는 데 실패한 적이 있다”고 답했고, 50% 이상이 “자신의 실험조차 재현하지 못한 적이 있다”고 고백했다 [1]. 재현성 위기(reproducibility crisis)는 과학 전반에 걸친 구조적 문제다.\n재현성 위기의 배경에는 의심스러운 연구 관행(questionable research practices)이 있다 [2]. 2012년 설문조사에 따르면 심리학자의 50% 이상이 이러한 관행을 경험했다고 보고했다. 대표적인 예로 p-해킹(p-hacking)은 통계적으로 유의미한 결과(p &lt; 0.05)가 나올 때까지 데이터를 조작하는 행위이고 [3], HARKing(Hypothesizing After the Results are Known)은 결과를 보고 나서 가설을 사후에 설정하는 것이다 [4]. 선별 취사(cherry-picking)는 자신에게 유리한 데이터만 선택적으로 보고하는 관행이다. 투명한 연구 컴펜디엄은 이러한 관행을 어렵게 만들어 과학의 신뢰성을 높인다.\n연구 컴펜디엄(Research Compendium)1은 재현성 문제에 대한 체계적인 해결책 중 하나로 제시되었다 [5]. 핵심 목표는 “연구의 모든 디지털 구성요소—데이터, 코드, 텍스트—를 하나의 컨테이너에 담아 결과 재현을 간단하게 만드는 것”이다.\n재현성 연구의 역사는 1990년대 초로 거슬러 올라간다. 스탠퍼드 대학 지구물리학 연구실에서 처음 도입되었고 [6], 2004년 R 기반 연구 컴펜디엄의 이론적 토대가 마련되었다 [7]. 2018년에는 이러한 아이디어가 실용적인 R 패키지 기반 워크플로우로 구체화되었다 [5].\n미국 국립과학재단(NSF) 사회과학분야 자문위원회는 2015년 보고서 [8]에서 과학 연구의 핵심 개념을 명확히 정의했다. 재현성(reproducibility), 복제성(replicability), 강건성(robustness), 일반화(generalizability)는 서로 다른 차원의 검증을 의미한다.\n그림 36.1 는 데이터와 분석 방법의 조합에 따른 4가지 검증 수준을 보여준다. 재현성은 동일한 데이터에 동일한 분석을 수행하여 같은 결과를 얻는 것으로, NSF 보고서가 명시한 과학적 발견의 최소한의 필요 조건이다. 복제성은 다른 데이터에 동일한 분석을 적용하여 유사한 결과를 얻는지 검증한다. 강건성은 동일한 데이터를 다른 분석 방법(예: R과 Python)으로 처리해도 같은 결론에 도달하는지 확인한다. 일반화는 복제성과 강건성을 결합한 가장 높은 수준의 검증으로, 다른 데이터와 다른 분석 방법을 사용해도 유사한 결론을 얻는지 평가한다.\n연구 컴펜디엄은 재현성 연구 핵심 개념 중 재현성을 보장하는 도구다. 재현성 없이는 복제성도, 강건성도, 일반화도 확인할 수 없다. 따라서 연구 컴펜디엄은 과학적 발견의 토대를 만드는 작업이다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-concepts",
    "href": "compendium.html#sec-compendium-concepts",
    "title": "36  연구 컴펜디엄",
    "section": "",
    "text": "그림 36.1: 재현성 연구 4가지 핵심 개념",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-what",
    "href": "compendium.html#sec-compendium-what",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.2 연구 컴펜디엄이란",
    "text": "36.2 연구 컴펜디엄이란\n연구 컴펜디엄은 논문과 함께 제공되는 분석 코드, 데이터, 그리고 필요한 계산 환경을 담은 단일 컨테이너다. 단순히 코드를 공개하는 수준을 넘어, 누구나 동일한 결과를 얻을 수 있도록 모든 구성요소를 체계적으로 조직화한다.\n마윅 등 [5]은 연구 컴펜디엄의 세 가지 핵심 원칙을 제시했다. 첫째, 관례적 폴더 구조다. 파일을 표준화된 디렉토리 구조로 조직하면 처음 보는 사람도 프로젝트 구성을 쉽게 파악할 수 있다. 둘째, 데이터·방법·결과 분리다. 원본 데이터, 분석 코드, 생성된 결과물을 명확히 구분하면 어떤 파일이 입력이고 어떤 파일이 산출물인지 혼동하지 않는다. 셋째, 계산 환경 명세다. 사용된 소프트웨어 버전과 의존성을 기록하면 “내 컴퓨터에서는 되는데요”라는 문제를 방지할 수 있다.\n\n\n\n\n\n그림 36.2: 연구 컴펜디엄의 구조\n\n\n그림 36.2 는 연구 컴펜디엄의 기본 구조를 보여준다. 가장 단순한 형태는 data/, analysis/ 폴더와 README.md만으로 구성된다. 하지만 재현가능성을 완전히 보장하려면 Dockerfile로 계산 환경을, renv.lock으로 패키지 버전을, Makefile로 실행 순서를 명시해야 한다. 이 모든 구성요소가 Git으로 버전 관리되고, GitHub에서 공유된다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-why",
    "href": "compendium.html#sec-compendium-why",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.3 왜 연구 컴펜디엄을 만드는가",
    "text": "36.3 왜 연구 컴펜디엄을 만드는가\n연구 컴펜디엄 작성에는 시간과 노력이 필요하다. 그런데도 왜 해야 할까? 마코베츠(Markowetz) [9]는 재현가능 연구를 해야 하는 “5가지 이기적인 이유”를 제시했다. 윤리적 의무를 넘어 연구자 본인에게 실질적으로 유리하기 때문이라는 것이다.\n첫째, 데이터 손실과 재난을 방지한다. 연구자들 사이에 회자되는 악몽이 있다. “SPSS 파일이 열리지 않습니다. 6개월 작업이 날아갔습니다.”라는 이메일이다. 바이너리 파일 형식은 손상 시 복구가 거의 불가능하다. 반면 Git으로 버전 관리되는 플레인 텍스트는 GitHub 서버, 로컬 PC, 연구실 백업 서버에 동시에 존재한다. 리눅스 커널은 20년 넘게 100만 건 이상의 커밋으로 관리되지만 단 한 줄의 코드도 잃어버린 적이 없다. 연구 컴펜디엄은 이런 수준의 안전망을 제공한다.\n둘째, 논문 작성 효율성이 높아진다. “심사자가 로그 스케일로 다시 그려달라고 요청했어요.” 전통적인 워크플로우에서는 엑셀에서 차트를 다시 그리고, 워드에 복사하고, 그림 번호를 다시 매기는 데 며칠이 걸린다. 쿼토로 작성된 논문은 코드 한 줄 수정(scale_y_log10())으로 몇 분 만에 끝난다. 데이터가 갱신되면 표와 그림이 자동으로 갱신되고, 본문의 통계값도 자동으로 업데이트된다. 피엔타 등 [10]은 7,040건의 NSF/NIH 연구비 수혜 과제를 분석한 결과, 데이터를 아카이브한 연구과제가 그렇지 않은 과제보다 출판 논문 수가 두 배(중앙값 10편 vs 5편) 많았음을 보여주었다.\n셋째, 심사자와 소통이 원활해진다. “그림 3의 p-value가 어떻게 계산되었는지 알 수 없습니다”라는 코멘트는 연구자에게 악몽이다. 반면 GitHub 저장소에 데이터와 분석 코드가 공개된 논문은 심사자가 직접 재현해볼 수 있다. PLOS ONE과 eLife 같은 저널들은 이제 코드 공개를 정책으로 요구하고 있다. 코드와 데이터로 말하면 “방법론이 불명확하다”는 심사 의견은 사라진다. 6개월 후의 자신은 거의 다른 사람이다. 잘 구조화된 컴펜디엄은 심사자뿐만 아니라 미래의 자신과도 효과적으로 소통하게 해준다.\n넷째, 연구 영속성이 보장된다. HWP 97로 작성된 문서가 HWP 2020에서 제대로 열리지 않는 경험을 해본 적 있는가? 10년 전 엑셀 파일의 한글 인코딩이 깨져서 당황한 적은? 플레인 텍스트 기반 마크다운 문서는 34년 전 리눅스 0.01 소스코드가 2025년 현재도 완벽하게 읽히는 것처럼 영원히 읽힌다. 소프트웨어가 사라져도, 회사가 망해도, 라이선스 계약이 만료되어도 연구는 남는다.\n다섯째, 국제적 명성과 영향력이 높아진다. 오픈 사이언스 연구 [11]에 따르면 코드와 데이터를 공개한 논문은 비공개 논문 대비 인용 횟수가 최대 3배까지 높다. 피워워 등 [12]의 연구도 데이터를 공개한 논문의 인용률이 유의미하게 높음을 보여주었고, 피워워와 비전 [13]은 이를 “개방 데이터 인용 이점(open data citation advantage)”이라 명명했다. 오픈소스 연구는 단순히 윤리적인 선택이 아니라 연구자의 영향력을 극대화하는 전략적 선택이다. GitHub 프로필은 이제 연구자의 두 번째 이력서가 되었다.\nR 패키지 형식의 컴펜디엄은 추가적인 이점이 있다. devtools::check()를 실행하면 코드의 품질을 자동으로 검사할 수 있고, roxygen2로 함수를 문서화하면 사용법이 명확해진다. 복사-붙여넣기 대신 함수를 작성하면 오류 발생 가능성이 줄어든다.\n\n\n\n\n\n\n노트파이썬 연구 컴펜디엄: 시도와 한계\n\n\n\n파이썬 생태계에서도 재현가능 연구에 대한 논의가 활발하다. 윌슨 등 [14]은 “충분히 좋은 과학 컴퓨팅 실천법”에서 파이썬을 포함한 언어 중립적인 재현가능 연구 가이드라인을 제시했다. 주피터 노트북(Jupyter Notebook)은 클루이버 등 [15]이 “재현가능 계산 워크플로우를 위한 출판 형식”으로 제안한 이후 데이터 과학의 핵심 도구가 되었고, 룰 등 [16]은 주피터 노트북에서 재현가능 연구를 위한 “10가지 간단한 규칙”을 정리했다.\n하지만 현실은 녹록지 않다. 피멘텔 등 [17]이 GitHub의 140만 개 주피터 노트북을 분석한 결과, 실행 가능한 노트북 중 24%만 오류 없이 실행되었고, 원본과 동일한 결과를 재현한 비율은 4%에 불과했다. 이 연구는 주피터 노트북이 재현가능성을 보장하지 않으며, 오히려 비선형 실행과 숨겨진 상태 문제로 재현성을 해칠 수 있음을 보여준다.\nR의 연구 컴펜디엄 개념과 비교하면, 파이썬 생태계는 통합된 프레임워크보다 개별 도구의 조합에 의존한다. Cookiecutter Data Science가 프로젝트 템플릿을, poetry/pipenv가 패키지 관리를, DVC가 데이터 버전 관리를 담당하지만, 이들을 하나로 묶는 학술적 프레임워크는 아직 정립되지 않았다. 마윅 등 [5]처럼 “연구 컴펜디엄”을 학술적으로 정의하고 R 패키지 시스템과 통합한 사례가 파이썬에는 부재하다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-organization",
    "href": "compendium.html#sec-compendium-organization",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.4 파일 조직 원칙",
    "text": "36.4 파일 조직 원칙\n연구 프로젝트의 파일은 세 가지 유형으로 나뉜다. 읽기 전용(read-only) 파일은 원본 데이터와 메타데이터다. 수정해서는 안 되며, 분석의 출발점이다. 사람이 생성한(human-generated) 파일은 분석 스크립트, 논문 원고, 문서다. 연구자가 직접 작성하고 수정한다. 프로젝트가 생성한(project-generated) 파일은 전처리된 데이터, 그래프, 테이블 등 코드 실행의 산출물이다.\n이러한 분류가 중요한 이유는 버전 관리 전략과 직결되기 때문이다. 읽기 전용 데이터는 변경되면 안 되고, 프로젝트 생성 파일은 코드에서 재생성할 수 있으므로 Git에서 제외할 수 있다. 사람이 생성한 파일만 Git으로 추적하면 저장소가 깔끔해진다.\nmyproject/\n├── README.md           # 프로젝트 설명\n├── LICENSE             # 라이선스\n├── DESCRIPTION         # 메타데이터 (R 패키지 형식)\n│\n├── data/               # 읽기 전용\n│   ├── raw/            # 원본 데이터\n│   └── processed/      # 전처리된 데이터 (재생성 가능)\n│\n├── analysis/           # 사람이 생성\n│   ├── 01_import.R\n│   ├── 02_clean.R\n│   ├── 03_analyze.R\n│   └── paper.qmd       # 논문 원고\n│\n├── figures/            # 프로젝트가 생성\n│   ├── figure1.png\n│   └── figure2.png\n│\n├── renv.lock           # R 패키지 버전\n├── Dockerfile          # 계산 환경\n└── Makefile            # 실행 순서\n\n36.4.1 AI 시대 파일 조직 원칙\n앞서 제시한 파일 분류 체계—읽기 전용, 사람 생성, 프로젝트 생성—는 연구자가 모든 코드를 직접 작성하던 시대의 산물이다. 그러나 ChatGPT, Claude, GitHub Copilot 같은 AI 도구가 연구 현장에 빠르게 침투하면서, “누가 이 코드를 작성했는가”라는 질문이 더 이상 자명하지 않게 되었다. AI가 초안을 작성하고 연구자가 검토·수정하는 협업 패턴이 일상화되면서, 파일의 출처와 생성 과정을 추적하는 새로운 원칙이 필요해졌다. 그림 36.3 은 수작업 시대에서 자동화 시대를 거쳐 AI 협업 시대로 이어지는 변화를 보여준다.\n\n\n\n\n\n그림 36.3: 수작업에서 자동화를 거쳐 AI 협업\n\n\n1단계: 수작업 시대(1990s~2010s)에는 연구자가 모든 작업을 직접 수행했다. 코드 작성, 문서화, 폴더 구조 설계, 데이터 전처리, 환경 명세까지 100% 연구자의 몫이었다. 재현성 검증은 “희망사항”에 가까웠고, 실제로 실행되는 경우는 드물었다.\n2단계: 자동화 시대(2010s~2020s)에 들어 Make, CI/CD, renv, Docker 같은 도구가 반복 작업을 자동화했다. 연구자는 “무엇을” 할지 결정하고, 스크립트가 “어떻게” 실행할지 담당했다. 재현성 검증이 자동화되면서 실질적인 재현가능 연구가 가능해졌다.\n3단계: AI 협업 시대(2020s~현재)는 LLM(Large Language Model)과 AI 에이전트가 연구 워크플로우에 참여하는 새로운 패러다임이다. 첸 등 [18]은 이를 “에이전틱 AI(Agentic AI) 시대의 과학 워크플로우 (R)evolution”이라 명명했다. 연구자는 의사결정, 검증, 연구 설계, 인과 추론에 집중하고, AI는 코드 생성, 문서 동기화, 구조 자동 생성, 패턴 인식을 지원한다.\n\n\n\n\n\n\n힌트문학적 프로그래밍의 부활\n\n\n\n도널드 크누스(Donald Knuth)가 1984년 제안한 문학적 프로그래밍(Literate Programming)이 LLM 시대에 부활하고 있다. 주 등 [19]은 “LLM 시대 문학적 프로그래밍의 르네상스”에서 상호운용 가능한 문학적 프로그래밍(Interoperable LP)을 제안했다. 코드와 자연어 설명을 함께 작성하면 LLM이 대규모 프로젝트에서도 더 정확한 코드를 생성한다는 것이다.\n아칸크샤 등 [20]은 한 걸음 더 나아가 자연어 아웃라인(NL Outline)을 제안했다. 코드 함수마다 간결한 산문체 설명을 붙이면, LLM이 코드↔︎자연어 간 양방향 동기화를 수행한다. 연구자가 코드를 수정하면 문서가 자동 갱신되고, 문서를 수정하면 코드가 자동 갱신된다.\n\n\nAI 협업 시대 파일 조직은 기존 원칙에서 확장이 요구되고 있다. 가장 근본적인 변화는 출처 추적(Provenance) 필수화다. 수자 등 [21]은 AI가 통합된 워크플로우에서 “에이전트 행동의 추적 가능성이 책임성, 투명성, 설명가능성, 감사가능성을 위해 필수”라고 강조한다. 어떤 코드가 AI가 생성했는지, 어떤 프롬프트로 생성되었는지, 연구자가 어떻게 검증했는지 기록해야 한다. PROV-AGENT [22]는 출처 추적을 위한 출처 모델을 제안했다.\n출처 추적 필요성은 파일 분류 체계의 확장으로 이어진다. 기존의 세 가지 유형—읽기 전용, 사람 생성, 프로젝트 생성—에 AI 협업 생성(AI-assisted) 파일이 추가된다. AI가 초안을 작성하고 연구자가 검증·수정한 파일이다. AI와 함께 작성된 파일은 생성 이력(프롬프트, 모델 버전, 검증 내역)을 메타데이터로 기록해야 한다.\nmyproject/\n├── README.md           # AI 협업 생성 (프롬프트 이력 포함)\n├── analysis/\n│   ├── 01_import.R     # 사람 생성\n│   ├── 02_clean.R      # AI 협업 생성 (Claude 3.5, 검증 완료)\n│   └── paper.qmd       # AI 협업 생성 (NL 아웃라인 동기화)\n├── .ai/                # AI 협업 메타데이터\n│   ├── prompts.md      # 사용된 프롬프트 기록\n│   ├── model_versions.yml  # 사용된 AI 모델 버전\n│   └── review_log.md   # 연구자 검증 이력\n└── ...\n이러한 메타데이터를 체계적으로 관리하기 위해 AGENT.md 또는 CLAUDE.md 같은 AI 협업 지침 파일이 등장했다. README.md가 “사람을 위한 현관문”이라면, AGENT.md는 “AI를 위한 계약서”다. 프로젝트의 맥락, 코딩 규칙, 선호하는 라이브러리, 금지된 패턴 등을 명시하면 AI가 프로젝트에 맞는 코드를 생성한다. Claude Code는 CLAUDE.md, Cursor는 .cursorrules, GitHub Copilot은 .github/copilot-instructions.md를 읽어 프로젝트별 지침을 따른다.\nAGENT.md의 핵심은 재현가능성의 확장이다. 전통적인 연구 컴펜디엄이 “같은 코드로 같은 결과”를 보장했다면, AI 시대 컴펜디엄은 “같은 지침으로 유사한 코드”까지 보장해야 한다. 연구자가 어떤 프롬프트로 AI에게 코드를 요청했는지, 어떤 모델 버전을 사용했는지, 생성된 코드를 어떻게 검증했는지 기록하면 제3자도 AI 협업 과정을 재현할 수 있다.\n새로운 분류 체계와 함께 검증 워크플로우가 핵심으로 부상한다. AI가 생성한 코드는 반드시 연구자 검증을 거쳐야 한다. 자동화된 테스트만으로는 부족하다. 과학적 발견은 “패턴 인식을 넘어 인과성 이해”를 요구하기 때문이다 [18]. 연구자는 AI를 “똑똑한 조수”로 활용하되, 최종 책임은 연구자에게 있다.\nDESCRIPTION 파일은 R 패키지 표준 메타데이터 형식이다. 연구 컴펜디엄에서 DESCRIPTION을 포함하면, 프로젝트가 “형식적으로 R 패키지”가 되어 패키지 개발 도구(devtools, usethis)의 이점을 활용할 수 있다. 의존성 자동 설치, 문서화, 테스트 프레임워크가 그것이다.\nPackage: myresearch\nTitle: Analysis of Urban Temperature Patterns\nVersion: 0.1.0\nAuthors@R:\n    person(\"홍길동\", email = \"hong@example.com\", role = c(\"aut\", \"cre\"))\nDescription: 도시 열섬 효과 분석을 위한 연구 컴펜디엄.\n    2020-2023년 서울 기온 데이터를 분석한다.\nLicense: MIT + file LICENSE\nDepends:\n    R (&gt;= 4.3.0)\nImports:\n    tidyverse,\n    sf,\n    terra\nSuggests:\n    testthat,\n    knitr",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-components",
    "href": "compendium.html#sec-compendium-components",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.5 핵심 구성요소",
    "text": "36.5 핵심 구성요소\n“모든 파일이 다 있는데 왜 재현이 안 될까?” 연구 컴펜디엄을 처음 접하는 연구자들이 흔히 던지는 질문이다. 코드와 데이터가 있어도 패키지 버전이 다르면 오류가 발생하고, 패키지 버전을 맞춰도 운영체제가 다르면 결과가 달라진다. AI 도구로 생성한 코드라면 어떤 프롬프트로 만들었는지, 어떤 모델을 사용했는지도 기록해야 한다. 재현성은 단순히 파일을 공유하는 것이 아니라, 연구의 모든 맥락을 함께 전달하는 것이다.\n재현성 성숙도 모델(Reproducibility Maturity Model)은 연구 컴펜디엄의 구성요소를 단계별로 정리한 프레임워크다. 기본적인 문서화에서 시작해 법적 명확성, 구조화된 명세, 패키지 고정, 환경 고정을 거쳐 AI 맥락 통합까지 이어진다. 각 단계는 이전 단계 위에 쌓이며, 높은 수준으로 갈수록 더 완전한 재현이 가능해진다. 모든 프로젝트가 최고 수준을 목표로 할 필요는 없다. 프로젝트의 복잡도와 재현성 요구 수준에 따라 적절한 단계를 선택하면 된다.\n\n\n\n\n\n그림 36.4: 연구 컴펜디엄의 핵심 구성요소\n\n\n그림 36.4 는 기본 재현에서 인지 재현(Cognitive Reproducibility)까지 이어지는 여섯 가지 핵심 구성요소를 보여준다. 가장 기본적인 README.md는 프로젝트의 “현관문”으로, 무엇을 연구했는지, 어떻게 실행하는지 설명한다. GitHub 저장소 첫 화면에 표시되므로 처음 방문자가 프로젝트를 이해하는 유일한 경로다.\nLICENSE는 코드와 데이터의 사용 권한을 명시하여 법적 보호를 제공한다. MIT, GPL, CC-BY 중 하나를 선택하며, 라이선스 없이 공개하면 저작권법상 “모든 권리 보유”가 되어 재사용이 법적으로 불가능해진다. DESCRIPTION은 R 패키지 표준 메타데이터 형식으로, 의존성 목록과 저자 정보를 기계가 읽을 수 있는 구조로 제공한다.\n재현성 수준이 높아지면 환경 고정이 필요하다. renv.lock은 R/Python 패키지 버전을 정확한 해시로 고정하여 “tidyverse 2.0에서는 되는데 1.3에서는 안 돼요” 문제를 방지한다. Dockerfile은 한 걸음 더 나아가 운영체제, 시스템 라이브러리, 런타임 환경까지 컨테이너화하여 완전한 환경 스냅샷을 제공한다.\nAI 협업 시대에는 여기서 멈추지 않는다. AGENT.md는 프로젝트 맥락과 도메인 지식, 코딩 규칙과 금지 패턴, 모델 버전과 검증 이력을 기록하여 AI 출처를 추적한다. Docker가 계산 환경을 재현한다면, AGENT.md는 AI 협업 맥락을 재현한다. 이 둘이 결합되어야 AI 시대의 진정한 재현성이 확보된다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-rrtools",
    "href": "compendium.html#sec-compendium-rrtools",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.6 rrtools: 컴펜디엄 자동화",
    "text": "36.6 rrtools: 컴펜디엄 자동화\n연구 컴펜디엄을 처음부터 만드는 것은 번거롭다. rrtools 패키지는 이 과정을 자동화한다. 벤 마윅이 개발한 이 도구는 한 줄 명령으로 재현가능한 연구 프로젝트 구조를 생성한다.\n# rrtools 설치\ninstall.packages(\"devtools\")\ndevtools::install_github(\"benmarwick/rrtools\")\n\n# 새 컴펜디엄 생성\nrrtools::use_compendium(\"myresearch\")\nuse_compendium() 명령은 DESCRIPTION 파일, R 프로젝트 파일(.Rproj), 기본 디렉토리 구조를 자동 생성한다. 이후 필요한 구성요소를 하나씩 추가한다.\n# 분석 폴더 생성 (Quarto 기반)\nrrtools::use_analysis()\n\n# MIT 라이선스 추가\nusethis::use_mit_license()\n\n# renv로 패키지 관리 시작\nrenv::init()\n\n# Docker 지원 추가\nrrtools::use_dockerfile()\n\n# GitHub Actions CI 추가\nrrtools::use_github()\n\n\n\n\n\n그림 36.5: rrtools 워크플로우\n\n\n그림 36.5 는 rrtools가 생성하는 프로젝트 구조를 보여준다. analysis/ 폴더에는 Quarto 기반 논문 템플릿이, R/ 폴더에는 재사용 함수가, 루트에는 DESCRIPTION과 README가 위치한다. GitHub Actions는 코드 변경 시 자동으로 Docker 이미지를 빌드하고 테스트를 실행한다.\nrrtools가 생성하는 analysis/ 폴더 구조:\nanalysis/\n├── paper/\n│   ├── paper.qmd       # 논문 원고\n│   └── references.bib  # 참고문헌\n├── figures/            # 생성된 그래프\n├── data/\n│   ├── raw_data/       # 원본 데이터\n│   └── derived_data/   # 전처리 데이터\n└── supplementary-materials/",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-examples",
    "href": "compendium.html#sec-compendium-examples",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.7 실제 연구 컴펜디엄 사례",
    "text": "36.7 실제 연구 컴펜디엄 사례\n마윅 등 [5]은 논문에서 복잡도에 따른 세 가지 수준의 실제 연구 컴펜디엄 사례를 제시한다. 각 사례는 GitHub에서 개발되고 Zenodo에서 DOI와 함께 아카이브되었다.\n\n36.7.1 소규모 컴펜디엄: Duffy (2015)\n더피(Duffy) 등의 기생충 연구는 가장 단순한 형태의 연구 컴펜디엄을 보여준다.\nBroodParasiteDescription/\n├── DESCRIPTION          # 프로젝트 메타데이터\n├── README.md            # 설명\n├── data/\n│   └── my_data.csv     # 원본 데이터\n└── analysis/\n    └── my_script.R     # 분석 코드\n\n\nGitHub: github.com/duffymeg/BroodParasiteDescription\n\nZenodo: doi.org/10.5281/zenodo.17804\n\nDESCRIPTION 파일이 R 버전(3.2.0 이상)과 의존 패키지를 명시하고 있어, 세 가지 핵심 원칙(관례적 폴더 구조, 데이터·방법 분리, 환경 명세)을 모두 충족한다. 이 정도면 대부분의 단일 논문 프로젝트에 충분하다.\n\n36.7.2 중규모 컴펜디엄: Hollister et al. (2016)\n홀리스터(Hollister) 등의 호수 영양 상태 모델링 연구는 R 패키지 구조를 더 완전하게 활용한다.\nLakeTrophicModelling/\n├── DESCRIPTION\n├── NAMESPACE\n├── README.md\n├── LICENSE\n├── R/                   # 재사용 함수\n│   └── my_functions.R\n├── man/                 # 자동 생성 문서\n│   └── my_functions.Rd\n├── data/\n│   └── my_data.csv\n└── vignettes/           # 논문 원고\n    └── manuscript.Rmd\n\n\nGitHub: github.com/USEPA/LakeTrophicModelling\n\nZenodo: doi.org/10.5281/zenodo.40271\n\n핵심 차이점은 R/ 디렉토리에 재사용 가능한 함수가 있고, man/ 디렉토리에 자동 생성된 문서가 있다는 것이다. 논문 원고는 vignettes/ 디렉토리에 R Markdown 형식으로 작성되어, 패키지 설치 시 자동으로 렌더링된다. 그래프, 테이블, 통계 결과가 모두 코드에서 생성된다.\n\n36.7.3 대규모 컴펜디엄: Boettiger et al. (2015)\n보에티거(Boettiger) 등의 어업 관리 연구는 가장 복잡한 형태의 연구 컴펜디엄이다.\nnonparametric-bayes/\n├── DESCRIPTION\n├── NAMESPACE\n├── README.md\n├── LICENSE\n├── Makefile             # 빌드 자동화\n├── Dockerfile           # 환경 격리\n├── .travis.yml          # 지속적 통합\n├── .zenodo.json         # 메타데이터\n├── R/\n├── man/\n├── data/\n├── tests/               # 단위 테스트\n│   └── testthat/\n└── manuscripts/\n    ├── paper.Rmd\n    └── Makefile\n\n\nGitHub: github.com/cboettig/nonparametric-bayes\n\nZenodo: doi.org/10.5281/zenodo.12669\n\nDocker 컨테이너가 전체 계산 환경을 캡슐화하고, Travis CI(현재는 GitHub Actions으로 대체)가 커밋마다 자동으로 분석을 재실행한다. .zenodo.json 파일은 Zenodo 아카이브를 위한 메타데이터를 제공한다. tests/ 디렉토리의 단위 테스트는 함수가 예상대로 작동하는지 확인한다.\n이 세 가지 사례는 프로젝트 규모와 요구사항에 따라 컴펜디엄 복잡도를 조절할 수 있음을 보여준다. 단순한 분석은 소규모 구조로 충분하고, 복잡한 시뮬레이션이나 장기 프로젝트는 대규모 구조가 필요하다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-environment",
    "href": "compendium.html#sec-compendium-environment",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.8 계산 환경 명세",
    "text": "36.8 계산 환경 명세\n코드와 데이터가 있어도 환경이 다르면 결과가 달라진다. R 4.2에서 4.3으로 업그레이드되면서 기본 난수 생성기가 바뀌었고, ggplot2 3.4에서 테마 기본값이 변경되었다. 재현가능성은 환경 명세에서 완성된다.\n\n36.8.1 R 패키지 버전 관리의 진화\nR 패키지 버전 관리 도구는 시간이 지나면서 발전해왔다.\npackrat(2014)은 RStudio가 개발한 최초의 프로젝트별 패키지 관리 도구였다. 사용한 패키지의 소스 코드를 프로젝트 내 packrat/ 디렉토리에 다운로드하여 저장한다. 그러나 대규모 프로젝트에서 느려지고, 재현성 보장이 불완전한 문제가 있었다.\ncheckpoint(2017)은 Microsoft가 개발했다. Microsoft R Archived Network(MRAN)에서 특정 날짜의 CRAN 스냅샷을 설치한다. “2023년 1월 15일 기준 CRAN”처럼 시점을 지정할 수 있어 간편하지만, MRAN 서비스가 2023년 종료되면서 더 이상 권장되지 않는다.\nrenv(2019)는 packrat의 후속 도구로, 현재 R 환경 관리의 표준이다. 프로젝트별로 독립된 라이브러리를 생성하고, renv.lock 파일에 정확한 버전을 기록한다.\n# renv 초기화\nrenv::init()\n\n# 필요한 패키지 설치\ninstall.packages(c(\"tidyverse\", \"sf\", \"gt\"))\n\n# 현재 상태 스냅샷\nrenv::snapshot()\n\n# 다른 환경에서 복원\nrenv::restore()\nrenv.lock 파일 예시:\n{\n  \"R\": {\n    \"Version\": \"4.3.0\",\n    \"Repositories\": [\n      {\"Name\": \"CRAN\", \"URL\": \"https://cloud.r-project.org\"}\n    ]\n  },\n  \"Packages\": {\n    \"ggplot2\": {\n      \"Package\": \"ggplot2\",\n      \"Version\": \"3.4.2\",\n      \"Source\": \"Repository\"\n    },\n    \"dplyr\": {\n      \"Package\": \"dplyr\",\n      \"Version\": \"1.1.2\",\n      \"Source\": \"Repository\"\n    }\n  }\n}\nrenv만으로는 시스템 라이브러리 의존성을 해결할 수 없다. sf 패키지가 GDAL에 의존하고, rJava가 Java에 의존하는 경우, 패키지 버전이 같아도 시스템 라이브러리 버전에 따라 결과가 달라질 수 있다. 이때 Docker가 필요하다.\nFROM rocker/verse:4.3.0\n\n# 시스템 라이브러리 설치\nRUN apt-get update && apt-get install -y \\\n    libgdal-dev \\\n    libgeos-dev \\\n    libproj-dev\n\n# renv 복원\nCOPY renv.lock renv.lock\nRUN R -e \"renv::restore()\"\n\n# 프로젝트 파일 복사\nCOPY . /home/rstudio/project\nWORKDIR /home/rstudio/project\nDocker와 renv를 함께 사용하면 “완전한 재현”이 가능하다. Docker가 OS와 시스템 라이브러리를, renv가 R 패키지 버전을 보장한다. 5년 후에도, 다른 대륙에서도, 정확히 같은 결과를 얻을 수 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-encore",
    "href": "compendium.html#sec-compendium-encore",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.9 ENCORE: 2024년의 실천 프레임워크",
    "text": "36.9 ENCORE: 2024년의 실천 프레임워크\n반캄펜 등 [23]이 Nature Communications에 발표한 ENCORE(ENhancing COmputational REproducibility)는 연구 컴펜디엄 개념을 실천적 프레임워크로 발전시켰다. 기존 가이드라인이 “무엇을 해야 하는지”를 설명했다면, ENCORE는 “어떻게 해야 하는지”를 구체화한다.\nENCORE의 핵심 특징:\n\n\n표준화된 파일 시스템 구조: 모든 프로젝트 구성요소를 정해진 위치에 배치\n\n사전 정의된 문서 템플릿: README, 메서드 설명, 데이터 사전 등을 템플릿으로 제공\n\nGitHub 통합: 버전 관리와 협업을 기본으로 내장\n\nHTML 기반 네비게이터: 프로젝트 구조를 시각적으로 탐색\n\nENCORE_project/\n├── 00_admin/           # 관리 문서\n│   ├── README.md\n│   └── project_log.md\n├── 01_data/\n│   ├── raw/            # 원본 데이터\n│   ├── processed/      # 전처리 데이터\n│   └── metadata/       # 데이터 설명\n├── 02_scripts/\n│   ├── 01_import.R\n│   ├── 02_preprocess.R\n│   └── 03_analyze.R\n├── 03_results/\n│   ├── figures/\n│   └── tables/\n├── 04_manuscript/\n│   └── paper.qmd\n└── 05_environment/\n    ├── Dockerfile\n    └── renv.lock\nENCORE가 지적하는 재현가능성의 가장 큰 장벽은 기술적 문제가 아니다. “연구자가 재현가능성을 위해 시간과 노력을 투자할 인센티브가 부족하다”는 점이다. 논문 출판이 주된 평가 기준인 학계에서, 코드 정리와 문서화에 시간을 쓰는 것은 “보상 없는 노동”으로 여겨진다. ENCORE는 이 문제를 최소한의 추가 노력으로 재현가능성을 달성하도록 프레임워크를 설계함으로써 해결하려 한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-worldbank",
    "href": "compendium.html#sec-compendium-worldbank",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.10 세계은행의 재현가능 연구 이니셔티브",
    "text": "36.10 세계은행의 재현가능 연구 이니셔티브\n2023년 세계은행(World Bank)은 대규모 조직이 연구 컴펜디엄을 제도화한 첫 사례를 만들었다 [24]. 기존의 개방 데이터·개방 지식 정책을 확장해 재현가능성 패키지(reproducibility package) 제출을 장려하기 시작했다.\n재현가능성 패키지는 세 가지 컬렉션으로 구성된다: - 정책 연구 워킹페이퍼(Policy Research Working Papers) - 학술지 논문(Journal Articles) - 세계은행 보고서(World Bank Reports)\n2024년 6월 기준, 2023년 9월 이후 제출된 워킹페이퍼 중 43.4%가 재현가능성 패키지를 포함했다. 의무가 아닌 자발적 참여임에도 높은 채택률을 보인 것은 연구자들이 재현가능성의 가치를 인식하고 있음을 보여준다.\n세계은행 재현가능성 저장소(Reproducible Research Repository)는 포괄적인 메타데이터와 함께 패키지를 공개해 검색과 발견이 가능하게 한다. 이는 연구 컴펜디엄이 개인 연구자의 선택이 아닌 조직 차원의 정책이 될 수 있음을 증명한 사례다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-sharing",
    "href": "compendium.html#sec-compendium-sharing",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.11 연구 컴펜디엄 공유 방법",
    "text": "36.11 연구 컴펜디엄 공유 방법\n연구 컴펜디엄 공유는 오픈 사이언스의 국제 표준인 FAIR 원칙 [25]에 부합해야 한다. FAIR는 Findable(찾을 수 있는), Accessible(접근 가능한), Interoperable(상호운용 가능한), Reusable(재사용 가능한)의 약자로, 과학 데이터 관리와 공유의 핵심 원칙이다.\n\n\n\n\n\n\n\n\nFAIR\n원칙\n컴펜디엄 적용\n\n\n\n\nFindable\n영구 식별자로 검색 가능\nGitHub + Zenodo DOI\n\n\n\nAccessible\n표준 프로토콜로 접근 가능\nGit clone 무료 접근\n\n\n\nInteroperable\n표준 포맷으로 상호 호환\n플레인 텍스트, CSV, JSON\n\n\n\nReusable\n명확한 라이선스로 재사용 가능\nMIT/CC-BY 라이선스\n\n\n\n\n\n\n\n표 36.1: FAIR 원칙과 연구 컴펜디엄의 관계\n\n\n\n연구 컴펜디엄을 공유할 때는 라이선스, 버전 관리, 영속성, 메타데이터를 고려해야 한다. 마윅 등 [5]은 각 요소에 대한 구체적인 권고사항을 제시한다.\n\n36.11.1 라이선스 선택\n라이선스 없이 공개된 코드와 데이터는 저작권법상 “모든 권리 보유”가 된다. 다른 연구자가 법적으로 재사용할 수 없다. 명시적인 라이선스가 필수다.\n데이터: 스토든 [26]은 데이터에 CC-0(Creative Commons Public Domain)을 권장한다. 데이터는 많은 법적 관할권에서 창작물이 아닌 “사실”로 간주되어 저작권 보호를 받지 못할 수 있다. CC-0는 이러한 법적 불확실성을 제거하고 최대한의 재사용을 허용한다.\n문서와 논문: CC-BY(Creative Commons Attribution)가 적절하다. 원저자 표시를 조건으로 재사용을 허용한다. 학술 인용 관행과 일치한다.\n코드: MIT 또는 GPL 같은 오픈소스 라이선스를 사용한다. MIT는 가장 관대하고, GPL은 파생 저작물도 오픈소스로 유지하도록 요구한다.\nmyproject/\n├── LICENSE            # MIT for code\n├── LICENSE-CC0        # CC-0 for data\n├── data/              # CC-0 applies here\n└── R/                 # MIT applies here\n\n36.11.2 버전 관리와 Git\nGit은 연구 컴펜디엄의 변경 이력을 보존하는 가장 좋은 방법이다. 모든 수정 사항이 기록되어, 특정 시점의 코드 상태를 정확히 복원할 수 있다. GitHub, GitLab 같은 호스팅 서비스는 협업과 배포를 용이하게 한다.\n\n36.11.3 DOI와 영속적 아카이브\nGitHub URL은 영구적이지 않다. 저장소가 삭제되거나 이름이 바뀌면 링크가 깨진다. 클라인 등 [27]의 연구에 따르면, 학술 논문 인용의 5분의 1이 “참조 부패(reference rot)”를 겪고 있다.\nDOI(Digital Object Identifier)를 발급하는 저장소에 아카이브하면 이 문제를 해결할 수 있다:\n\n\nZenodo (zenodo.org): CERN이 운영, GitHub 통합 우수\n\nOSF (osf.io): Open Science Framework, 프로젝트 관리 기능\n\nFigshare (figshare.com): 대용량 파일 지원\n\nDryad (datadryad.org): 생태학·진화생물학 중심\n\nZenodo는 GitHub 저장소와 자동 통합되어, 릴리스를 생성하면 자동으로 DOI가 발급된다. 논문에 이 DOI를 인용하면 심사위원과 독자가 정확한 버전의 코드에 접근할 수 있다.\n\n36.11.4 CRAN을 피하는 이유\nCRAN(Comprehensive R Archive Network)은 R 패키지의 표준 저장소지만, 연구 컴펜디엄에는 적합하지 않다:\n\n\n엄격한 디렉토리 구조: analysis/ 같은 최상위 디렉토리가 허용되지 않음\n\n5 MB 용량 제한: 데이터 파일, 캐시된 결과, 이미지를 포함하기 어려움\n\n업데이트 제약: 잦은 업데이트가 요구되는 개발 중 프로젝트에 부적합\n\nZenodo, OSF 같은 DOI 발급 저장소는 이러한 제한이 없고, 오히려 연구 아카이브에 특화되어 있다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-practice",
    "href": "compendium.html#sec-compendium-practice",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.12 실전: 논문 프로젝트 구축",
    "text": "36.12 실전: 논문 프로젝트 구축\n논문 프로젝트를 연구 컴펜디엄으로 구축하는 전체 과정을 살펴보자.\n1단계: 프로젝트 생성\n# rrtools로 컴펜디엄 생성\nrrtools::use_compendium(\"urban-heat-analysis\")\n\n# Quarto 기반 분석 폴더 추가\nrrtools::use_analysis()\n\n# 라이선스 추가\nusethis::use_mit_license()\n\n# Git 초기화\nusethis::use_git()\n2단계: 패키지 환경 설정\n# renv 초기화\nrenv::init()\n\n# 필요한 패키지 설치\ninstall.packages(c(\"tidyverse\", \"sf\", \"terra\", \"gt\", \"quarto\"))\n\n# 환경 스냅샷\nrenv::snapshot()\n3단계: 데이터 구조화\n# 데이터 폴더 생성\nfs::dir_create(\"analysis/data/raw_data\")\nfs::dir_create(\"analysis/data/derived_data\")\n\n# 원본 데이터 복사 (수정 금지)\nfs::file_copy(\"~/Downloads/seoul_temp_2020-2023.csv\",\n              \"analysis/data/raw_data/\")\n4단계: 분석 스크립트 작성\nanalysis/\n├── 01_import.R         # 데이터 로드\n├── 02_clean.R          # 전처리\n├── 03_analyze.R        # 분석\n├── 04_visualize.R      # 시각화\n└── paper/\n    └── paper.qmd       # 논문 원고\n5단계: Makefile로 워크플로우 정의\nall: paper\n\n# 데이터 전처리\nanalysis/data/derived_data/clean.rds: analysis/data/raw_data/seoul_temp.csv \\\n                                       analysis/01_import.R \\\n                                       analysis/02_clean.R\n    Rscript analysis/01_import.R\n    Rscript analysis/02_clean.R\n\n# 분석 실행\nanalysis/data/derived_data/results.rds: analysis/data/derived_data/clean.rds \\\n                                         analysis/03_analyze.R\n    Rscript analysis/03_analyze.R\n\n# 그래프 생성\nanalysis/figures/figure1.png: analysis/data/derived_data/results.rds \\\n                               analysis/04_visualize.R\n    Rscript analysis/04_visualize.R\n\n# 논문 렌더링\npaper: analysis/figures/figure1.png analysis/paper/paper.qmd\n    quarto render analysis/paper/paper.qmd\n\nclean:\n    rm -rf analysis/data/derived_data/*\n    rm -rf analysis/figures/*\n\n.PHONY: all paper clean\n6단계: Docker 환경 추가\nFROM rocker/verse:4.3.0\n\n# 시스템 의존성 설치\nRUN apt-get update && apt-get install -y \\\n    libgdal-dev libgeos-dev libproj-dev\n\n# renv 복원\nWORKDIR /home/rstudio/project\nCOPY renv.lock renv.lock\nRUN R -e \"renv::restore()\"\n\n# 프로젝트 복사\nCOPY . .\n\n# 분석 실행\nCMD [\"make\", \"all\"]\n7단계: GitHub Actions CI\n# .github/workflows/reproduce.yml\nname: Reproduce Analysis\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    container:\n      image: rocker/verse:4.3.0\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Restore renv\n        run: R -e \"renv::restore()\"\n\n      - name: Run analysis\n        run: make all\n\n      - name: Upload paper\n        uses: actions/upload-artifact@v4\n        with:\n          name: paper\n          path: analysis/paper/paper.pdf",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-comparison",
    "href": "compendium.html#sec-compendium-comparison",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.13 연구 컴펜디엄 vs 단순 코드 공개",
    "text": "36.13 연구 컴펜디엄 vs 단순 코드 공개\n“GitHub에 코드만 올리면 되지 않나요?”라는 질문을 자주 받는다. 코드 공개와 연구 컴펜디엄은 근본적으로 다르다.\n\n\n\n\n\n\n\n\n구분\n단순 코드 공개\n연구 컴펜디엄\n\n\n\n폴더 구조\n임의\n표준화\n\n\n패키지 버전\n미기록\nrenv.lock\n\n\n실행 순서\n추측 필요\nMakefile\n\n\n계산 환경\n미명세\nDockerfile\n\n\n문서화\n최소\nREADME + DESCRIPTION\n\n\n재현 난이도\n높음 (며칠~몇 주)\n낮음 (분~시간)\n\n\n\n\n\n\n\n표 36.2: 코드 공개 vs 연구 컴펜디엄 비교\n\n\n\n단순 코드 공개는 “이론적으로 재현 가능”하다. 하지만 실제로 재현하려면 패키지 버전을 맞추고, 실행 순서를 파악하고, 누락된 데이터를 찾아야 한다. 연구 컴펜디엄은 “실질적으로 재현 가능”하다. docker build && docker run 두 줄이면 논문의 모든 결과를 재생성한다.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#sec-compendium-turingway",
    "href": "compendium.html#sec-compendium-turingway",
    "title": "36  연구 컴펜디엄",
    "section": "\n36.14 The Turing Way: 커뮤니티 가이드",
    "text": "36.14 The Turing Way: 커뮤니티 가이드\nThe Turing Way [28]는 영국 앨런 튜링 연구소가 운영하는 재현가능 연구 가이드북이다. 오픈소스 커뮤니티 방식으로 작성되어 누구나 기여할 수 있으며, 연구 컴펜디엄을 포함한 재현가능 연구의 모든 측면을 다룬다.\nThe Turing Way가 제시하는 연구 컴펜디엄의 두 가지 수준:\n기본 컴펜디엄 (Basic Compendium):\ncompendium/\n├── data/\n├── analysis/\n├── DESCRIPTION\n└── README.md\n실행 가능 컴펜디엄 (Executable Compendium):\ncompendium/\n├── CITATION\n├── code/\n├── data_clean/\n├── data_raw/\n├── Dockerfile\n├── figures/\n├── LICENSE\n├── Makefile\n├── paper.Rmd\n└── README.md\n기본 컴펜디엄은 코드와 데이터를 조직화한 최소 구조다. 실행 가능 컴펜디엄은 make all 한 줄로 전체 분석을 재현할 수 있는 완전한 구조다. 프로젝트 규모와 재현성 요구 수준에 따라 선택한다.\n💡 생각해볼 점\n연구 컴펜디엄은 “미래의 나를 위한 투자”다. 6개월 후 심사위원이 재현을 요청하면, 잘 구조화된 컴펜디엄은 몇 시간 만에 응답할 수 있게 한다. 반면 정리되지 않은 코드는 며칠, 심지어 몇 주의 작업이 필요하다. “지금 바빠서 나중에 정리하겠다”는 말은 “영원히 정리하지 않겠다”와 같다.\n마윅 등 [5]의 세 가지 원칙—관례적 폴더 구조, 데이터·방법·결과 분리, 환경 명세—을 기억하자. rrtools로 프로젝트를 시작하면 이 원칙이 자동으로 적용된다. renv로 패키지 버전을 잠그고, Docker로 전체 환경을 패키징하면 “완전한 재현”이 가능해진다.\n세계은행의 사례가 보여주듯, 연구 컴펜디엄은 개인의 선택에서 조직의 정책으로 발전하고 있다. Nature, Science 같은 주요 저널도 재현가능성 패키지 제출을 권장하기 시작했다. 지금 연구 컴펜디엄을 익히는 것은 미래의 표준을 선점하는 것이다.\n다음 장에서는 Make와 연구 컴펜디엄을 결합해 전체 분석 파이프라인을 자동화하는 방법을 다룬다. make all 한 줄로 데이터 전처리부터 논문 렌더링까지 완료하는 워크플로우를 구축한다.\n\n\n\n\n[1] \nM. Baker, “1,500 scientists lift the lid on reproducibility”, Nature, vol 533, 호 7604, pp 452–454, 5 2016, doi: 10.1038/533452a.\n\n\n[2] \nL. K. John, G. Loewenstein, 와/과 D. Prelec, “Measuring the prevalence of questionable research practices with incentives for truth telling”, Psychological Science, vol 23, 호 5, pp 524–532, 5 2012, doi: 10.1177/0956797611430953.\n\n\n[3] \nJ. P. Simmons, L. D. Nelson, 와/과 U. Simonsohn, “False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant”, Psychological Science, vol 22, 호 11, pp 1359–1366, 11 2011, doi: 10.1177/0956797611417632.\n\n\n[4] \nN. L. Kerr, “HARKing: Hypothesizing after the results are known”, Personality and Social Psychology Review, vol 2, 호 3, pp 196–217, 1998, doi: 10.1207/s15327957pspr0203_4.\n\n\n[5] \nB. Marwick, C. Boettiger, 와/과 L. Mullen, “Packaging data analytical work reproducibly using R (and friends)”, The American Statistician, vol 72, 호 1, pp 80–88, 2018.\n\n\n[6] \nJ. F. Claerbout 와/과 M. Karrenbach, “Electronic Documents Give Reproducible Research a New Meaning”, in SEG Technical Program Expanded Abstracts, New Orleans, Louisiana: Society of Exploration Geophysicists, 1992, pp 601–604. doi: 10.1190/1.1822162.\n\n\n[7] \nR. Gentleman 와/과 D. Temple Lang, “Statistical Analyses and Reproducible Research”, Bioconductor Project, Working Paper 2, 5 2004. Available at: https://biostats.bepress.com/bioconductor/paper2/\n\n\n\n[8] \nK. Bollen, J. T. Cacioppo, R. M. Kaplan, J. A. Krosnick, J. L. Olds, 와/과 H. Dean, “Social, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science”, National Science Foundation, Directorate for Social, Behavioral,; Economic Sciences, Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation, 2015. Available at: https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf\n\n\n\n[9] \nF. Markowetz, “Five selfish reasons to work reproducibly”, Genome Biology, vol 16, 호 1, p 274, 12 2015, doi: 10.1186/s13059-015-0850-7.\n\n\n[10] \nA. M. Pienta, G. C. Alter, 와/과 J. A. Lyle, “The Enduring Value of Social Science Research: The Use and Reuse of Primary Research Data”, in The Organisation, Economics and Policy of Scientific Research Workshop, Torino, Italy, 2010. Available at: https://deepblue.lib.umich.edu/handle/2027.42/78307\n\n\n\n[11] \nE. C. McKiernan 기타, “How open science helps researchers succeed”, eLife, vol 5, p e16800, 2016, doi: 10.7554/eLife.16800.\n\n\n[12] \nH. A. Piwowar, R. S. Day, 와/과 D. B. Fridsma, “Sharing Detailed Research Data Is Associated with Increased Citation Rate”, PLoS ONE, vol 2, 호 3, p e308, 3 2007, doi: 10.1371/journal.pone.0000308.\n\n\n[13] \nH. A. Piwowar 와/과 T. J. Vision, “Data reuse and the open data citation advantage”, PeerJ, vol 1, p e175, 2013, doi: 10.7717/peerj.175.\n\n\n[14] \nG. Wilson, J. Bryan, K. Cranston, J. Kitzes, L. Nederbragt, 와/과 T. K. Teal, “Good enough practices in scientific computing”, PLOS Computational Biology, vol 13, 호 6, p e1005510, 2017, doi: 10.1371/journal.pcbi.1005510.\n\n\n[15] \nT. Kluyver 기타, “Jupyter Notebooks – a publishing format for reproducible computational workflows”, in Positioning and Power in Academic Publishing: Players, Agents and Agendas, IOS Press, 2016, pp 87–90. doi: 10.3233/978-1-61499-649-1-87.\n\n\n[16] \nA. Rule 기타, “Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks”, PLOS Computational Biology, vol 15, 호 7, p e1007007, 2019, doi: 10.1371/journal.pcbi.1007007.\n\n\n[17] \nJ. F. Pimentel, L. Murta, V. Braganholo, 와/과 J. Freire, “A Large-scale Study about Quality and Reproducibility of Jupyter Notebooks”, in Proceedings of the 16th International Conference on Mining Software Repositories (MSR), IEEE, 2019, pp 507–517. doi: 10.1109/MSR.2019.00077.\n\n\n[18] \nH. Chen, R. Souza, 기타, “The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science”, Proceedings of the SC ’25 Workshops, 2025, doi: 10.1145/3731599.3767580.\n\n\n[19] \nY. Zhu 기타, “Renaissance of Literate Programming in the Era of LLMs: Enhancing LLM-Based Code Generation in Large-Scale Projects”, arXiv preprint, 2024, Available at: https://arxiv.org/abs/2502.17441\n\n\n\n[20] \nAakanksha, P. Kumari, M. Thakur, 와/과 S. Chakraborty, “Natural Language Outlines for Code: Literate Programming in the LLM Era”, Proceedings of the ACM International Conference on the Foundations of Software Engineering (FSE), 2024, doi: 10.1145/3696630.3728541.\n\n\n[21] \nR. Souza 기타, “Workflow Provenance in the Computing Continuum for Responsible, Trustworthy, and Energy-Efficient AI”, in IEEE International Conference on e-Science, 2024.\n\n\n[22] \nR. Souza 기타, “PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows”, 5th Workshop on Reproducible Workflows, Data Management, and Security, 2024.\n\n\n[23] \nA. H. C. van Kampen 기타, “ENCORE: a practical implementation to improve reproducibility and transparency of computational research”, Nature Communications, vol 15, 호 1, p 8117, 9 2024, doi: 10.1038/s41467-024-52446-8.\n\n\n[24] \nM. Jones, “Introducing Reproducible Research Standards at the World Bank”, Harvard Data Science Review, vol 6, 호 4, 10 2024, doi: 10.1162/99608f92.21328ce3.\n\n\n[25] \nM. D. Wilkinson 기타, “The FAIR Guiding Principles for scientific data management and stewardship”, Scientific Data, vol 3, 호 1, p 160018, 2016, doi: 10.1038/sdata.2016.18.\n\n\n[26] \nV. Stodden, “The Legal Framework for Reproducible Scientific Research: Licensing and Copyright”, Computing in Science & Engineering, vol 11, 호 1, pp 35–40, 2009, doi: 10.1109/MCSE.2009.19.\n\n\n[27] \nM. Klein 기타, “Scholarly Context Not Found: One in Five Articles Suffers from Reference Rot”, PLoS ONE, vol 9, 호 12, p e115253, 2014, doi: 10.1371/journal.pone.0115253.\n\n\n[28] \nThe Turing Way Community, The Turing Way: A handbook for reproducible, ethical and collaborative research. Zenodo, 2024. doi: 10.5281/zenodo.3233853.",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "compendium.html#footnotes",
    "href": "compendium.html#footnotes",
    "title": "36  연구 컴펜디엄",
    "section": "",
    "text": "컴펜디엄(compendium)은 라틴어 compendere(함께 저울질하다)에서 유래했다. 원래 “특정 주제에 관한 정보를 간결하게 모아놓은 모음집”을 의미하며, 중세 학자들이 방대한 지식을 요약한 편람을 지칭할 때 사용했다. 연구 컴펜디엄은 이 전통을 이어받아 “연구의 모든 구성요소를 하나로 모은 패키지”라는 의미로 사용된다.↩︎",
    "crumbs": [
      "**6부** 자동화, 도커, 재현성",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>연구 컴펜디엄</span>"
    ]
  },
  {
    "objectID": "glossary.html",
    "href": "glossary.html",
    "title": "용어사전",
    "section": "",
    "text": "프로그래밍과 컴퓨터 과학에서 사용되는 핵심 용어를 정리한다.\n\n\n\n\n\n\n\n용어\n정의\n\n\n\n\n구문 오류(syntax error)\n프로그래밍 언어의 문법 규칙을 위반했을 때 발생하는 오류. 괄호 누락, 오타, 잘못된 들여쓰기 등이 원인이다. 프로그램 실행 전에 발견된다.\n\n\n구문론(syntax)\n프로그래밍 언어의 문법 규칙. 코드가 어떤 형식으로 작성되어야 하는지를 정의한다.\n\n\n기계어 코드(machine code)\n중앙처리장치(CPU)가 직접 실행할 수 있는 가장 낮은 수준의 프로그래밍 언어. 0과 1의 이진수로 구성된다.\n\n\n논리 오류(logic error)\n문법적으로는 올바르지만 프로그램의 실행 순서나 조건이 잘못되어 의도한 결과가 나오지 않는 오류. 찾기 어려운 경우가 많다.\n\n\n디버깅(debugging)\n프로그램의 오류(버그)를 찾아서 수정하는 과정. 프로그래밍에서 가장 많은 시간이 소요되는 활동 중 하나다.\n\n\n로우레벨 언어(low-level language)\n기계어와 가까운 프로그래밍 언어. 하드웨어를 직접 제어할 수 있지만 사람이 읽고 쓰기 어렵다. 어셈블리 언어가 대표적이다.\n\n\n문제 해결(problem solving)\n문제를 분석하고, 해결 방법을 설계하며, 그 해결책을 구현하는 과정. 프로그래밍의 본질적인 활동이다.\n\n\n버그(bug)\n프로그램의 오류를 일컫는 일반적인 용어. 1947년 하버드 대학의 Mark II 컴퓨터에서 실제 나방(bug)이 발견된 것에서 유래했다는 설이 있다.\n\n\n변수(variable)\n데이터를 저장하는 이름이 붙은 메모리 공간. 프로그램 실행 중에 값을 저장하고 참조하는 데 사용한다.\n\n\n보조 기억장치(secondary memory)\n전원이 꺼져도 데이터를 보존하는 저장 장치. 하드 디스크, SSD, USB 플래시 드라이브 등이 해당한다. 주기억장치보다 속도는 느리지만 용량이 크고 영구적이다.\n\n\n소스 코드(source code)\n프로그래머가 작성한 프로그램의 원본 텍스트. 하이레벨 언어로 작성되며, 사람이 읽고 수정할 수 있다.\n\n\n스크립트(script)\n인터프리터가 실행할 수 있는 명령어들이 저장된 텍스트 파일. 파이썬 스크립트는 .py 확장자를 사용한다.\n\n\n예약어(reserved word)\n프로그래밍 언어에서 특별한 의미를 가지며, 변수명이나 함수명으로 사용할 수 없는 단어. 파이썬의 if, for, def, return 등이 해당한다.\n\n\n의미론(semantics)\n프로그램이나 명령문의 의미. 코드가 실행될 때 어떤 동작을 수행하는지를 나타낸다.\n\n\n의미론적 오류(semantic error)\n문법적으로 올바르고 실행도 되지만, 프로그래머가 의도한 것과 다른 동작을 하는 오류. 프로그램이 “잘못된 일을 올바르게” 수행하는 경우다.\n\n\n이식성(portability)\n프로그램이 다른 컴퓨터 환경에서도 실행될 수 있는 특성. 하이레벨 언어로 작성된 프로그램은 이식성이 높다.\n\n\n인터랙티브 모드(interactive mode)\n프롬프트에서 명령어를 입력하면 즉시 실행 결과를 확인할 수 있는 모드. 파이썬 REPL(Read-Eval-Print Loop)이 대표적이다.\n\n\n인터프리터(interpreter)\n소스 코드를 한 줄씩 읽어서 즉시 실행하는 프로그램. 파이썬, 자바스크립트가 인터프리터 방식을 사용한다. 코드를 바로 실행할 수 있어 개발과 테스트가 편리하다.\n\n\n입출력 장치(input/output device)\n컴퓨터와 외부 세계 간에 데이터를 주고받는 장치. 키보드, 마우스, 모니터, 프린터 등이 해당한다.\n\n\n주기억장치(main memory)\nCPU가 직접 접근하여 데이터를 읽고 쓸 수 있는 고속 저장 장치. RAM(Random Access Memory)이 대표적이며, 전원이 꺼지면 데이터가 사라지는 휘발성 메모리다.\n\n\n중앙처리장치(central processing unit, CPU)\n컴퓨터의 두뇌에 해당하는 핵심 부품. 프로그램의 명령어를 해석하고 실행하며, 연산과 제어를 담당한다. 3.0 GHz CPU는 초당 약 30억 개의 명령어를 처리할 수 있다.\n\n\n출력문(print statement)\n프로그램의 결과를 화면에 표시하는 명령문. 파이썬에서는 print() 함수를 사용한다.\n\n\n컴파일(compile)\n하이레벨 언어로 작성된 소스 코드 전체를 기계어로 번역하는 과정. 컴파일된 프로그램은 실행 속도가 빠르지만, 수정 후 다시 컴파일해야 한다.\n\n\n파싱(parsing)\n소스 코드의 문법 구조를 분석하는 과정. 인터프리터나 컴파일러가 코드를 실행하거나 번역하기 전에 수행한다.\n\n\n프로그램(program)\n컴퓨터가 특정 작업을 수행하도록 작성된 명령어들의 집합. 소프트웨어라고도 부른다.\n\n\n프롬프트(prompt)\n사용자의 입력을 기다리는 상태를 나타내는 기호. 파이썬 인터랙티브 모드에서는 &gt;&gt;&gt;가 프롬프트로 사용된다.\n\n\n하이레벨 언어(high-level language)\n사람이 이해하기 쉽게 설계된 프로그래밍 언어. 파이썬, 자바, C++ 등이 해당한다. 실행 전에 기계어로 번역되어야 한다.",
    "crumbs": [
      "**부록**",
      "용어사전"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "참고문헌",
    "section": "",
    "text": "[1] 이경화, 고등학교 실용통계. 통계청\n통계교육원, 2020.\n\n\n[2] N.\nWiener, “A new theory of measurement: A study in the logic of\nmathematics,” Proceedings of the London Mathematical\nSociety, vol. 2, no. 1, pp. 181–205, 1921.\n\n\n[3] S.\nS. Stevens, “On the theory of scales of measurement,”\nScience, vol. 103, no. 2684, pp. 677–680, 1946.\n\n\n[4] F.\nMarkowetz, “Five selfish reasons to work reproducibly,”\nGenome Biology, vol. 16, no. 1, p. 274, Dec. 2015, doi: 10.1186/s13059-015-0850-7.\n\n\n[5] M.\nBaker, “1,500 scientists lift the lid on reproducibility,”\nNature, vol. 533, no. 7604, pp. 452–454, May 2016, doi: 10.1038/533452a.\n\n\n[6] A.\nVaswani et al., “Attention is all you need,”\nAdvances in neural information processing systems, vol. 30,\n2017.\n\n\n[7] T.\nWu et al., “A brief overview of ChatGPT: The history,\nstatus quo and potential future development,” IEEE/CAA\nJournal of Automatica Sinica, vol. 10, no. 5, pp. 1122–1136,\n2023.\n\n\n[8] T.\nChiang, “ChatGPT is a blurry JPEG of the web,” The New\nYorker, vol. 9, p. 2023, 2023.\n\n\n[9] H.\nWickham, M. Çetinkaya-Rundel, and G. Grolemund, R for data\nscience. \" O’Reilly Media, Inc.\", 2023.\n\n\n[10] R.\nGozalo-Brizuela and E. C. Garrido-Merchan, “ChatGPT is not all you\nneed. A state of the art review of large generative AI models,”\narXiv preprint arXiv:2301.04655, 2023.\n\n\n[11] B.\nMarwick, C. Boettiger, and L. Mullen, “Packaging data analytical\nwork reproducibly using r (and friends),” The American\nStatistician, vol. 72, no. 1, pp. 80–88, 2018.\n\n\n[12] E.\nC. McKiernan et al., “How open science helps researchers\nsucceed,” eLife, vol. 5, p. e16800, 2016, doi: 10.7554/eLife.16800.\n\n\n[13] K.\nBollen, J. T. Cacioppo, R. M. Kaplan, J. A. Krosnick, J. L. Olds, and H.\nDean, “Social, behavioral, and economic sciences perspectives on\nrobust and reliable science,” National Science Foundation,\nDirectorate for Social, Behavioral,; Economic Sciences, Report of the\nSubcommittee on Replicability in Science Advisory Committee to the\nNational Science Foundation, 2015. Available: https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf\n\n\n[14] J.\nP. Simmons, L. D. Nelson, and U. Simonsohn, “False-positive\npsychology: Undisclosed flexibility in data collection and analysis\nallows presenting anything as significant,” Psychological\nScience, vol. 22, no. 11, pp. 1359–1366, Nov. 2011, doi: 10.1177/0956797611417632.\n\n\n[15] N.\nL. Kerr, “HARKing: Hypothesizing after the results are\nknown,” Personality and Social Psychology Review, vol.\n2, no. 3, pp. 196–217, 1998, doi: 10.1207/s15327957pspr0203_4.\n\n\n[16] L.\nK. John, G. Loewenstein, and D. Prelec, “Measuring the prevalence\nof questionable research practices with incentives for truth\ntelling,” Psychological Science, vol. 23, no. 5, pp.\n524–532, May 2012, doi: 10.1177/0956797611430953.\n\n\n[17] M.\nD. Wilkinson et al., “The FAIR guiding principles for\nscientific data management and stewardship,” Scientific\nData, vol. 3, no. 1, p. 160018, 2016, doi: 10.1038/sdata.2016.18.\n\n\n[18] R.\nGentleman and D. Temple Lang, “Statistical analyses and\nreproducible research,” Bioconductor Project, Working Paper 2,\nMay 2004. Available: https://biostats.bepress.com/bioconductor/paper2/\n\n\n[19] J.\nF. Claerbout and M. Karrenbach, “Electronic documents give\nreproducible research a new meaning,” in SEG technical\nprogram expanded abstracts, New Orleans, Louisiana: Society of\nExploration Geophysicists, 1992, pp. 601–604. doi: 10.1190/1.1822162.\n\n\n[20] H.\nA. Piwowar, R. S. Day, and D. B. Fridsma, “Sharing detailed\nresearch data is associated with increased citation rate,”\nPLoS ONE, vol. 2, no. 3, p. e308, Mar. 2007, doi: 10.1371/journal.pone.0000308.\n\n\n[21] H.\nA. Piwowar and T. J. Vision, “Data reuse and the open data\ncitation advantage,” PeerJ, vol. 1, p. e175, 2013, doi:\n10.7717/peerj.175.\n\n\n[22] A.\nM. Pienta, G. C. Alter, and J. A. Lyle, “The enduring value of\nsocial science research: The use and reuse of primary research\ndata,” in The organisation, economics and policy of\nscientific research workshop, Torino, Italy, 2010. Available: https://deepblue.lib.umich.edu/handle/2027.42/78307\n\n\n[23] V.\nStodden, “The legal framework for reproducible scientific\nresearch: Licensing and copyright,” Computing in Science\n& Engineering, vol. 11, no. 1, pp. 35–40, 2009, doi: 10.1109/MCSE.2009.19.\n\n\n[24] M.\nKlein et al., “Scholarly context not found: One in five\narticles suffers from reference rot,” PLoS ONE, vol. 9,\nno. 12, p. e115253, 2014, doi: 10.1371/journal.pone.0115253.\n\n\n[25] A.\nH. C. van Kampen et al., “ENCORE: A\npractical implementation to improve reproducibility and transparency of\ncomputational research,” Nature Communications, vol. 15,\nno. 1, p. 8117, Sep. 2024, doi: 10.1038/s41467-024-52446-8.\n\n\n[26] The Turing Way Community, The turing way: A\nhandbook for reproducible, ethical and collaborative research.\nZenodo, 2024. doi: 10.5281/zenodo.3233853.\n\n\n[27] M.\nJones, “Introducing reproducible research standards at the world\nbank,” Harvard Data Science Review, vol. 6, no. 4, Oct.\n2024, doi: 10.1162/99608f92.21328ce3.\n\n\n[28] G.\nWilson, J. Bryan, K. Cranston, J. Kitzes, L. Nederbragt, and T. K. Teal,\n“Good enough practices in scientific computing,” PLOS\nComputational Biology, vol. 13, no. 6, p. e1005510, 2017, doi: 10.1371/journal.pcbi.1005510.\n\n\n[29] A.\nRule et al., “Ten simple rules for writing and sharing\ncomputational analyses in jupyter notebooks,” PLOS\nComputational Biology, vol. 15, no. 7, p. e1007007, 2019, doi: 10.1371/journal.pcbi.1007007.\n\n\n[30] J.\nF. Pimentel, L. Murta, V. Braganholo, and J. Freire, “A\nlarge-scale study about quality and reproducibility of jupyter\nnotebooks,” in Proceedings of the 16th international\nconference on mining software repositories (MSR), IEEE, 2019, pp.\n507–517. doi: 10.1109/MSR.2019.00077.\n\n\n[31] T.\nKluyver et al., “Jupyter notebooks – a publishing format\nfor reproducible computational workflows,” in Positioning and\npower in academic publishing: Players, agents and agendas, IOS\nPress, 2016, pp. 87–90. doi: 10.3233/978-1-61499-649-1-87.\n\n\n[32] Aakanksha, P. Kumari, M. Thakur, and S.\nChakraborty, “Natural language outlines for code: Literate\nprogramming in the LLM era,” Proceedings of the ACM\nInternational Conference on the Foundations of Software Engineering\n(FSE), 2024, doi: 10.1145/3696630.3728541.\n\n\n[33] Y.\nZhu et al., “Renaissance of literate programming in the\nera of LLMs: Enhancing LLM-based code generation in large-scale\nprojects,” arXiv preprint, 2024, Available: https://arxiv.org/abs/2502.17441\n\n\n[34] R.\nSouza et al., “Workflow provenance in the computing\ncontinuum for responsible, trustworthy, and energy-efficient AI,”\nin IEEE international conference on e-science, 2024.\n\n\n[35] R.\nSouza et al., “PROV-AGENT: Unified provenance for\ntracking AI agent interactions in agentic workflows,” 5th\nWorkshop on Reproducible Workflows, Data Management, and Security,\n2024.\n\n\n[36] H.\nChen, R. Souza, et al., “The (r)evolution of scientific\nworkflows in the agentic AI era: Towards autonomous science,”\nProceedings of the SC ’25 Workshops, 2025, doi: 10.1145/3731599.3767580.",
    "crumbs": [
      "참고문헌"
    ]
  }
]